<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is my first book on data science">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my first book on data science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is my first book on data science" />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-12-11">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-11.html">
<link rel="next" href="section-13.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 数据操作</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 数据读写</a><ul>
<li class="chapter" data-level="6.1.1" data-path="section-6.html"><a href="section-6.html#tibble"><i class="fa fa-check"></i><b>6.1.1</b> 取代传统数据框的<code>tibble</code>对象</a></li>
<li class="chapter" data-level="6.1.2" data-path="section-6.html"><a href="section-6.html#readr"><i class="fa fa-check"></i><b>6.1.2</b> 高效数据读写：<code>readr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 数据整合</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#baseapply"><i class="fa fa-check"></i><b>6.2.1</b> base包：apply()</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#plyrddply"><i class="fa fa-check"></i><b>6.2.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#dplyr"><i class="fa fa-check"></i><b>6.2.3</b> dplyr包</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据整形</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#reshape2"><i class="fa fa-check"></i><b>6.3.1</b> <code>reshape2</code>包</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#tidyr"><i class="fa fa-check"></i><b>6.3.2</b> <code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>6.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 基础建模技术</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="7.3.1" data-path="section-7.html"><a href="section-7.html#section-7.3.1"><i class="fa fa-check"></i><b>7.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="7.3.2" data-path="section-7.html"><a href="section-7.html#section-7.3.2"><i class="fa fa-check"></i><b>7.3.2</b> 重抽样</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#-2"><i class="fa fa-check"></i><b>7.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 模型评估度量</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 回归模型评估度量</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 分类模型评估度量</a><ul>
<li class="chapter" data-level="8.2.1" data-path="section-8.html"><a href="section-8.html#kappa"><i class="fa fa-check"></i><b>8.2.1</b> Kappa统计量</a></li>
<li class="chapter" data-level="8.2.2" data-path="section-8.html"><a href="section-8.html#roc"><i class="fa fa-check"></i><b>8.2.2</b> ROC曲线</a></li>
<li class="chapter" data-level="8.2.3" data-path="section-8.html"><a href="section-8.html#section-8.2.3"><i class="fa fa-check"></i><b>8.2.3</b> 提升图</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#-3"><i class="fa fa-check"></i><b>8.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 特征工程</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 特征构建</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 特征提取</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 初步探索数据</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 主成分分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 探索性因子分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 高维标度化</a></li>
<li class="chapter" data-level="9.2.5" data-path="section-9.html"><a href="section-9.html#section-9.2.5"><i class="fa fa-check"></i><b>9.2.5</b> 知识扩展</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 特征选择</a><ul>
<li class="chapter" data-level="9.3.1" data-path="section-9.html"><a href="section-9.html#section-9.3.1"><i class="fa fa-check"></i><b>9.3.1</b> 过滤法</a></li>
<li class="chapter" data-level="9.3.2" data-path="section-9.html"><a href="section-9.html#section-9.3.2"><i class="fa fa-check"></i><b>9.3.2</b> 绕封法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="10.1.2" data-path="section-10.html"><a href="section-10.html#section-10.1.2"><i class="fa fa-check"></i><b>10.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="10.1.3" data-path="section-10.html"><a href="section-10.html#section-10.1.3"><i class="fa fa-check"></i><b>10.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 收缩方法</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 岭回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.2.2</b> Lasso</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 弹性网络</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.3</b> 知识扩展：Lasso的变量选择功能</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> 主成分和偏最小二乘回归</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 广义线性模型压缩方法</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#glmnet"><i class="fa fa-check"></i><b>11.1</b> 初识<code>glmnet</code></a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 收缩线性回归</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 逻辑回归</a><ul>
<li class="chapter" data-level="11.3.1" data-path="section-11.html"><a href="section-11.html#section-11.3.1"><i class="fa fa-check"></i><b>11.3.1</b> 普通逻辑回归</a></li>
<li class="chapter" data-level="11.3.2" data-path="section-11.html"><a href="section-11.html#section-11.3.2"><i class="fa fa-check"></i><b>11.3.2</b> 收缩逻辑回归</a></li>
<li class="chapter" data-level="11.3.3" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>11.3.3</b> 知识扩展：群组lasso逻辑回归</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="section-11.html"><a href="section-11.html#section-11.4"><i class="fa fa-check"></i><b>11.4</b> 收缩多项回归</a></li>
<li class="chapter" data-level="11.5" data-path="section-11.html"><a href="section-11.html#section-11.5"><i class="fa fa-check"></i><b>11.5</b> 泊松收缩回归</a></li>
<li class="chapter" data-level="11.6" data-path="section-11.html"><a href="section-11.html#-4"><i class="fa fa-check"></i><b>11.6</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 树模型</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#section-12.1"><i class="fa fa-check"></i><b>12.1</b> 分裂准则</a></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#section-12.2"><i class="fa fa-check"></i><b>12.2</b> 树的修剪</a></li>
<li class="chapter" data-level="12.3" data-path="section-12.html"><a href="section-12.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 回归树和决策树</a><ul>
<li class="chapter" data-level="12.3.1" data-path="section-12.html"><a href="section-12.html#section-12.3.1"><i class="fa fa-check"></i><b>12.3.1</b> 回归树</a></li>
<li class="chapter" data-level="12.3.2" data-path="section-12.html"><a href="section-12.html#section-12.3.2"><i class="fa fa-check"></i><b>12.3.2</b> 决策树</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="section-12.html"><a href="section-12.html#section-12.4"><i class="fa fa-check"></i><b>12.4</b> 装袋树</a></li>
<li class="chapter" data-level="12.5" data-path="section-12.html"><a href="section-12.html#section-12.5"><i class="fa fa-check"></i><b>12.5</b> 随机森林</a></li>
<li class="chapter" data-level="12.6" data-path="section-12.html"><a href="section-12.html#section-12.6"><i class="fa fa-check"></i><b>12.6</b> 助推法</a></li>
<li class="chapter" data-level="12.7" data-path="section-12.html"><a href="section-12.html#section-12.7"><i class="fa fa-check"></i><b>12.7</b> 知识扩展：助推法的可加模型框架</a></li>
<li class="chapter" data-level="12.8" data-path="section-12.html"><a href="section-12.html#section-12.8"><i class="fa fa-check"></i><b>12.8</b> 知识扩展：助推树的数学框架</a><ul>
<li class="chapter" data-level="12.8.1" data-path="section-12.html"><a href="section-12.html#section-12.8.1"><i class="fa fa-check"></i><b>12.8.1</b> 数学表达</a></li>
<li class="chapter" data-level="12.8.2" data-path="section-12.html"><a href="section-12.html#section-12.8.2"><i class="fa fa-check"></i><b>12.8.2</b> 梯度助推数值优化</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="section-12.html"><a href="section-12.html#-5"><i class="fa fa-check"></i><b>12.9</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 深度学习</a><ul>
<li class="chapter" data-level="13.1" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>13.1</b> 介绍</a></li>
<li class="chapter" data-level="13.2" data-path="section-13.html"><a href="section-13.html#r"><i class="fa fa-check"></i><b>13.2</b> R中深度学习包</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-12" class="section level1">
<h1><span class="header-section-number">第12章</span> 树模型</h1>
<p>树模型可以用于回归和判别。这类模型常被称为决策和回归树（CART：Classification And Regression Trees），是经典的机器学习算法，也是最广泛使用的工具。和线性模型相比，树模型能够较好的捕捉到非线性关系。</p>
<p>CART可以用来指代广义的树模型，有时也特别指代Breiman最初提出的建立分类回归树的算法<span class="citation">[<a href="#ref-Breiman1984">72</a>]</span>。在Breiman之后又有很多新的算法出现，比如ID3、C4.5和C5.0，这几个都是Ross Quinlan提出的。是C4.5的改进版本，但由于C5.0还没有开源，因此C4.5算法依然非常流行。原始的CART算法只针对二分类的应变量，但是C4.5能处理多分类结果。CART使用Gini系数准则，C4.5使用熵。CART通过复杂性成本模型来对树进行剪枝，通过交互校验来估计参数；C4.5使用的是一个从二项置信区间衍生出的单通算法。在对缺失值的处理上，CART使用的是代理切分。对于每一个切分，模型会计算一系列的备选方案（称为代理切分）。代理切分是指与树中实际切分结果相类似的备选切分方案，如果一个代理切分对原始切分的近似效果良好，那么当原始切分的预测变量有缺失值时，代理切分就可以发挥作用。在实际应用中，树中的每一个切分都可以事先计算一些代理切分。C4.5算法不是直接填充缺失值或寻找替代，而是用概率知识把信息增益率的求解进行一些变化。</p>
<p>不太大的决策树简洁明了，容易解释。但是简单的树表现不一定好，复杂的树（比如之后会讲到的集成方法）效果大为提高，但过程如同黑箱，无法解释。所以建模者需要在解释性和精确性之间进行权衡。之所以称其为“树”当然因为结构有类似之处，只是决策树的方向和真实的树相反，根在上，叶在下。一棵决策树从单个根节点开始划分为几个不同的枝桠，从⽽产生更多的节点,在每个节点都可以决定是不是要继续划分，如果停止则该节点就是叶节点，若继续就是枝节点接着分裂产生下一层新节点。每个⾮叶节点都牵扯到决定接下来选择哪根树枝。叶节点包含 最终“决策”，将该样本归于哪个最终类或者取值。树模型中有如下几个重要的定义：</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/tree.png" alt="男神分类器" />
<p class="caption">男神分类器</p>
</div>
<ul>
<li>分类树：用于预测离散型结果的树</li>
<li>回归树：用于预测连续型结果的树</li>
<li>分裂点：每个非叶节点的处都有一个分裂点用来决定样本的走向（如：年龄&lt;=25；25<年龄<=35；年龄>35）</li>
<li>根节点：最开始的包含所有观测的节点</li>
<li>叶节点（或者终节点）：包含样本的最终“决策”，没有分裂点</li>
<li>节点的度：一个节点含有的子树的个数称为该节点的度；</li>
<li>树的度：一棵树中，最大的节点的度称为树的度；</li>
<li>修剪：移除一些不必要的分裂点的过程，这是和分裂相反的过程</li>
<li>树枝（或子树）：非终节点下的一个完整旁支</li>
<li>亲节点和子节点：亲节点分裂后得到子节点</li>
</ul>
<p>比如上面的简易男神分类器（分类器纯属虚构，如有雷同，纯属巧合）：<strong>长相</strong>是<strong>根节点</strong>同时也是<strong>分裂点</strong>；<strong>年龄</strong>和<strong>经济状况</strong>是分裂点; <strong>长相</strong>这个节点的<strong>度</strong>是2；整棵<strong>树的度</strong>是4；最后<strong>小鲜肉</strong>等所在的那些节点是<strong>终节点</strong>；如果我们将<strong>王XX</strong>那个枝桠移除，就是<strong>修剪</strong>；<strong>长相</strong>是<strong>年龄</strong>和<strong>经济状况</strong>的<strong>亲节点</strong>，反之<strong>年龄</strong>和<strong>经济状况</strong>是<strong>长相</strong>的<strong>子节点</strong>。</p>
<p>树模型和规则模型之所以成为非常流行的建模工具有下面几个原因：</p>
<ol style="list-style-type: decimal">
<li>能处理变量个数相对于观测个数很大情况</li>
<li>对冗余变量具有抗性</li>
<li>小型的树非常容易解释（但一旦树结构复杂或者使用集成方法时模型变得无法解释）</li>
<li>根据它们建立模型时采用的逻辑，它们能有效地处理各种类型的预测变量（稀疏的，偏态的，连续的，分类的，等等），而不需要对这些变量事先进行预处理。此外，这些模型没有任何变量分布的假设，而在回归模型中通常有分布假设</li>
<li>这些模型可以有效地处理缺失值，并内嵌有特征选择的功能，这一点在很多实际建模问题中非常有用</li>
</ol>
<p>单棵树或简单规则模型具有局限性，其中最重要的就是模型不稳定以及预测能力比较差。数据中的微小变动可能会引起树或规则结构的巨大变化。单棵树定义的一系列的矩形区域过于简单，一旦因变量与预测变量之间的关系不能充分地通过矩形子空间来进行表达， 那么树模型和规则模型将产生比其他模型更大的预测误差。为了克服这些缺点，研究者提出了集成模型，它们将许多棵树（或规则）进行组合。集成模型通常具有比单一的树模型好得多的预测表现。我们在之后会做介绍。</p>
<div id="section-12.1" class="section level2">
<h2><span class="header-section-number">12.1</span> 分裂准则</h2>
<p>分裂节点的方式能够极大的影响树的精确度。回归树和分类树所使用的分裂准则非常不同。与回归树一样，分类树的目标是把数据划分为更小、同质性更强的组。在这里同质意味着分裂的节点更纯（即在每个节点有一个类的样本比例很大）。最原始的CART算法使用基尼系数作为分裂准则；ID3、C4.5以及C5.0使用交叉熵，也被称为信息或散度作为标准。下面逐一介绍这三个标准。</p>
<p><strong>Gini系数</strong></p>
<p>基尼（Gini）系数<span class="citation">[<a href="#ref-Breiman1984">72</a>]</span>用来衡量一个集合样本的杂质（我们希望的是更高的纯度，更少的杂质）。对于二分类问题，给定节点的基尼系数定义为：</p>
<p><span class="math display">\[p_{1}(1-p_{1})+p_{2}(1-p_{2})\]</span></p>
<p>其中<span class="math inline">\(p_{1}\)</span>和<span class="math inline">\(p_{2}\)</span>分别为类1、类2的概率。不难看出，当集合样本纯度很高时，某一类概率趋近于0，基尼系数最小。相反，当<span class="math inline">\(p_{1}=p_{2}=0.5\)</span>时基尼系数最大，在这种情况下，节点的纯度最小。我们来看一个例子，假设我们想要判定哪些学生是计算机专业的，下面是用性别这个变量得到的简单分类树结果。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/gini.png" alt="用性别判定计算机专业的学生" />
<p class="caption">用性别判定计算机专业的学生</p>
</div>
<p>现在我们来计算用性别变量划分对应的Gini系数：</p>
<ol style="list-style-type: decimal">
<li>计算女生对应的Gini系数=<span class="math inline">\(\frac{1}{6}\times\frac{5}{6}+\frac{5}{6}\times\frac{1}{6}=\frac{5}{18}\)</span></li>
<li>计算男生对应的Gini系数=<span class="math inline">\(0\times1+1\times 0=0\)</span></li>
</ol>
<p>可以用如下加权计算性别这个分裂总体的Gini系数：</p>
<p><span class="math display">\[\frac{3}{5}\times\frac{5}{18}+\frac{2}{5}\times 0=\frac{1}{6}\]</span></p>
<p>亲节点中50个观测的Gini系数是：<span class="math inline">\(\frac{1}{2}\)</span>。很容易得出，经过性别这个分裂点后Gini系数从原来的<span class="math inline">\(\frac{1}{2}\)</span>降至<span class="math inline">\(\frac{1}{6}\)</span>，该分裂点对降低Gini的贡献就是<span class="math inline">\(\frac{1}{3}\)</span>。算法会选择对Gini系数减小最有效的的分裂。</p>
<p><strong>信息增益</strong></p>
<p>看下面二分类问题中三个节点内的样本，哪个最容易描述？显然是C，因为C中所有的样本都是一类的，这样描述起来需要的信息最少。相反B需要更多的信息，A需要的信息最多。换句话说，C的纯度最高，B次之，A的纯度最差。我们可以这么说，纯度更高的节点描述起来需要的信息更少。反之，纯度更低的节点描述起来需要的信息更多。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/infogain.png" />

</div>
<p>信息理论就是为了衡量系统的无序度的，无序的度量也叫做熵。如果某个节点对应的样本全都是一类（如C）,其熵就是0。如果某个节点中各类样本比例是50%－50%，那么熵就是1。熵自然是越小越好。</p>
<p>熵（Entropy）的计算公式如下：</p>
<p><span class="math display">\[Entropy=-plog_{2}p-(1-p)log_{2}(1-p)\]</span></p>
<p>这里p是其中一类样本的比例。熵也能用来分裂分类树节点。其选择和亲节点以及其它分裂点相比熵最小的那个分裂。计算某个分裂的熵也是对每个分裂后子节点熵的加权平均。比如之前对50个学生的分类树：</p>
<ul>
<li>亲节点中50个学生对应的熵是：<span class="math inline">\(-\frac{25}{50}log_{2}\frac{25}{50}-\frac{25}{50}log_{2}\frac{25}{50}=1\)</span>，这里1表明节点纯度是最低的，也就是各类样本占一半。</li>
<li>对应性别这个分裂的熵计算分为3步：
<ol style="list-style-type: decimal">
<li>女生对应的熵：<span class="math inline">\(-\frac{5}{30}log_{2}\frac{5}{30}-\frac{25}{30}log_{2}\frac{25}{30}=0.65\)</span></li>
<li>男生对应的熵为0，因为<span class="math inline">\(p=1\)</span></li>
<li>性别这个分裂对应的熵为上述两个的加权平均：<span class="math inline">\(\frac{3}{5}\times 0.65+\frac{2}{5}\times 0=0.39\)</span></li>
</ol></li>
</ul>
<p>可以看到，分裂将原先的熵从1降到0.39。</p>
<p><strong>最小化SSE</strong></p>
<p>目前为止我们讨论了对于分类树（离散应变量）情况的分裂准则。下面我们介绍回归树使用的分裂准则。构建回归树有许多不同的准则，其中最古老也最常用的是最小化SSE。对于回归问题，假设要将数据集<span class="math inline">\(S\)</span>分成两组<span class="math inline">\(S_{1}\)</span>和<span class="math inline">\(S_{2}\)</span>，其中<span class="math inline">\(S_{1}\)</span>和<span class="math inline">\(S_{2}\)</span>的选取需要使得整体的误差平方和达到最小：</p>
<p><span class="math display">\[SSE=\Sigma_{i\in S_{1}}(y_{i}-\bar{y}_{1})^{2}+\Sigma_{i\in S_{2}}(y_{i}-\bar{y}_{2})^{2}\]</span></p>
<p>式中<span class="math inline">\(\bar{y}_{1}\)</span>和<span class="math inline">\(\bar{y}_{1}\)</span>是<span class="math inline">\(S_{1}\)</span>和<span class="math inline">\(S_{2}\)</span>组内训练集因变量的的平均值。接下来分别在<span class="math inline">\(S_{1}\)</span>和<span class="math inline">\(S_{2}\)</span>中， 模型继续搜索预测变量和切分点，以使得SSE达到最大的缩减。由于回归树的这一过程本质上是递归的切分，因此这种方法也通常称为递归划分。</p>
<p>看看下面这个简单的回归树，对10个学生以性别为分裂点，对身高做回归：</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/var.png" />

</div>
<ol style="list-style-type: decimal">
<li>女生对应身高测量的SSE为：136</li>
<li>男生对应身高测量的SSE为：32</li>
<li>性别这个分裂对应的SSE为这两个SSE之和：168</li>
</ol>
<p>亲节点中10个观测的SSE是：522.9。经过性别这个分裂点后SSE从原来的522.9降至168。</p>
<p>如果还有另外一种可能的分裂方式，用专业来划分，结果如下：</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/var2.png" />

</div>
<p>这种情况下：</p>
<ol style="list-style-type: decimal">
<li>女生对应身高测量的方差为：184</li>
<li>男生对应身高测量方差为：302.8</li>
<li>专业这个分裂对应的方差为之前两个方差的加权和：486.8</li>
</ol>
<p>比较性别和专业两个不同的分裂，之前性别这个分裂点将SSE从原来的522.9降至168；专业这个分裂点将SSE降至486.8。如果用最小化SSE准则，应该选择使用性别为分裂点。</p>
<p>上面提到的这三种分裂准则是建立树模型的基础。</p>
</div>
<div id="section-12.2" class="section level2">
<h2><span class="header-section-number">12.2</span> 树的修剪</h2>
<p>树模型面对的主要挑战是过度拟合。假设我们对决策树的参数没有任何限制，那么得到的树模型在训练集上的准确度将会是100%，因为每个终结点将只对应一个样本。因此，防止过度拟合是创建树模型的关键所在。总的说来可以通过下面两种方法来实现这一点：</p>
<ol style="list-style-type: decimal">
<li>对树的大小进行限制</li>
<li>对树进行修剪</li>
</ol>
<p>现在我们对上面两点逐一展开。</p>
<p><strong>限制树的大小</strong></p>
<p>可以通过一些参数来限制树的大小。</p>
<ul>
<li>每个节点处的最小样本量：通过定义节点处的最小样本量可以防止终结点只有一个样本的情况。这里样本量的设置可以作为调优参数。如果设置的样本量太大，那么会导致拟合不足，如果样本量太小，又会过度拟合。在严重类失衡的情况下，最小样本量的设置可能需要小一些，因为某一类样本本身数目就很少。</li>
<li>最大树深度：如果树生长的过深，那么模型就会过度拟合特定的样本。这也是一个需要调优的参数。</li>
<li>最大终结点数目：对终结点数目的限制和对树深度的限制是类似的，可以取代使用。因为这两者是成正比的。 每个分裂考虑的变量个数：在每一层级寻找最优分裂点的时候使用的变量是随机抽取的。通常情况下，取变量个数的平方根效果最好，这也是R种函数的默认设置。但我们还是应该对该参数在变量个数的30%~40%区间内调优。</li>
</ul>
<p>另外一种方法是先让树充分生长，然后再回过头移除一些不显著的树枝，以回到一个较小的深度。背后原理是先让树在训练集上过度拟合，然后通过测试集对树进行调整以校正过度拟合，这里树模型在测试集上的表现代表了其在新样本上的表现。下面介绍实现这一目的几种常见方法。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/prunetree.png" />

</div>
<ul>
<li>代价-复杂度调优</li>
</ul>
<p>Breiman等的论文中采用的剪枝过程称为代价-复杂度调优<span class="citation">[<a href="#ref-Breiman1984">72</a>]</span>。这是针对回归问题的修剪方法。也就是在原来SSE的基础上加上一个关于终节点数目的罚函数，通过一个调优参数控制罚函数的权重：</p>
<p><span class="math display">\[SSE_{c_{p}}=SSE+c_{p}\times 终节点数目\]</span></p>
<p>其中<span class="math inline">\(c_{p}\)</span>被称为复杂度参数。该方法对于一个给定的<span class="math inline">\(c_{p}\)</span>值，我们希望寻找最小的剪枝后的树，以使得惩罚后的误差达到最小。 给定<span class="math inline">\(c_{p}\)</span>的取值时，Breiman等给出了寻找最优树的理论和算法<span class="citation">[<a href="#ref-Breiman1984">72</a>]</span>。与之前讨论过的收缩方法类似，较小的罚倾向于产生较大的树。<span class="math inline">\(c_{p}\)</span>取值很大时生成的树可能只有一次分裂，甚至根本没有分裂。后一种情况意味着在当前选择的复杂度参数下， 没有任何一个预测变量能充分地解释因变量的变异。</p>
<p>为了找到最优的剪枝树，需要在一系列的<span class="math inline">\(c_{p}\)</span>取值上对数据进行计算， 这一过程会对每一个<span class="math inline">\(c_{p}\)</span>值计算一个 SSE。但我们知道的是，当选择了一个不同的样本时，SSE的数值也会有所变化。为了体现每一个<span class="math inline">\(c_{p}\)</span>取值下 SSE 的变异，Breiman等建议使用类似于第四章中的交叉验证方法<span class="citation">[<a href="#ref-Breiman1984">72</a>]</span>。他们还提出了一倍标准差准则作为优化准则，来给出最简单的树：在一倍的标准差之内，找到最简单的使得绝对误差最小的树。另外一些方法则是选择使得数值上误差达到最小的树尺寸<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>。</p>
<ul>
<li>降低误判率修剪</li>
</ul>
<p>该修剪方法最早由Quinlan提出<span class="citation">[<a href="#ref-Quinlan1999">74</a>]</span>。这是最容易理解的修剪方法。树的所有分裂点都纳入修剪的候选名单，对某个分裂点进行修剪意味着将该分裂点下的整个子树都去掉，将该节点设置为叶节点（或者终节点）。这里数据集将被分成3个子集：</p>
<p>（1）用于训练完整的树；</p>
<p>（2）用于修剪；</p>
<p>（3）用于测试最终模型。</p>
<p>如果对某个节点修剪后的的树在第（2）个子集上得到的准确度不小于原来完整的树在（2）上的精确度，那么就将该节点设置为叶节点。否则保留该节点。该算法的好处在于计算上较简单。当子集（2）的样本量比用于训练的子集（1）小很多时，该方法存在过度修剪的风险。许多研究人员发现，这类基于判别误差的修剪方法得到的模型准确度比那些基于树大小得到的模型高<span class="citation">[<a href="#ref-Espoito1997">75</a>]</span>。</p>
<ul>
<li>误判率-复杂度修剪</li>
</ul>
<p>由于每个分裂节点对降低误判率有潜在的作用，但节点越多，意味着树越复杂。该方法就是在这两者之间权衡。假设某个分裂节点<span class="math inline">\(t\)</span>，该节点对应的整个子树为<span class="math inline">\(T\)</span>。该节点修剪后在降低误判率上的损失可以用下面的<strong>误判率损失</strong>衡量：</p>
<p><span class="math display">\[R(t)=r(t)\times p(t)\]</span></p>
<p>其中<span class="math inline">\(r(t)\)</span>是某个节点的误判率：</p>
<p><span class="math display">\[r(t)=\frac{该节点下误判样本的数目}{该节点下所有样本的数目}\]</span></p>
<p><span class="math inline">\(p(t)\)</span>是该节点样本占总样本的比例：</p>
<p><span class="math display">\[p(t)=\frac{该节点的样本数目}{总体样本数目}\]</span></p>
<p>根植于节点<span class="math inline">\(t\)</span>的子树<span class="math inline">\(T\)</span>对应的误判率损失是：</p>
<p><span class="math display">\[R(T)=\Sigma_{i是子树T的叶节点}R(i)\]</span></p>
<p>该节点对应的误判率-复杂度定义为：</p>
<p><span class="math display">\[a(t)=\frac{R(t)-R(T)_{t}}{子树T的叶节点数目-1}\]</span></p>
<p><span class="math inline">\(a(t)\)</span>可以看成是子树<span class="math inline">\(T\)</span>对应价值的衡量。基于上面介绍的一些度量，该修剪过程大致如下<span class="citation">[<a href="#ref-Nikita2012">76</a>]</span>：</p>
<ol style="list-style-type: decimal">
<li>对每个分裂节点计算对应的价值度量<span class="math inline">\(a\)</span></li>
<li>剪去价值最低的节点</li>
<li>不断重复上面的过程，每次都产生一棵修剪后的树，这些树组成“森林”</li>
<li>在这片森林中选出精确度最高的树</li>
</ol>
<ul>
<li>最小化误判率修剪</li>
</ul>
<p>该方法由Niblett和Brotko在1991年提出<span class="citation">[<a href="#ref-Cestnik1991">77</a>]</span>。这是一个自下而上的过程，目的在于寻找能够最小化模型在新数据上预期误判率的树。对于某个分裂点t，如果该节点修剪成叶节点后，其下所有的样本都被预测为c类，那么该节点对应的修剪预期误判率为：</p>
<p><span class="math display">\[E(t)=\frac{n_{t}-n_{t,c}+k-1}{n_{t}+k}\]</span></p>
<p>其中：</p>
<p><span class="math display">\[k=类别数目\]</span> <span class="math display">\[n_{t}=节点t的样本总数\]</span> <span class="math display">\[n_{t,c}=节点t下c类样本的数目\]</span></p>
<p>基于上述定义，该修剪算法过程如下<span class="citation">[<a href="#ref-Espoito1997">75</a>]</span>：</p>
<ul>
<li>在树的每个非叶节点处，计算对该节点修剪后的预期误判率</li>
<li>计算如果该节点下的子树未经修剪得到的预期误判率</li>
<li>如果修剪使得预期误判率提高，那不修剪，否则修剪</li>
</ul>
</div>
<div id="section-12.3" class="section level2">
<h2><span class="header-section-number">12.3</span> 回归树和决策树</h2>
<div id="section-12.3.1" class="section level3">
<h3><span class="header-section-number">12.3.1</span> 回归树</h3>
<p>我们现在进一步介绍回归树的构建过程<span class="citation">[<a href="#ref-ISLR15">78</a>]</span>。建立回归树大致分两步：</p>
<ol style="list-style-type: decimal">
<li>将自变量<span class="math inline">\(X_1,X_2,\dots,X_p\)</span>所有可能取值构成的自变量空间划分成<span class="math inline">\(J\)</span>个彼此不重叠的区域：<span class="math inline">\(R_1,R_2,\dots,R_J\)</span></li>
<li>落入某个区域<span class="math inline">\(R_j\)</span>的新样本对应相同的预测值，即训练集中<span class="math inline">\(R_j\)</span>内所有观测的平均</li>
</ol>
<p>一个及其简化的例子，假设我们就用性别划分成两个区域<span class="math inline">\(R_1\)</span>（女）和<span class="math inline">\(R_2\)</span>（男）：</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/var.png" />

</div>
<p>那么，落入<span class="math inline">\(R_1\)</span>的训练集样本均值为163，落入<span class="math inline">\(R_2\)</span>的训练集样本均值为176。那么对新样本，如果是女生，树模型预测的身高就是163，男生则为176。第2步其实很好理解。现在我们更详细的讲解第1步，也就是怎么划分出区域<span class="math inline">\(R_1,R_2,\dots,R_J\)</span>。</p>
<p>理论上说，划分的区域可以是任何形状，但这里为了简化问题便于解释，我们选择将自变量空间划分成高维矩形，或者说高维盒子。对于回归模型划分目标是最小化之前讲过的RSS。考虑所有可能的划分在现实问题中几乎不可能，这和之前特征选择中讲到的穷举法是一个道理，理论上最优但是实际不可操作。所以建造树模型的时候使用的是从上到下（top-down）的贪婪算法——递归二元分割。该方法从树的根节点开始逐步向下分割自变量空间。每次分裂都产生2条树枝，所以叫做“二元分割”。之所以说该算法贪婪是因为在建造树过程中的每一步，都只是针对当前情况寻找最优分割方式而没有考虑之后在这之后的分裂。</p>
<p>首先在根节点处选择一个变量<span class="math inline">\(X_j\)</span>和分裂点<span class="math inline">\(s\)</span>，将自变量空间划分成下面两个空间：</p>
<p><span class="math display">\[R_{1}(j, s)=\{X|X_j&lt;s\}\ 和\ R_{2}(j, s)=\{X|X_j\geq s\}\]</span> 计算相应分裂后RSS的减少量。对不同的<span class="math inline">\((j,s)\)</span>搜索能最大程度减少RSS的组合，也就是最小化下面式子：</p>
<p><span class="math display">\[\Sigma_{i:x_i\in R_1(j,s)}(y_i-\hat{y}_{R_{1}})^2+\Sigma_{i:x_i\in R_2(j,s)}(y_i-\hat{y}_{R_{2}})^2\]</span> 其中<span class="math inline">\(\hat{y}_{R_1}\)</span>是<span class="math inline">\(R_1\)</span>中训练样本的应变量均值，<span class="math inline">\(\hat{y}_{R_2}\)</span>是<span class="math inline">\(R_2\)</span>中训练样本的应变量均值。优化上面的式子很容易，尤其当<span class="math inline">\(p\)</span>不是很大的时候。</p>
<p>接下来就在这两个生成的子区域中按照同样的方式继续寻找最优化该区域RSS的分裂。注意这里只在新的子区域内优化。这个过程一直延续到满足设定的停止准则，比如区域内的样本量少于5，或者RSS降低的百分比小于1%。大家可以脑补下这个动态的过程，节点不断分裂出两个新的子节点直到所有的节点满足停止条件。这就好像一棵树在不断生长。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/grow_tree.png" />

</div>
<p>在R中有好几个包能够用来建造回归树，如<code>ctree</code>、<code>rpart</code>和<code>tree</code>。<code>rpart</code>是广为使用的一个建造单棵树的包，切分方法基于<code>CART</code>，使用<code>rpart()</code>函数，用公式表达法。<code>rpart()</code>有若干调节参数，可以通过<code>rpart.control</code>选项设定。或者你可以使用之前反复讲到的神器<code>caret</code>包的<code>train()</code>函数，通过其为接口调用<code>rpart()</code>函数，方便进行交互校验。 <code>train()</code>在此情况下常用的函数设定的参数是复杂度参数（<code>cp</code>）和最大节点深度（<code>maxdepth</code>）。为了对 <code>CART</code>树的复杂度参数进行调优，<code>train()</code>中的方法选项应该设定为<code>method = &quot;rpart&quot;</code>。为了对最大深度进行调优，方法选项则应为<code>method = &quot;rpart2&quot;</code>：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)
<span class="kw">library</span>(tree)
dat &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)
<span class="co"># 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数</span>
dat &lt;-<span class="st"> </span><span class="kw">subset</span>(dat, store_exp &gt;<span class="st"> </span><span class="dv">0</span> &amp;<span class="st"> </span>online_exp &gt;<span class="st"> </span><span class="dv">0</span>)
<span class="co"># 将10个问卷调查变量当作自变量</span>
trainx &lt;-<span class="st"> </span>dat[, <span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>, <span class="kw">names</span>(dat))]
<span class="co"># 将实体店消费量和在线消费之和当作应变量</span>
<span class="co"># 得到总消费量=实体店消费+在线消费</span>
trainy &lt;-<span class="st"> </span>dat$store_exp +<span class="st"> </span>dat$online_exp
<span class="kw">set.seed</span>(<span class="dv">100</span>)
rpartTune &lt;-<span class="st"> </span><span class="kw">train</span>(trainx, trainy,
                   <span class="dt">method =</span> <span class="st">&quot;rpart2&quot;</span>,
                   <span class="dt">tuneLength =</span> <span class="dv">10</span>,
                   <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>))
<span class="kw">plot</span>(rpartTune)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-251-1.png" width="672" /></p>
<p>最大树的深度大于2貌似RMSE就不再变化了。这里我们就用深度为2来建立树：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpartTree &lt;-<span class="st"> </span><span class="kw">rpart</span>(trainy ~<span class="st"> </span>., <span class="dt">data =</span> trainx, <span class="dt">maxdepth =</span> <span class="dv">2</span>)</code></pre></div>
<p>你可以通过<code>print()</code>查看相应的规则：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(rpartTree)</code></pre></div>
<pre><code>## n= 999 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 999 15812720000  3479.113  
##   2) Q3&lt; 3.5 799  2373688000  1818.720  
##     4) Q5&lt; 1.5 250     3534392   705.193 *
##     5) Q5&gt;=1.5 549  1919009000  2325.791 *
##   3) Q3&gt;=3.5 200  2436211000 10112.380 *</code></pre>
<p>可见，<code>Q3</code>和<code>Q5</code>被最终用来预测总花销。要对<code>rpart</code>生成的树绘制图形，可以使用<code>partykit</code>包先将<code>rpart</code>对象转换成<code>party</code>对象，然后再使用<code>plot()</code>：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(partykit)
rpartTree2 &lt;-<span class="st"> </span><span class="kw">as.party</span>(rpartTree)
<span class="kw">plot</span>(rpartTree2)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-254-1.png" width="672" /></p>
</div>
<div id="section-12.3.2" class="section level3">
<h3><span class="header-section-number">12.3.2</span> 决策树</h3>
<p>决策树和回归树的思想是类似的，目标是把数据划分为更小、同质性更强的组。不同在于应变量是个分类变量而不是数值。这时，预测就不是基于平均而是基于每个类别样本的频数。叶节点的预测值就是落入相应区域训练集样本中频数最高的类别。决策树的分裂准则不是RSS，而是之间介绍的熵（Entropy）或者Gini系数。CART使用Gini系数准则，C4.5使用熵。CART通过复杂性成本模型来对树进行剪枝，通过交互校验来估计参数；C4.5使用的是一个从二项置信区间衍生出的单通算法。在对缺失值的处理上，CART使用的是代理切分。对于每一个切分，模型会计算一系列的备选方案（称为代理切分）。C4.5算法不是直接填充缺失值或寻找替代，而是用概率知识把信息增益率的求解进行一些变化。</p>
<p>当自变量是连续型时，确定最佳分裂点的划分过程很直接。当自变量是分类型时有两种处理方式：</p>
<ol style="list-style-type: decimal">
<li><p>不对分类变量进行变换，每个分类型自变量作为单独的个体输入到模型当中以便模型决定如何对值进行分组或分裂。这时可以对数据做更为动态的分裂，如分裂点一侧有两个或更多的组。为了进行这样的分裂，算法需要对自变量的类别按照某种方式进行排序。</p></li>
<li><p>分类型自变量先被重新编码为二元虚拟变量，这样将类别信息分解成独立信息块。每一个虚拟变量都融入各自的模型中。这样一来评估每个这些新自变量的方法就很简单，因为每个自变量仅有一个分裂点。</p></li>
</ol>
<p>如果某些类对结果有强预测性，第一种方法可能更合适。然而，正如我们后面看到的，该选择会对模型的复杂度和模型性能有显著影响。在接下来的章节，我们将使用上面说的两种方法构建模型，以便评估那种方法更优。从业者需要根据哪一种方法更合适当前的问题来进行选择。</p>
<p>下面我们用不同的方法对服装消费者性别进行判定（这里是分类模型而非回归模型）：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">library</span>(pROC)
dat &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)
<span class="co"># 将10个问卷调查变量当作自变量</span>
trainx1 &lt;-<span class="st"> </span>dat[, <span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>, <span class="kw">names</span>(dat))]
<span class="co"># 将类别也作为自变量</span>
<span class="co"># 这里用两种方法编码分类变量</span>
<span class="co"># trainx1 不对消费者类别进行变换</span>
trainx1$segment &lt;-<span class="st"> </span>dat$segment
<span class="co"># trainx2 中的消费者类别被转化成虚拟变量</span>
dumMod&lt;-<span class="kw">dummyVars</span>(~.,
                  <span class="dt">data=</span>trainx1,
                  <span class="co"># 用原变量名加上因子层级的名称作为新的名义变量名</span>
                  <span class="dt">levelsOnly=</span>F)
trainx2 &lt;-<span class="st"> </span><span class="kw">predict</span>(dumMod,trainx1)
<span class="co"># 性别作为应变量</span>
trainy &lt;-<span class="st"> </span>dat$gender</code></pre></div>
<p>构建分类树的R包也有很多，这里讲主要的<code>rpart</code>包。 <!--有很多R包能构建单棵分类树。主要的包是rpart。如在回归中介绍过的，函数只需要明确模型的形式的公式。
如前面提及到的，经费申请数据有大量的自变量。用程序创建R公式来对分组类进行建模。下面的语句对这些使用数据切分策略生成的自变量拟合CART模型。

> library(rpart)
> cartModel <- rpart(factorForm, data = training[pre2008,])

该函数通过内置的交互校验过程自动构建并且修剪树。Parms是该分类函数的一个重要选项。
可以通过该选项设定几个候选模型训练过程，如结果的先验概率，和分裂的类型(Gini系数或者信息统计量。)这些值应该放在一个列表上【脚注6：16.9小节展示了一个这类参数的例子，其中拟合rpart的过程假设了不同类的错误对应损失不同】。更多的细节见?rpart。此外，选项control 能够定义数值方法（如树深度）。

分类树的模型输出和回归树不同。为了展示这点，我们拟合了一个只有两个变量的小模型：

> rpart(Class ~ NumCI + Weekday, data = training[pre2008,])
--></p>
<p><code>caret</code>包中的<code>train()</code>函数将建立单棵树的一些函数包装起来，我们可以用它来训练树模型。我们分别对分类变量两种编码方法进行建模比较：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
rpartTune1 &lt;-<span class="st"> </span>caret::<span class="kw">train</span>(trainx1, trainy, <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,
                       <span class="dt">tuneLength =</span> <span class="dv">30</span>,
                       <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>, 
                       <span class="co"># 规定了预留数据集以及需要计算那些模型表现度量（如敏感度，特异度和AUC）。</span>
                       <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,
                                                <span class="dt">summaryFunction =</span> twoClassSummary,
                                                <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                                                <span class="dt">savePredictions =</span> <span class="ot">TRUE</span>))
rpartTune1</code></pre></div>
<pre><code>## CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: &#39;Female&#39;, &#39;Male&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 899, 900, 900, 899, 899, 901, ... 
## Resampling results across tuning parameters:
## 
##   cp           ROC        Sens       Spec     
##   0.000000000  0.7005168  0.6498377  0.7062626
##   0.008350085  0.7086874  0.6297727  0.7354040
##   0.016700170  0.6856826  0.5411688  0.8026768
##   0.025050255  0.6801479  0.5106494  0.8496465
##   0.033400340  0.6801479  0.5106494  0.8496465
##   0.041750425  0.6801479  0.5106494  0.8496465
##   0.050100510  0.6801479  0.5106494  0.8496465
##   0.058450595  0.6801479  0.5106494  0.8496465
##   0.066800680  0.6801479  0.5106494  0.8496465
##   0.075150765  0.6801479  0.5106494  0.8496465
##   0.083500850  0.6801479  0.5106494  0.8496465
##   0.091850936  0.6801479  0.5106494  0.8496465
##   0.100201021  0.6801479  0.5106494  0.8496465
##   0.108551106  0.6801479  0.5106494  0.8496465
##   0.116901191  0.6801479  0.5106494  0.8496465
##   0.125251276  0.6801479  0.5106494  0.8496465
##   0.133601361  0.6801479  0.5106494  0.8496465
##   0.141951446  0.6801479  0.5106494  0.8496465
##   0.150301531  0.6801479  0.5106494  0.8496465
##   0.158651616  0.6801479  0.5106494  0.8496465
##   0.167001701  0.6801479  0.5106494  0.8496465
##   0.175351786  0.6801479  0.5106494  0.8496465
##   0.183701871  0.6801479  0.5106494  0.8496465
##   0.192051956  0.6801479  0.5106494  0.8496465
##   0.200402041  0.6801479  0.5106494  0.8496465
##   0.208752126  0.6801479  0.5106494  0.8496465
##   0.217102211  0.6801479  0.5106494  0.8496465
##   0.225452296  0.6553102  0.5427922  0.7678283
##   0.233802381  0.6553102  0.5427922  0.7678283
##   0.242152466  0.5609993  0.7828571  0.3391414
## 
## ROC was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.008350085.</code></pre>
<p>上面是不对分类变量进行编码的情况。这里<code>cp</code>指的是复杂度参数（complexity parameter）。是树生长的停止准则，<code>cp = 0.01</code>意味者相应分裂度量（Gini，熵等）每一步分裂都需要比之前提高0.01，在交互校验结果中不满足0.01提升的部分会被修剪掉。</p>
<p>下面我们接着对将分类变量进行编码后的数据集进行训练：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpartTune2 &lt;-<span class="st"> </span>caret::<span class="kw">train</span>(trainx2, trainy, <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,
                       <span class="dt">tuneLength =</span> <span class="dv">30</span>,
                       <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>, 
                       <span class="co"># 规定了预留数据集以及需要计算那些模型表现度量（如敏感度，特异度和AUC）。</span>
                       <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,
                                                <span class="dt">summaryFunction =</span> twoClassSummary,
                                                <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                                                <span class="dt">savePredictions =</span> <span class="ot">TRUE</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpartRoc &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> rpartTune1$pred$obs,
                <span class="dt">predictor =</span> rpartTune1$pred$Female,
                <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(rpartTune1$pred$obs)))

rpartFactorRoc &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> rpartTune2$pred$obs,
                      <span class="dt">predictor =</span> rpartTune2$pred$Female,
                      <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(rpartTune1$pred$obs)))

<span class="kw">plot</span>(rpartRoc, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>),
     <span class="dt">print.thres.pch =</span> <span class="dv">3</span>,
     <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>,
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>,
     <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>,
     <span class="dt">print.thres.col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = rpartTune1$pred$obs, predictor = rpartTune1$pred$Female,     levels = rev(levels(rpartTune1$pred$obs)))
## 
## Data: rpartTune1$pred$Female in 13380 controls (rpartTune1$pred$obs Male) &lt; 16620 cases (rpartTune1$pred$obs Female).
## Area under the curve: 0.667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rpartFactorRoc,
     <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>,
     <span class="dt">add =</span> <span class="ot">TRUE</span>,
     <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>),
     <span class="dt">print.thres.pch =</span> <span class="dv">16</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>,
     <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>,
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = rpartTune2$pred$obs, predictor = rpartTune2$pred$Female,     levels = rev(levels(rpartTune1$pred$obs)))
## 
## Data: rpartTune2$pred$Female in 13380 controls (rpartTune2$pred$obs Male) &lt; 16620 cases (rpartTune2$pred$obs Female).
## Area under the curve: 0.6547</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">legend</span>(.<span class="dv">75</span>, .<span class="dv">2</span>,
       <span class="kw">c</span>(<span class="st">&quot;Grouped Categories&quot;</span>, <span class="st">&quot;Independent Categories&quot;</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>),
       <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">16</span>, <span class="dv">3</span>))</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-258-1.png" width="672" /></p>
<p>可以看到，对于使用CART构建的树，对消费者类别变量编码或者不编码并不影响对受访者性别做预测。同样也可以通过<code>partykit</code>包对最终的模型绘制图形。这里不展示结果：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(partykit)
<span class="kw">plot</span>(<span class="kw">as.party</span>(rpartTune1$finalModel))</code></pre></div>
<p>单棵树很直观，容易解释。但它有两个缺点：</p>
<ol style="list-style-type: decimal">
<li>和很多回归模型相比精确度差</li>
<li>非常不稳定，数据微小的变化会导致模型结果很大的变化</li>
</ol>
<p>将不同的决策树聚合起来能够解决这两个问题，比如下面要介绍的装袋树，随机森林和助推树就是这样的思想。这些模型的表现和单棵树相比显著提高。</p>
</div>
</div>
<div id="section-12.4" class="section level2">
<h2><span class="header-section-number">12.4</span> 装袋树</h2>
<p>Bootstrap 样本是对数据进行有放回随机抽样得到的样本<span class="citation">[<a href="#ref-Efron1986">79</a>]</span>。这意味着，当一个样本点被选中时，它有可能会在将来的抽取中继续被选中。Bootstrap 样本和原数据的样本量一样。因此，一些样本可能被抽到过很多次，而另一些则可能没有被选到。没有被选到的样本被称为“袋外样本“（out-of-bag）。这在统计学史上是一个看似平淡无奇，但实际上具有突破性意义的思想。在很多难以甚至不可能直接计算标准差的情况下能够用bootstrap来对估计标准差。很长一段时间我并不理解这样一种流氓的方法怎么会大受追捧，这里追捧的人指的不是一般群众，而是象牙塔里那些根正苗红的统计教授。这个方法就像聚宝盆，一直不停的有放回抽样。一个极端的情况，假如你只有1个样本，难道你不停有放回抽样就能得到大样本了？当然不是，这是对该方法的扭曲。bootstrap要在样本量足够多的时候才最有效。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/bootstrap.png" alt="bootstrap示意图" />
<p class="caption">bootstrap示意图</p>
</div>
<p>之前介绍的单棵树最大的问题就是结果不稳定。直观的说，假如你把样本随机分成两部分，用各个子集建造树模型，得到的两棵树可能大相径庭。相反，对于一个稳定的模型，其在这两个数据集上拟合结果应该是很相近的。传统的参数回归模型相对稳定性高，比如线性回归。</p>
<p>在20世纪90年代，集成方法（即将许多模型组合起来进行预测的模型）开始出现。但当样本量n较之于变量个数p而言比较大时，该方法可以作为降低模型方差的一般方法。装袋法（Bagging，bootstrap aggregation 的缩写）最初由 Leo Breiman 提出，它是最早发展起来的集成方法之一（Breiman 1996a）。装袋法是一种利用 bootstrap的通用方法，可用于任何回归（或分类）模型来构建集成组合。</p>
<p>假设n个独立随机变量<span class="math inline">\(Z_1,\dots,Z_n\)</span>，每个的方差是<span class="math inline">\(\sigma^2\)</span>。那么它们的均值<span class="math inline">\(\bar{Z}\)</span>对应的方差为<span class="math inline">\(\frac{\sigma^2}{n}\)</span>。这个统计学中的基本性质大家应该都很熟悉。也就是说，对观测取平均可以减小方差。因此一个很自然的减小模型估计方差，增加模型预测精确度的方法就是让模型作用与不同的训练集，然后将模型结果取平均。假设我们将模型应用于B个训练集，得到估计<span class="math inline">\(\hat{f}^1(x),\hat{f}^2(x)\dots,\hat{f}^B(x)\)</span>，我们可以用：</p>
<p><span class="math display">\[\hat{f}_{avg}(x)=\frac{1}{B}\Sigma^B_{b=1}\hat{f}^b(x)\]</span> 作为最终模型结果。当然这严格说来无法实现，因为我们只有一个训练集。这就是需要bootstrap的地方了。我们将每个bootstrap样本当作训练集合。这种方法的构建非常简单，它包含下面算法中所述的步骤：</p>
<blockquote>
<p><strong>算法：装袋法</strong></p>
<ol style="list-style-type: decimal">
<li>对 i=1 到 B 执行</li>
<li>从原数据中生成bootstrap样本</li>
<li>在生成的bootstrap样本上建立未修剪的树</li>
<li>终止</li>
</ol>
</blockquote>
<p>集成组合中的每一个模型都对新样本进行一次预测，然后将这些预测进行平均。每一次bootstrap重抽样迭代中，选中的样本点被用来建立模型，而袋外样本则被用于预测。对于回归树，装袋法很好理解，就是将不同预测值平均。那么分类树呢？在这种情况下有若干可能的办法。这里讲最简单的一种。对于测试集的某个样本，我们可以记录下每棵树对其判定的类别，这样我们得到B个判定类别，然后取票数最高的那个。很自然，这里树的数目B是一个需要调优的重要参数。</p>
<div class="figure">
<img src="http://scientistcafe.com/book/Figure/bagging.png" alt="装袋树示意图" />
<p class="caption">装袋树示意图</p>
</div>
<p><strong>装袋法的优势</strong></p>
<p>装袋法模型相对于没有装袋的模型具有若干优势。</p>
<p>首先，装袋法通过模型的聚集过程有效地降低了预测的方差。对于那些预测值不稳定的模型，例如回归树，将不同版本的训练集进行聚集，可以减小预测的方差，从而使得预测值更加稳定。假设我们有10个bootstrap样本各自生成了一棵最大深度的树。这些树在结构上有所差异，每棵树对新样本的预测都有所不同。如果将这10棵树的预测结果进行平均作为新样本的预测，那么这一平均值将比单棵树的预测方差更小。这意味着，如果我们产生另一组bootstrap样本，在其中每一个样本上建立一个模型，然后对所有模型的预测值进行平均，那么得到的结果将与前一个装袋模型的结果相类似。</p>
<p>装袋模型比未装袋的模型具有更好的预测效能。如果建模的目标是得到最优的估计而不是解释树的结构，那么装袋法更有优势。对稳定、方差小的模型（如回归，MARS）进行装袋则只会对其预测效能带来较小的改进。在预测结果具有内在的不稳定性的情况下，可以用装袋法进行改进。虽然理论上装袋法不仅限于树模型，但是其对树模型的改进效果最好，尤其是决策树，这就是对症下药。</p>
<p>其次，装袋法模型的另一个优势是它可以提供内在的预测效能估计。因为这里用的是bootstrap过程中剩下的袋外样本，它们并没有参与建模于是扮演着测试集的角色，可以用来评估模型的预测效能。因此，集成组合中的每个模型都可以通过袋外样本计算得到一个预测效能的估计，而对所有袋外效能估计进行平均就能计算出整个集成组合的预测效能。 这一结果通常与交叉验证或测试集验证的结果非常吻合，该误差估计称为袋外估计。平均说来，每棵树大约使用了2/3的样本，另外1/3的样本是袋外数据。这意味着，对于每个样本，在B次抽样中，大约会有B/3次是袋外数据，因而有对应的预测值。让这些预测值投票得到每个样本对应的预测。进一步可以计算所有样本的误差。可以证明当抽样的次数B足够大时，袋外样本误差几乎等价于留一校验误差。</p>
<p>对于基本的装袋法，用户可以选择bootstrap样本的数目。《应用预测模型（Applied Predictive Modeling）》<span class="citation">[<a href="#ref-APM">13</a>]</span>的作者指出， 通常模型的预测效能与迭代次数之间会出现指数递减的关系； 大部分预测效能的提升是由少数几棵树实现的。根据他们的经验，一直到50个bootstrap样本，模型都可能还会有微小的改进，如果迭代了50次代后模型的表现还是不令人满意，那就需要尝试使用其他更强大的集成预测方法，如随机森林和助推。</p>
<p><strong>装袋法的局限</strong></p>
<p>尽管装袋法通常都能改进不稳定模型的预测效能，但它同样有一些缺陷。 首先，是计算量。随着bootstrap 样本数目的增多，计算成本和内存需求也会相应增加。这一劣势可以通过并行计算来得到大部分的消减，原因是装袋的过程是非常容易并行化的。 回顾之前的介绍可以发现，每一个 boostrap 样本和相应的模型都是独立于其他样本和模型的。 这意味着每个模型都可以单独进行建模， 而只需在最后将所有模型的结果组合起来以生成最终的预测。类似能够并行化的还有随机森林模型。但是助推树不能，因为其集成方式不是独立的。</p>
<p>装袋法的另一个劣势在于解释性差，这是所有类似集成模型共同的劣势。通常也被称为黑箱模型。我们无法在装袋法中得到之前单棵回归树给出的简洁且易于描述的规则。然而，变量重要性依旧可以通过将单个模型的重要性得分集合起来得到。比如，我们可以记录有将某个变量用于分裂点的树中其导致RSS的减小，然后在所有的树上取平均。</p>
<p>下面我们展示如何用R建立装袋树，先得到自变量和应变量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">library</span>(pROC)
dat &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;</span>)
<span class="co"># 将10个问卷调查变量当作自变量</span>
trainx &lt;-<span class="st"> </span>dat[, <span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>, <span class="kw">names</span>(dat))]
<span class="co"># 将类别也作为自变量</span>
<span class="co"># 不对消费者类别进行变换</span>
trainx$segment &lt;-<span class="st"> </span>dat$segment
<span class="co"># 性别作为应变量</span>
trainy &lt;-<span class="st"> </span>dat$gender</code></pre></div>
<p>大家可以自己对树的数目进行调优，这里我们用1000棵树：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
bagTune &lt;-<span class="st"> </span>caret::<span class="kw">train</span>(trainx, trainy, 
                           <span class="dt">method =</span> <span class="st">&quot;treebag&quot;</span>,
                           <span class="dt">nbagg =</span> <span class="dv">1000</span>,
                           <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                           <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,
                           <span class="dt">summaryFunction =</span> twoClassSummary,
                           <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                           <span class="dt">savePredictions =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p>调优的结果如下：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bagTune</code></pre></div>
<pre><code>## Bagged CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: &#39;Female&#39;, &#39;Male&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 900, 899, 901, 900, 900, 900, ... 
## Resampling results:
## 
##   ROC        Sens       Spec     
##   0.7016242  0.6642532  0.6522727
## 
## </code></pre>
<p>可以看到，最优的ROC比之前单棵树有所改进。ROC曲线上的最优点，也就是最靠近左上角的点对应敏感度（<code>Sens</code>）为0.66，特异度（<code>Spec</code>）为0.65。这里因为变量的个数并不多，所以改进不那么明显，在变量多的时候装袋树的表现可能远好过单棵树。</p>
</div>
<div id="section-12.5" class="section level2">
<h2><span class="header-section-number">12.5</span> 随机森林</h2>
<p>我们已经知道装袋树使用了boostrap样本，但这些树之间并不是独立的，因为这些树的每个分裂点上都考虑了所有的自变量。可以想象，如果初始的样本量足够大，而且树模型可以充分刻画预测变量与因变量之间的关系，那么不同bootstrap样本生成的树应该具有类似的结构（特别是在树顶部分），因为它们背后的关系是相近的。这一特点被称为树相关性，它会使得装袋法不能最大限度地减少预测值的方差。这说明，装袋法对方差的缩减还可以进一步通过减小树之间的相关性得以提升。对树相关现象的数学解释，可以参见<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>。随机森林就是通过减少树的相关性在装袋树的基础上进行提高的。</p>
<p>从统计的角度来看，要减小预测变量之间的相关性，可以在建立树的过程中引入一定的随机性，使得每一棵树使用的变量有些不同。在Breiman发明装袋法后，有一些其他的作者通过在训练过程中加入随机性来进一步优化模型算法。由于树是装袋法中一个常见的模型，Dietterich<span class="citation">[<a href="#ref-Dietterich2000">80</a>]</span>提出了随机选择切分点的想法，即在树的每一个分裂点处随机选择<span class="math inline">\(m\)</span>个变量来生成树。另一种方法是随机选择变量的子集来构建整棵树<span class="citation">[<a href="#ref-Ho1998">81</a>, <a href="#ref-amit1997">82</a>]</span>。Breiman同样尝试了在响应变量中加入噪声来对树的结构进行扰动<span class="citation">[<a href="#ref-Breiman2000">83</a>]</span>。在对这些各种升级改版的装袋法进行研究之后，Breiman于2001年提出了随机森林<span class="citation">[<a href="#ref-Breiman2001">84</a>]</span>。随机森林建造树的时候，每个分裂处都会从所有<span class="math inline">\(p\)</span>个变量中随机抽取<span class="math inline">\(m\)</span>个，然后在其中选出最优的<strong>一个</strong>变量用于分裂。</p>
<p>通常情况下<span class="math inline">\(m=\sqrt{p}\)</span>。比如这里是10个问卷调查的问题，那么每个分裂点出随机抽取用于候选的变量大约为4。在考虑每个分裂点的时候，算法都会随机挑选新变量，通过这种方式减小树之间的相关性。这对于变量数目多的情况更加有效，这里由于我们一共只有10个变量，大家之后会看到，随机森林算法对结果的改进并不是很明显。这里每次选择变量的个数也是一个调优参数。在数据集合很大变量个数又很多的时候，对该参数调优的过程计算量比较大。这里建议在<span class="math inline">\(m=\sqrt{p}\)</span>附近取5个值先初步调优。森林中树的棵树是另外一个需要调优的参数。由于森林的规模越大，计算量就越大，通常情况下需要至少1000棵树，逐渐增加直到模型的效果没有改进。当模型表现趋于稳定后，增加更多的树没有什么帮助。</p>
<p>一般的基于树的随机森林算法如下：</p>
<blockquote>
<p>基本的随机森林算法</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>选择模型数目B</li>
<li>对 i=1 到 B 执行
<ul>
<li>从原数据中生成一个bootstrap样本</li>
<li>在该样本上训练一个树模型
<ul>
<li>对每个分裂点执行
<ul>
<li>随机抽取m（&lt;p）个预测变量</li>
<li>在这k个变量中选择能用于划分数据的最优变量</li>
</ul></li>
<li>终止</li>
</ul></li>
<li>使用通常的终止树模型的规则决定何时让树停止生长（不要修剪）</li>
</ul></li>
<li>终止</li>
</ol>
<p>随机森林和树的主要不同在于随机抽取m个预测变量。如果<span class="math inline">\(m=p\)</span>，那么随机森林等同于装袋。当我们有大量相关的变量时，通常选择较小的m比较好。下面我们用<code>caret</code>包调优随机森林模型：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 对入选的变量个数参数进行调优</span>
mtryValues &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">5</span>)
<span class="kw">set.seed</span>(<span class="dv">100</span>)
rfTune &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> trainx, 
               <span class="dt">y =</span> trainy,
               <span class="co"># 指定随机森模型</span>
               <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>,
               <span class="dt">ntree =</span> <span class="dv">1000</span>,
               <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">.mtry =</span> mtryValues),
               <span class="dt">importance =</span> <span class="ot">TRUE</span>,
               <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
               <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,
                           <span class="dt">summaryFunction =</span> twoClassSummary,
                           <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                           <span class="dt">savePredictions =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p>随机森林调优结果，在这个例子中，变量的数目不多，随机森林调优过程得到的每次考虑的变量数目是1。最优的曲线下面积和装袋树相比又有所提高但是提高的程度不大：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rfTune</code></pre></div>
<pre><code>## Random Forest 
## 
## 1000 samples
##   11 predictor
##    2 classes: &#39;Female&#39;, &#39;Male&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 899, 900, 900, 899, 899, 901, ... 
## Resampling results across tuning parameters:
## 
##   mtry  ROC        Sens       Spec     
##   1     0.7169190  0.5340584  0.8204545
##   2     0.7136964  0.6333766  0.7174747
##   3     0.7149947  0.6477922  0.6995455
##   4     0.7113993  0.6550325  0.6950000
##   5     0.7092069  0.6514286  0.6882323
## 
## ROC was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 1.</code></pre>
<p>得到调优参数之后也可以通过<code>randomForest</code>包拟合随机森林。由于装袋树只是随机森林的一种特殊情况，所以当你在随机森林函数中设置<span class="math inline">\(mtry=p\)</span>时，就能得到装袋树。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(randomForest)
rfit =<span class="st"> </span><span class="kw">randomForest</span>(trainy ~<span class="st"> </span>., trainx, <span class="dt">mtry =</span> <span class="dv">1</span>, <span class="dt">ntree =</span> <span class="dv">1000</span>)</code></pre></div>
<p>可以通过<code>importance()</code>函数得到变量的重要性：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">importance</span>(rfit)</code></pre></div>
<pre><code>##         MeanDecreaseGini
## Q1              9.403995
## Q2              7.402103
## Q3              8.145370
## Q4             10.976084
## Q5              5.351417
## Q6              9.440028
## Q7              6.341507
## Q8              7.988312
## Q9              5.853341
## Q10             4.017603
## segment        13.228502</code></pre>
<p>这里对于分类的情况，重要性的衡量基于预测袋外数据时基尼系数减小的均值。可以用<code>varImpPlot()</code>函数对重要性绘图：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImpPlot</span>(rfit)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-268-1.png" width="672" /></p>
<p>可以看到，平均考虑所有的树，变量<code>segment</code>和<code>Q4</code>最重要对于区分用户性别最重要。</p>
</div>
<div id="section-12.6" class="section level2">
<h2><span class="header-section-number">12.6</span> 助推法</h2>
<p>助推法最早发明于20世纪80年代<span class="citation">[<a href="#ref-Valiant1984">85</a>, <a href="#ref-KV1989">86</a>]</span>，是用来解决分类问题。其被证明是一种强大的预测工具，被广泛地应用于基因表达<span class="citation">[<a href="#ref-dudoit2002">87</a>, <a href="#ref-ben-dor2000">88</a>]</span>、化学计量学<span class="citation">[<a href="#ref-Varmuza2003">89</a>]</span>、音乐流派识别<span class="citation">[<a href="#ref-Bergstra2006">90</a>]</span>等各个领域中。其大致思想是组合一系列的弱分类器（仅比随机猜测的预测效果好一些的分类器），使总体的误判率有所改进。</p>
<p>研究者花费了一段时间来寻找一种有效实现助推理论的算法，最后终于在1996年，Yoav Freund和Robert Schapire合作提出了自适助推（AdaBoost）算法<span class="citation">[<a href="#ref-Schapire1999">91</a>]</span>，这是Adaptive Boosting的缩写。在自适助推算法的成功问世之后，一些研究者<span class="citation">[<a href="#ref-Friedman2000">92</a>]</span>开始将自适助推算法与一系列的统计学概念联系起来，如损失函数，可加模型，逻辑回归等，并且指出助推法可以被解释为<strong>最小化指数损失的向前逐步可加模型</strong>。这用一个新的视角理解助推法的本质，使得助推法扩展至回归的问题。助推算法有好几种，这里我们介绍两种主要的方法：<strong>自适助推</strong>和<strong>随机梯度助推</strong>。</p>
<ul>
<li>自适助推（AdaBoost）</li>
</ul>
<p>我们从有名的“AdaBoost.M1.”算法开始，其由Yoav Freund和Robert Schapire的<span class="citation">[<a href="#ref-Freund1997">93</a>]</span>提出。该算法考虑二分类问题，应变量编码为<span class="math inline">\(Y \in \{-1, 1\}\)</span>。对于自变量<span class="math inline">\(X\)</span>，对应的分类器<span class="math inline">\(G(X)\)</span>输出的预测值是1或者－1。在训练集样本上的误判率为：</p>
<p><span class="math display">\[\bar{err}=\frac{1}{N}\Sigma_{i=1}^NI(y_i\neq G(x_i))\]</span></p>
<p>对于自适助推生成一系列弱分类器<span class="math inline">\(G_m(x),\ m=1,2,...,M\)</span>，每次迭代，算法都会基于当前样本权重发现最佳的分类器。在第m轮迭代中被误分的样本在m+1轮迭代中将赋予更高的权重，被正确分类的样本在下一轮迭代中权重会降低。这意味着分类困难的样本的权重会不断加大直至算法识别出能正确分类这些样本的模型。因此，该算法要求每轮迭代学习数据的不同方面，着眼于包含难以分类的样本区域。每一次迭代中都会基于误差率计算一个阶段权重。最后的预测是将这些弱分类器通过这些阶段权重进行加权平均：</p>
<p><span class="math display">\[G(x)=sign ( \Sigma_{m=1}^M \alpha_{m}G_m(x))\]</span> 这里<span class="math inline">\(\alpha_1,\alpha_2,...,\alpha_M\)</span>是每个阶段的权重。</p>
<blockquote>
<p>AdaBoost.M1算法</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>一类样本值标记为+1，另一类样本值为-1</li>
<li>每个样本有着相同的起始权重（<span class="math inline">\(w_i=\frac{1}{N},i=1,...,N\)</span>）</li>
<li>对 m = 1到M 执行:
<ul>
<li>用<span class="math inline">\(w_i\)</span>加权后的样本拟合一个弱分类器<span class="math inline">\(G_m(x)\)</span></li>
<li>计算出第M个模型的误判率（<span class="math inline">\(err_m=\frac{\Sigma_{i=1}^Nw_i I(y_i\neq G_m(x_i))}{\Sigma_{i=1}^Nw_i}\)</span>）</li>
<li>计算第m轮迭代的权重值<span class="math inline">\(\alpha_m=ln\frac{1-err_m}{err_m}\)</span></li>
<li>更新样本权重<span class="math inline">\(w_i = w_i\cdot exp[\alpha_m\cdot I(y_i \neq G_m(x_i))],\ i=1,2,\dots,N\)</span></li>
</ul></li>
<li>通过下面方式计算助推分类器对每个样本的预测：<span class="math inline">\(G(x)=sign[\Sigma_{m=1}^M\alpha_mG_m(x)]\)</span>，<span class="math inline">\(sign(\cdot)\)</span>表示如果<span class="math inline">\(\cdot\)</span>是正数，那么将样本判定为+1类，反之为-1类</li>
</ol>
<p>AdaBoost.M1算法也称为“离散AdaBoost”算法，因为迭代产生的分类器<span class="math inline">\(G_m(x)\)</span>返回的是离散的标签，如果分类器返回的是数值，比如一个概率值，可以对上面算法进行适当修改<span class="citation">[<a href="#ref-Friedman2000">92</a>]</span>。助推可应用于任何分类技术，但是分类树是助推的一个常用方法，因为分类树可以通过限制树的深度减少分裂数目制造弱分类器。Breinman<span class="citation">[<a href="#ref-Breiman1998">94</a>]</span>解释了为什么分类树在助推上表现良好。由于分类树是一种低偏差/高方差的技术，树的集合有助于降低方差，产生一个低方差低偏差的结果。助推无法显著改进低方差的模型。因此，助推对诸如LDA或KNN等的改善程度不像其对神经网络<span class="citation">[<a href="#ref-Freund1996">95</a>]</span>和朴素贝叶斯方法那样显著<span class="citation">[<a href="#ref-Bauer1999">96</a>]</span>。</p>
<ul>
<li>随机梯度助推</li>
</ul>
<p>Friedman等<span class="citation">[<a href="#ref-Friedman2000">92</a>]</span>提供了自适助推算法的统计学见解，并且指出助推法可以被解释为<strong>最小化指数损失的向前逐步可加模型</strong>。该框架产生了一些泛化算法，如Real AdaBoost、Gentle AdaBoost和LogitBoost。随后，这些算法被统一放入一个称为<strong>梯度助推器</strong>的框架内。本章最后的知识扩展小节介绍了将助推放在向前逐步可加模型框架内，希望有一定数学基础的小伙伴能花些时间理解背后的基本原理。</p>
<blockquote>
<p>对二分类问题的简单梯度助推</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>设定样本预测初始值为对数发生：</li>
<li>对 j=1到M 执行
<ul>
<li>计算残差（即，梯度）<span class="math inline">\(z_i=y_i-\hat{p}_i\)</span></li>
<li>对训练集随机抽样</li>
<li>基于随机样本，将之前得到的残差作为结果变量训练树模型</li>
</ul></li>
<li>计算终节点Pearson残差的估计：<span class="math inline">\(r_i=\frac{1/n\Sigma_i^n(y_i-\hat{p}_i)}{1/n\Sigma_i^n\hat{p}_i(1-\hat{p}_i)}\)</span></li>
<li>更新当前模型为：<span class="math inline">\(f_i=f_i+\lambda f_i^{(j)}\)</span></li>
<li>结束</li>
</ol>
<p>在回归中，当树模型用作基础的学习器，基本的梯度助推有两个调优参数：树深度（或交互深度）和迭代的次数。随机梯度助推对事件概率建模的公式为，与我们在逻辑回归中见到的类似：</p>
<p><span class="math display">\[\hat{p}_i=\frac{1}{1+exp[-f(x)]}\]</span></p>
<p>上式中，<span class="math inline">\(f(x)\)</span>为在的模型预测值。举例来说，模型的初始估计可能是样本的对数发生比，公式中p为训练集中一个类的样本比例。</p>
<p>使用者可以通过选择合适的损失函数和对应的梯度来使算法更具有针对性<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>。收缩可以在算法最后一步实现。若在该算法第一步内循环前添加一个随机抽样方案，则其可以归入<strong>随机梯度助推</strong>框架。</p>
<p>助推方法在分类问题中变量重要性的计算方式和在回归问题中类似：对于集合中任何一棵树，每个变量带来的分裂准则的改进（对于所有使用该变量的分裂点）的累加得到一个重要性值（这个值是某个变量在某个树上的重要性累加值）。集合内所有树上的重要性值的平均就是相应变量重要性。</p>
<p>自从助推法问世以来一直很受青睐，尤其是在分类问题上，常常被用来当作基础学习器。很多崇尚“拿来主义”的分析师通常将助推树当成一切问题的万精油。目前为止，这个方法在大多数情况下都能够给出合理的结果，虽然并不总是最优的模型。对于那些对模型背景知识不了解，只知道通过使用相应代码实践模型的分析人员，助推树确实是很好的“现成模型”，因为它不需要对数据进行预处理，也不要求你解释变量。但对于想要更近一步的小伙伴们，我建议大家还是努力了解背后的原理，这样一来能够知道在什么场合其它模型可能会给出更好的结果。使用一个你完全不了解的东西不仅仅有风险，也不符合匠人精神。个人认为，模型和分析的美，都在于其背后的原理和思想，而数学只是表达这个思想的一种方式。</p>
<p>下面我们展示如何用R拟合助推树。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbmGrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">interaction.depth =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>),
                       <span class="dt">n.trees =</span> <span class="dv">1</span>:<span class="dv">5</span>,
                       <span class="dt">shrinkage =</span> <span class="kw">c</span>(.<span class="dv">01</span>, .<span class="dv">1</span>),
                       <span class="dt">n.minobsinnode =</span> <span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">10</span>))

<span class="kw">set.seed</span>(<span class="dv">100</span>)
gbmTune &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> trainx, 
                <span class="dt">y =</span> trainy,
                <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>,
                <span class="dt">tuneGrid =</span> gbmGrid,
                <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
                <span class="dt">verbose =</span> <span class="ot">FALSE</span>,
                <span class="dt">trControl =</span> <span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,
                           <span class="dt">summaryFunction =</span> twoClassSummary,
                           <span class="dt">classProbs =</span> <span class="ot">TRUE</span>,
                           <span class="dt">savePredictions =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p>得到的调优结果显示，最优的参数设置是<code>n.trees = 4</code>，<code>interaction.depth = 3</code>，<code>shrinkage = 0.01</code>以及<code>n.minobsinnode = 6</code>。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 由于篇幅所限，这里只展示部分输出</span>
gbmTune</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">...

ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 4, interaction.depth =
 3, shrinkage = 0.01 and n.minobsinnode = 6. </code></pre></div>
<p>我们来比较下各种树模型给出的结果：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">treebagRoc &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> bagTune$pred$obs,
                        <span class="dt">predictor =</span> bagTune$pred$Female,
                        <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(bagTune$pred$obs)))
rfRoc &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> rfTune$pred$obs,
             <span class="dt">predictor =</span> rfTune$pred$Female,
             <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(rfTune$pred$obs)))
gbmRoc &lt;-<span class="st"> </span><span class="kw">roc</span>(<span class="dt">response =</span> gbmTune$pred$obs,
              <span class="dt">predictor =</span> gbmTune$pred$Female,
              <span class="dt">levels =</span> <span class="kw">rev</span>(<span class="kw">levels</span>(gbmTune$pred$obs)))
<span class="kw">plot</span>(rpartRoc, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>),
     <span class="dt">print.thres.pch =</span> <span class="dv">16</span>,
     <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>,
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>,
     <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>,
     <span class="dt">print.thres.col =</span> <span class="st">&quot;black&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = rpartTune1$pred$obs, predictor = rpartTune1$pred$Female,     levels = rev(levels(rpartTune1$pred$obs)))
## 
## Data: rpartTune1$pred$Female in 13380 controls (rpartTune1$pred$obs Male) &lt; 16620 cases (rpartTune1$pred$obs Female).
## Area under the curve: 0.667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(treebagRoc, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>), 
     <span class="dt">print.thres.pch =</span> <span class="dv">3</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>, 
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>,
     <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">print.thres.col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = bagTune$pred$obs, predictor = bagTune$pred$Female,     levels = rev(levels(bagTune$pred$obs)))
## 
## Data: bagTune$pred$Female in 446 controls (bagTune$pred$obs Male) &lt; 554 cases (bagTune$pred$obs Female).
## Area under the curve: 0.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rfRoc, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>), 
     <span class="dt">print.thres.pch =</span> <span class="dv">1</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>, 
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>,
     <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, <span class="dt">print.thres.col =</span> <span class="st">&quot;green&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = rfTune$pred$obs, predictor = rfTune$pred$Female,     levels = rev(levels(rfTune$pred$obs)))
## 
## Data: rfTune$pred$Female in 2230 controls (rfTune$pred$obs Male) &lt; 2770 cases (rfTune$pred$obs Female).
## Area under the curve: 0.7113</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(gbmRoc, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres =</span> <span class="kw">c</span>(.<span class="dv">5</span>), 
     <span class="dt">print.thres.pch =</span> <span class="dv">10</span>, <span class="dt">legacy.axes =</span> <span class="ot">TRUE</span>, <span class="dt">print.thres.pattern =</span> <span class="st">&quot;&quot;</span>, 
     <span class="dt">print.thres.cex =</span> <span class="fl">1.2</span>,
     <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">print.thres.col =</span> <span class="st">&quot;blue&quot;</span>)</code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = gbmTune$pred$obs, predictor = gbmTune$pred$Female,     levels = rev(levels(gbmTune$pred$obs)))
## 
## Data: gbmTune$pred$Female in 223000 controls (gbmTune$pred$obs Male) &lt; 277000 cases (gbmTune$pred$obs Female).
## Area under the curve: 0.69</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">legend</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>,
       <span class="kw">c</span>(<span class="st">&quot;Single Tree&quot;</span>, <span class="st">&quot;Bagged Tree&quot;</span>, <span class="st">&quot;Random Forest&quot;</span>, <span class="st">&quot;Boosted Tree&quot;</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;blue&quot;</span>),
       <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">16</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">10</span>))</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-271-1.png" width="672" /></p>
<p>这里由于数据集中的变量并不多，各个模型的差异并不是那么明显，但是集成方法还是优于单棵树。在很多实际应用中，集成方法通常远好于单棵树。树模型还有一个作用，就是能很快的给你一个模型表现的基准线。也就是说在你刚拿到数据时，可以运行一个随机森林模型看看精确度如何，这可以给你一个大致模型可能表现的概念。之后可以探索不同的模型在此基础上进行精度优化。倘若随机森林给出的模型精度和随机猜测差不多，那你可能需要考虑收集更多的数据，或者重新审视商业问题了。因为在这种情况下，即使你找到更好的模型，精度也未必能够高出太多。这个诀窍可以让你避免很多不必要的模型探索时间。</p>
<p>想要了解助推方法更多理论背景的小伙伴可以花时间阅读知识扩展小节，这些小节要求一定的数学背景。</p>
</div>
<div id="section-12.7" class="section level2">
<h2><span class="header-section-number">12.7</span> 知识扩展：助推法的可加模型框架</h2>
<p>助推法其实没有想象中的那么神秘。如前所述，Friedman<span class="citation">[<a href="#ref-Friedman2000">92</a>]</span>将自适助推算法与一系列的统计学概念联系起来，并且指出助推法可以被解释为<strong>最小化指数损失的向前逐步可加模型</strong>。本小节将介绍可加模型框架下的助推法，理解这一点有助于大家理解该模型的本质。</p>
<p>很多看似不同的模型，其本质都是<strong>基扩展模型</strong>。回顾AdaBoost.M1算法最终得到的分类器：</p>
<p><span class="math display">\[G(x)=sign ( \Sigma_{m=1}^M \alpha_{m}G_m(x))\]</span></p>
<p>其实上面式子就符合基扩展模型：</p>
<p><span class="math display">\[
\begin{equation}
f(x)=\Sigma_{m=1}^M \beta_m b(x,\gamma_m)
\label{eq:basisexp}
\end{equation}
\]</span> 其中<span class="math inline">\(\beta_m,\ m=1,\dots,M\)</span>是扩展系数，<span class="math inline">\(b(x,\gamma)\in \mathbb{R}\)</span>就是基函数，通常是x的函数，其中<span class="math inline">\(\gamma\)</span>是定义函数的参数。很多常见的方法都可以表达为这种基扩展模型的形式，由于篇幅所限，本书并没有讲到所有的方法，这里列举几个这类模型，感兴趣的小伙伴可以参考相关资料：</p>
<ul>
<li>对于单层级神经网络（可参考<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>的第11章），<span class="math inline">\(b(x;\gamma)=\sigma(\gamma_0+\mathbf{\gamma_1^{T}x})\)</span>，其中<span class="math inline">\(\sigma(t)=\frac{1}{1+e^{-t}}\)</span>是一个S型曲线函数，<span class="math inline">\(\mathbf{\gamma}\)</span>是自变量<span class="math inline">\(\mathbf{x}\)</span>线性组合的参数。</li>
<li>多元自适应回归样条（MARS）法中（可参考<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>的9.4小节），其中<span class="math inline">\(b(x;\gamma)=(x_j-\gamma_m)_{+}\)</span>或者<span class="math inline">\(b(x;\gamma)=(\gamma_m-x_j)_{+}\)</span>。</li>
<li>对于树模型，参数<span class="math inline">\(\gamma\)</span>控制了每个节点使用的变量和分裂点，以及最后的总节点的预测。</li>
</ul>
<p>这些模型本质上其实是最小化在训练集样本上的损失函数：</p>
<p><span class="math display">\[\underset{\{\beta_m,\gamma_m\}_i^M}{min}\Sigma_{i=1}^N L\left(y_i,\Sigma_{m=1}^M\beta_{m}b(x_i;\gamma_m)\right)\]</span></p>
<p>对于不同的模型，基础函数<span class="math inline">\(b(x_i;\gamma_m)\)</span>不同，同时损失函数<span class="math inline">\(L(\cdot)\)</span>也有很多不同的选择，比如平方误差，或者基于似然函数的损失函数。不管怎么选择这两个函数，通常情况下在整个训练集样本上最优化上式的计算量都非常大。好消息是，通常问题可以简化为优化单一迭代的损失：</p>
<p><span class="math display">\[\underset{\beta,\gamma}{min}=\Sigma_{i=1}^N L(y_i,\beta b(x_i;\gamma))\]</span></p>
<p>向前逐步可加模型算法可以用来逼近上面优化解，该算法在原基底上迭代加上新的基函数。具体算法如下：</p>
<blockquote>
<p>向前逐步可加模型算法</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>初始化函数<span class="math inline">\(f_0(x)=0\)</span></li>
<li>对于<span class="math inline">\(m=1,\dots,M\)</span>：
<ul>
<li>计算 <span class="math display">\[(\beta_m,\gamma_m)=\underset{\beta,\gamma}{argmin}\Sigma_{i=1}^NL(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))\]</span></li>
<li>设置<span class="math inline">\(f_m(x)=f_{m-1}(x)+\beta_m b(x;\gamma_m)\)</span></li>
</ul></li>
</ol>
<p>在每次迭代m中，算法会在之前基底<span class="math inline">\(f_{m-1}(x)\)</span>上寻找最优的基函数<span class="math inline">\(b(x;\gamma_m)\)</span>和<span class="math inline">\(\beta_m\)</span>，基底加上新的基函数能够最小化损失函数。随后更新得到新的基底<span class="math inline">\(f_m(x)\)</span>。</p>
<p>如果我们使用平方误差损失：</p>
<p><span class="math display">\[L(y,f(x))=(y-f(x))^2\]</span></p>
<p>对应可以得到：</p>
<p><span class="math display">\[L(y_i,f_{m-1}(x_i)+\beta b(x_i;\gamma))=(y_i-f_{m-1}(x_i)-\beta b(x_i;\gamma))^2\]</span></p>
<p>其中<span class="math inline">\(y_i-f_{m-1}(x_i)\)</span>是当前模型下第i个样本对应的残差。也就是说，在平方误差损失下，每一步迭代其实是在拟合之前模型的残差。这也是最小二乘助推回归的基本思想。但平方损失并不是一个好的选择，用于回归问题时容易受离群点的影响，所以我们通常会选择其它损失函数。</p>
<p>类似的，之前的AdaBoost.M1算法是向前逐步可加模型算法取下面损失函数时的一个特例：</p>
<p><span class="math display">\[L(y,f(x))=exp(-yf(x))\]</span></p>
<p>在AdaBoost.M1算法中，基函数是每次迭代得到的分类器<span class="math inline">\(G_m(x)\in \{-1,1\}\)</span>。如果使用上面指数损失函数，相应优化问题为：</p>
<p><span class="math display">\[\begin{array}{ccc}
(\beta_m,G_m) &amp; = &amp; \underset{\beta,G}{argmin}\Sigma_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\beta G(x_i))]\\
&amp; = &amp; \underset{\beta, G}{argmin}\Sigma_{i=1}^N exp[-y_i \beta G(x_i)]\cdot exp[-y_if_{m-1}(x_i)]\\
&amp; = &amp; \underset{\beta, G}{argmin}\Sigma_{i=1}^N w_i^m exp[-y_i\beta G(x_i)]
\end{array}
\]</span></p>
<p>其中<span class="math inline">\(w_i^m= exp[-y_if_{m-1}(x_i)]\)</span>，其并不依赖于<span class="math inline">\(\beta\)</span>和<span class="math inline">\(G(x)\)</span>，因此可以看成对每个观测赋予的权重。该权重和<span class="math inline">\(f_{m-1}(x_i)\)</span>有关，因此每次迭代权重也会相应变化。我们可以进一步分解上面优化函数：</p>
<p><span class="math display">\[\begin{array}{ccc}
(\beta_{m},G_{m}) &amp; = &amp; \underset{\beta,G}{argmin}\Sigma_{i=1}^{N}w_{i}^{m}exp[-y_{i}\beta G(x_{i})]\\
 &amp; = &amp; \underset{\beta,G}{argmin}\Sigma_{i=1}^{N}\left\{ w_{i}^{m}e^{-\beta}I(y_{i}=G(x))+w_{i}^{m}e^{\beta}I(y_{i}\neq G(x))\right\} \\
 &amp; = &amp; \underset{\beta,G}{argmin}\Sigma_{i=1}^{N}\left\{ w_{i}^{m}e^{-\beta}[1-I(y_{i}\neq G(x))]+w_{i}^{m}e^{\beta}I(y_{i}\neq G(x))\right\} \\
 &amp; = &amp; \underset{\beta,G}{argmin}\left\{ (e^{\beta}-e^{-\beta})\cdot\Sigma_{i=1}^{N}w_{i}^{m}I(y_{i}\neq G(x_{i}))+e^{-\beta}\cdot\Sigma_{i=1}^{N}w_{i}^{m}\right\} 
\end{array}\]</span></p>
<p>当<span class="math inline">\(\beta &gt;0\)</span>时，上式的解为：</p>
<p><span class="math display">\[G_{m} = \underset{G}{argmin}\Sigma_{i=1}^{N}w_{i}^{m}I(y_{i}\neq G(x))\]</span></p>
<p>也就是寻找最小化加权误判率的判别器。将上面<span class="math inline">\(G_m\)</span>代入优化函数，对<span class="math inline">\(\beta\)</span>求导设置其为0，可以解出：</p>
<p><span class="math display">\[\beta_m =\frac{1}{2}ln\frac{1-err_m}{err_m}\]</span></p>
<p>其中</p>
<p><span class="math display">\[err_m = \frac{\Sigma_{i=1}^N w_i^{m}I(y_i \neq G_m(x_i))}{\Sigma_{i=1}^N w_i^{m}}\]</span></p>
<p>根据向前逐步可加模型算法，结果更新为：</p>
<p><span class="math display">\[f_m(x)=f_{m-1}(x)+\beta_m G_m(x)\]</span></p>
<p>进而我们可以得到下一次迭代的权重：</p>
<p><span class="math display">\[\begin{array}{ccc}
w_i^{m+1} &amp; = &amp; exp[-y_if_m (x_i)]\\
&amp; = &amp; exp[-y_if_{m-1}(x)-y_i \beta_m G_m(x)]\\
&amp; = &amp; w_{i}^{m}\cdot exp[-\beta_m y_i G_m(x_i)]
\end{array}\]</span></p>
<p>由于<span class="math inline">\(-y_i G_m(x_i)=2\cdot I(y_i \neq G_m(x_i))-1\)</span>，上式可以进一步写为：</p>
<p><span class="math display">\[w_i^{m+1}=w_i^m \cdot exp[\alpha_mI(y_i\neq G_m(x_i))] \cdot exp[-\beta_m]\]</span> 其中<span class="math inline">\(\alpha_m=2\beta_m=ln\frac{1-err_m}{err_m}\)</span>，和之前AdaBoost.M1算法中的<span class="math inline">\(\alpha_m\)</span>一样。因此，AdaBoost.M1算法实际上是向前逐步可加模型算法的一个特例。关于损失函数的选择和比较，大家可以参考<span class="citation">[<a href="#ref-Hastie2008">73</a>]</span>的10.5和10.6小节。</p>
</div>
<div id="section-12.8" class="section level2">
<h2><span class="header-section-number">12.8</span> 知识扩展：助推树的数学框架</h2>
<div id="section-12.8.1" class="section level3">
<h3><span class="header-section-number">12.8.1</span> 数学表达</h3>
<p>之前介绍简单回归和分类树时讲过，建立树的目的是找到自变量区域的划分<span class="math inline">\(R_j,\ j=1,2,\dots,J\)</span>，对每个划分区域内的样本指定一个拟合值<span class="math inline">\(\gamma_j\)</span>：</p>
<p><span class="math display">\[x\in R_j \Rightarrow f(x)=\gamma_j\]</span></p>
<p>树模型可以用如下方式表达：</p>
<p><span class="math display">\[
\begin{equation}
T(x;\Theta)=\Sigma_{j=1}^J\gamma_j I(x\in R_j)
\label{eq:btree}
\end{equation}
\]</span></p>
<p>这里<span class="math inline">\(\Theta=\{R_j,\gamma_j\}_i^J\)</span>。通常将J视为元参数。我们通过最小化下面的损失函数来估计参数：</p>
<p><span class="math display">\[
\begin{equation}
\hat{\Theta}=\underset{\Theta}{argmin}\Sigma_{j=1}^J \Sigma_{x_i\in R_j}L(y_i,\gamma_i)
\label{eq:theta}
\end{equation}\]</span></p>
<p>之前讲过，这个优化几乎不可能实现。我们只能通过某种算法逼近局部最优解。将这个复杂优化问题拆分成两部分可能有助于理解：</p>
<ol style="list-style-type: decimal">
<li><strong>给定<span class="math inline">\(R_j\)</span>的请况下优化<span class="math inline">\(\gamma_j\)</span></strong>：如果给定了<span class="math inline">\(R_j\)</span>，那么估计<span class="math inline">\(\gamma_j\)</span>就是分分钟的事情。对于回归，我们通常取每个区域的训练样本均值<span class="math inline">\(\hat{\gamma}_j=\bar{y}_j\)</span>。对于分类问题，我们就选择对应样本最多的类别。</li>
<li><strong>寻找<span class="math inline">\(R_j\)</span></strong>：这才是真正困难的部分，也是需要设计算法逼近局部最优解的地方。注意在搜索<span class="math inline">\(R_j\)</span>的过程也包含了估计<span class="math inline">\(\gamma_j\)</span>。典型的方法就是我们之前介绍过的从上到下（top-down）的递归贪婪算法。此外，为了逼近<span class="math inline">\(\eqref{eq:theta}\)</span>，我们通常需要选择一个平滑且方便的损失函数来优化<span class="math inline">\(R_j\)</span>：</li>
</ol>
<p><span class="math display">\[\begin{equation}
\tilde{\Theta}=\underset{\Theta}{argmin}\ \Sigma_{i=1}^N\tilde{L}(y_i, T(x_i,\Theta))
\label{eq:ttheta}
\end{equation}\]</span></p>
<p>给定<span class="math inline">\(\hat{R_j}=\tilde{R_j}\)</span>可以得到<span class="math inline">\(\gamma_j\)</span>的估计。这样可能非常抽象，举个例子。对于二分类问题之前讲到过3个用来衡量节点杂合度的度量，它们都可以在这种情境下作为损失函数：</p>
<ol style="list-style-type: decimal">
<li>误判率：<span class="math inline">\(\frac{1}{N_m}\Sigma_{i\in R_m}I(y\neq k(m))=1-\hat{p}_{mk(m)}\)</span>（<span class="math inline">\(k(m)=argmax_k\hat{p}_{mk}\)</span>，也就是节点m中的样本观测频数最多的类）</li>
<li>Gini系数：<span class="math inline">\(\Sigma_{k\neq k^{&#39;}}\hat{p}_{mk}\)</span></li>
<li>熵：<span class="math inline">\(-\Sigma_{k=1}^K \hat{p}_{mk}log(\hat{p}_{mk})\)</span></li>
</ol>
<p>在二分类的情况下，如果<span class="math inline">\(p\)</span>是其中某类样本的比例，对应3个损失函数值分别是：<span class="math inline">\(1-max(p,1-p)\)</span>，<span class="math inline">\(2p(1-p)\)</span>和<span class="math inline">\(-plog(p)-(1-p)log(1-p)\)</span>。可以看到，后两者是连续可导的，这大大方便了优化。所以我们通常使用Gini系数或者熵，而不用误判率来优化。</p>
<p>之前讲过，助推符合基扩展模型<span class="math inline">\(\eqref{eq:basisexp}\)</span>,其是对树的求和：</p>
<p><span class="math display">\[
\begin{equation}
f_M(x)=\Sigma_{m=1}^M T(x;\Theta_m)
\label{eq:btree2}
\end{equation}
\]</span></p>
<p>在向前逐步可加模型算法中的每一步迭代，都在当前模型<span class="math inline">\(f_{m-1}(x)\)</span>的条件下，计算下一棵树对应的<span class="math inline">\(\Theta_m=\{R_{jm}, \gamma_{jm}\}_1^{J_{m}}\)</span>：</p>
<p><span class="math display">\[
\begin{equation}
\hat{\Theta}_m=\underset{\Theta_m}{argmin}\Sigma_{i=1}^N L(y_i, f_{m-1}(x_i)+T(x_i;\Theta_m))
\label{eq:gb}
\end{equation}
\]</span></p>
<p>给定<span class="math inline">\(R_{jm}\)</span>很容易估计<span class="math inline">\(\gamma_{jm}\)</span>：</p>
<p><span class="math display">\[
\begin{equation}
\hat{\gamma}=\underset{\gamma_{jm}}{argmin}\ \Sigma_{x_i\in R_{jm}}L(y_i,f_{m-1}(x_i)+\gamma_{jm})
\label{eq:gamma}
\end{equation}
\]</span> 优化<span class="math inline">\(R_{jm}\)</span>是困难的。对于平方误差损失，<span class="math inline">\(\eqref{eq:gb}\)</span>其实就是对当前残差<span class="math inline">\(y_i-f_{m-1}(x_i)\)</span>拟合回归树，且<span class="math inline">\(\hat{\gamma}_{jm}\)</span>是当前每个区域对应的训练样本均值。</p>
<p>对于使用指数损失的二分类问题，当我们将<span class="math inline">\(T(x;\Theta_m)\)</span>的取值限定在<span class="math inline">\(\{1,-1\}\)</span>上时，我们在前一个知识扩展小节已经证明过，逐步可加算法就是自适助推。用当前的表达就是寻找优化下面加权错误率的树：</p>
<p><span class="math display">\[\Sigma_{i=1}^N\ w_i^m I(y_i\neq T(x_i;\Theta_m))\]</span></p>
<p>其中<span class="math inline">\(w_i^m=e^{-y_if_{m-1}(x_i)}\)</span>，这里应变量的取值被标度化了，即<span class="math inline">\(\gamma_{jm}\in \{-1,1\}\)</span>。这里即使不标度化，在指数损失的情况下<span class="math inline">\(\eqref{eq:gb}\)</span>仍然能够简化成一个对指数加权和的优化：</p>
<p><span class="math display">\[\begin{array}{ccl}
\hat{\Theta}_{m} &amp; = &amp; \underset{\Theta}{argmin}\Sigma_{i=1}^{N}exp\{-y_{i}[f_{m-1}(x_{i})+T(x_{i};\Theta_{m})]\}\\
 &amp; = &amp; \underset{\Theta}{argmin}\Sigma_{i=1}^{N}exp\{-y_{i}f_{m-1}(x_{i})\}\cdot exp\{-y_{i}T(x_{i};\Theta_{m})\}\\
 &amp; = &amp; \underset{\Theta}{argmin}\Sigma_{i=1}^{N}w_{i}^{m}exp\{-y_{i}T(x_{i};\Theta_{m})\}
\end{array}\]</span></p>
<p>使用上面加权指数损失为分裂准则，应用贪婪递归算法，对于每个<span class="math inline">\(R_{jm}\)</span>，<span class="math inline">\(\hat{\gamma}_{jm}\)</span>的估计为：</p>
<p><span class="math display">\[\begin{array}{ccl}
\hat{\gamma}_{jm} &amp; = &amp; \underset{\gamma_{jm}}{argmin}\Sigma_{x_{i}\in R_{jm}}exp\{-y_{i}[f_{m-1}(x_{i})+\gamma_{jm}]\}\\
 &amp; = &amp; \underset{\gamma_{jm}}{argmin}\Sigma_{x_{i}\in R_{jm}}exp\{-y_{i}f_{m-1}(x_{i})\}\cdot exp\{-y_{i}\gamma_{jm}\}\\
 &amp; = &amp; \underset{\gamma_{jm}}{argmin}\Sigma_{x_{i}\in R_{jm}}w_{i}^{m}exp\{-y_{i}\gamma_{jm}\}\\
 &amp; = &amp; \underset{\gamma_{jm}}{argmin}\left\{ \left[\Sigma_{x_{i}\in R_{jm}}w_{i}^{m}I(y_{i}=1)\right]e^{-\gamma_{jm}}+\left[\Sigma_{x_{i}\in R_{jm}}w_{i}^{m}I(y_{i}=-1)\right]e^{\gamma_{jm}}\right\}
\end{array}\]</span></p>
<p>假设<span class="math inline">\(Q(\gamma_{jm})=\left\{ \left[\Sigma_{x_{i}\in R_{jm}}w_{i}^{m}I(y_{i}=1)\right]e^{-\gamma_{jm}}+\left[\Sigma_{x_{i}\in R_{jm}}w_{i}^{m}I(y_{i}=-1)\right]e^{\gamma_{jm}}\right\}\)</span>。通过求解<span class="math inline">\(\frac{\partial Q}{\partial\gamma_{jm}}=0\)</span>可以得到：</p>
<p><span class="math display">\[\hat{\gamma}_{jm}=\frac{1}{2}ln\frac{\Sigma_{x_i\in R_{jm}}w_i^mI(y_i=1)}{\Sigma_{x_i\in R_{jm}}w_i^mI(y_i=-1)}\]</span></p>
<p>对于回归的情况，用Huber损失函数（绝对值损失）取代平方误差损失。对于分类情况，用</p>
<p><span class="math display">\[L(y,p(x))=-\Sigma_{k=1}^K I(Y=G_k)\frac{e^{f_k(x)}}{\Sigma_{l=1}^ke^{f_l(x)}}\]</span> 作为损失函数取代指数损失得到的助推树更加稳定。但是用这些损失函数并不能加速助推算法。对于一般的损失函数，给定<span class="math inline">\(R_{jm}\)</span>的情况下<span class="math inline">\(\eqref{eq:gamma}\)</span>的解只不过是一个给定区域的位置估计，很容易得到。对于绝对值误差，这只不过是每个划分区域内相应样本残差的中位数。对于其它损失函数，也很能有迭代算法很快的得出相应区域的最优<span class="math inline">\(\gamma\)</span>取值。这里困难的依旧是寻找相应的划分区域<span class="math inline">\(R_{jm}\)</span>。对于更加一般的损失函数，没有简单快速的求解<span class="math inline">\(\eqref{eq:gb}\)</span>的算法。因此我们需要用一种尽量逼近解的算法。</p>
</div>
<div id="section-12.8.2" class="section level3">
<h3><span class="header-section-number">12.8.2</span> 梯度助推数值优化</h3>
<p>对于任何可微的损失函数，我们可以用类似于传统梯度优化的方法来逼近<span class="math inline">\(\eqref{eq:gb}\)</span>。假设在训练集上用<span class="math inline">\(f(x)\)</span>来预测变量<span class="math inline">\(y\)</span>，那么需要优化的就是如下损失函数:</p>
<p><span class="math display">\[
\begin{equation}
L(f)=\Sigma_{i=1}^N L(y_i, f(x_i))
\label{eq:generalLf}
\end{equation}
\]</span></p>
<p>我们需要最小化<span class="math inline">\(L(f)\)</span>。在助推树中，<span class="math inline">\(f\)</span>是一系列树的和：</p>
<p><span class="math display">\[f_{M}=\Sigma_{m=0}^M h_m\  h_m\in R^N\]</span></p>
<p>设定一个初始值<span class="math inline">\(f_0=h_0\)</span>，接下来的每一次迭代中的<span class="math inline">\(f_m\)</span>都是基于之前得到的<span class="math inline">\(f_{m-1}\)</span>推导而来。不同的优化逼近的方法的差异就在于计算每一次迭代中的增量<span class="math inline">\(h_m\)</span>。梯度下降法是非常流行的一种优化逼近算法，通常也称为最速下降法。该算法非常贪婪，要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。这里的每一步选择：</p>
<p><span class="math display">\[h_m=-\rho_m g_m\]</span></p>
<p>其中<span class="math inline">\(\rho_m\)</span>是一个标量，<span class="math inline">\(g_m\in R^N\)</span>是损失函数<span class="math inline">\(L(f)\)</span>在当前值<span class="math inline">\(f=f_{m-1}\)</span>时的梯度：</p>
<p><span class="math display">\[
\begin{equation}
g_{im}=\left[\frac{\partial L(y_{i},f(x_{i}))}{\partial f(x_{i})}\right]_{f(x_{i})=f_{m-1}(x_{i})}
\label{eq:gradienm}
\end{equation}
\]</span></p>
<p>每一步乘的标量<span class="math inline">\(\rho_m\)</span>通过如下式子得到：</p>
<p><span class="math display">\[
\begin{equation}
\rho_{m}=\underset{\rho}{argmin}L(f_{m-1}-\rho g_{m})
\label{eq:rhom}
\end{equation}
\]</span></p>
<p>于是当前迭代更新为：</p>
<p><span class="math display">\[
\begin{equation}
f_m=f_{m-1}-\rho_m g_m
\label{eq:fm}
\end{equation}
\]</span></p>
<p>向前逐步助推（在二分类问题中，当使用指数损失且将结果限定在{-1,1}上时就是自适助推）也是一种非常贪婪的算法。每一步迭代都力图最大程度的拟合当前残差。因此该过程可以类比于<span class="math inline">\(\eqref{eq:gradienm}\)</span>。向前逐步助推和梯度助推的主要不同在于，逐步助推中最后组成结果的树是不独立的：</p>
<p><span class="math display">\[t_{m}=\{T(x_{1};\Theta_{m}),\dots,T(x_{N};\Theta_{m})\}^{T}\]</span></p>
<p>这里的<span class="math inline">\(\Theta_{m}=\{R_{jm},\gamma_{jm}\}_{1}^{Jm}\)</span>的估计有个限制，就是终结点的数目是<span class="math inline">\(J_m\)</span>个。而梯度助推没有这样的限定，该方法只是寻找最快速的下降路径。</p>
<p>通过逐步可加算法求解<span class="math inline">\(\eqref{eq:gamma}\)</span>的思想可以类比于通过<span class="math inline">\(\eqref{eq:rhom}\)</span>寻找最快速的下降路径。不同在于<span class="math inline">\(\eqref{eq:gamma}\)</span>是在不同的区域<span class="math inline">\(R_{jm}\)</span>分别搜寻。如果最小化训练集上的损失<span class="math inline">\(\eqref{eq:generalLf}\)</span>是唯一目标的话，梯度下降法是很好的选择。对于任何可微的损失函数<span class="math inline">\(L(y,f(x))\)</span>，梯度<span class="math inline">\(\eqref{eq:gradienm}\)</span>都很容易计算。</p>
<p>不幸的是，这里梯度<span class="math inline">\(\eqref{eq:gradienm}\)</span>仅仅在训练集数据上定义，然而我们的最终目标是能够预测新样本。一个解决方法是我们在第m次迭代中建立树<span class="math inline">\(T(x;\Theta_m)\)</span>来拟合基于训练集样本得出的负梯度。这里树的建造使用的是平方误差：</p>
<p><span class="math display">\[
\begin{equation}
\hat{\Theta}_{m}=\underset{\Theta}{argmin}\Sigma_{i=1}^{N}(-g_{im}-T(x_{i};\Theta))^{2}
\label{eq:negradient}
\end{equation}
\]</span></p>
<p>存在能够快速建立最小二乘回归树的算法。这里要特别注意一点，得到树之后我们使用的是推导出的划分区域<span class="math inline">\(R_{jm}\)</span>，之后在该划分区域上继续沿用可加模型算法的思想。虽然<span class="math inline">\(\eqref{eq:negradient}\)</span>得到的划分区域和<span class="math inline">\(\eqref{eq:theta}\)</span>得到的划分区域不同，但通常很相近。下面是一般的梯度助推回归树算法：</p>
<blockquote>
<p>梯度助推回归树</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>设置初始<span class="math inline">\(f_0(x)=\underset{\gamma}{argmin}\Sigma_{i=1}^{N}L(y_{i},\gamma)\)</span></li>
<li>对<span class="math inline">\(m=1\dots M\)</span>：
<ul>
<li>对<span class="math inline">\(i=1\dots N\)</span>，计算<span class="math inline">\(-g_{im}=-\left[\frac{\partial L(y_{i};f(x_{i}))}{\partial f(x_{i})}\right]_{f=f_{m-1}}\)</span></li>
<li>对<span class="math inline">\(-g_{im}\)</span>拟合回归树，得到终结点划分区域<span class="math inline">\(R_{jm},\ j=1,2,\dots,J_m\)</span></li>
<li>对<span class="math inline">\(j=1,2,\dots,J_m\)</span>，计算<span class="math inline">\(\gamma_{jm}=\underset{\gamma}{argmin}\Sigma_{x_{i}\in R_{jm}}L(y_{i},f_{m-1}(x_{i})+\gamma)\)</span></li>
<li>更新<span class="math inline">\(f_{m(x)}=f_{m-1}(x)+\Sigma_{j=1}^{J_{m}}\gamma_{jm}I(x\in R_{jm})\)</span></li>
</ul></li>
<li>输出<span class="math inline">\(\hat{f}(x)=f_M(x)\)</span></li>
</ol>
<p>对于分类的情况算法也类似，只是损失函数不同。如果类别数目<span class="math inline">\(K&gt;2\)</span>，那么在每次迭代m内都需要对各个类别分别建立<span class="math inline">\(K\)</span>棵树，即最后我们会得到<span class="math inline">\(f_{kM},\ k=1,\dots,K\)</span>。</p>
</div>
</div>
<div id="-5" class="section level2">
<h2><span class="header-section-number">12.9</span> 本章总结</h2>
<p>预测建模是数据挖掘的一个重要话题。每个特定的方法都有适用和不适用的时候。但在实际应用中，事先很少知道哪个过程对于给定的问题将表现最好或甚至良好。</p>
<p>工业和商业数据挖掘应用在对学习过程的要求方面往往特别具有挑战性。因为现实情况可能有各种问题。数据集可能很大，所以需要考虑计算量的问题。而且数据通常不那么干净：自变量可能有多种类型，数值，二项以及多分类变量。而且时常发生数据缺失，完整无缺失的数据很少出现。数值型的变量观测常是长尾而且高度有偏的，而且还有离群值。变量的取值范围也不一样。</p>
<p>此外，通常自变量集合中只有很小一部分真正对应变量有预测作用。和模式识别的问题不同，在预测问题中通常无法通过相关应用领域的知识来筛选变量。和应变量无关的预测变量会影响很多模型的表现。如果应用的语境要求模型可解释，比如在市场营销中需要知道具体那些变量如何影响消费者行为，以便营销人员能够采取相应的行动，而不仅仅是预测，这时很多黑箱模型，如神经网络，就无法给出答案。</p>
<p>这些对计算机速度，结果可解释性的要求，以及不干净的数据使得很多模型不能拿来就用。那些“现成”模型指的是不需要数据预处理以及仔细的模型调试就能应用的模型。在所有模型中，树模型最接近“现成”的模型。 树模型可以处理不同类型的变量，对缺失值和离群值也稳健，如果对数值型变量进行单调变换的话不会影响模型拟合结果。由于其内在过程中有对变量进行选择（选择那些能够最优化相应准则的变量，如Gini系数，熵等），即使不能说完全不受冗余变量的影响，至少对无信息变量具有抗性。当树很小的时候可能还好解释，但前所述，单棵树通常非常不稳定，因此广泛使用的是集成方法。这导致模型难以解释（除了能够给出变量重要性排序以外）。总的来说，上面的这些特性使得树模型成为最受欢迎的模型。</p>
<!--
## 其它树话题
-->

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-Breiman1984">
<p>72. al, L.B. et.: Classification and regression trees. Monterey, CA: Wadsworth &amp; Brooks/Cole Advanced Books &amp; Software (1984).</p>
</div>
<div id="ref-Hastie2008">
<p>73. Hastie T, F.J., Tibshirani R: The elements of statistical learning: Data mining, inference and prediction. Springer (2008).</p>
</div>
<div id="ref-Quinlan1999">
<p>74. Quinlan, J.: Simplifying decision trees. International Journal of Human-Computer Studies. 61, (1999).</p>
</div>
<div id="ref-Espoito1997">
<p>75. F. Espoito, D.M., Semeraro, G.: A comparative analysis of methods for pruning decision trees. IEEE Transactions on Pattern Analysis and Machine Intelligence. 19, 476–491 (1997).</p>
</div>
<div id="ref-Nikita2012">
<p>76. Patel, N., Upadhyay, S.: Study of various decision tree pruning methods with their empirical comparison in weka. International Journal of Computer Applications. 60, (2012).</p>
</div>
<div id="ref-Cestnik1991">
<p>77. B. Cestnik, Bratko, I.: Estimating probabilities in tree pruning. EWSL. 138–150 (1991).</p>
</div>
<div id="ref-ISLR15">
<p>78. Gareth James, T.H., Daniela Witten, Tibshirani, R.: An introduction to statistical learning. Springer (2015).</p>
</div>
<div id="ref-Efron1986">
<p>79. B, E., R, T.: Bootstrap methods for standard errors, con- fidence intervals, and other measures of statistical accuracy. Statistical Science. 54–75 (1986).</p>
</div>
<div id="ref-APM">
<p>13. Max Kuhn, K.J.: Applied predictive modeling. Springer (2013).</p>
</div>
<div id="ref-Dietterich2000">
<p>80. T, D.: An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. Machine Learning. 40, 139–158 (2000).</p>
</div>
<div id="ref-Ho1998">
<p>81. T, H.: The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence. 13, 340–354 (1998).</p>
</div>
<div id="ref-amit1997">
<p>82. Y, A., D, G.: Shape quantization and recognition with randomized trees. Neural Computation. 9, 1545–1588 (1997).</p>
</div>
<div id="ref-Breiman2000">
<p>83. L, B.: Randomizing outputs to increase prediction accuracy. Machine Learning. 40, 229–242 (2000).</p>
</div>
<div id="ref-Breiman2001">
<p>84. L, B.: Random forests. Machine Learning. 45, 5–32 (2001).</p>
</div>
<div id="ref-Valiant1984">
<p>85. L, V.: A theory of the learnable. Communications of the ACM. 27, 1134–1142 (1984).</p>
</div>
<div id="ref-KV1989">
<p>86. M, K., L, V.: Cryptographic limitations on learning boolean formulae and finite automata, (1989).</p>
</div>
<div id="ref-dudoit2002">
<p>87. Dudoit S, F.J., T, S.: Comparison of discrimination meth- ods for the classification of tumors using gene expression data. Journal of the American Statistical Association. 97, 77–87 (2002).</p>
</div>
<div id="ref-ben-dor2000">
<p>88. Ben-Dor A, F.N., Bruhn L, Z, Y.: Tissue classification with gene expression profiles. Journal of Computational Biology. 7, 559–583 (2000).</p>
</div>
<div id="ref-Varmuza2003">
<p>89. Varmuza K, H.P., K, F.: Boosting applied to classification of mass spectral data. Journal of Data Science. 1, (2003).</p>
</div>
<div id="ref-Bergstra2006">
<p>90. Bergstra J, E.D., Casagrande N, B, K. ́egl: Aggregate features and adaboost for music classification. Machine Learning. 65, 473–484 (2006).</p>
</div>
<div id="ref-Schapire1999">
<p>91. YFR, S.: Adaptive game playing using multiplicative weights. Games and Economic Behavior. 29, 79–103 (1999).</p>
</div>
<div id="ref-Friedman2000">
<p>92. Friedman J, H.T., R, T.: Additive logistic regression: A statistical view of boosting. Annals of Statistics. 38, 337–374 (2000).</p>
</div>
<div id="ref-Freund1997">
<p>93. Freund, Y., Schapire, R.: A decision-theoretic generalization of online learning and an application to boosting. Journal of Computer and System Sciences. 55, 119–139 (1997).</p>
</div>
<div id="ref-Breiman1998">
<p>94. L, B.: Arcing classifiers. The Annals of Statistics. 26, 123–140 (1998).</p>
</div>
<div id="ref-Freund1996">
<p>95. Y, F., R, S.: Experiments with a new boosting algorithm, (1996).</p>
</div>
<div id="ref-Bauer1999">
<p>96. E, B., R, K.: An empirical comparison of voting classifica- tion algorithms: Bagging, boosting, and variants. Machine Learning. 36, 105–142.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-11.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-13.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/12-shumoxing.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
