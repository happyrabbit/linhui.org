[
["index.html", "数据科学家：R语言 第1章 介绍", " 数据科学家：R语言 林荟 2016-12-11 第1章 介绍 数据科学家目前是北美最热门的职业之一，平均年薪突破10万美元。但数据科学并不是一个低门槛的行业，所有数据科学家都会认同这一点。除了对数学，统计，计算机等相关科学领域的学位要求以外，还要需要相关应用领域的知识。这个职业听起来很酷，但如果你对数据分析没有兴趣的话，你也会觉得这个行业很苦。这里我默认本书的读者都至少是对这个行业有兴趣和激情的。本书的写作对象是那些现在从事数据分析相关行业，或者之后想从事数据分析行业的人，意在为实践者提供数据科学家这门职业的相关信息。读者可以从阅读中了解到数据科学家需要的技能，及背后的“分析哲学”。书中会对部分最常用，有效的模型加以展开。关于模型技术部分，我希望读者有初步统计知识，最好知道线性回归。 数据科学家这个行业的本质是应用。市面上有很多文章，出版物介绍各种数据模型，大多数此类书籍并不能让读者重复书中所述的分析过程，对于书中介绍的知识，读者真正实践起来会遇到很多困难。本书着重在于数据科学的实际应用，让读者能够重复书中的结果，这也用到了统计软件R的自动化报告功能。可能有读者会问，为什么要可重复？根据个人经验，学习数据分析技能最好的方式是实践：动手重复分析的过程，检查分析结果，发现问题后再去查询相关模型的背景技术知识。这一过程得到的学习效果远远超过死磕一本大部头的技术理论书籍。磕了一年之后发现碰到实际问题不知道该用什么工具实践这些书中讲到的模型方法。而且对于新手而言，一开始就直奔艰深的理论，很容易因为困难而失去兴趣最终放弃。本书倡导的是一种循序渐进的启发性教学路径，从实际问题入手，抽丝剥茧进入技术内核。此外，分析师通常需要写很多分析报告，描述分析结果。这样的报告如果可以重复的话将极大提高工作效率。我们会在“数据可视化和结果展示”这一章中对此做更详细的介绍。 本书主要部分将避免过多的数学公式，但难免有例外。我们在一些地方提到方法背后的技术细节是为了帮助读者理解模型的长处和弱点，而非单纯的介绍数理统计知识。这并不意味着这些数理背景知识不重要，相反尽可能多的了解模型背后的数学重要且有意义，为了平衡理论和应用，我们会在有的章中加一些选学小节，用来介绍更多的模型数理背景或给出必要的参考资料来源，如果不感兴趣的读者可以跳过这些小节，不会影响本书主要部分的阅读。书中的每一章都只是冰山一角，我并不试图彻底的介绍模型，而是有选择性的解释其中部分我觉得重要的地方。我会尽量将想要强调的概念和内容在分析数据的过程中体现出来，而不仅仅是数学公式符号表达。想要成为数据科学家，仅靠阅读本书是远远不够的，读者需要进一步查阅书中提到的参考资料，或者选修相关课程。 随着计算机科学的发展，不仅收集存储的数据增加了，分析数据的软件包也不断推陈出新，这极大的降低了应用统计学习方法的壁垒。现在不管会建模的不会建模的，大都听过线性回归，这个经典统计模型可追根溯源至19世纪Legendre和Gauss发表的若干关于最小二乘的论文。现在你要通过最小二乘拟合一个线性模型那就动动指头两秒钟的事情。可在那个计算器都没有的时代，能优化误差平方和这样的东西的大牛都会被认为是火星人。那会美国宪法规定每十年必须进行一次人口普查，1880年排山倒海的普查资料花了8年时间处理分析，一个名叫Herman Hollerith的品学兼优的美国少年跳出来，在1890年发明了一种排序机，利用打孔卡储存资料，再由机器感测卡片，协助人口调查局对统计资料进行自动化制表，结果不出3年就完成了户口普查工作，Herman同学也顺带用这个发明拿个了工程学博士学位。你可能要问，计算能力这么落后那这伙数学家捣鼓出来的方法谁用？天文学家用。线性模型最早用在天文学研究中。研究使用统计方法的，那会绝对是小众边缘群体，全都可以贴上火星制造的标签。然后盼星星盼月亮我们终于在1912年6月等到了图灵这个天才的降临。 若不是图灵这个孩子被性取向拖了后腿，数据科学家这个行业早几十年可能就火了。当然，统计泰斗们也没有闲着，Fisher在1936年提出了线性判别分析。在1940s，又一家喻户晓的经典统计模型——逻辑回归——问世了！在1970s早期，Nelder和Wedderburn发明了广义线性模型这个词，这是一个更大的统计模型框架，它将随机分布函数和系统效应（非随机效应）通过一个连接函数（link function）连起来，之前的线性模型和逻辑回归都是该框架下的特例。到1970s末，可以用来分析数据的方法已经有好些了，但这些方法几乎都是线性模型，因为在那时，拟合非线性关系的计算量相对当时计算机水平来说还是太大了。等到1980s，计算机技术终于发展到可以使用非线性模型了。Breiman, Fridman, Olshen和Stone提出了分类回归树。随后的一些机器学习方法进一步丰富了数据科学家可以使用的工具集。计算机软件的飞速发展使得这些方法模型得以应用在更加广泛的领域，应用涵盖了商业，健康，基因，社会心理学研究和政策分析等等。数据科学家这个行业随着数据量的增加和分析软件的进步不断向前发展。 关于分析软件，本书使用R。选择R语言的原因如下： R免费，且可以在不同操作系统上使用。 R开源、可扩展：它在通用公共许可（General Public License）下发行，在此构架下任何人可以检查修改源程序。含有很多最新的模型。 R有强大图形可视化和自动化报告功能 笔者10年使用R的经验证明无论在学术还是业界，这都是非常有效的工具。 网上有大量的R入门教程，关于用R进行数据分析的书也有好些，所以这里就不重复造轮子，不熟悉R的读者可以先学习相关资料，这里我假设读者已经有一定R语言基础。 本书布局如下，本书第2章，第3章主要介绍数据科学家这个行业和“分析哲学”和数据分析的一般流程。这是非技术的部分，但对于从业者来说非常重要，它帮助你对这个职业设定一个合理的预期。其中会讨论数据科学家需要的技能。之后的章节会对这里提到的部分我觉得重要的技能进一步展开讨论，由于篇幅所限，不可能详细讨论开始这几章中提到的所有技能。第4章开始进入技术部分，本章讲的是分析环节的第一步——数据预处理，这一步虽然不是正式建模，但却是整个分析过程中最耗时的一个环节。这步没有到位将严重影响模型质量。也正是因为预处理重要，所以单独作为一个章节，没有和第5章其它建模技术合并起来。第5章介绍的是一些在建模过程中需要的辅助性的技术以及建模需要注意的问题。第6章到第10章正式介绍各种笔者在从业过程中经常用到的模型。后面几个章节末尾有比较完整的案例，案例放在这些章节是因为其中主要的模型方法是该章节的主题，但些案例都综合性的用到之前提到的许多方法，对读者理解模型应用和建模背后的思路很有帮助。 本书用来展示模型的数据大部分是通过R得到的模拟数据集。为什么用模拟数据而不是真实数据呢？原因如下： 你可以控制数据生成过程，免去了传输下载数据的麻烦。 你可以根据需要改变生成数据的代码，得到新的数据，观察数据变化对模型结果的影响。 对于自己创建的数据，我们知道数据要表达的真实信息，那么就可以评估分析使用的模型的准确性，然后再用于真实数据。 可以通过使用模拟数据在拿到真实数据前准备好代码模板，这样，当你有真实数据时就可以迅速进行分析。 通过重复数据模拟的过程可以加深对模型假设的理解。 同一章后面的代码通常建立在之前代码上，但每章的代码自成系统，也就是说你不需要以其它章节代码运行结果为前提重复某章的代码。有一定R语言基础的读者可以通过学习生成数据的代码了解数据的结构，以及模型假设。R语言的新手学习这些代码可能会觉得太困难，没有关系，你们可以跳过生成数据的细节，只需要了解数据的语境，都有哪些变量以及变量类型。你可以直接从网站上读取这些数据。书中的代码和数据可以在这个github页面上找到：https://github.com/happyrabbit/happyrabbit.github.com/tree/master/Book/DataScientistR 现在开始我们的旅程吧！ "],
["section-2.html", "第2章 数据科学 2.1 什么是数据科学？ 2.2 什么是数据科学家？ 2.3 数据科学家需要的技能 2.4 数据科学可以解决什么问题？", " 第2章 数据科学 数据科学和数据科学家成为了流行词汇。当有人问你干什么，你回答说数据科学家。对方会恍然大悟，觉得特别高大上，奥，数据科学家啊，听说过。是啊，没听说过数据科学家那就out了。如果接着问，数据科学家具体干什么的？然后就没有然后了。不知道你们有没有听过这样一则轶事，美国最高法院法官Potter Stewart被问到什么是淫秽时，他回答：“看下才知道。”这和数据科学很类似，很多概念，在大而化之的时候都可以存在，大家口耳相传，聊的不亦乐乎，但一追究细节，立即土崩瓦解。那么什么是数据科学家呢？我谷歌了一下数据科学家的定义，下面是其中的一些： 住在加州的数据分析师 数据科学家是商业（数据）分析师的进化版 比软件学家更懂统计，比统计学家更懂软件科学的人 拥有出众数据分析能力的BI咨询师，尤其是能用大量数据增加商业竞争力的人 会编程，懂统计，能通过多种方式从数据中掘金的人 此外，很多其它职位其职责都和“从数据中获取信息”有关，比如：数据分析师，BI咨询师，统计学家，金融分析师、商业分析师，预测分析师……这些不同职业有什么区别？即便都是数据科学家，教育背景等等也是千差万别。由于媒体的炒作以及对“数据科学家”这个名称的滥用，尽管总的分析行业正在飞速发展，但大家对这个行业从业人员的认识却越来越混乱。现在大部分商业领域所谓的分析都达不到“科学”的程度，而仅仅是加减乘除的游戏。 这些不同的职位要求有何不同？在北美总体说来： 金融分析师一般有金融方向的MBA学位。他／她会用电子表格，知道会计软件，分析各部门的预算数据，分析实际经营结果和预测之间的差别，做一些预测，但这里的预测不会涉及复杂的机器学习，统计模型。 数据分析师一般有MBA学位，有一些计算机背景，很擅长使用电子表格，会用高阶的电子表格编程功能如VBA，自定义函数，宏。根据情况，会使用一些BI的软件，如Tableau，主要都是用鼠标点拖的方式。会用SQL从数据库中读取数据。我所见的商业分析师拥有很少（或没有）统计知识。所以这部分人有处理数据的知识，但是没有统计学的知识，能做的分析非常有限。 统计学家一般多在药厂，生物技术公司，做一些非常传统的混合效应模型，方差分析等生物统计分析。由于行业要求，多用SAS而非开源软件R。 BI咨询师，一般也是工商管理专业，有MBA学位，受传统的商学院教育（熟悉4Ps或6Ps,4Cs,使用SWOT法分析市场），熟练使用电子表格，很少或没有其它技术背景。 数据科学家，多是数学／统计，计算机，工程学专业出身，会使用R,Python等多种编程语言，熟悉数据可视化。大多数在入职前没有太多市场营销知识。掌握高等概率统计，熟悉如下概念：抽样，概率分布，假设检验，方差分析，拟合优度检验，回归，时间序列预测模型，非参数估计，实验设计，决策树，马尔可夫链，贝叶斯统计（很快就能在白板上写下贝叶斯定理） 数据科学家都分布在哪些行业呢？根据Burtch Works Executive Recruiting在2015年4月发布的“数据科学家薪资调查报告”，科技公司（包括互联网）是数据科学家最大的雇主。其次是一些为其它公司提供如广告，市场调查，市场分析等商业服务的公司。这两者之和超过了50%。2014年创业公司雇佣了29.4%的数据科学家，2015年这个比例降至14.3%，原因不是创业公司招的数据科学家职位少了，而是大公司招入的数据科学家增长迅速，整体基数变大。总体来说数据科学家就业前景在北美是非常好的。调查还显示，在北美，大部分数据科学家（70%）工作经验小于10年。因此数据科学还是个很年轻的行业。现在，大家对数据科学领域应该有个大致的感觉了。下面我们对其进一步探讨。 2.1 什么是数据科学？ 50年前，John Tukey他老人家就预言有个类似今天的数据科学的东西会出现。早在1962年，他在“数据分析的未来（The Future of Data Analysis）”中[1]就嚷着要对学术统计进行改革。这篇文章当时发表在“数理统计年鉴（The Annals of Mathematical Statistics）”上，他的观点震惊了许多统计界的同事，这都是一群根正苗红的数理统计出身的大神们，那会数理统计年鉴中的文章都是满满的数学公式推导，从定义，定理到证明，逻辑缜密，理论精确。当然牛人最大的特点就是可以随时任性。John推了大半辈子公式突然有天发现统计不是这么玩的，于是他跳出来说： “很长一段时间我觉得自己是统计学家，对统计推断情有独钟，将从小样本上研究得到的结论推广到更大的群体。但随着数理统计的发展，我越发觉得这个路数不大对…总的来说，我觉得自己感兴趣的是数据分析，它包括：分析数据的过程，解释该过程得到结果的技术，合理计划收集数据的方案使得之后的分析过程更方便准确，以及所有分析中需要用到的仪器和数学理论。” 用简短的一句话概括就是：仅仅研究数学理论不是数据科学，数据科学的内容涵盖更广。 美国密歇根大学在2015年9月宣布了一个1亿美金的“数据科学项目（Data Science Initiative）”，计划在未来4年聘请35名新教授，支持与数据相关的跨学科研究。大学媒体大胆的宣称： “数据科学已经成为第4大科学发现手段，前三个为：实验，模型和计算。” 这里的数据科学指的是什么？该项目的网站上有如下对数据科学的描述： “数据科学是科学发现和实践的结合，其包括对大量类型各异的数据进行收集，管理，清理，分析，可视化和结果解释。其应用遍及各种科学，平移和交叉领域。” 如前所述，数据科学是一个新兴领域。在美国，对数据分析类专业人才的需求不断上升。研究估计 [2]，从2015到2018年，美国预计有400-500万工作岗位要求数据分析技能，大部分这些岗位的人才需要经过特殊训练。前面已经介绍过各种和数据分析相关的行业，这些行业对专业训练的要求参差不齐。其中数据科学家的门槛是最高的。成为一个数据科学家不是容易的事。不可否认，即使是数据科学家这个职业名称，当前也被滥用了。这些工作的本质都是从数据中获取信息。但不是每个都能称为“科学”。什么样的东西能够称为科学？我们看看John Tukey在50年前是怎么说的[1]： 怎样才能称为科学呢？回答因人而异。但下面3点大多数人都同意： 学术知识（intellectual content） 用能让人理解的方式组织起来 实践是检验其结果的最终标准 也就是说，数据分析要通过上面3条检验才能称为数据科学。我是这样定义数据科学的： 数据科学=数据+科学=从数据中获取信息的科学 这是一门新的科学，有各种因素推动了这门科学的产生。John提到了4个驱动因素： 正统统计学理论 计算机和电子显示设备的高速发展 很多领域内更多更大的数据提出的挑战 定量分析在更广的领域受到重视 很难想象这些观点是在1962年提出的，现在看来一点也不过时。7年之后，Tukey和Wilk在1969年又将这门科学和已经存在的科学进行对比，进一步限定了统计学在数据科学中所扮演的角色： “…数据科学是一个困难的领域。它需要和人们能用数据做什么和想用数据做什么这样的外在条件相适应。从某种意义上说，生物比物理困难，行为科学比这两者都难，很可能总体数据科学的问题比这三者还要难。无论在现在还是短期的将来，要建立一个正式的能够给数据分析实践提供高效指导的数据科学的结构还有很长的路要走。数据科学可以从正规正统统计学那里获得很多，但它们之间也需要保持适当的距离。” 数据科学不仅是个科学领域，而且和其它已经存在很久的科学领域一样困难。统计理论只在数据科学中扮演了部分角色，因为数据科学还有艺术的一面，艺术部分的发挥就需要数据科学家啦！ 2.2 什么是数据科学家？ 数据科学家=数据+科学+艺术家=用数据和科学从事艺术创作的人 数据科学家立足于科学，但不止于科学。从数据中提取出信息无疑是重要且有意义的过程，但这还不够。因为分析的终极目标是能够解决问题，实现价值。而从信息到具体应用领域的知识，进而应用所得知识创造价值，这两步都是需要一些艺术的，需要一点想象力。在之后“数据分析一般流程”那章中我会进一步讨论这个职业中艺术的部分。科学家需要不断学习，数据科学家是一个需要终身学习职业，其实很多职业都要求这一点。当然，你进入这个领域之前有一个门槛得要跨过去，有些基本的技能需要掌握。上面关于数据科学以及数据科学家的定义听起来非常高大上，可能有些抽象，感觉自己是个文艺女青年。其实也可以用一种更接地气的方式表达： 数据科学=从数据中得到问题答案的科学 数据科学家=通过科学方法从数据中得到有实际意义 的问题答案的人 数据科学结合了一整套科学工具与技术（数学，计算，视觉，分析，统计，试验，问题界定，模型建立与检验等），用于从数据收集中获得新发现、洞察与价值。使用数据科学的根本目的是解决实际问题。David Donoho在他2015年的文章“数据科学50年（50 years of Data Science）”中[3]讨论了当今数据科学的全貌，其中他将数据科学这个大领域分成6块： 数据探索和准备 数据表示和变换 数据编程计算 数据建模 数据可视化和展示 数据科学的科学 而一个合格的数据科学家，应该掌握这6个子领域的相关技能。我们会在本书剩余的部分围绕这6个方面展开讨论。 2.3 数据科学家需要的技能 我们在之前介绍北美各种和数据分析相关职位要求的时候，从技术层面上列举了一些数据科学家需要的技能。我们现在进一步讨论下这个职业需要的不同方面技能。 首先谈谈数据科学家的教育背景。数学、统计、计算机或其它定量分析学科（电子工程，运筹学等）的本科以上学历是必须的。根据2015年的统计数据，美国的数据科学家有48%有博士学位，44%有硕士学位，只有8%是本科。研究生博士期间的课题最好偏向机器学习，数据挖掘或预测模型。其次需要的是数据库操作技能。在工作中通常需要用SQL从数据库读取数据。所以能熟练使用SQL是基础。对于统计或者数学专业的学生，在校期间可能不需要使用SQL，因此不太熟悉。这没有关系，我也是工作以后才开始使用SQL的。但你要确保自己至少精通一种程序语言，之后遇到需要用到的新语言可以迅速学习。在学校期间的主要目的不是学会毕业后所需的全部技能，这是不可能完成的任务。高等教育（本科，研究生和博士）后应该具有的是基本的专业知识和自学能力。数据科学和很多其它领域一样，需要终身学习。有很多人问，要成为优秀的数据科学家是不是一定需要博士？这个问题很难用简单的是或者不是来回答。我看到的大多数优秀数据科学家确实都有博士学位，其余也都是硕士。我并不是要说高学历是成为优秀数据科学家的必要条件，其实真正重要的不是那个学历本身，而是拿到那个学历的过程，以及会选择获许这些学位的人共有的一些特质。 在美国，一般情况下，如果你拿到数理专业的博士学位，至少说明一个问题，就是你对学习的东西有兴趣。这样成天在电脑前面分析数据，编写程序的生活，对于那些对此不感兴趣的人来说必定是难以想象的痛苦。其次是研究生期间系统的理论训练。很多人可能觉得模型背后的数理知识不重要，只要会用模型就可以。统计软件使得很多模型使用者不需要知道具体的模型原理。了解模型原理是否能够帮助你更好的使用模型？当然会有帮助。但问题是这个帮助有多大？是不是值得我们花几年时间去学习？学习很多东西的好处是很难用短期去衡量的。我没有严格的分析，只是个人觉得了解模型原理是必要的。我很喜欢一个词“匠人精神”，也很乐意将“数据科学家”称为匠人，这是一种精益求精的精神。当然这种精神和学位没有必然联系，有本科毕业而对数据科学很感兴趣，自己学习也能够对这个学科有很深的理解。但大多数对这个领域感兴趣又具有“匠人精神”的人都有相关领域的更高等学历。最后，当然就是学习的能力。即使拿到博士学位，也不意味着学完了所有知识，而是具备进一步自学的能力，可以自己看懂数新方法的论文，也就是具备了在这个领域发展的自学能力。总的来说，这个领域的高学历现象并不能说明学历是必要条件，也不是充分条件。真正重要的是兴趣、匠人精神和自学能力。 编程能力也是数据科学家需要的基本技能。熟练使用一种编程语言是必须的，如R，Phython，C等。有人可能会问，只会SAS够不够？个人意见是：不够。这里不想对SAS过多评价。我的建议是大家至少要熟悉一门开源语言。当然，这些都只是工具，工具是解决问题的手段，而非目的。你必须要有一个能用来进行数据分析的工具，偏好因人而异，但你选择工具的时候最好考虑工具的灵活性和可扩展性。 接下来就要提到具体的分析技能。数据科学家应该掌握高等概率统计，能够熟练进行t检验，开方检验，拟合优度检验，方差分析。能够清楚的解释Spearman秩相关和Pearson相关之间的区别。熟悉抽样，概率分布，实验设计相关概念。了解贝叶斯统计（很快就能在白板上写下贝叶斯定理）。知道什么是有监督学习，什么是无监督学习。知道重要的聚类，判别和回归方法。知道基于罚函数的模型，关联法则分析。如果从事心理相关的应用的话（如消费者认知调查），还需要知道基本的潜变量模型，如探索性因子分析，验证性因子分析，结构方程模型。这个单子还可以一直列下去。看起来是不是不只一点吓人？我说过，数据科学家不是一个低门槛的行业，之前需要接受的训练对于没有兴趣的人来说是无比痛苦的。还有，单子是动态的，因为你在工作过程中还是需要不断学习。这些技能只是让你能够很好的开始。再次强调自学能力和成为一个终生学习者是优秀的数据科学家的必要条件。 除了技术能力以外，还需要其它一些非技术的能力。这些包括将实际问题转化成数据问题的能力，这一过程需要交流，也就要求良好的交流沟通能力。关注细节，分析是一个需要细心和耐心的职业。还有就是展示结果的能力，如何让没有分析背景的客户理解模型的结果，并且最终在实践中应用模型的结论。“数据科学家技能表”中总结了数据科学家需要的各方面技能。 总而言之，关于数据科学家有三个关键词：数据，科学和艺术。数据是基础；科学是工具；艺术是纽带，最终通过艺术将数据和科学结合得出的结果转化成相关领域的可应用知识，解决问题，真正产生价值。在实际应用中，以需要解决的问题为导向的思维方式很重要，否则分析很容易沦落为手段淹没目的的过程，很多分析行业的人就会犯这个错误，一味追求高大上的模型，酷炫的可视化，而忘了分析的根本目的是为了解决问题。说到这里，大家应该对这个行业有了一些概念性的了解，可能有读者会问：你这么强调数据科学是为了解决问题的，那么都解决哪些问题呢？我们在接下来的小节会介绍数据学科家都使用什么技术，解决哪些问题。 在此之前，插播下数据科学家和数据工程师的区别。因为这两个角色确实很令人混淆，他们之间的合作最密切，而且其合作的融洽度很大程度上决定了数据科学在组织内能否高效产生价值。这两个角色的区别当然在某种程度上和具体工作环境有关。比如在互联网行业，这两个角色重叠的部分更多。在传统行业各自的职责更加明晰。数据科学家需要知道数据能解决哪些问题，需要哪些数据以及用什么方法解决这些问题。找到问题的答案需要统计，机器学习等相关知识，在需要的时候，数据科学家得很快学会新的模型方法，以及如何用计算实施。这也是为什么数据科学家也要具备一定编程能力的原因，包括R、Python和MySQL。 数据工程师能够让数据科学家更加高效的工作。有的公司也会将其称为数据构架师。他们收集，储存数据，对数据进行批量处理或者实时处理。有的公司的数据科学家通过API获取数据，这样更容易不需要使用SQL。但也有很大一部分公司的科学家是通过SQL获取数据，这样有更高的灵活度，也更利于两者的合作。当前有很多大数据的工具可以用于收集，储存和处理数据，数据工程师的重要职责之一是选择好的工具，这里需要能够用专业知识有理有据的支撑这个选择，而不是选择当前最流行的。因此数据工程师需要有很强的软件工程相关知识，他们不仅仅要能够学习如何使用这些工具 ，也要能够在必要的时候优化这些工具。一个好的数据工程师需要精通数据库和强大的工程实践能力，包括处理和记录错误，检测系统，设计具有容错能力的数据管道，理解如果要要对当前构架进行扩展需要什么（为日后可能的新数据做准备），并且要持续处理各种可能的系统整合，数据库管理，清理和维护，保证数据管道通向的是想要达成的目标。 这两者之间也会有重叠的地方，比如数据科学家可能也会使用Hadoop生态群来解决某些数据问题，而数据工程师有时也可能可能在Spark集群上运行机器学习算法。最好的情况是这两个角色都能一定程度上了解对方的技能，这样对他们之间的合作有极大的帮助。可以这样比喻，数据工程师是提供建房材料的人，而数据科学家是那个造房子的人。这样可能就很容易理解为什么这两者之间的合作对于一个成功的数据科学团队来说如此重要了。如果没有很好的沟通，建房的材料不符合房子建造者的需要，那即使建造者技术再好，也很难建造出好的房子，而且造成资源的极大浪费。 2.4 数据科学可以解决什么问题？ 2.4.1 前提要求 数据科学不是万能药，数据科学家也不是魔术师，有些问题我们无法用数据科学解决，最好在一开始就对问题做出判断，对于那些无法解决的问题，诚实的告诉对方并解释原因，那我们对问题有什么要求呢？ 你的问题需要尽可能具体 来看两个例子： 问题1: 如何提高产品销售量？ 问题2: 今年年初推出的新促销手段是不是提高了先锋先玉696玉米种子在西南地区的销售量？ 比较上面这两个问题，大家是不是很快能发现它们的差别？问题1从语法上是个正确的问题，但从解决的角度，并不是一个能够用分析给出答案的问题。为什么？因为问题太泛了，根本无从定义该问题背后的自变量和应变量。而问题2就是一个恰当的问题。从分析的角度，应变量很明显是“先锋先玉696玉米种子在西南地区的销售量”，感兴趣的自变量是“今年年初推出的新促销手段”，我们想要研究的就是这两者之间的关系。从这里开始再去寻找其它变量，这样就慢慢的进入分析流程了。当然，问题具体不代表就能够回答。比如我曾经遇到一个很具体的供应链问题，问的是针对某一个特定产品在特定区域的库存该是多少。这个问题为什么无法回答呢？这个项目一开始我通过多元自适应回归样条（MARS）模型以为找到了一个合理的答案，但到项目的最后才发现，他们给我的供应相关的数据极其不准确，很多地区的供应量都只是估计。这是我从业生涯中的一次教训，这告诉我们下面将要提到的一点。 你要有和问题相关的必要数据 巧妇难为无米之炊，这老古人的话放在那里时刻闪闪发光。艺术源于生活，所以你首先得要有数据，之所以数据科学会火也是因为计算机的发展，使数据的收集更容易。上面提到的供给问题就是一个很好的例子，没有相对准确的数据，之后任何模型都没有意义。当然，任何数据都是存在误差的，但是误差必须在一定范围内。尤其是感兴趣的自变量（如之前问题2里的“新促销手段”相关的数据）和应变量（“先锋先玉696玉米种子在西南地区的销售量”），如果这些必要的变量有很大缺失，或者不准确的话，模型是无法发挥作用的。再如，你要预测某个产品的消费者中谁最可能在接下来的3个月内购买该产品。要解决这个问题，你需要有目标消费者群体历史购买行为的信息：上一次购买的时间，消费量，优惠券使用情况等等。如果你仅仅知道这些客户的银行卡号，身份证号，出生月份之类的信息是不会对你的预测有任何帮助的。 很多时候数据的质量比数量重要，但数量也是不容忽视的。在能保证数据质量的前提下，数量越多越好。样本量越大，你能够回答的问题也就更细，且模型发现的置信度也更高。如果你有一个具体合理的问题，有足够大，质量合理的相关数据集，那么恭喜你，可以开始玩数据科学啦！ 2.4.2 问题种类 很多数据科学的书籍都从技术的角度对各种模型分类。比如有监督模型和无监督模型，线性模型和非线性模型，参数模型和参数模型等等。这里我们换而使用之前提到的“问题导向”的思维方式，对数据科学回答的问题进行分类，然后介绍哪些模型可以用于回答相应类别的问题，希望这些分组能在你面对自己的问题时帮助思考。 比较 第一类常见的问题是比较组之间不同的问题。常见的句式是：A在某方面是不是比B好？或者多者比较：A、B、C之间在某方面有没有差别？下面是一些问题的例子： 参与促销活动和没有参与促销活动消费者购买量有差异么？ 男性是不是比女性更倾向于购买我们的产品？ 用户满意度在不同商业区是不是有不同？ 服用某种药物的老鼠比没有服用药物的老鼠体重增长的是否更快？ 携带某种基因的大豆是不是比普通大豆产油量高？ 对于这类数据，通常从各组观测的基本统计量和可视化开始初步探索数据。在对数据分布和组之间的差异有个初步直观了解之后，通过统计检验测试组间是否在感兴趣的变量上有显著不同。处理这类问题常用的是经典统计推断：开方检验，t检验和方差分析。放在贝叶斯框架下也有一种比较组间不同的方法。如果因子增加，结构变得复杂（如在生物医药领域的复杂实验设计有随机效应因子），则需要使用更加复杂的混合效应模型。 描述 在分析中不可避免的要描述数据。比如聚类问题。当你通过算法找到不同的样本分类后，就需要对类进行定义，这要通过比较各类中变量的描述统计量得到。常用的描述问题有： 样本中家庭年观测的收入是不是无偏的？ 某产品在不同区域的月销售量均值／方差是多少？ 变量的量级差异大么？（决定是否需要对数据标准化） 模型中的预测变量观测缺失情况如何？ 问卷调查回复者的年龄分布范围是多少？ 这类数据描述常用于检查数据，找到合适的数据预处理方法，以及拟合模型后对结果的分析和展示。 聚类 聚类是一个极其常见的问题，其通常和判别联系在一起。聚类模型回答的问题是： 哪些消费者有相似的产品偏好？（市场营销） 哪些打印机损坏的模式相同？（质量控制） 公司员工在对公司评价上可以分为几类？（人力资源） 哪些词更经常同时出现？（自然语义处理） 哪些文档可能有相似的主题？（自然语义处理） 聚类是无监督分析。 判别 判别是另外一个经典的分析问题。通常用类别已知的样本作为训练集拟合判别器，然后用训练好的判别器预测新样本的类别。下面是一些关于判别的问题： 哪些新客户最有可能转化（购买）？ 当前的压力度数是正常的么？ 某贷款人有不还款的风险么？ 这个消费者还可能喜欢什么产品？ 这本书的作者可能是谁？ 这封邮件是不是垃圾邮件？ 关于判别的模型有数百种，在实践中我们其实不必要尝试所有的模型而只要拟合其中几种在大部分情况下表现最好的模型即可。我们在后面判别的章节还会介绍。 回归 当你感兴趣的量是一个数值而非类别时，通常就是一个回归问题。比如： 明天的气温可能会是多少？ 公司今年第4季度的销售额会是多少？ 某品牌打印机明年上半年在北京市的销量会是多少？ 该引擎还能工作多久？ 这次活动中需要准备多少啤酒？ 通常情况下，回归能够给出一个数值答案。回归通常解决“…是多少？”这样的问题。在有些时候模型给出的负数结果可能需要解释为0，或者有小数点的结果需要解释为最近的整数。 References "],
["section-3.html", "第3章 数据集模拟和背景介绍 3.1 服装消费者数据 3.2 航空公司满意度调查 3.3 生猪疫情风险预测数据", " 第3章 数据集模拟和背景介绍 之后的章节将通过案例讨论建模的各个方面。在进入正题之前，我先用本章介绍书中使用的数据，包括模拟数据的代码，数据的获取以及数据语境背景。很多R包里有现成的数据，网上也有各种机器学习竞赛的数据，但本书用来展示模型的数据大部分是通过R得到的模拟数据集。其原因我在第1章开始已经讲过了。 3.1 服装消费者数据 我们先模拟一个关于某品牌服装消费者的数据，这个数据会在之后的章节中反复用到。数据中包含N=1000个观测，我们将模拟3类变量（括号内是变量对应的模拟数据框中的列标签名）： （1）人口统计学变量。 年龄（age） 性别（gender） 有房还是租房（house） （2）消费者行为变量。 2015年实体店购买该品牌服装花销（store_exp） 2015年在线购买该品牌服装花销（online_exp） 2015年实体店交易次数（store_trans） 2015年在线交易次数（online_trans） （3）客户认知问卷调查。为了进一步了解消费者，商家时常对消费者进行问卷调查，然后对调查结果进行分组，其目标是寻找在产品兴趣，市场参与度或营销反应的重要方面有显著差异的客户群。通过了解组间的不同，市场营销人员可以优化产品定位，进行更加精准的营销。这里我们假设该服装品牌对消费者进行了下面的调查，并模拟该调查问卷的回复。 你是否同意下面的申明？ 问题 1（非常不同意） 2（有点不同意） 3（中立/不知道） 4（有点同意） 5（非常同意） （Q1）：我喜欢买不同品牌的服装，比较它们 （Q2）：我喜欢买同一个品牌的服装 （Q3）：品牌的知名度对我来说非常重要 （Q4）：服装质量对我来说非常重要 （Q5）：我有特定喜欢的风格 （Q6）：我喜欢在实体店购买 （Q7）：我喜欢在网上购买 （Q8）：价格对我来说很重要 （Q9）：我喜欢不同风格的衣服 （Q10）：我喜欢自己挑选服装，不需要周围人的建议 我们进一步假设这些根据问卷调查的结果可以将消费者分成4组：价格敏感（Price），炫耀性消费（Conspicuous），质量（Quality），风格（Style）。 （本章我们不会提到如何得到这些分组；我们假设这些已知。我们会在第9章中介绍聚类分析时会更详细的说明。） 你也可以重复下面的代码，自己创建该数据。我们强烈建议读者重复数据模拟的过程，这样能加深对模型方法的理解。如果你对此不感兴趣，也可以从本书网站上直接下载数据： sim.dat&lt;-read.csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;) 获得该数据集后你可以跳过本小节后半部分直接跳到下一节对分析流程的讲解。否则，继续本节。 模拟该数据的过程有些复杂，我们先模拟描述客户的变量。模拟该数据的代码分为3部分： 定义数据结构：定义变量名，变量类型，消费者分组名，各组大小。 变量分布参数，如各自的均值和方差。 在各组和各个变量上迭代，基于定义和参数设置抽取随机数。 通过这种方式组织代码，如果我们要改变部分模拟方式重新抽取数据就比较容易。例如，如果我们想要加一个组，或者改变其中某个人口统计变量的均值，只要稍微改变代码就好。我们也想通过这个结构介绍新的R代码，生成数据的第3个步骤中将用到这些代码。 # 设置随机种子，使数据模拟过程可重复 set.seed(12345) # 定义观测数目 ncust&lt;-1000 # 建立数据框存放模拟观测，初始数据框中只有一列id，即消费者编号 seg_dat&lt;-data.frame(id=as.factor(c(1:ncust))) # 指定要生成的变量，并为变量命名 vars&lt;-c(&quot;age&quot;,&quot;gender&quot;,&quot;income&quot;,&quot;house&quot;,&quot;store_exp&quot;,&quot;online_exp&quot;,&quot;store_trans&quot;,&quot;online_trans&quot;) # 每个变量对应的数据类型 # norm： 正态分布 # binom: 二项分布 # pois： 泊松分布 vartype&lt;-c(&quot;norm&quot;,&quot;binom&quot;,&quot;norm&quot;,&quot;binom&quot;,&quot;norm&quot;,&quot;norm&quot;,&quot;pois&quot;,&quot;pois&quot;) # 四个消费者分组的名称 group_name&lt;-c(&quot;Price&quot;,&quot;Conspicuous&quot;,&quot;Quality&quot;,&quot;Style&quot;) # 各消费者群组的大小 group_size&lt;-c(250,200,200,350) # group_name和group_size的第一个元素表明，对于“Price”这组消费者，我们将模拟N=250个观测。 定义好了数据的基本结构之后，我们下一步是定义分布参数，用这些参数来抽取相应数据。 这里我们要 模拟的数据有4个样本类，8个非抽样调查变量，因此我们创建一个4×8的均值矩阵，因为不同类别的 消费者对应不同的分布参数。下面代码用来创建均值矩阵： # 定义均值矩阵 mus &lt;- matrix( c( # 价格敏感（Price）类对应均值 60, 0.5, 120000,0.9, 500,200,5,2, # 炫耀性消费（Conspicuous）类对应均值 40, 0.7, 200000,0.9, 5000,5000,10,10, # 质量（Quality）类对应均值 36, 0.5, 70000, 0.4, 300, 2000,2,15, # 风格（Style）类对应均值 25, 0.2, 90000, 0.2, 200, 2000,2,20), ncol=length(vars), byrow=TRUE) 具体过程是怎样的？ 均值矩阵mus指定，例如，价格敏感（Price）类群体的第一个变量（这里是年龄age）均值为60，炫耀性消费（Conspicuous）类群体的年龄均值为40依次类推。正态分布变量需要指定均值和方差，如年龄（age）， 实体店花销（store_exp）和在线花销（online_exp）。对于二项分布（只有两个可能取值）和泊松分布变量，我们只需要规定均值。其中，性别（gender），有房还是租房（house）是二项数据，生成这样的数据需要指定得到其中某一观测值的概率，比如矩阵mus中。实体店交易次数（store_trans）和线交易次数（online_trans）是泊松变量（频数），泊松分布只有一个参数——分布均值。所以在下面的标准差矩阵sds中，非正态分布变量对应的标准差为缺失值NA。（注意这里我们只是用这些分布为例生成数据，并不意味着这些是最好的拟合变量观测的分布。例如，真实的收入数据更可能是一个有偏的分布而非正态）。 下面我们对正态分布变量创建标准差矩阵： # 每类的标准差 (NA = 标准差无定义) sds&lt;- matrix( c( # 价格敏感（Price）类对应均值 3,NA,8000,NA,100,50,NA,NA, # 炫耀性消费（Conspicuous）类对应均值 5,NA,50000,NA,1000,1500,NA,NA, # 质量（Quality）类对应均值 7,NA,10000,NA,50,200,NA,NA, # 风格（Style）类对应均值 2,NA,5000,NA,10,500,NA,NA), ncol=length(vars), byrow=TRUE) 将这两个矩阵加在一起我们就能够完全定义各个类的分布了。例如，我们来看下每个矩阵的第1行，其代表第1类群体（价格敏感）的分布参数。这些值规定该类群体的年龄（age）均值为60（见第一个矩阵第1行第1列），标准差为3（第二个矩阵第1行第1列）。另外，其中大约有50%的男性（第一个矩阵第1行第2列），年收入（income）均值为120000元，标准差为8000元。将这些设置分开存在不同表格中，将来想要修改十分容易。将数据定义和抽样过程分开是个很好的习惯。下面开始抽取数据： # 抽取非抽样调查数据 sim.dat&lt;-NULL set.seed(2016) # 对消费者类别进行循环（i） for (i in seq_along(group_name)){ # 为了核实代码，展示循环运行过程，我们在循环中添加了这样一行代码 # 函数运行时会打印出正在抽取的样本类名 cat (i, group_name[i],&quot;\\n&quot;) # 创建一个空矩阵用于存放该类消费者相关数据 seg&lt;-data.frame(matrix(NA,nrow=group_size[i], ncol=length(vars))) # 在这个类之内，对不同变量迭代，抽取相应的随机数据 for (j in seq_along(vars)){ # 在每个变量上迭代 if (vartype[j]==&quot;norm&quot;){ # 抽取正态分布变量 seg[,j]&lt;-rnorm(group_size[i], mean=mus[i,j], sd=sds[i,j]) } else if (vartype[j]==&quot;pois&quot;) { # 抽取泊松分布变量 seg[,j]&lt;-rpois(group_size[i], lambda=mus[i,j]) } else if (vartype[j]==&quot;binom&quot;){ # 抽取二项分布变量 seg[,j]&lt;-rbinom(group_size[i],size=1,prob=mus[i,j]) } else{ # 如果变量类型不是上述几种，程序停止运行并提示信息 stop (&quot;Don&#39;t have type:&quot;,vartype[j]) } } # 将该消费者类的数据依行添加到总数据集 sim.dat&lt;-rbind(sim.dat,seg) } 上面的代码是随机抽样的主要过程，其中cat()函数使得循环运行时会打印出正在抽取的样本类名，最后得到的sim.dat是初始描述客户的变量部分的数据，在对数据进行润色前，提醒大家注意两个关于R的技巧： 第一、在i循环内，我们事先定义一个有着相应行数和列数的没有元素值的数据框seg，之后每迭代一次就将样本赋值到事先定义的seg的特定行。这么做的原因是由于只要R在某个对象上添加东西——如在数据框上增加一行——它都会将原对象拷贝一份。这将使用两倍的内存，减慢运行速度。通过这种方法可以避免对内存的浪费。对这里的小数据可能感觉不出差别，但对于大数据，运行速度会有极大不同。 第二、对循环指针范围的设定用的是seq_along()而非1:length()。这是为了够避免一些常见的错误，如指针向量长度为0或者不经意将向量方向弄反了。 之后我们对描述客户的这部分数据进行完善，添加合适的列标签，将二项（0/1）变量转化为贴有标签的因子变量。 # 指定数据框的列名为我们定义的变量名 names(sim.dat)&lt;-vars # 加上一个因子列表明每个观测的对应的消费者类别 sim.dat$segment&lt;-factor(rep(group_name,times=group_size)) # 将二项变量转化为贴有标签的因子变量 # Female: 女性 # Male: 男性 sim.dat$gender&lt;-factor(sim.dat$gender, labels=c(&quot;Female&quot;,&quot;Male&quot;)) sim.dat$house&lt;-factor(sim.dat$house, labels=c(&quot;No&quot;,&quot;Yes&quot;)) # 假设在线购买和在实体店购买的次数至少为1，所以这里在原随机值上加1 sim.dat$store_trans&lt;-sim.dat$store_trans+1 sim.dat$online_trans&lt;-sim.dat$online_trans+1 # 年龄为整数 sim.dat$age&lt;-floor(sim.dat$age) 真实市场营销数据往往没有这么干净，数据缺失，以及错误输入等问题常常发生。我们最后对模拟的数据做一点“破坏”，使其更像真实的数据。我们假设一些人不愿意给出关于收入（income）的信息。我们建立一个逻辑变量idxm，然后将逻辑变量idxm值为真的对应位置消费者收入观测设为缺失值NA（R用NA表示缺失值）。我们假设年龄（age）越大的消费者对应缺失值的概率越大： # 加入缺失值 idxm &lt;- as.logical(rbinom(ncust, size=1, prob=sim.dat$age/200)) sim.dat$income[idxm]&lt;-NA 真实的数据中可能有错误的输入，或者离群点： # 错误输入，离群点 set.seed(123) idx&lt;-sample(1:ncust,5) sim.dat$age[idx[1]]&lt;-300 sim.dat$store_exp[idx[2]]&lt;- -500 sim.dat$store_exp[idx[3:5]]&lt;-c(50000,30000,30000) 到目前为止我们已经建立了一部分数据，你可以通过summary(sim.dat)检查数据。下面我们接着抽取问卷调查回复数据。我们先通过rnorm()生成正态分布随机数。但从上面的问卷调查表格中可以看到，这是一个1-5分量级的问卷，1代表非常不同意，5代表非常同意。于是接下来我们通过floor()函数将连续值转化成离散整数。 # 抽取问卷调查回复 # 问卷问题数目 nq&lt;-10 # 各类消费者对问卷回复的正态分布均值矩阵 mus2 &lt;- matrix( c( # 价格敏感（Price）类对应均值 5,2,1,3,1,4,1,4,2,4, # 炫耀性消费（Conspicuous）类对应均值 1,4,5,4,4,4,4,1,4,2, # 质量（Quality）类对应均值 5,2,3,4,3,2,4,2,3,3, # 风格（Style）类对应均值 3,1,1,2,4,1,5,3,4,2), ncol=nq, byrow=TRUE) # 方差假设都是0.2 sd2&lt;-0.2 sim.dat2&lt;-NULL set.seed(1000) # 对消费者类别进行循环（i） for (i in seq_along(group_name)){ # 为了核实代码，展示循环运行过程，我们在循环中添加了这样一行代码 # 函数运行时会打印出正在抽取的样本类名，这里不再显示输出 # cat (i, group_name[i],&quot;\\n&quot;) # 创建一个空矩阵用于存放该类消费者相关数据 seg&lt;-data.frame(matrix(NA,nrow=group_size[i], ncol=nq)) # 在这个类之内，对不同变量迭代，抽取相应的随机数据 for (j in 1:nq){ # 抽取正态分布变量 res&lt;-rnorm(group_size[i], mean=mus2[i,j], sd=sd2) # 设置上下限度 res[res&gt;5]&lt;-5 res[res&lt;1]&lt;-1 # 通过 floor()函数将连续值转化成离散整数。 seg[,j]&lt;-floor(res) } # 将该消费者类的数据添加到总数据集 sim.dat2&lt;-rbind(sim.dat2,seg) } # 为数据框添加列标签 names(sim.dat2)&lt;-paste(&quot;Q&quot;,1:10,sep=&quot;&quot;) # 合并两部分数据 sim.dat&lt;-cbind(sim.dat,sim.dat2) # 加上一个因子列表明每个观测的对应的消费者类别 sim.dat$segment&lt;-factor(rep(group_name,times=group_size)) 至此为止我们得到了需要的数据集。让我们检查一下抽取的数据集： str(sim.dat,vec.len=3) ## &#39;data.frame&#39;: 1000 obs. of 19 variables: ## $ age : int 57 63 59 60 51 59 57 57 ... ## $ gender : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 1 2 2 2 2 2 2 ... ## $ income : num 120963 122008 114202 113616 ... ## $ house : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 2 2 2 ... ## $ store_exp : num 529 478 491 348 ... ## $ online_exp : num 304 110 279 142 ... ## $ store_trans : int 2 4 7 10 4 4 5 11 ... ## $ online_trans: int 2 2 2 2 4 5 3 5 ... ## $ Q1 : int 4 4 5 5 4 4 4 5 ... ## $ Q2 : int 2 1 2 2 1 2 1 2 ... ## $ Q3 : int 1 1 1 1 1 1 1 1 ... ## $ Q4 : int 2 2 2 3 3 2 2 3 ... ## $ Q5 : int 1 1 1 1 1 1 1 1 ... ## $ Q6 : int 4 4 4 4 4 4 4 4 ... ## $ Q7 : int 1 1 1 1 1 1 1 1 ... ## $ Q8 : int 4 4 4 4 4 4 4 4 ... ## $ Q9 : int 2 1 1 2 2 1 1 2 ... ## $ Q10 : int 4 4 4 4 4 4 4 4 ... ## $ segment : Factor w/ 4 levels &quot;Conspicuous&quot;,..: 2 2 2 2 2 2 2 2 ... 可以看到，服装消费者数据有1000个观测，19个变量。前8个变量是关于样本的人口统计学和购买行为描述。Q1-Q10是关于消费者选择偏好的问卷调查回复，问卷分值量表为1-5分（最常见的市场调查设计）。最后一列是消费者类别，样本观测的模拟是根据消费者类别进行的，因此这些可以当作“真实”的消费者类别。使用随机模拟的一个重要优点就是能够通过这种方式验证模型的效果。而实际生活中的数据样本真正所属类别通常是未知的。我们在之后对聚类和判别分析进行介绍的时候会使用样本类别信息。下面我们会反复用该数据集为例。 3.2 航空公司满意度调查 这一小节我们模拟一个航空公司满意度调查数据。数据中包含N=1000个受访者，每个受访者基于最近一次航班体验对3个航空公司进行评分，问卷调查一共15项，每项评分从1-9，分值越大满意度越高。这15个调查项分为4类（括号中为相应数据集中的变量名）： 购票体验 购票容易度（Easy_Reservation） 座椅选择（Preferred_Seats） 航班选择（Flight_Options） 票价（Ticket_Prices） 机舱设施 座椅舒适度（Seat_Comfort） 位置前后空间（Seat_Roominess） 随机行李存放（Overhead_Storage） 机舱清洁（Clean_Aircraft） 空航服务 礼貌（Courtesy） 友善（Friendliness） 能够提供需要的帮助（Helpfulness） 食物饮料服务（Service） 总体指数 总体满意度（Satisfaction） 再次选择次航空公司（Fly_Again） 向朋友推荐此航空公司（Recommend） # 先建立因子载荷矩阵 # 其中前12项符合双因子结构，因为每项对应一个总体因子载荷和某特定因子的载荷 # 比如购票容易度对应总体因子载荷0.33，对因特定购票因子载荷0.58 # 我们可以将结果评分看成是总体因子和特定因子共同作用的结果 loadings &lt;- matrix(c ( # 购票体验 .33, .58, .00, .00, # 购票容易度 .35, .55, .00, .00, # 座椅选择 .30, .52, .00, .00, # 航班选择 .40, .50, .00, .00, # 票价 # 机舱设施 .50, .00, .55, .00, # 座椅舒适度 .41, .00, .51, .00, # 位置前后空间 .45, .00, .57, .00, # 随机行李存放 .32, .00, .54, .00, # 机舱清洁 # 空航服务 .35, .00, .00, .50, # 礼貌 .38, .00, .00, .57, # 友善 .60, .00, .00, .50, # 能够提供需要的帮助 .52, .00, .00, .58, # 食物饮料服务 # 总体指数 .43, .10, .30, .30, # 总体满意度 .35, .50, .40, .20, # 再次选择次航空公司 .25, .50, .50, .20), # 向朋友推荐此航空公司 nrow=15,ncol=4, byrow=TRUE) # 将载荷矩阵乘以它的转秩，然后将对角线元素设置为1得到相关矩阵 cor_matrix&lt;-loadings %*% t(loadings) # Diagonal set to ones. diag(cor_matrix)&lt;-1 # 我们通过mvtnorm包模拟有特定相关矩阵的数据集 library(mvtnorm) # 设置3个航空公司对应的评分均值向量 mu1=c(5,6,5,6, 7,8,6,7, 5,5,5,5, 6,6,6) mu2=c(3,3,2,3, 5,4,5,6, 8,8,8,8, 3,3,3) mu3=c(2,2,2,2, 8,8,8,8, 8,8,8,8, 8,8,8) #设置随机种子 set.seed(123456) # 受访者ID resp.id &lt;- 1:1000 library(MASS) rating1 &lt;- mvrnorm(length(resp.id), mu=mu1, Sigma=cor_matrix) rating2 &lt;- mvrnorm(length(resp.id), mu=mu2, Sigma=cor_matrix) rating3 &lt;- mvrnorm(length(resp.id), mu=mu3, Sigma=cor_matrix) # 将分值限定在1到9之间 rating1[rating1&gt;9]&lt;-9 rating1[rating1&lt;1]&lt;-1 rating2[rating2&gt;9]&lt;-9 rating2[rating2&lt;1]&lt;-1 rating3[rating3&gt;9]&lt;-9 rating3[rating3&lt;1]&lt;-1 # 将分值转化为整数 rating1&lt;-data.frame(round(rating1,0)) rating2&lt;-data.frame(round(rating2,0)) rating3&lt;-data.frame(round(rating3,0)) rating1$ID&lt;-resp.id rating2$ID&lt;-resp.id rating3$ID&lt;-resp.id rating1$Airline&lt;-rep(&quot;AirlineCo.1&quot;,length(resp.id)) rating2$Airline&lt;-rep(&quot;AirlineCo.2&quot;,length(resp.id)) rating3$Airline&lt;-rep(&quot;AirlineCo.3&quot;,length(resp.id)) rating&lt;-rbind(rating1,rating2,rating3) # 为数据集的各列命名 names(rating)&lt;-c( &quot;Easy_Reservation&quot;, &quot;Preferred_Seats&quot;, &quot;Flight_Options&quot;, &quot;Ticket_Prices&quot;, &quot;Seat_Comfort&quot;, &quot;Seat_Roominess&quot;, &quot;Overhead_Storage&quot;, &quot;Clean_Aircraft&quot;, &quot;Courtesy&quot;, &quot;Friendliness&quot;, &quot;Helpfulness&quot;, &quot;Service&quot;, &quot;Satisfaction&quot;, &quot;Fly_Again&quot;, &quot;Recommend&quot;, &quot;ID&quot;, &quot;Airline&quot;) 让我们检查一下抽取的数据集： str(rating,vec.len=3) ## &#39;data.frame&#39;: 3000 obs. of 17 variables: ## $ Easy_Reservation: int 6 5 6 5 4 5 6 4 ... ## $ Preferred_Seats : int 5 7 6 6 5 6 6 6 ... ## $ Flight_Options : int 4 7 5 5 3 4 6 3 ... ## $ Ticket_Prices : int 5 6 6 5 6 5 5 5 ... ## $ Seat_Comfort : int 5 6 7 7 6 6 6 4 ... ## $ Seat_Roominess : int 7 8 6 8 7 8 6 5 ... ## $ Overhead_Storage: int 5 5 7 6 5 4 4 4 ... ## $ Clean_Aircraft : int 7 6 7 7 7 7 6 4 ... ## $ Courtesy : int 5 6 6 4 2 5 5 4 ... ## $ Friendliness : int 4 6 6 6 3 4 5 5 ... ## $ Helpfulness : int 6 5 6 4 4 5 5 4 ... ## $ Service : int 6 5 6 5 3 5 5 5 ... ## $ Satisfaction : int 6 7 7 5 4 6 5 5 ... ## $ Fly_Again : int 6 6 6 7 4 5 3 4 ... ## $ Recommend : int 3 6 5 5 4 5 6 5 ... ## $ ID : int 1 2 3 4 5 6 7 8 ... ## $ Airline : Factor w/ 3 levels &quot;AirlineCo.1&quot;,..: 1 1 1 1 1 1 1 1 ... 3.3 生猪疫情风险预测数据 本小节中我们将模拟一个生猪疫情数据。假设研究人员对800个养猪场进行和某生猪疫情有关的问卷调查，问卷由120个问题组成。每个问题有3个可能选项。目的是根据问卷调查回复得到每个养猪场在未来爆发疫情的概率。每个养猪场在问卷问题的3个可选项中等概率选择。第\\(i\\)个养猪场对应的疫情爆发概率服从\\(Bernoulli(1,p_{i})\\)分布。其中 \\[ln(\\frac{p_{i}}{1-p_{i}})=\\beta_{0}+\\sum_{g=1}^{G}\\mathbf{x_{i,g}^{T}}\\beta_{g}\\] \\(\\beta_{0}\\)是截距项，\\(\\mathbf{x_{i,g}}\\)是第\\(i\\)观测对应第\\(g\\)个问题的回复。这里将问题回复转化为0/1虚拟变量，因为每个问题有3个可能选项，所以\\(\\mathbf{x_{i,g}}\\)是一个取值为0/1的含有三个元素的向量。\\(\\mathbf{\\beta_{g}}\\)是对应的参数。 我们在这里考虑3类问题。第1类（问题1到问题40）问题中有两个选项对应变量有预测能力。第2类（问题41到问题80）问题中只有一个选项对结果有预测能力。第3类（问题81到问题120）对结果预测没有帮助，也就是我们希望能够去除的变量。模拟数据的参数设置如下： \\[\\mathbf{\\beta^{T}}=\\left(\\underset{question\\ 1}{\\frac{40}{3},\\underbrace{1,0,-1}},...,\\underset{question\\ 40}{\\underbrace{1,0,-1}},\\underset{question\\ 41}{\\underbrace{1,0,0}},...,\\underset{question\\ 80}{\\underbrace{1,0,0}},\\underset{question\\ 81}{\\underbrace{0,0,0}},...,\\underset{question\\ 120}{\\underbrace{0,0,0}}\\right)*\\gamma\\] 这里我们通过设置5个\\(\\gamma\\)值（\\(\\gamma \\in \\{0.1,0.25,0.5,1,2\\}\\) ）模拟了5种参数情况下的数据。 \\(\\gamma\\)越大，参数值越大，也就意味着有效问题对结果的预测性越强。对于每个参数设定模拟了20个数据集，之后我们会以这些数据为例展示不同模型变量选择的效果。模拟多个数据集是为了研究一些估值的稳定性。 # sim1_da1.csv 模拟的第一个数据集 # similar sim1_da2 and sim1_da3 # sim1.csv simulated data, the first simulation # dummy.sim1.csv dummy variables for the first simulated data with all the baseline in #code for simulation # setwd(dirname(file.choose())) # library(grplasso) nf&lt;-800 for (j in 1:20){ set.seed(19870+j) x&lt;-c(&#39;A&#39;,&#39;B&#39;,&#39;C&#39;) sim.da1&lt;-NULL for (i in 1:nf){ # sample(x, 120, replace=TRUE)-&gt;sam sim.da1&lt;-rbind(sim.da1,sample(x, 120, replace=TRUE)) } data.frame(sim.da1)-&gt;sim.da1 paste(&quot;Q&quot;, 1:120, sep = &quot;&quot;)-&gt;col paste(&quot;Farm&quot;, 1:nf, sep = &quot;&quot;)-&gt;row colnames(sim.da1)&lt;-col rownames(sim.da1)&lt;-row # 用nnet包中的class.ind()函数将问题回复编码为名义变量 library(nnet) dummy.sim1&lt;-NULL for (k in 1:ncol(sim.da1)) { tmp=class.ind(sim.da1[,k]) colnames(tmp)=paste(col[k],colnames(tmp)) dummy.sim1=cbind(dummy.sim1,tmp) } data.frame(dummy.sim1)-&gt;dummy.sim1 # 每个问题对应的3个名义变量中有重复信息 # 将C选项设置为基线回复 # 删除基线名义变量 base.idx&lt;-3*c(1:120) dummy1&lt;-dummy.sim1[,-base.idx] # 对每个r设置依次抽取相应的因变量 # 每次只对一个r值抽取，将其余代码注释掉 # 得到r=0.1 时每个农场对应的连接函数值 c(rep(c(1/10,0,-1/10),40),rep(c(1/10,0,0),40),rep(c(0,0,0),40))-&gt;s1 as.matrix(dummy.sim1)%*%s1-40/3/10-&gt;link1 # r=0.25 # c(rep(c(1/4,0,-1/4),40),rep(c(1/4,0,0),40),rep(c(0,0,0),40))-&gt;s1 # as.matrix(dummy.sim1)%*%s1-40/3/4-&gt;link1 # r=0.5 # c(rep(c(1/2,0,-1/2),40),rep(c(1/2,0,0),40),rep(c(0,0,0),40))-&gt;s1 # as.matrix(dummy.sim1)%*%s1-40/3/2-&gt;link1 # r=1 # c(rep(c(1,0,-1),40),rep(c(1,0,0),40),rep(c(0,0,0),40))-&gt;s1 # as.matrix(dummy.sim1)%*%s1-40/3-&gt;link1 # r=2 # c(rep(c(2,0,-2),40),rep(c(2,0,0),40),rep(c(0,0,0),40))-&gt;s1 # as.matrix(dummy.sim1)%*%s1-40/3/0.5-&gt;link1 # 在连接函数的基础上计算每个农场对应的爆发概率 exp(link1)/(exp(link1)+1)-&gt;hp1 # 基于爆发概率hp1，抽取相应的因变量res res&lt;-rep(9,nf) for (i in 1:nf){ sample( c(1,0),1,prob=c(hp1[i],1-hp1[i]))-&gt;res[i] } # 这里将数据存成3个不同的版本，只是为了之后不同模型使用方便 # 3个数据集都含有所有120个问题的回复，但彼此稍微有不同 # da1 含有因变量，但没有名义变量所属问题的信息 # da2 没有因变量，但最后一行包括的名义变量所属的问题 # da3 没有因变量，没有名义变量所属问题的信息 dummy1$y&lt;-res da1&lt;-dummy1 y&lt;-da1$y ind&lt;-NULL for (i in 1:120){ c(ind,rep(i,2))-&gt;ind } da2&lt;-rbind(da1[,1:240],ind) da3&lt;-da1[,1:240] # 将数据集储存起来 write.csv(da1,paste(&#39;sim&#39;,j,&#39;_da&#39;,1,&#39;.csv&#39;,sep=&#39;&#39;),row.names=F) write.csv(da2,paste(&#39;sim&#39;,j,&#39;_da&#39;,2,&#39;.csv&#39;,sep=&#39;&#39;),row.names=F) write.csv(da3,paste(&#39;sim&#39;,j,&#39;_da&#39;,3,&#39;.csv&#39;,sep=&#39;&#39;),row.names=F) write.csv(sim.da1,paste(&#39;sim&#39;,j,&#39;.csv&#39;,sep=&#39;&#39;),row.names=F) write.csv(dummy.sim1,paste(&#39;dummy.sim&#39;,j,&#39;.csv&#39;,sep=&#39;&#39;),row.names=F) } 要理解这里数据模拟的代码，读者需要了解逻辑回归和分组lasso的理论知识，这超出了本书的范围。这里的代码仅供大家参考。可以重复上面的代码生成相应的数据集。因为这里生成的数据量较大，在网上只有\\(\\gamma=2\\)对应的一次模拟的数据集。我们看下得到的数据集： library(dplyr) disease_dat&lt;-readr::read_csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/sim1_da1.csv&quot;) # 这里只截取最后的7列 head(subset(disease_dat,select=c( &quot;Q118.A&quot;,&quot;Q118.B&quot;,&quot;Q119.A&quot;,&quot;Q119.B&quot;,&quot;Q120.A&quot;,&quot;Q120.B&quot;,&quot;y&quot;))) 其中最后一列y代表相应农场疫情爆发情况，y=1代表从问卷调查之后5年内有疫情爆发。剩余的列表示农场问卷调查结果，如Q120.A=1对应问卷调查中第120个问题选择A的农场，类似的Q120.B=1对应第120个问题中选择B的农场，我们将选项C作为基准选项。之后我会用这个数据集展示一些相关的模型。 "],
["section-4.html", "第4章 数据分析一般流程 4.1 问题到数据 4.2 数据到信息 4.3 信息到行动", " 第4章 数据分析一般流程 数据科学的目的是找到数据背后潜藏的模式，这个模式就是我们所说的信息。仅仅挖掘出信息是不够的，你还要利用信息作出具体的行动，最终将信息转化成知识，然后从知识到行动从而创造价值。这个数据分析流程将数据分析的技术部分放在了一个更大的应用语境下，重点从技术建模到根据发现采取行动，这章我们要重点讨论得到可实践的数据分析结果。当前有太多介绍分析技术的书籍对数据分析定义很狭隘，好像只要将当前最华丽的模型（如神经网络，随机森林，支持向量机）通过某种统计软件套用在数据上，得到结果报告就结束了。这些方法模型都是很重要的，但是分析的过程可不仅仅是一系列功能强大的模型和结构完整的数据。我们要在恰当的应用领域，将正确的方法用在合适的数据上。整个数据分析的流程是个迭代学习的过程，每一步都在前一步的结果之上更深入的理解（挖掘）数据。积累的经验反馈又可用于优化整个过程。因此这是一个自反馈的生态环。该流程具体是怎样的呢？“数据分析的一般流程”图展示了这个生态环的6个阶段，图中每一个步骤旁边方括号内的百分比是该步骤大致占用的时间范围。整个分析成功的关键在于将数据分析嵌入实际问题的语境中，最终分析师能够将数据中提取的信息通过交流传达给客户，指导推动用户付出行动创造价值。下面我会逐一对每个阶段进行讲解。但在此之前，我们先模拟一个关于某品牌服装消费者的数据，本章会用该数据为例展示数据分析的流程，该数据及也会在之后的章节中反复用到。 4.1 问题到数据 分析的流程开始于一个具体的问题，一定确保准确理解客户的问题。这里所说的“客户”是广义上的，如果你是在专门的统计咨询公司工作，那客户可以是其它需要统计分析帮助的组织机构，如果你在企业内部从事相关分析工作，那客户可以是你所支持的部门的同事，如产品经理，市场总监，科研部门化学、生物领域的科学家等等。分析的新手很容易犯的一个错误就是在没有确保准确理解客户问题的情况下就开始收集分析数据，最后白忙一场，对于各方都造成时间上的损失。如何避免这样的情况发生？交流！通过交流，将问题尽可能具体化。这个在之前讲到过，你的问题需要尽可能具体到： 知道问题的类别：是比较，描述，聚类，判别还是回归 知道需要什么样的数据：我们有哪些数据，数据的质量如何，还需要收集哪些数据，哪些是自变量，哪些是应变量。 以上面服装消费者为例。假设某服装公司的营销人员找到你，希望知道该如何通过更精准的营销提高效率。该服装公司旗下有多个品牌。这是一个非常泛的商业问题，遇到这样的问题你下一步该怎么办？对，将问题具体化。在我看来，问题的关键在于清晰的定义客户所谓的精准具体指哪方面？是针对某一品牌的线上广告希望能准确锁定消费者的注意力？还是某个特定款式的服装打算打折，想要知道谁最可能对这个打折信息感兴趣？或是不同品牌有不同价位，不同款式，他们想知道关于这些不同类型的服装的产品信息的目标客户群是什么？可能之前他们没有对客户进行区分，广告信息对所有客户都是相同的，现在他们希望更加精确的对不同类型的客户提供不同的服装信息，如可以在用户浏览网页时对不同客户显示不同的服装推荐，可以在不同的杂志刊登不同的广告（不同杂志可能对应不同的读者群），或者对系统内客户发送不同的邮件促销广告。 假设通过进一步交流知道客户感兴趣的是最后一个问题：跨品牌的精准营销。那么接下来我会继续问客户下面的问题： 你们都有什么品牌？这些品牌的价位都是怎样的？风格质量如何？ 你们有哪些关于消费者的数据？（人口统计学数据，在线消费，实体店消费） 是不是还有其它关于消费者选择偏好的数据？ 反复交流过后，我们或许可以得到类似模拟的服装消费者数据，其中包括1000个消费者的人口统计学数据，1年内的在线/实体店消费量，在线购/实体店购买次数，以及关于选择偏好的问卷调查数据。此外，我们可以将该问题定义为聚类问题。在你阅读了全书之后，遇到这种情况可能脑子里已经有一些候选模型了。你还需要和客户协商制定一个结果交付的计划，什么时候交付结果，结果是书面报告还是需要一个演讲展示，在项目进行的过程中是不是需要设定几个时间点双方交流讨论进展情况，有什么新数据，或客户有什么需要补充的，这些和数据分析不直接相关，但对于一个合格的数据科学家而言，项目管理能力同样不可缺少。至此，在这个例子中我们完成从问题到数据这一步骤了。关于这一步骤最后强调一点，在和客户交流的过程中，保证交流的重点是客户要解决的问题，而不是你要使用的分析技术和算法。除非客户对你要用的模型方法有兴趣，一般情况下不需要提及具体可能用到的模型。 4.2 数据到信息 数据到信息的过程牵扯到流程图中的四步：数据准备，数据清理，建模和模型评估。对于数据准备这里不过多介绍，对于非实验环境（如市场的案例），这一步主要是通过SQL从数据库中读取相应数据，或者有些客户以电子表格的形式给你的数据（如调查问卷回复），你需要将不同来源的数据合并起来。对于实验室环境下，如医药，生物相关实验，数据科学家（更常见的称呼是“统计师”，这些几乎全都是根正苗红的统计学背景的研究人员）或许会涉入收集数据之前的实验设计环节，确保收集到的数据能够用来回答相应的问题。 对于从数据预处理到模型检验这些步骤的具体细节和常用方法我会在之后专门章节更详细的介绍。但这里我想先对数据分析这个过程进行一个大体描述。有几个方面值得深入进行探讨。首先大家可以从图上看到，数据预处理占用相当大比例的时间。预处理技术一般指数据的清理、变换或者缺失值填补，这些我们在下面数据预处理的章节会更详细的介绍。虽然数据预处理不是正式建模，但这一步能够极大的影响模型的精确度（对于预测模型）和可解释性。一个简单的例子是通过回归系数估计比较回归模型中各参数对结果变量的贡献，在这个问题中，需要保证数据中各个变量的尺度一致，我们模拟的服装消费者数据中的变量尺度就不一致： # 选取数据框中的列“age”和“income”，得到子数据框 sdat&lt;-subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot;)) # 对子数据框进行总结 summary(sdat) ## age income ## Min. : 16.00 Min. : 41776 ## 1st Qu.: 25.00 1st Qu.: 85832 ## Median : 36.00 Median : 93869 ## Mean : 38.84 Mean :113543 ## 3rd Qu.: 53.00 3rd Qu.:124572 ## Max. :300.00 Max. :319704 ## NA&#39;s :184 从上面通过summary()函数的输出可以看到（这里我们只展示其中两个变量，想要检查整个数据框的总结信息，可以键入 summary(sim.dat)），收入（income）的观测尺度明显大于年龄（age）。如果没有数据变换，拟合模型的变量系数之间是没有可比性的。 其次，建立和评估模型通常离不开数据划分（交互校验）在服装消费者数据的例子中，如果研究兴趣在于预测一个新的消费者在未来一年里在这个公司服装上的消费额，这种情况下预测的样本和用来建模的样本属于不同的群体。这意味着，我们不仅需要检查模型对当前数据的拟合程度，还需要评估模型外推至新样本的能力。为了做到这一点，我们需要将样本划分成训练集和测试集。训练集用于拟合模型，测试集用于评估模型在新样本上预测的能力。我们会在之后的建模技术模块进一步介绍划分训练集和测试集的不同方法。 实际应用中的数据有时含有许多变量（多维度），这可能导致一系列问题。如由于自变量之间存在相关性导致模型估计不稳定，如果模型是以预测为目的，则会降低预测准确性。太多变量还会导致模型难以解释，极大削弱其应用价值，尤其在市场营销这样的领域，模型的解释性和其应用价值紧密联系。例如，在服装消费者调查问卷中有10个关于消费者对服装不同方面的在意程度的问题，可能在这些问题的回复背后有几个潜在的概念，如对价格的敏感，炫耀性心理的满足，产品质量和风格，这些概念是潜藏在背后促使消费者对表面上10个问题做出回复的因子。如果我们能将这样的问卷调查观测降至少数潜在因子的维度，便可更清晰的识别人们在哪些因子上存在不同，进而更有针对性的进行品牌营销。因为这个话题在实际应用中非常重要，我们会用专门一个章节（特征工程）进行讲解。 关于这部分流程还有一个重要的问题是选择合适的模型评估标准。在使用测试集之前，有两种方法可以用来决定模型的效能。首先，可以使用一些模型表现的度量。根据具体数据评估度量可能不同，比如对离散应变量，我们通常使用AUC，每类的错误率来作为评估标准；对于连续应变量，可以使用\\(R^2\\)，RMSE等方式。另外一个工具是进行简单的模型可视化，如作出观测数据与预测数据的散点图，发掘出模型表现特别好或者特别差的区域。这些定性的信息对改进模型非常关键，如果只是用总结性的统计量去衡量就会失去这些信息。 根据经验，一些建模者会依赖于自己钟爱的某个模型。然而天下没有免费的午餐，关于你要解决的问题信息不足的情况下，没有一个模型总是比其它模型更有效。因此，建模者应该在一个具体问题上尝试各种方法，之后再选择一个特定的模型。 有两种意义上的模型选择。我们可以选择一类模型而放弃另一类，比如因为线性回归模型拟合效果不好，因而用多元自适应回归样条（MARS）。在这种情况下，我们其实是在模型之间进行选择。模型选择还有另外一种形式，就是在同类模型中选择。比如在拟合MARS时，我们通过交叉验证选择模型中的调优参数，这也是一种模型选择。这里我们选择的是MARS模型的具体种类，即是在MARS模型这个大类之内进行选择。在两种情形下，我们都依赖于交叉检验，模型评估标准和测试集得到定量的模型评估，从而帮助我们作出选择。 4.3 信息到行动 业界普遍反映数据科学家欠缺将数据中的信息转化为商业知识的能力，大部分数据科学家止于从数据到信息这一步。如何做到从信息到知识呢？这个需要你对所在行业有较深入的了解，具有应用该行业说故事的能力。这是艺术的部分。这也是一个矛盾的地方，因为这意味着数据科学家不如很多人之前所设想的可以单独成为一个职能，应用在不同的领域。当从技术角度上说这是可行的，但是从实践的角度，仅是应用技术得到一个模型结果远远不够，将结果转化为真正的市场营销的决策建议并和相关营销人员交流，保证结果应用在市场营销中提高效率，是非常关键的收尾环节，这一步决定了你工作的价值。但这一步要求深入了解行业，做到这点需要在某个特定行业中从业较长时间，因此从实践上讲，一个数据分析师很难细致了解每一个行业，即使“从数据到信息”这个步骤可以一般化到不同领域，但从“信息到知识”将数据科学家从某种程度上限定于某一领域。 我想以一个中学时代就听过的故事结束本章：美国福特公司的一台高级马达坏了，公司所有技术人员都束手无策，公司只好请来了德国籍电机专家维修。他经过研究和计算后在电机上划了一条线，说：“打开电机，把划线处线圈减去16圈。”果然，电机很快恢复正常了。福特公司问需要多少酬金。专家回答：1万美元。在场的人都惊呆了：划条线这么贵！德国专家坦然地说：“划条线1美元，知道在哪里划线9999美元。” 现在很多机器学习和统计模型都可以轻易用代码实现，就好像是在电机上划条线，但前提是你知道在什么情况下用什么模型能够解决问题。数据科学家不仅仅是那个编写执行代码的人，更重要的是成为数据科学行业中那个“知道在哪里划线”的人，这是也是本书最重要的写作目的。 "],
["section-5.html", "第5章 数据预处理 5.1 介绍 5.2 数据清理 5.3 缺失值填补 5.4 中心化和标量化 5.5 有偏分布 5.6 处理离群点 5.7 共线性 5.8 稀疏变量 5.9 编码名义变量 5.10 本章总结", " 第5章 数据预处理 5.1 介绍 许多数据分析相关书籍着重介绍模型，算法和统计推断。但在实际应用中，刚到手的原始数据通常都不能直接用于建模。数据预处理是将原始数据转化成能够用于建模的一致数据的过程。建模失败的原因有多种，其中之一就是在建模前没有对数据进行恰当的预处理。数据预处理会极大的影响建模结果，如缺失值填补和对离群点的处理显然会影响统计分析的结果。因此这是整个分析流程中非常关键的一个环节，这一步没有到位，之后的分析就如同在沙地上建房，及其不稳固。 在实际分析项目中，根据数据清理的不同阶段，有下面几类数据： 原始数据 技术上正确的数据 可以用于模型的数据 整合后的数据 设置了固定格式的数据 原始数据是刚开始得到的第一手数据，可以是从数据库读取出的销售数据，市场调查的同事给你的调查问卷回复，研发部门收集的实验数据等等。这些数据集可能很粗糙，不一定能直接读入R。 比如多行表格标题，或者格式不符合要求： 用50%表示百分比而不是0.5，这样R读入时会将其当作字符型； 销售额的缺失值用“-”表示，而不是空格，这样R会将销售额当成字符型； 数据是在幻灯片文档中，或者电子表格不是“.csv”而是“.xlsx”格式； … 总而言之，这样的数据有时不能直接读入R，需要进行一些清理；有些格式的数据需要安装特定的包读取。当对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据。这样的数据载入R后有合理的列标签，变量格式等等。但这不意味着这时的数据是完全无误的，如年龄变量可能是负数，折扣百分比可能大于1，没到法定年龄的某人可能有驾照号码，或者数据缺失。取决于你的具体情况，数据可能存在各种问题。你在建模之前需要对这样的数据进行进一步清理。除了数据本身是否合理的角度对数据进行清理以外，取决于你要使用的模型，还需要从技术层面对数据进行预处理，使之尽可能不要太过偏离模型假设。比如有偏数据，变量量级不同，离群值，变量间的共线性，需要将分类变量转化为数值变量等等。对技术上正确的数据进行进一步清理后就得到可以用于建模的数据。 有时我们需要对数据进行整合。比如你可能需要展示某个产品在不同价格下的年销售量，这时就需要将每天的销售量相加得到相应的年销售量；在聚类分析中，当你得到各个分类后，通常需要对不同类进行描述，这时也需要整合各个类的描述统计量（比如平均年龄，平均收入，年龄标准差等等）。数据整合通常是为了给人展示，或者进一步用于可视化。 对整合好的数据，根据不同客户的要求我们需要更改数据格式。比如简洁明了的行列标签，单元格颜色，对一些需要强调的数据高亮等等。 这里我们建议大家分别储存每一步得到的数据，以及各个处理过程使用的R代码，使得这个过程尽可能可重复。如果需要检查更改某个环节，也相对容易。在本章的剩余部分我们针对建模前的数据预处理以及数据整合。本章我们将介绍一系列的数据清理技术，并用R进行实践。除了技术以外，我们还会讲到如何针对不同的情况选择合适的数据预处理方式。 前面有提到，数据预处理一般指数据的清理、变换或者缺失值填补。不同的模型对于预测变量的类型有不同的敏感度，此外变量以什么形式进入模型也很重要，如5分量表的调查问卷回复是当作因子变量还是数值变量。 本章将介绍无监督数据处理，有监督的方法会在其它章节中讨论。例如，偏最小二乘回归（PLS）模型本质上是主成分分析（PCA）的有监督版本。我们还将描述不考虑因变量时移除自变量的方法。 先载入本章需要的R包（我将在相应代码注释中解释每个包的用途）： # 先安装这些包才能用library()函数载入 # caret: 提供获取、使用、评估成百上千个机器学习模型及其拟合效果的系统交互界面 # 为机器学习提供了结构化的方法并且对一系列机器学习过程进行评估 library(caret) # e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别 library(e1071) # gridExtra: 绘图辅助功能，讲不同的图形组合在一起成为图表 library(gridExtra) # lattice: 建立在核心绘图能力上的格子框架图形 library(lattice) # imputeMissings: 填补缺失值 library(imputeMissings) # RANN: 应用k邻近算法 library(RANN) # corrplot: 相关矩阵的高级可视化 library(corrplot) # nnet: 拟合单个潜层级的神经网络模型 library(nnet) # car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数 library(car) # gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵 library(gpairs) # reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast() library(reshape2) # psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型； # 我们会使用包中的describe()函数 library(psych) # plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总 library(plyr) # tidyr: 清理揉合数据的包，主要函数是spread()和gather() library(tidyr) 5.2 数据清理 当你得到上述技术上正确的数据后，第一步就是检查数据，看看都有哪些变量，这些变量分布如何，是不是存在错误的观测。我们先读取并且检查服装消费者数据： sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) summary(sim.dat) ## age gender income house ## Min. : 16.00 Female:554 Min. : 41776 No :432 ## 1st Qu.: 25.00 Male :446 1st Qu.: 85832 Yes:568 ## Median : 36.00 Median : 93869 ## Mean : 38.84 Mean :113543 ## 3rd Qu.: 53.00 3rd Qu.:124572 ## Max. :300.00 Max. :319704 ## NA&#39;s :184 ## store_exp online_exp store_trans online_trans ## Min. : -500.0 Min. : 68.82 Min. : 1.00 Min. : 1.00 ## 1st Qu.: 205.0 1st Qu.: 420.34 1st Qu.: 3.00 1st Qu.: 6.00 ## Median : 329.0 Median :1941.86 Median : 4.00 Median :14.00 ## Mean : 1356.8 Mean :2120.18 Mean : 5.35 Mean :13.55 ## 3rd Qu.: 597.3 3rd Qu.:2440.78 3rd Qu.: 7.00 3rd Qu.:20.00 ## Max. :50000.0 Max. :9479.44 Max. :20.00 Max. :36.00 ## ## Q1 Q2 Q3 Q4 ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :1.000 Median :3.000 ## Mean :3.101 Mean :1.823 Mean :1.992 Mean :2.763 ## 3rd Qu.:4.000 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :5.000 Max. :5.000 ## ## Q5 Q6 Q7 Q8 ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.750 1st Qu.:1.000 1st Qu.:2.500 1st Qu.:1.000 ## Median :4.000 Median :2.000 Median :4.000 Median :2.000 ## Mean :2.945 Mean :2.448 Mean :3.434 Mean :2.396 ## 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:3.000 ## Max. :5.000 Max. :5.000 Max. :5.000 Max. :5.000 ## ## Q9 Q10 segment ## Min. :1.000 Min. :1.00 Conspicuous:200 ## 1st Qu.:2.000 1st Qu.:1.00 Price :250 ## Median :4.000 Median :2.00 Quality :200 ## Mean :3.085 Mean :2.32 Style :350 ## 3rd Qu.:4.000 3rd Qu.:3.00 ## Max. :5.000 Max. :5.00 ## 发现什么问题没有？问卷调查回复Q1-Q10貌似合理，最小值都是1，最大值是5，因为问卷分值表是1-5。在实体店交易次数（store_trans）和在线交易次数（store_trans）看上去也合理。收入（income）有缺失值，处理缺失值的问题我们在下一小节会介绍。在线花销（online_exp）分布看上去没什么问题。实体店花销（store_exp）存在离群值，最大值有50000人民币，有个别受访者有着浓浓的土豪味。还有呢？大家可能已经发现其中有负值（最小值是－500），花销不可能是负数，这里你就要怀疑存在输入错误。类似的，age也存在不大可能的观测值，最大年龄是300，如果不是真的碰到青春期的千年老妖的话，这个年龄值应该是错误的。那怎么处理这些错误的值呢？取决于你的实际情况，如果你的样本量很大，不在乎这几个样本，可以删除这些不合理的值。在这里我们一共就1000个观测，而且问卷调查的数据在现实中通常都不容易获得，需要花费人力财力，故若因为其中某一个变量的值错误就将整个样本删去在此情况下有些可惜，所以我们可以将这些值设置成缺失状态，在下一步介绍缺失值处理的时候进行填补。 # 将错误的年龄观测设置为缺失值 sim.dat$age[which(sim.dat$age&gt;100)]&lt;-NA # 将错误的实体店购买观测设置为缺失值 sim.dat$store_exp[which(sim.dat$store_exp&lt;0)]&lt;-NA # 通过summary()函数检查清理情况 summary(subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot;))) ## age income ## Min. :16.00 Min. : 41776 ## 1st Qu.:25.00 1st Qu.: 85832 ## Median :36.00 Median : 93869 ## Mean :38.58 Mean :113543 ## 3rd Qu.:53.00 3rd Qu.:124572 ## Max. :69.00 Max. :319704 ## NA&#39;s :1 NA&#39;s :184 现在我们接着处理数据中的缺失值。 5.3 缺失值填补 缺失值填补是个大话题，单这一个就可以写本书。这里不会详细给大家介绍这个子领域，而是展示一些常用的缺失值处理方法，并且根据个人的工作经验对这些方法进行一些说明。对想进一步学习的读者，可以参考本小节中提到的相关参考资料。缺失值填补是对缺失的数据观测进行估计的过程。De Waal, Pannekoek和Scholtus的书[4]中第7章对现存的一些缺失值填补方法做了简洁的概述。具体填补方法的选择取决于你的实际应用情况：关于缺失数据你有哪些辅助信息（比如如果客户管理系统将没有购买的客户对应的购买量设置为缺失的话，那你就该用0填补），变量之间是不是有些相关性限制（比如关于是否有驾照信息的缺失就可能受到年龄的限制，如果某人年龄低于16周岁，那就不可能有驾照信息）。因为情况各不相同，所以没有某个方法永远比其它方法好。 决定处理缺失值的方法之前要先了解缺失的原因等关于缺失的辅助信息。缺失是随机发生的么？如果这样的话，可以用中位数/众数填补，也可以使用均值填补。或者缺失其实是有潜在发生机制的？比如年龄大的人在问卷调查中更不愿意透露年龄，这样关于年龄的缺失就不是随机发生的，如果用均值或者中位数填补可能产生很大偏差。这时需要利用年龄和其它自变量的关系对缺失的值进行估计。比如可以基于那些没有缺失值的数据，用是否有子女，收入，问卷调查的回复这些信息来对年龄建模，然后用拟合的模型来进行预测（如用树模型）。 此外，建模的目的对于选择缺失值填补方法也很重要。若建模目的是对传统统计模型结果进行解释和推断，那么仔细研究缺失机制，尽可能用非缺失信息建模来估计缺失值就显得尤为重要。相反，如果建模的目的是预测，大部分情况下不会很严格的研究缺失机制（缺失机制很明显的时候除外），在缺失机制不太清楚的情况下，可以当成随机缺失进行填补（使用均值，中位数或者用K-近邻）。由于统计推断对缺失值更加敏感，所以抽样调查统计学对各种缺失值填补方法进行了深入的研究，这些研究着重于有效的统计推断。而在预测模型中的缺失值填补的问题和抽样调查中的有所不同，因为预测模型的主要目的是预测而非推断。因此关于预测模型中的缺失值填补方面的研究文献没有传统抽样调查统计那么多。想深入学习这方面知识的读者可以参考Saar-Tsechansky 和 Provost对判别模型中不同缺失值方法的比较[5]。还有之前提到的De Waal, Pannekoek和Scholtus的书[4]。 5.3.1 中位数或众数填补 在假设随机缺失的情况下，一个常用的填补方法是可以用含有缺失观测变量的中位数（连续变量）或者众数（分类变量）填补缺失值。 imputeMissings包中的函数impute()可以实现这类填补。我们用该函数对sim.dat数据框填补缺失值： # 将填补后的数据存在另外一个数据框中 demo_imp&lt;-impute(sim.dat,method=&quot;median/mode&quot;) # 只检查前5列，因为后面没有缺失值 summary(demo_imp[,1:5]) ## age gender income house store_exp ## Min. :16.00 Female:554 Min. : 41776 No :432 Min. : 155.8 ## 1st Qu.:25.00 Male :446 1st Qu.: 87896 Yes:568 1st Qu.: 205.1 ## Median :36.00 Median : 93869 Median : 329.8 ## Mean :38.58 Mean :109923 Mean : 1357.7 ## 3rd Qu.:53.00 3rd Qu.:119456 3rd Qu.: 597.3 ## Max. :69.00 Max. :319704 Max. :50000.0 从上面输出可以看到，填补后的数据框demo_imp没有缺失值。这个方法简单迅速，在工作中经常使用。但其有一个缺点，单独对每个变量进行缺失值填补而没有考虑到变量之间的关系，因而有的时候不太准确，如果缺失的比例较大，且你的建模目的是统计推断，建议进一步研究变量之间的关系，发觉缺失机制，通过对缺失变量建模来进行填补。上面的例子中缺失变量都是数值变量，如果缺失变量是分类／因子变量的话，impute()函数会用众数进行填补。 你也可以用上面讲到的preProcess()函数进行中位数填补，但该函数只针对数值变量，不能对分类变量进行众数填补。由于这里含有缺失值的都是数值变量，可以使用preProcess()函数。得到的结果和之前impute()函数相同。preProcess()函数的功能很强大，你可以将其想象成连接各种数据预处理方法的接口，我们之后会介绍该函数其它数据预处理功能。 imp&lt;-preProcess(sim.dat,method=&quot;medianImpute&quot;) demo_imp2&lt;-predict(imp,sim.dat) summary(demo_imp2[,1:5]) ## age gender income house store_exp ## Min. :16.00 Female:554 Min. : 41776 No :432 Min. : 155.8 ## 1st Qu.:25.00 Male :446 1st Qu.: 87896 Yes:568 1st Qu.: 205.1 ## Median :36.00 Median : 93869 Median : 329.8 ## Mean :38.58 Mean :109923 Mean : 1357.7 ## 3rd Qu.:53.00 3rd Qu.:119456 3rd Qu.: 597.3 ## Max. :69.00 Max. :319704 Max. :50000.0 5.3.2 K-近邻填补 直观的讲，K-邻近方法（也称为KNN）就是“物以类聚”这一思想的统计学表达。如果某人留着海藻般的长发，喜欢安妮宝贝的“现世安稳，岁月静好”，一会明亮一会忧伤，问题是你要知道这个人喜欢什么样的鞋子怎么办？去看看其他那些留着同样长发喜欢同样句子又明亮又忧伤的人都穿什么鞋子，然后你很可能得出结论：此人喜欢棉布鞋。 技术上讲，K-近邻方法建立在距离的定义之上（通常时欧几里德距离），其基本思路是对于含有缺失值的样本，寻找该离样本最近的K个样本（邻居），然后用这些邻居的观测均值对该样本的缺失值进行填补。由于这里找邻居根据的是样本点之间的距离，各个变量的标度需要统一，不然尺度大的变量在决定距离上会占主导作用。 我们使用preProcess()实现KNN填补。 imp&lt;-preProcess(sim.dat,method=&quot;knnImpute&quot;,k=5) # 用predict()函数进行KNN填补 demo_imp&lt;-predict(imp,sim.dat) Error in `[.data.frame`(old, , non_missing_cols, drop = FALSE) : undefined columns selected 程序报错说“undefined columns selected（选择了无法定义的列）”。这是因为sim.dat中有函数无法处理的非数值型变量，在上面代码的第一行使用preProcess()时，函数会自动忽略非数值型变量，所以你运行第一行代码没有问题。但是在第二行代码，通过predict()函数对数据框进行KNN填补时，数据框有非数值变量就会导致填补无法进行。我们移除这些变量，再进行填补就没有问题了。 # 找到因子变量 imp&lt;-preProcess(sim.dat,method=&quot;knnImpute&quot;,k=5) idx&lt;-which(lapply(sim.dat,class)==&quot;factor&quot;) demo_imp&lt;-predict(imp,sim.dat[,-idx]) summary(demo_imp[,1:3]) ## age income store_exp ## Min. :-1.5910972 Min. :-1.43989 Min. :-0.43345 ## 1st Qu.:-0.9568733 1st Qu.:-0.53732 1st Qu.:-0.41574 ## Median :-0.1817107 Median :-0.37606 Median :-0.37105 ## Mean : 0.0000156 Mean : 0.02389 Mean :-0.00042 ## 3rd Qu.: 1.0162678 3rd Qu.: 0.21540 3rd Qu.:-0.27437 ## Max. : 2.1437770 Max. : 4.13627 Max. :17.52734 当前的例子中非数值型的变量只有因子，你在自己应用该方法时要注意是否还有字符型（character）变量。 lapply(data,class)命令可以返回一个数据框各列对应类别的列表，你只要将data换成你处理的数据框名即可。这里我们的数据框是sim.dat，于是你可以这样获得数据框各列的类别： # 这里只显示前3个元素 lapply(sim.dat,class)[1:3] ## $age ## [1] &quot;integer&quot; ## ## $gender ## [1] &quot;factor&quot; ## ## $income ## [1] &quot;numeric&quot; 将KNN填补的结果和之前中位数填补结果进行比较大家发现什么了？结果好像完全不一样。KNN返回的数据框整个尺度都变了。这是因为当你告诉preProcess()函数进行KNN填补时（选项method=&quot;knnImpute&quot;），函数会自动对数据进行标准化（下一小节将提到的中心化和标量化）。另外一种方法是使用下一小节中介绍的袋状树填补。关于KNN填补还有一点需要注意，算法无法对整行缺失的观测进行填补。这个并不难从直观上理解，既然改算法是通过邻近点的取值平均来填补，如果某一样本所有值都缺失，那怎么定义该样本的邻近点呢？下面我们在原数据框上添加一个所有观测都缺失的样本，将这个新的数据框储存在temp对象中，然后对temp进行KNN填补，看看会发生什么： temp&lt;-rbind(sim.dat,rep(NA,ncol(sim.dat))) imp&lt;-preProcess(sim.dat,method=&quot;knnImpute&quot;,k=5) idx&lt;-which(lapply(temp,class)==&quot;factor&quot;) demo_imp&lt;-predict(imp,temp[,-idx]) Error in FUN(newX[, i], ...) : cannot impute when all predictors are missing in the new data point 运行结果中有错误警告“cannot impute when all predictors are missing in the new data point（当样本对应的所有观测都缺失时无法填补）”。我们在拿到数据的时可以查找并删除这些完全缺失的样本。我们可以通过下面代码找到这样的行： idx&lt;-apply(temp,1,function(x) sum(is.na(x)) ) as.vector(which(idx==ncol(temp))) ## [1] 1001 结果显示第1001行所有的观测都缺失。你可以进一步删除所有观测都缺失的行。 5.3.3 袋状树填补 另外一种填补方法是装袋树（Bagging，bootstrap aggregation 的缩写），最初由 Leo Breiman 提出，它是最早发展起来的集成方法之一[6]。对于数据中需要填补的变量，我们使用剩下的变量训练装袋树，然后再用训练出的树来对缺失值进行预测。虽然理论上说该方法更加强大，但计算量比KNN大了许多。在实际应用中，你一定要根据自己的具体情况选择填补的方式。因为你可以不断的探索使用理论上更加精确的填补方式，但也要考虑在这上面花的时间成本是不是值得，如果一个中位数，或者均值填补就可以满足建模需要，即使用袋状树填补可以提高些许精度，但是提升很可能非常小，没有太大的实际意义，尤其在样本量很大的时候。袋状树本身就是一个模型，可以用于回归和判别，我们之后在介绍树相关的方法时会进一步介绍。下面我们用preProcess()对数据框sim.dat进行袋状树填补。 imp&lt;-preProcess(sim.dat,method=&quot;bagImpute&quot;) demo_imp&lt;-predict(imp,sim.dat) summary(demo_imp[,1:5]) age gender income house store_exp Min. :16.00 Female:554 Min. : 41776 No :432 Min. : 155.8 1st Qu.:25.00 Male :446 1st Qu.: 86762 Yes:568 1st Qu.: 205.1 Median :36.00 Median : 94739 Median : 329.0 Mean :38.58 Mean :114629 Mean : 1357.6 3rd Qu.:53.00 3rd Qu.:123726 3rd Qu.: 597.3 Max. :69.00 Max. :319704 Max. :50000.0 5.4 中心化和标量化 这是最基本的数据变换。中心化是通过将变量的每个观测减去该变量均值，这样中心化后的变量观测均值为0。标量化是将变量观测除以变量标准差，标量化后的变量标准差为1。对于一些要对变量进行线性组合的模型，中心化和标量化保证了变量的线性组合是基于组合后的新变量能够解释的原始变量中的方差。统计学上的方差，从直观的角度讲就是信息。试想若上面的消费者数据中，所有人的在线交易次数都是相同的，那么在线交易次数这个变量方差就是0，从应用的角度这个变量没有给我们提供可以区分这些消费者的信息。用到基于方差的变量线性组合的模型有主成分分析（PCA）[7]，偏最小二乘分析（PLS）[8]，探索性因子分析（EFA）[9]等等。这两个变换可以很容易自己编写程序实施，我们以服装装消费者数据（sim.dat）中的收入（income）变量为例： income&lt;-sim.dat$income # 变量income的均值，na.rm=T告诉R忽略缺失值 mux&lt;-mean(income,na.rm=T) # 变量income的标准差，na.rm=T告诉R忽略缺失值 sdx&lt;-sd(income,na.rm=T) # 中心化 tr1&lt;-income-mux # 标量化 tr2&lt;-tr1/sdx 上面代码中，tr1是income中心化后的结果。tr2是对中心化后的结果tr1进一步标量化的结果。下面是关于这三步分别得到结果的总结： summary(data.frame(cbind(income,tr1,tr2))) ## income tr1 tr2 ## Min. : 41776 Min. :-71767 Min. :-1.4399 ## 1st Qu.: 85832 1st Qu.:-27711 1st Qu.:-0.5560 ## Median : 93869 Median :-19674 Median :-0.3947 ## Mean :113543 Mean : 0 Mean : 0.0000 ## 3rd Qu.:124572 3rd Qu.: 11029 3rd Qu.: 0.2213 ## Max. :319704 Max. :206161 Max. : 4.1363 ## NA&#39;s :184 NA&#39;s :184 NA&#39;s :184 可以看到，中心化后的tr1均值为0，但取值跨度依旧很大。接着标量化后的tr2就是一个均值为0，标准差为1的向量。 你也可以直接用caret包中的函数preProcess()对多个变量同时进行中心化和标量化，这里我选取其中2个变量进行展示： sdat&lt;-subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot;)) # method选项用于设置变换的方式，你可以同时进行一系列变换。 # center：中心化 # scale：标量化 trans&lt;-preProcess(sdat,method=c(&quot;center&quot;,&quot;scale&quot;)) # preProcess函数的给出的还不是变换后的结果 # 你需要通过predict函数对你想要变换的数据应用preProcess的结果才能够得到变换后的数据框 transformed&lt;-predict(trans,sdat) 变换后这两个变量就分布在相似的尺度上： summary(transformed) ## age income ## Min. :-1.5911 Min. :-1.4399 ## 1st Qu.:-0.9569 1st Qu.:-0.5560 ## Median :-0.1817 Median :-0.3947 ## Mean : 0.0000 Mean : 0.0000 ## 3rd Qu.: 1.0163 3rd Qu.: 0.2213 ## Max. : 2.1438 Max. : 4.1363 ## NA&#39;s :1 NA&#39;s :184 有时只要标量化数据而不一定要中心化。例如，如果模型中有针对参数估计绝对值的罚函数和且通过调优参数来进行变量选择（如LASSO）的话，变量大体在一个量级范围内使得能确保对参数“公平”的变量选择。之后在对于收缩方法（shrinkage method）的介绍能够帮助你更清楚的理解这一点。当然，如果你要通过参数估计衡量各个自变量和应变量之间关系强度的话，必须要对变量观测标量化。我是收缩方法的重度使用者，在工作中，我针对自己的分析项目设计了下面这种变换方式，该方式对我处理的问题非常有效，称其为分位数变换吧： \\[\\label{eq:quantile1} x_{ij}^{*}=\\frac{x_{ij}-quantile(x_{.j},0.01)}{quantile(x_{.j}-0.99)-quantile(x_{.j},0.01)}\\] 这里\\(x_{ij}\\)代表第i个样本的第j个变量观测，\\(quantile(x_{.j},0.01)\\)指的是第j个变量所有样本观测组成的向量的1%分位数，类似的\\(quantile(x_{.j},0.99)\\)是99%分位数，的这里之所以使用99%和1%分位数，而非最大值和最小值是为了减弱离群点的影响。编写函数进行分位数变换 非常容易： qscale&lt;-function(dat){ for (i in 1:ncol(dat)){ up&lt;-quantile(dat[,i],0.99) low&lt;-quantile(dat[,i],0.01) diff&lt;-up-low dat[,i]&lt;-(dat[,i]-low)/diff } return(dat) } 这里我们对中位数填补后的数据集demo_imp2中的变量收入（income），实体店消费（store_exp）和在线消费（online_exp）进行上面的分位数变换： demo_imp3&lt;-qscale(subset(demo_imp2,select=c(&quot;income&quot;,&quot;store_exp&quot;,&quot;online_exp&quot;))) summary(demo_imp3) ## income store_exp online_exp ## Min. :-0.05776 Min. :-0.003407 Min. :-0.006023 ## 1st Qu.: 0.15736 1st Qu.: 0.003984 1st Qu.: 0.042719 ## Median : 0.18521 Median : 0.022704 Median : 0.253691 ## Mean : 0.26009 Mean : 0.176965 Mean : 0.278417 ## 3rd Qu.: 0.30456 3rd Qu.: 0.062849 3rd Qu.: 0.322871 ## Max. : 1.23857 Max. : 7.476996 Max. : 1.298845 变换后的变量取值基本分布在0-1的范围之内。 5.5 有偏分布 如果模型要求变量服从一定的对称分布（如正态分布）时，则需要进行数据变换去除分布的偏度。偏度是3阶标准化中心矩，是用来衡量分布不对称程度的，该统计量的数学定义如下： \\[偏度=\\frac{\\sum(x_{i}+\\bar{x})^{3}}{(n-1)v^{3/2}}\\] \\[v=\\frac{\\sum(x_{i}=\\bar{x})^{2}}{(n-1)}\\] # 需要使用e1071包中的偏度计算函数skewness() set.seed(1000) par(mfrow=c(1,2),oma=c(2,2,2,2)) # 抽取1000个自由度为2的开方分布，右偏分布 x1&lt;-rchisq(1000,2, ncp = 0) # 通过x1得到对应的左偏分布变量x2 x2&lt;-max(x1)-x1 plot(density(x2),family =&quot;Songti SC&quot;,main=paste(&quot;左偏，偏度＝&quot;,round(skewness(x2),2)), xlab=&quot;X2&quot;) plot(density(x1),family =&quot;Songti SC&quot;,main=paste(&quot;右偏，偏度＝&quot;,round(skewness(x1),2)), xlab=&quot;X1&quot;) Figure 5.1: 有偏分布展示 分布是否有偏可以很容易从图上看到。图5.1显示了两种类型的不对称分布。分布对称时偏度=0，分布左偏时偏度&lt;0，分布右偏时偏度&gt;0，且偏离程度越大，偏度统计量的绝对值越大。有很多变换有助于去除偏度，如log变换，平方根或者取倒数。但是仅仅靠观察图形无法知道哪种变换方法最好。大家有没有注意到，常用的一些变换都和指数函数有关，如 \\(log(x)\\)（这个是对数函数，但也是指数函数的近亲嘛：））、\\(x^2\\) 和 \\(\\frac{1}{x}\\)。于是Box和Cox（1964）[10]提出了含有一个参数\\(\\lambda\\)的指数变换族： \\[x^{*}=\\begin{cases} \\begin{array}{c} \\frac{x^{\\lambda}-1}{\\lambda}\\\\ log(x) \\end{array} &amp;amp; \\begin{array}{c} if\\ \\lambda\\neq0\\\\ if\\ \\lambda=0 \\end{array}\\end{cases}\\] 很容易看出这个变换族群包含了\\(log(x)\\)变换（\\(\\lambda\\)=0），\\(x^2\\)变换（\\(\\lambda\\)=2），\\(sqrt(x)\\)变换（\\(\\lambda\\)=0.5）以及\\(frac{1}{x}\\)变换（\\(\\lambda\\)=-1）等常用的变换。Box-Cox覆盖的面更加广，变换指数可能是任意实数。caret包中有两个函数可以进行该变换，一个是BoxCoxTrans()。另外一个是我们之前用到的preProcess()，这里推荐大家使用后者，因为我们可以通过更改其中method选项对数据进行不同的变换，可以把该函数看作是不同预处理方法的接口，熟练使用后大家会发现其功能强大且及其方便。这里给大家插播一则广告，关于psych包中的describe()函数。我很喜欢用这个函数来在处理数据的不同阶段检查各个变量的情况，偏度，峰度，是不是可能有离群值，取值范围，均值等等，这个函数比summary()好用多了。当然这因人而异，有的人喜欢通过散点图矩阵来看各个变量的分布情况，个人还是喜欢看变量分布的各个统计量。 describe(sim.dat) ## vars n mean sd median trimmed mad ## age 1 999 38.58 14.19 36.00 37.67 16.31 ## gender* 2 1000 1.45 0.50 1.00 1.43 0.00 ## income 3 816 113543.07 49842.29 93868.68 104841.94 28989.47 ## house* 4 1000 1.57 0.50 2.00 1.58 0.00 ## store_exp 5 999 1358.71 2775.17 329.80 845.14 197.47 ## online_exp 6 1000 2120.18 1731.22 1941.86 1874.51 1015.21 ## store_trans 7 1000 5.35 3.70 4.00 4.89 2.97 ## online_trans 8 1000 13.55 7.96 14.00 13.42 10.38 ## Q1 9 1000 3.10 1.45 3.00 3.13 1.48 ## Q2 10 1000 1.82 1.17 1.00 1.65 0.00 ## Q3 11 1000 1.99 1.40 1.00 1.75 0.00 ## Q4 12 1000 2.76 1.16 3.00 2.83 1.48 ## Q5 13 1000 2.94 1.28 4.00 3.05 0.00 ## Q6 14 1000 2.45 1.44 2.00 2.43 1.48 ## Q7 15 1000 3.43 1.46 4.00 3.54 0.00 ## Q8 16 1000 2.40 1.15 2.00 2.36 1.48 ## Q9 17 1000 3.08 1.12 4.00 3.23 0.00 ## Q10 18 1000 2.32 1.14 2.00 2.27 1.48 ## segment* 19 1000 2.70 1.15 3.00 2.75 1.48 ## min max range skew kurtosis se ## age 16.00 69.00 53.00 0.47 -1.18 0.45 ## gender* 1.00 2.00 1.00 0.22 -1.95 0.02 ## income 41775.64 319704.34 277928.70 1.69 2.57 1744.83 ## house* 1.00 2.00 1.00 -0.27 -1.93 0.02 ## store_exp 155.81 50000.00 49844.19 8.08 115.04 87.80 ## online_exp 68.82 9479.44 9410.63 1.18 1.31 54.75 ## store_trans 1.00 20.00 19.00 1.11 0.69 0.12 ## online_trans 1.00 36.00 35.00 0.03 -0.98 0.25 ## Q1 1.00 5.00 4.00 -0.12 -1.36 0.05 ## Q2 1.00 5.00 4.00 1.13 -0.32 0.04 ## Q3 1.00 5.00 4.00 1.06 -0.40 0.04 ## Q4 1.00 5.00 4.00 -0.18 -1.46 0.04 ## Q5 1.00 5.00 4.00 -0.60 -1.40 0.04 ## Q6 1.00 5.00 4.00 0.11 -1.89 0.05 ## Q7 1.00 5.00 4.00 -0.90 -0.79 0.05 ## Q8 1.00 5.00 4.00 0.21 -1.33 0.04 ## Q9 1.00 5.00 4.00 -0.68 -1.10 0.04 ## Q10 1.00 5.00 4.00 0.39 -1.23 0.04 ## segment* 1.00 4.00 3.00 -0.20 -1.41 0.04 大家可以很清楚的看到哪些变量有偏（skew），通过比较均值（mean）和修剪后的均值（trimmed），大概知道哪些变量可能存在离群值。修剪后的均值是去除最大和最小的一部分观测点后得出的均值。这两个值差距很大说明对应变量存在离群点，这里很明显在线消费（store_exp）存在离群点。 下面我们以数据集sim_dat中的变量store_trans和online_trans为例展示Box-Cox变换函数的使用方法： # 选取需要的两列，存在dat_bc中 dat_bc&lt;-subset(sim.dat,select=c(&quot;store_trans&quot;,&quot;online_trans&quot;)) (trans&lt;-preProcess(dat_bc,method=c(&quot;BoxCox&quot;))) ## Created from 1000 samples and 2 variables ## ## Pre-processing: ## - Box-Cox transformation (2) ## - ignored (0) ## ## Lambda estimates for Box-Cox transformation: ## 0.1, 0.7 上面的输出的第一行显示了样本量是1000，有2个变量。输出的最后一行表明每个变量对应的参数\\(\\lambda\\)估计值（0.1和0.7）。和之前一样，我们接着用predict()函数对数据框应用估计的变换： transformed&lt;-predict(trans,dat_bc) par(mfrow=c(1,2),oma=c(2,2,2,2)) hist(dat_bc$store_trans,main=&quot;原始商店消费次数&quot;,xlab=&quot;store_trans&quot;,family =&quot;Songti SC&quot;) hist(transformed$store_trans,main=&quot;变换后商店消费次数&quot;,xlab=&quot;store_trans&quot;,family =&quot;Songti SC&quot;) Figure 5.2: Box-Cox变换展示 从图5.2可以看到，变换前商店消费量分布明显右偏，变换后情况显著改善，基本对称。BoxCoxTrans() 也可以进行Box-Cox变换，使用方法类似。但要注意的是BoxCoxTrans()只能作用于单个数值变量，不能像之前那样对一个数据框中的列一次性进行变换。 (trans&lt;-BoxCoxTrans(dat_bc$store_trans)) ## Box-Cox Transformation ## ## 1000 data points used to estimate Lambda ## ## Input data summary: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 3.00 4.00 5.35 7.00 20.00 ## ## Largest/Smallest: 20 ## Sample Skewness: 1.11 ## ## Estimated Lambda: 0.1 ## With fudge factor, Lambda = 0 will be used for transformations transformed&lt;-predict(trans,dat_bc$store_trans) skewness(transformed) ## [1] -0.2154708 参数\\(\\lambda\\)的估计和之前相同（0.1），原始观测的偏度为1.1，变换后偏度为－0.2，虽然不严格为0，但和之前比较有极大改善，可以用来计算变量间线性相关性，用于回归等。 5.6 处理离群点 有时判断离群点并不是那么容易，因为没有一个非黑即白的标准。箱线图和直方图等一些基本的可视化可以用来初步检查是否有离群点。举个例子，我们可以对服装消费者数据中的数值型非问卷调查变量进行可视化： # 选取数值型非问卷调查变量 sdat&lt;-subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot;,&quot;store_exp&quot;,&quot;online_exp&quot;,&quot;store_trans&quot;,&quot;online_trans&quot; )) # 用car包中的函数scatterplotMatrix()绘制散点图矩阵 par(oma=c(2,2,1,2)) scatterplotMatrix(sdat,diagonal=&quot;boxplot&quot;,smoother=FALSE) Figure 5.3: 数值型非问卷调查变量散点图矩阵 从图5.3，商店消费量（store_exp）明显有离群点（记得之前的土豪么）。你也可以从中看到一些变量两两之间的关系。年龄和在线交易次数负相关，但和实体店交易次数正相关，貌似年纪大的人更倾向于实体店购买。当然，还有消费量和收入正相关。这样的散点图简单但是有效，可以在建模之前告诉你很多关于数据的信息。 除了可视化这样直观的方式外，在一定的假设条件下，有一些统计学的定义离群值的方法。如常用Z分值来判断可能的离群点。对于某观测变量\\(\\mathbf{Y}\\)的Z分值定义为： \\[Z_{i}=\\frac{Y_{i}-\\bar{Y}}{s}\\] 其中\\(\\bar{Y}\\)和\\(s\\)分别为观测列的均值和标准差。直观的理解Z分值就对观测离均值的距离的度量（多少个标准差单位）。这种方法可能具有误导性，尤其是在样本量小的时候。Iglewicz和Hoaglin提出使用修正后的Z分值来判断离群点[11]： \\[M_{i}=\\frac{0.6745(Y_{i}-\\bar{Y})}{MAD}\\] 其中MAD是一系列\\(|Y_{i}-\\bar{Y}|\\)的中位数，称为绝对离差中位数。他们建议将上面修正后的Z分值大于3.5的点标记为可能的离群点。我们来检查下商店消费量观测对应的Z分值： # 计算商店消费量的绝对离差中位数，这里用na.omit()告诉R忽略缺失值 ymad&lt;-mad(na.omit(sdat$income)) # 计算Z分值 zs&lt;-(sdat$income-mean(na.omit(sdat$income)))/ymad # 看看有多少个离群点 sum(na.omit(zs&gt;3.5)) ## [1] 59 用该标准，商店消费量对应的离群点有59个。关于离群点还有其它不同的检测。更多关于不同检测方法可以参考[11]。 很重要的一点是离群点的影响取决于你使用的模型。有的模型对离群值很敏感，如线性回归，逻辑回归。有的对离群点具有抗性，如基于树的模型，支持向量机。此外离群点和错误的观测不一样，它是真实的观测，其中包含信息，所以不能随意的删除。如果你使用的模型对离群点非常敏感，可以使用空间表示变换[12]。该变换将自变量取值映射到高维的球面上。变换公式如下： \\[x_{ij}^{*}=\\frac{x_{ij}}{\\sqrt{\\sum_{j=1}^{p}x_{ij}^{2}}}\\] 其中\\(x_{ij}\\)表示第i个样本对应第j个变量的观测。由公式可见，每个样本都除以了它们的平方模。公式的分母其实可以看作是该样本到p维空间0点的欧几里德距离，有三点需要特别注意： 在该变换前需要对自变量标准化 与中心化和标准化不同，这个变换操作的对象是所有自变量 如果需要移除变量（之后会提到移除高度相关变量），这一步必须要在空间表示变换之前，否者会导致一系列问题 作为例子，我们用caret包中的spatialSign()函数对收入和年龄两个变量进行空间表示变换： # 用KNN填补缺失值 sdat&lt;-sim.dat[,c(&quot;income&quot;,&quot;age&quot;)] imp&lt;-preProcess(sdat,method=c(&quot;knnImpute&quot;),k=5) sdat&lt;-predict(imp,sdat) transformed &lt;- spatialSign(sdat) transformed &lt;- as.data.frame(transformed) par(mfrow=c(1,2),oma=c(2,2,2,2)) plot(income ~ age,data = sdat,col=&quot;blue&quot;,main=&quot;变换前&quot;,family =&quot;Songti SC&quot;) plot(income ~ age,data = transformed,col=&quot;blue&quot;,main=&quot;变换后&quot;,family =&quot;Songti SC&quot;) Figure 5.4: 空间表示变换图 细心的读者可能已经发现，上面的代码中貌似并没有对数据进行标准化。如果你还记得，在介绍KNN填补的时候讲过，preProcess()在进行KNN的同时默认会对数据框进行标准化，所以上面代码没有特地标准化数据。 5.7 共线性 共线性可能是大多数地球人都听过的一个词了，即使在传统企业市场部的营销人员都知道这个词，这也可能是他们唯一可以拿出来显摆的技术词汇。关于变量间的相关性，有个非常好用的包corrplot，其中同名函数corrplot()能够对变量相关矩阵进行可视化。函数中有一个选项可以设置变量的排序方式，使得相关性高的变量排列在一起。和之前一样，我们选取其中数值类的非问卷调查变量为例子，展示如何使用该函数探索变量之间共线性： # 选取数值型非问卷调查变量 sdat&lt;-subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot;,&quot;store_exp&quot;,&quot;online_exp&quot;,&quot;store_trans&quot;,&quot;online_trans&quot; )) # 用装袋树填补，换着用，帮大家练练手：） imp&lt;-preProcess(sdat,method=&quot;bagImpute&quot;) sdat&lt;-predict(imp,sdat) # 得到相关矩阵 correlation&lt;-cor(sdat) # 对相关矩阵作图 par(oma=c(2,2,2,2)) corrplot.mixed(correlation,order=&quot;hclust&quot;,tl.pos=&quot;lt&quot;,upper=&quot;ellipse&quot;) Figure 5.5: 相关矩阵可视化 这里我们使用的是corrplot.mixed()函数对相关矩阵可视化（图5.5）。其中相关性越接近0颜色越浅且形状越接近圆，相关性不等于0的用椭圆表示（因为我们设置了选项upper=“ellipse”），相关性越大椭圆越窄，蓝色代表正相关，红色代表负相关，椭圆的方向也随着相关性正负变化。 相关系数在矩阵的下三角显示。可以看到，我们之前在散点图矩阵（图5.3）中看到的变量相关性在这里很明显的展现出来，年龄和在线购物次数负相关，消费量和收入正相关。且有些线性相关性非常强（online_trans和age的相关系数是－0.85）。这会导致什么问题呢？这其实很容易理解，两个变量高度相关意味着它们含有重复的信息，我们其实不需要讲两个变量同时留在模型中。你可能会问，那重复未必有害处不是么？变量高度相关会倒是参数估计极为不稳定。举个例子，我们可以对收入进行简单的线性回归： cfit1&lt;-lm(income~age+online_trans+store_exp+store_trans,data=sdat) summary(cfit1) ## ## Call: ## lm(formula = income ~ age + online_trans + store_exp + store_trans, ## data = sdat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -183840 -14126 -914 10944 156106 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 67790.0372 8640.8338 7.845 1.11e-14 *** ## age 221.5832 135.9644 1.630 0.103 ## online_trans -270.9619 249.5672 -1.086 0.278 ## store_exp 5.7269 0.4356 13.147 &lt; 2e-16 *** ## store_trans 6399.5252 357.8722 17.882 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 31650 on 995 degrees of freedom ## Multiple R-squared: 0.5763, Adjusted R-squared: 0.5746 ## F-statistic: 338.3 on 4 and 995 DF, p-value: &lt; 2.2e-16 大家可以看到，年龄和在线购买的方差都比较大。因为这两个变量高度相关，模型也拿不准到底该如和分配这两个变量的系数。下面我们将年龄（age）删除，再进行一次回归： cfit2&lt;-lm(income~online_trans+store_exp+store_trans,data=sdat) summary(cfit2) ## ## Call: ## lm(formula = income ~ online_trans + store_exp + store_trans, ## data = sdat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -182372 -14498 -1179 11127 156121 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 80861.0786 3217.6962 25.130 &lt; 2e-16 *** ## online_trans -606.4452 141.2126 -4.295 1.92e-05 *** ## store_exp 5.6427 0.4329 13.035 &lt; 2e-16 *** ## store_trans 6425.0185 357.8273 17.956 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 31670 on 996 degrees of freedom ## Multiple R-squared: 0.5752, Adjusted R-squared: 0.5739 ## F-statistic: 449.5 on 3 and 996 DF, p-value: &lt; 2.2e-16 比较cfit1和cfit2中online_trans对应的系数估计之间巨大的变化，就可以很容易看出高度共线的变量同时出现在回归模型中对参数估计可能带来的影响了。于此同时store_exp和store_trans的参数估计在两个结果中差异不大。所以我们在进行回归之前需要移除一些高度相关的变量，使得模型中变量相关性在一定范围之内。我个人比较喜欢用《应用预测模型》[13]书中3.5小节中展示的算法，其核心思想是在删除尽可能少的变量的情况下将变量两两相关性控制在人为设定的一个阈值内： 算法：处理高度相关变量 计算自变量的相关系数矩阵 找出相关系数绝对值最大的那对自变量（记为自变量A和B） 计算A和其他自变量相关系数的均值。对B也做同样的计算 如果A的平均相关系数更大，则将A移除；如若不然，移除B 重复步骤2到4，直至所有相关系数的绝对值都低于设定的阈值 caret中的findCorrelation()函数能够实施上面的算法： (highCorr&lt;-findCorrelation(cor(sdat),cutoff=.75)) ## [1] 1 结果返回的是需要删除的列号，这里算法告诉我们若要使得变量相关性在0.75内，需要删除第1列。 # 将高相关的变量删除 sdat&lt;-sdat[-highCorr] # 查看新的相关矩阵 cor(sdat) ## income store_exp online_exp store_trans online_trans ## income 1.0000000 0.6004006 0.5198623 0.7069595 -0.3572884 ## store_exp 0.6004006 1.0000000 0.5349527 0.5399121 -0.1367411 ## online_exp 0.5198623 0.5349527 1.0000000 0.4420638 0.2256370 ## store_trans 0.7069595 0.5399121 0.4420638 1.0000000 -0.4367544 ## online_trans -0.3572884 -0.1367411 0.2256370 -0.4367544 1.0000000 移除变量后相关矩阵中元素的绝对值都低于0.75。这里需要提醒大家一点，关于这个相关性阈值的选取强烈建议大家将这个阈值成一个调优参数，试验不同的值，看哪个对应的模型精度最高。建议在0.6-0.8范围内寻找最优的阈值。关于共线性的处理还有一些其它方法，如主成分分析和因子分析，这些方法我们将在特征工程那一章进行讲解。 5.8 稀疏变量 除了高度相关的变量以外，我们还需要移除那些观测非常稀疏的变量。一个极端的例子是某变量观测只有一个取值，我们可以将其称为0方差变量。有的可能只有若干取值，我们称其为近0方差变量。这里所讲的处理稀疏变量的方法无法解决大规模基因表达研究中的问题，在基因表达研究中的一个常见问题是观测少，同时变量数目远远超过观测，几乎所有变量都很稀疏，这种情况下需要很多新的高维模型，这是当前非常活跃的一个研究领域，但这不在本书讨论范围之内。这里讨论情况是由于各种原因，出现某些稀疏变量的情况。我们需要做的是识别这些变量然后将其删除。这些变量的存在对如线性回归和逻辑回归这样的模型拟合的表现和稳定性会有很大影响，但决策树模型没有影响。 通常识别这样的变量有两个法则： 不同取值数目和样本量的比值 最常见的取值频数和第二常见的取值频数之间的比值 我们可以设定上面的规则，然后用caret包中的nearZeroVar()函数过滤近0方差变量。为了展示该方法，我们在数据中加入一些这样的变量，然后应用该函数查找它们： # 先备份数据 zero_demo&lt;-sim.dat # 加上两个稀疏变量 # zero1 的取值全是1 # zero2 除了第一个元素是1以外其余全是0 zero_demo$zero1&lt;-rep(1,nrow(zero_demo)) zero_demo$zero2&lt;-c(1,rep(0,nrow(zero_demo)-1)) 上面代码中我们生成了两个新的变量（zero1和zero2），它们分别为0方差和近0方差变量，然后将这两个变量添加到数据框zero_demo上。 nearZeroVar(zero_demo,freqCut = 95/5, uniqueCut = 10) 我们将函数nearZeroVar()应用在含有稀疏变量的数据框上，和之前查找高共线性变量一样，函数返回的是稀疏变量对应的列号。这里返回的是我们生成的两个稀疏变量所在的列。你可以接下来删除这两列。注意这里的两个选项分别对应我们上面提到的两个定义稀疏变量的标准。uniqueCut =是不同取值数目和样本量的比值； freqCut =是最常见的取值频数和第二常见的取值频数之间的比值。你可以根据具体情况提高或者降低这些标准。一个很自然的问题是该怎么选？你要是在这个行业久了就会发现，即使是这样一个和数学相关的技术性行业，非黑即白的事情也是很少存在的。目前为止在我看来（我也还在这个领域不停的学习），所有关于标准，参数，模型选择的问题，最好的答案只有一个，看哪种选择能帮你达成建模目标。比如你的建模目标预测，那你就要看看不同选择下给出的预测精度哪个更高。这个标准甚至超过的p值， AIC等等一堆统计学的测量。我们在下一章讨论建模技术的时候会进一步展开。 5.9 编码名义变量 名义变量，又称虚设变量，是一个指标性质的变量，通常取值0或1。有时你需要将分类变量转化成名义变量。比如一些问卷调查每个问题都有A,B,C,D,E五个选项，你得到数据后通常要将每个问题对应的分类变量转化成5个名义变量，然后将其中一个选项当作基准选项。我们在介绍逻辑回归及其衍生模型的那节中会展示一个这样的案例分析。我们还是用服装消费者的数据为例，假设我们要将性别（gender）和房产拥有情况（house）这两个变量转化为名义变量，R中有两个函数可以进行这项操作，nnet包中的｀class.ind()｀函数，但该函数有个局限是一次只能处理一个变量： dumVar&lt;-class.ind(sim.dat$gender) head(dumVar) ## Female Male ## [1,] 1 0 ## [2,] 1 0 ## [3,] 0 1 ## [4,] 0 1 ## [5,] 0 1 ## [6,] 0 1 我们可以看到性别这个变量被重新编码为2个名义变量，你在建模时需要删除其中一个，因为它们之间有重复信息（正常情况下非男即女嘛）。这样在分类变量多的时候得写个循环来进行重新编码还是有些麻烦。另外一个更加方便的方法是caret包（功能强大的包，简直是居家旅行必备神器！）中的dummyVars() 函数： dumMod&lt;-dummyVars(~gender+house+income, data=sim.dat, # 用原变量名加上因子层级的名称作为新的名义变量名 levelsOnly=F) head(predict(dumMod,sim.dat)) ## gender.Female gender.Male house.No house.Yes income ## 1 1 0 0 1 120963.4 ## 2 1 0 0 1 122008.1 ## 3 0 1 0 1 114202.3 ## 4 0 1 0 1 113616.3 ## 5 0 1 0 1 124252.6 ## 6 0 1 0 1 107661.5 dummyVars()可以用类似模型公式的表达方式对任何变量同时进行转化。而且公式右边不一定要是分类变量，你发现我将收入（income）这个变量也加上去了，对于数值型变量，函数会保持原变量，这样的好处在于你不需要特地选定其中的因子变量，转换后再添加到原数据框上，还要删除原变量，省去了很多麻烦。不仅仅如此，该函数还可以添加交互效应，比如： dumMod&lt;-dummyVars(~gender+house+income+income:gender, data=sim.dat, levelsOnly=F) head(predict(dumMod,sim.dat)) ## gender.Female gender.Male house.No house.Yes income ## 1 1 0 0 1 120963.4 ## 2 1 0 0 1 122008.1 ## 3 0 1 0 1 114202.3 ## 4 0 1 0 1 113616.3 ## 5 0 1 0 1 124252.6 ## 6 0 1 0 1 107661.5 ## gender.Female:income gender.Male:income ## 1 120963.4 0.0 ## 2 122008.1 0.0 ## 3 0.0 114202.3 ## 4 0.0 113616.3 ## 5 0.0 124252.6 ## 6 0.0 107661.5 这里，如果你觉得男性中收入水平对行为的影响和女性收入水平对行为的影响不一样，女性高收入的人在服装购买上大花销更大，而男性收入高低对服装花销影响不大，这就要检测收入和性别的交互效应，可以在公式中加入income:gender得到交互效应编码。是不是很方便？ 到目前为止，我们讲了几种常用的数据预处理方式，这些处理的目的是为了得到我们在本章开始所讲的可以用于模型的数据。本章的最后一部分想讲讲一些数据整合的方法。数据整合可能用在任何一个阶段，可能数据行列安排的方式不符合建模要求，或者之后的数据展示需要对比不同的群体，这些都涉及到数据整合。下面我介绍一些自己工作中常用到的数据整合方法。 5.10 本章总结 本章介绍了常用的建模前的数据预处理方法。需要补充一点，这里我没有讲到是连续变量的离散化，也称为区间化自变量。比如将年龄转变为由&lt;25，25-40，40-60和&gt;60组成的分类变量。个人不赞成分析师自行将连续变量离散化，如果客户或相关领域专家给出明确的理由，在该领域这么划分是通常惯例，或者只有划分成某种区间模型结果才能够解释，那么你可以根据对方的观点划分。而从分析的角度，手动区间化连续型数据是不推荐的。连续变量的效能通常比区间变量高。你需要权衡将连续变量离散化对可解释性的提升和对模型精确度的损害。注意这里指的是人为主观的将一些连续变量转变为分类变量而非模型检测出的截断点。有一些模型，如分类/回归树和多元自适性回归样条，它们在建模过程中能够估计合适的截断点。这些模型使用了所有自变量的信息，对不同变量进行评估，使用可靠的统计方法，并且是基于某个准则（我们在下一章会讲到）来得到合适的区间划分。这样的划分是可以的，但这属于建模，而非数据预处理。 下面总结一下通常情况下得到技术上正确的数据（对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据）后需要经历的数据预处理流程： 检查数据：变量分布，是不是存在错误的观测 缺失值填补：了解缺失原因，选择填补方式 数据变换：取决于需要建立的模型，对不符合正态分布假设，变量尺度差异大，有离群值的数据进行变换 检查共线性：找到高度线性相关的变量，决定删除变量，还是使用PCA，CFA这类非监督方法得到不相关的变量线性组合 稀疏变量：查找并且删除稀疏变量 编码名义变量：对于不能作用于分类变量的模型，将分类变量转化成0/1名义变量 我们将在下一章介绍一些数据整合和整形的方法，以及R中能够进行高效数据操作的包。得到可以用于模型的数据后，接下来就该进入建模阶段了。 References "],
["section-6.html", "第6章 数据操作 6.1 数据读写 6.2 数据整合 6.3 数据整形 6.4 本章总结", " 第6章 数据操作 这章专门介绍一些经常用到的有效数据操作方法，展示如何用R实现。在进行分析之前用描述统计量（均值，标准差等等）和数据可视化总结探索数据集很重要，在分析之后对结果进行总结也很重要，此外我们还经常需要对数据的格式和排列方式进行变换，使得数据结构符合模型的要求。这里默认读者已经熟悉一些传统的R数据操作，如数据框的变量截取，删除。基础R包中的数据读写函数（read.csv()和write.csv()等）。接下来要介绍的是一些更加高效的实现这些操作的方法。 我们会跳过一些基础的变量水平的描述，比如对于离散变量，我们通常会用频数表格稍微在需要时查看变量各个层级观测的频数（table()），或者两个变量的交叉表格。还可以通过对离散变量绘制条形图。对于连续变量，我们时不时需要查看某个变量的均值（mean()），标准差（sd()）,分位数（quantile()）之类的。此外还有一些像summary()，str()和describe()（这个函数是’psych’包里的，之前有用过）这样的函数能给出关于一个数据框的总结。以上提到的这些都是一些最基础的探索各个阶段数据（包括模型结果）的方法。但仅仅这些是不够的，这些方法的灵活性不高，输出的信息是固定的。我们可能不想要summary()函数输出的全部信息，而有些我们想要的信息它却没有。比如如果我们想要知道每个类别的客户收入，在线花销等的均值；或者我们想要在每个类别中找到收入最高的人，然后将他们提取出来集合在一起；又或者我们希望有一个新的变量指示购买的渠道（是在线还是实体店），并且将这个变量用于建模，这时就需要对数据进行整形，将在线购买的记录和实体店购买的记录逐行排列而非现在的逐列。这些操作如果仅仅使用初级函数会非常繁琐，且运算效率也不高。R中有一些其它包可以非常高效简洁的完成这些看似复杂的任务。初次接触这些函数的小伙伴会觉得它们不太好学，那是自然，灵活性越强的工具需要学习掌握的时间自然长些，但这就是一个熟能生巧的过程。 本章内容安排如下，在介绍数据整合和整形操作之前，先介绍一个新的可以取代数据框的对象，tibble。我们会介绍如何将传统的数据框转化为tibble对象，以及它们之间的不同。接着我们会介绍一个高效读取数据集的包readr。虽然这个包并不用来进行数据变换操作，但数据读写也是分析的一个必要基础环节。当数据大时，读取数据会成为一个耗时的环节，使用一些高效的数据读写包在数据量大时显著提高效率。此外，和R基础包中相应的读写函数相比，readr包还有一些友好的新特征。之后我们将介绍基础包中用于数据整合的apply()函数，以及更高级的plyr包和它专门针对数据框的优化版dplyr包，后两个包能够进行高效的数据整合操作。最后介绍两个用于数据整形的包：reshape2包和tidyr包。所有这些包都是数据处理的利器，使用频率非常高。大家需要通过实践不断熟悉。 6.1 数据读写 6.1.1 取代传统数据框的tibble对象 tibble在原有数据框的基础上做了改进，使得日后进一步处理建模更加容易。R基础包中的一些设计现在已经不那么适用，但是要改变R的底层设计同时保留R代码现有的使用方式非常困难，因此，R社区的创新改进通常都依赖于新的包。这个小节介绍的tibble包就是对基础R中的数据框对象进行改进。 我们还是使用服装消费者数据为例。先载入相应的包和数据： library(tibble) library(dplyr) library(ggplot2) sim.dat&lt;-read.csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;) 大部分的R包都还在使用传统的数据框，你可以通过tibble包中的as_tibble()函数将其转化成tibble对象： # 创建一个小数据框 df=data.frame(x=c(1:5),y=rep(&quot;a&quot;,5)) as_tibble(df) 和数据框一样，你也可以自己构建tibble对象： tibble( x = 1:5, y = 1, z = x ^ 2 + y ) 可见tibble()可以自动将y的值重复向量x的长度。如果你熟悉数据框的话应该知道，data.frame()函数总是将字符变量转化为因子变量（还有其它变量类型自动转化带来的麻烦），而tibble()不会改变输入变量的类型，也不会自行改变变量的名字，甭管这名字是否符合R对变量名的要求（比如必须要用字母开头，不能有空格等）： tb &lt;- tibble( `:)` = &quot;smile&quot;, ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) print(tb) 注意这里你需用单引号将变量名引起来。如果你要在其它包（如ggplot2、dplyr和tidyr）中使用tibble对象中的变量也需要加单引号，比如： tb=tibble( `:)` = 1:5, ` ` = 1, `T_T` = `:)` ^ 2 + ` ` ) ggplot(tb,aes(`:)`,`T_T`))+geom_point() 6.1.1.1 tibble和传统数据框的区别 tibble和传统数据框的不同主要在于输出显示和截取变量这两方面。 输出显示 tibble格式的数据输出显示更友好。它只显示头10行，而且会根据屏幕自动调整输出的列数。此外，在列名后还会显示每列的类型。虽然不是直接涉及数据操作，但在数据分析的过程中我们需要不时查看数据，这些友好的特征给处理大数据带来方便。 print(as_tibble(sim.dat)) 默认设置下，tibble对象会根据控制器窗口的大小调整输出，如果你用普通的数据框将会占满整个控制器，数据量过大时可能无法看到最开始的数据。如果你要查看更多的行和列，可以使用print()函数并且自定义设置，其中width = Inf告诉函数输出所有的列： # 这里不显示输出 print(sim.dat,n = 15, width = Inf) 还有其它关于输出的设置，想要了解更多信息可以键入下面命令查看帮助文档： package?tibble 截取变量 从tibble对象中截取某一个变量会用到“$” 和“[[”符号。“[[”能够通过变量的名字或者位置指针来截取，“$”只能通过变量名截取。 # 通过变量名截取，不显示输出 # sim.dat$age # 通过变量名截取 # sim.dat[[&quot;age&quot;]] # 通过位置截取 # sim.dat[[1]] 当你通过“$”或“[”操作符从传统数据框中截取一个变量，有时该变量时向量的形式，有时是另外一个数据框的形式。这时常会导致之后的程序运行出现错误（比如你需要进一步进行矩阵运算），这样的错误因为细微反对于新手来说不好查找。而从tibble中截取任何一个变量依旧是个tibble对象。 你也可以使用管道操作符（“%&gt;%”）进行数据截取。关于该操作符，我们会在之后讲到。这里我们先展示如何用管道操作符截取数据。这种情况下需要额外的特殊占位符“.”： # 不显示输出结果 library(dplyr) sim.dat%&gt;%.$age sim.dat%&gt;%.[[&quot;age&quot;]] 由于tibble对象比较新，R中很多函数可能不能处理该对象。当你清理了数据之后要对数据建模时可以很容易将tibble对象转成原始数据框格式： sim.dat=as.data.frame(sim.dat) class(sim.dat) ## [1] &quot;data.frame&quot; 6.1.2 高效数据读写：readr包 大家应该熟悉基础R中的read.csv()、write.csv()等函数。这里给大家介绍一种更加高效的数据读取包readr包。RStudio在2015年推出的readr包可以取代传统的read.csv()和read.table()等函数。使用该包中对应的read_csv()和write_csv()函数读写数据的效率大幅度提高。readr包基于 C++ 的SourceFile，SourceString，SourceRaw的文件API接口，避免了数据的复制和分配，能更加快速读取格式化数据（和传统基础R中的包相比，速度快乐超过10倍）。此外，readr不会将字符串转化成因子变量，能够解析时间观测，不会修改列名。和传统的导入函数相比，个人认为readr的必杀特征就是它提供进度条。 生命的进度条 知乎上有这样一条神回复: &gt; 某女问：为什么追了我这么长时间的男生突然不追了？ 某男答：你特么倒是给个进度条啊！ 可见等待并不可怕，没有进度条的等待才是难以忍受的。言归正传，readr包中用于读入数据的函数主要有如下几种： read_csv()读入逗号分隔文件 read_csv2()a用于读入分号分隔文件 read_tsv()读入制表符分隔文件 read_delim()读入任意分隔符文件 这些函数的使用语法很类似，由于.csv文件是最常用的数据存储形式，read_csv()函数就可以涵盖大部分的数据读入需要了。所以这里我们将着重介绍该函数，由于各个函数使用方式类似，只要学会一种，举一反三，其它函数也就不难了。 read_csv()函数的第一个参数是最重要的，也就是你要读的数据集路径： library(readr) sim.dat &lt;- read_csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv &quot;) 用该函数读入的数据集自动是tibble格式的。在运行read_csv()的时候，会自动输出列的基本信息：列名和类型。这是readr包的一个重要特征。你也可以直接在代码中手动输入一些csv格式的文档，这有助于理解readr的工作原理以及向人展示该包的使用。read_csv()通常将数据的第一行作为变量名： dat=read_csv(&quot;a,b,c 1,2,3 4,5,6&quot;) print(dat) 有时数据的头几行是关于数据集的说明，这个时候你可以设置skip选项跳过这些行： dat=read_csv(&quot;这是个样本数据 这行只是注释 x,y,z 1,2,3&quot;, skip = 2) print(dat) 如果数据没有变量名，那可以设置col_names = FALSE，这样变量将被自动贴上 X1到Xn的标签： dat=read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = FALSE) print(dat) 这里“”表示另起一行。或者你可以指定变量名称： dat=read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)) print(dat) 此外，如前所述，对于分号分隔文件可以使用read_csv2()： dat=read_csv2(&quot;x;y;Z\\n1;2;3&quot;) print(dat) 对于制表符分隔文件，可以用read_tsv()： dat=read_tsv(&quot;x\\ty\\tz\\n1\\t2\\t3&quot;) print(dat) 或者可以用read_delim()，然后指定分隔符： dat=read_delim(&quot;x|y|z\\n1|2|3&quot;, delim = &quot;|&quot;) print(dat) 另外一个经常遇到的问题是指定缺失值。比如我在处理市场调查问卷回复的数据时，负责问卷设计和数据收集的人将缺失的回复设置为99，那么你可以通过设置na=&quot;99&quot;告诉函数将取值为99的观测读入为缺失值： dat=read_csv(&quot;x,y,z\\n1,2,99&quot;,na=&quot;99&quot;) print(dat) 到此为止，几乎涵盖了大部分你可能会用到的数据读取。readr同样有两个储存数据的函数： write_csv()和write_tsv()。它们和之前的write.csv()函数相比有两个优势： 对字符串总是使用UTF-8编码 将日期和时间用ISO8601格式储存，便于其它软件解析 如果你要将.csv格式的数据导出成Excel格式，可以使用write_excel_csv()，该函数会告诉Excel使用UTF-8编码。函数的语法和传统write.csv()几乎一样，如： write_csv(sim.dat, &quot;sim.dat.csv&quot;) 对于其它类型的数据，可以使用下面的包： Haven：读入SPSS, Stata和SAS数据 Readxl：读取excel文档（.xls和.xlsx） DBI：在指定了相应数据库（RMySQL、RSQLite和RPostgreSQL）的情况下，可以直接从数据库中通过SQL读取数据。 对于网络数据的读取，可以参考“XML and Web Technologies for Data Sciences with R”[14]。关于其它数据的读取有一个非常好的免费使用手册：R data import/export manual（https://cran.r-project.org/doc/manuals/r-release/R-data.html#Acknowledgements）。大家也可以自己尝试下号称数据读写的“瑞士军刀”的 rio包：https://github.com/leeper/rio。 6.2 数据整合 6.2.1 base包：apply() R基础包中有几个强大的函数，apply()、lapply()和sapply()等。它们做的事情类似，只是对应的对象，或返回对象的格式不同。这些函数对于R的初学者来说可能有些难，但一旦熟悉以后会发现它们非常有效。它们是干什么的？简单来说就是依次对某一对象的某一部分重复应用一个指定的函数。它们的不同在于，apply()将你指定的函数作用于数据框对象的行或列，返回一个向量。‘lapply()’ 将指定的函数作用于列表或者数据框对象，返回一个长度相同的列表。sapply()更加便捷，且算是对lapply()进行了包装，若sapply()中参数simplify=FALSE，那么其返回的值和lapply()是一样的。若simplify=TRUE，则sapply()的返回值不是一个列表，而是一个矩阵。因为在平常工作中通常处理的都是数据框，所以这里主要介绍函数apply()的用法。大家可能会觉得很抽象，觉得抽象很正常，因为这几兄弟确实不太接地气，我现在用这些函数几乎每次都得去查帮助文档。回到我们的服装消费者数据。如果我想知道样本中所有数值变量的均值和标准差该怎么办？这在建模前检查数据和建模后展示数据时都经常用到。 记得我们之前通过preProcess()函数对数据进行KNN填补时，需要提取数据框中所有的数值变量用到的是lapply()函数。这里不能用apply()函数是因为apply()函数自动将对象转化成矩阵，这样就会丢失每列的类别信息，而lapply()不会对对象进行转化（这样细微的差别需要常用R渐渐熟悉了才会慢慢了解，我也是写书的时候发现这个，方才请教了一位R高人才明白个中缘由：））。我们再次用该函数选取其中数值型的变量： sim.dat&lt;-read.csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;) sdat&lt;-sim.dat[,!lapply(sim.dat,class)==&quot;factor&quot;] 现在的数据框sdat中只包括数值型的变量。这样我们就可以用apply()函数对每列求均值和标准差了： apply(sdat, MARGIN=2,function(x) mean(na.omit(x))) ## age income store_exp online_exp store_trans ## 38.840 113543.065 1356.851 2120.181 5.350 ## online_trans Q1 Q2 Q3 Q4 ## 13.546 3.101 1.823 1.992 2.763 ## Q5 Q6 Q7 Q8 Q9 ## 2.945 2.448 3.434 2.396 3.085 ## Q10 ## 2.320 这里我们定义了一个函数function(x) mean(na.omit(x))，这个函数很简单，就是对任何向量求均值同时忽略其中的缺失值。MARGIN=2告诉函数逐列应用定义的函数。如果要计算行均值，只要简单的将margin参数设置为1即可。结果可见，平均说来在线购买次数和消费量都要高于实体店购买。对于10个问卷调查，第二个问题（Q2）平均得分最低。 apply(sdat, MARGIN=2,function(x) sd(na.omit(x))) ## age income store_exp online_exp store_trans ## 16.416818 49842.287197 2774.399785 1731.224308 3.695559 ## online_trans Q1 Q2 Q3 Q4 ## 7.956959 1.450139 1.168348 1.402106 1.155061 ## Q5 Q6 Q7 Q8 Q9 ## 1.284377 1.438529 1.455941 1.154347 1.118493 ## Q10 ## 1.136174 让我们再来看看标准差，代码和计算均值几乎是一样的，只是将均值函数mean()换成标准差函数sd()。虽然在线花费的均值高过实体店花费，但是实体店花费的标准差比在线花费高很多，认真看过本章开头的读者应该知道，这是由于个把土豪在实体店买了上万的衣服。还有问卷调查的第二个问题，虽然之前看到的均值很小，但是标准差也很小，这说明了什么？说明总体对该问题的评分都偏低，如果用于客户分组的话该问题可能不具有太高的区分度。关于这点，我们可以在客户分组那个章节以该数据集为例进行核实。虽然这都是一些简单的统计量，但能够使你在建模前了解更多的关于数据的信息，这对于模型选择和结果解释都有无形的帮助。 6.2.2 plyr包：ddply()函数 之前讲过一个居家旅行必备神器是caret包，希望大家还记得，这个包实在是太强大了，我们之后会反复用到里面的各个函数，但这里不会详细介绍这个包的所有功能，因为具体介绍R中函数的用法不是本书主要目的，而且关于各种包网上有很多文档材料，如果你真的知道你要对数据做什么，找到相应的R包并在网上查看相应帮助资料学会如何使用并不困难（对于有一定经验的R用来说），但很多时候，我们的问题在于即使不知道该如何解决实际问题，本书的重点是给大家展示数据科学家是如何通过这些技术手段解决问题的，R是一个功能强大的工具，但是手段不是目的。回归主题，现在要再讲第二个必备神器，plyr包。同样我不会详细介绍这个包的用法，而是展示如何用这个包中的ddply()函数帮助我们进行数据分析。还是服装消费者的数据（我知道这很没有创意，但太有创意了老换数据集对你们理解模型方法没有什么好处：）），之前我们都没有用到数据框中的最后一列指明消费者类别的变量segment。已经忘记了消费者类别定义的小伙伴们请回到生成数据的那小节，复习下。有客户分组项目经验的人都知道，在通过聚类（在聚类的章节会说到）得到分组以后，下一件事情就是看看每组客户都是些什么样的人，也就是建立各组客户档案。下面我们就来看看各组客户的人口统计学和消费行为档案吧： ddply(sim.dat,&quot;segment&quot;,summarize, Age=round(mean(na.omit(age)),0), FemalePct=round(mean(gender==&quot;Female&quot;),2), HouseYes=round(mean(house==&quot;Yes&quot;),2), store_exp=round(mean(na.omit(store_exp),trim=0.1),0), online_exp=round(mean(online_exp),0), store_trans=round(mean(store_trans),1), online_trans=round(mean(online_trans),1)) ## segment Age FemalePct HouseYes store_exp online_exp store_trans ## 1 Conspicuous 42 0.32 0.86 4990 4898 10.9 ## 2 Price 60 0.45 0.94 501 205 6.1 ## 3 Quality 35 0.47 0.34 301 2013 2.9 ## 4 Style 24 0.81 0.27 200 1962 3.0 ## online_trans ## 1 11.1 ## 2 3.0 ## 3 16.0 ## 4 21.1 这结果信息量太大了，不过并不奇怪。在实际应用中，真实客户分组是未知的并且分析的目标就是找到这样的组。也就是说在实际客户分组的项目中，这是我们希望的到的分析上的最终结果。在对这个结果进行解读之前，我们先看看上面ddply()代码。函数的第一个参数是数据集（sim.dat），其次是告诉函数要按照哪个分类变量进行总结，这里我们只想对不同类别的消费者进行总结，但也可以是多个变量，如你可以将该参数设置成ddply(sim.dat, c(“segment”,”house”), …)，结果读者试着自行脑补下：）。接下来summarize是说我们希望对数据框分组做总结，你可以设置其它功能比如transform（在组内进行数据变换）和subset（在组内进行数据选择）。接下来分别是： Age：计算每组的年龄均值 FemalePct：计算每组女性的比例 HouseYes：计算每组内有房的人的比例 store_exp：计算每组实体店消费均值，这里我们用修剪后的（trim=0.1）均值，因为通过之前的数据探索我们知道这个变量观测有些土豪离群点。 online_exp：计算每组在线消费均值 store_trans：计算每组实体店消费次数均值 online_trans：计算每组在线消费次数均值 了解这些以后，我们看看消费者群体之间有何不同。 炫耀性消费（Conspicuous）人群年龄平均40岁左右，基本中年土豪，女性大概占了1/3另外2/3是男性（基本是大叔控的目标），土豪在哪里都买的多，在线消费量和实体店消费量都远大于其他人，在线和实体店消费的量和次数都差不多，反正有钱不在乎在哪买，看到好的就买，有钱任性嘛！基本有房（0.86），剩下14%没房的如果不是由于观点坚决不买房的话，那或许是在北上广这样的地方高不成低不就，买房不够消费有余，这也提醒我们如果这些样本是来自不同城市的话，我们可能还需要收集消费者所在城市的信息，城市的生活水平很大程度上影响了消费行为。 对价格敏感的人（Price）年龄大（60），基本有房（0.94）这和他们的年龄有关，房奴是后来时代发展的产物。这类人在线消费比其他人都少，还是倾向于在实体店消费（平均在线交易次数是3，而实体店消费次数是6），这也是唯一一类在线消费低于实体店消费的。 注重服装质量的人（Quality）平均年龄居中，可能和炫耀性消费人群没有显著差别，男女比例基本一半一半。明显偏爱在线消费，消费量和土豪比差远了，但位居其次，估计是中产。有房的人不是很多（0.34），这代人很不幸已经进入房奴的时代。 风格类（Style），这些无疑是年轻人了，平均年龄只有24，大学生或者刚工作不久的白领，绝大多数是女性（0.81），有房的不多（0.27）或者可以说能完全靠啃老的不多：），也是典型的在线一族，在线购买的次数比Quality和Conspicuous的人多但是消费额却没有他们大。 这里就提醒我们需要计算平均每次购买的花销，这样可以了解各个群体大概都买什么价位的东西。大家看到没有，分析是一个迭代学习的过程，我们在探索数据的过程中可能会发现一些问题，促使我们去检查某部分数据或者计算一些新的变量，使用新的可视化来探索数据。我们接着用ddply()补充计算这两个统计量： ddply(sim.dat,&quot;segment&quot;,summarize,avg_online=round(sum(online_exp)/sum(online_trans),2), avg_store=round(sum(store_exp)/sum(store_trans),2)) ## segment avg_online avg_store ## 1 Conspicuous 442.27 479.25 ## 2 Price 69.28 81.30 ## 3 Quality 126.05 105.12 ## 4 Style 92.83 121.07 结果显示价格敏感的人群果然买的价位最低，其次是风格类人群，这些人不一定是对价格敏感，但或许钱包不允许他们买太贵的。注重质量的买的东西价格比风格类的高些，但远不及土豪组，物美价廉的东西毕竟少，这些人可能更看重性价比，不会炫耀性消费但也不会买低质廉价的东西。我们在之后客户分组的时候还会进行类似的总结，那时我们会加上关于问卷调查的回复。大家看到了么，短短的几行代码就可以得到这么有信息量的总结。你可能会说这样的总结通过excel的数据透视表（pivot table）也能完成，但是用R代码要快得多，而且这只是其中一部分功能，如果之前说的，你可以设置其它功能比如transform（在组内进行数据变换）和subset（在组内进行数据选择），并且计算的东西也是可以自己定义。 为了方便，我们按照消费者类别比例随机抽取11个样本，选择3个变量（age，store_exp和segment）用于展示（数据框：examp）。这里用于分层抽样的函数在之后介绍建模辅助技术时会讲到，所以这里不做介绍。 library(caret) set.seed(2016) trainIndex&lt;-createDataPartition(sim.dat$segment,p=0.01,list=F,times=1) examp&lt;-sim.dat[trainIndex,c(&quot;age&quot;,&quot;store_exp&quot;,&quot;segment&quot;)] examp数据集只有11行3列。我们先看看transform设置的作用： ddply(examp,&quot;segment&quot;,transform,store_pct=round(store_exp/sum(store_exp),2)) ## age store_exp segment store_pct ## 1 42 6319.0718 Conspicuous 0.55 ## 2 42 5106.4816 Conspicuous 0.45 ## 3 55 595.2520 Price 0.42 ## 4 64 399.3550 Price 0.28 ## 5 64 426.6653 Price 0.30 ## 6 39 362.4795 Quality 0.58 ## 7 35 260.5065 Quality 0.42 ## 8 23 205.6099 Style 0.25 ## 9 24 212.3040 Style 0.26 ## 10 24 202.1017 Style 0.25 ## 11 28 200.1906 Style 0.24 可以看到，设置transform使得函数对数据集按照指定分类变量（segment）在组内进行数据变换，并将变换后得到的新变量添加到原数据集后。再来看看subset设置： ddply(examp,&quot;segment&quot;,subset,store_exp&gt;median(store_exp)) ## age store_exp segment ## 1 42 6319.0718 Conspicuous ## 2 55 595.2520 Price ## 3 39 362.4795 Quality ## 4 23 205.6099 Style ## 5 24 212.3040 Style 上面代码可以获取每个消费者类别（segment）中实体店消费（store_exp）大于该类别中位数的样本。 6.2.3 dplyr包 dplyr包是plyr包中的ddply()等函数的强化版，专门处理数据框（dataframe）对象，大幅提高了速度, 并且提供了更稳健的与其它数据库对象间的接口。由于分析中绝大多数是处理数据框，这个包尤其好用。这里我对这个包进行比较详细的介绍。接下来会按顺序介绍该包的几块重要功能： 数据框显示 数据截选（按行／列） 数据总结 生成新变量 合并数据集 6.2.3.1 数据框显示 tbl_df()函数: 能将数据转化成tbl类，这样查看起来更加方便，输出会调整适应当前窗口 # 这里不展示输出 dplyr::tbl_df(sim.dat) glimpse()函数：类似之前的tbl_df()函数，只是转了方向。变量由列变成行。输出结果同样可以自动调整以适应窗口。 # 这里不展示输出 dplyr::glimpse(sim.dat) 6.2.3.2 数据截选（按行／列） 先介绍按行截选。 # 提取出满足条件的行：收入大于30万的样本 library(magrittr) library(dplyr) dplyr::filter(sim.dat, income &gt;300000) %&gt;% dplyr::tbl_df() 这里用到了一个可能大家之间没有见过的操作符号%&gt;%，这是管道操作，其意思是将%&gt;%左边的对象传递给右边的函数，作为第一个选项的设置（或剩下唯一一个选项的设置）。比如： x %&gt;% f(y) 等同于 f(x, y) y %&gt;% f(x, ., z) 等同于 f(x, y, z ) 管道操作来自于magrittr包，它能够极大简化代码，增加代码可读性。尤其对于dplyr包中的函数操作。大家看下面这段代码，能够知道都干了什么么？ ave_exp &lt;- filter( summarise( group_by( filter( sim.dat, !is.na(income) ), segment ), ave_online_exp = mean(online_exp), n = n() ), n &gt; 200 ) 再看看用管道操作符进行相同操作的代码： avg_exp &lt;- sim.dat %&gt;% filter(!is.na(income)) %&gt;% group_by(segment) %&gt;% summarise( ave_online_exp = mean(online_exp), n = n() ) %&gt;% filter(n &gt; 200) 用%&gt;%的代码是不是简洁清晰的多？我们从上掉下依次读下代码都干了什么： 选出数据框sim.dat中收入未缺失的观测 按照segment变量对观测分组 对每组数据求在线消费额的平均值，并赋予新的变量ave_online_exp 对每组计算观测个数，赋值为n 选出结果中观测个数大于200的行 上面代码中用到的一些没有讲到的函数马上就会介绍。 distinct()函数可以删除数据框中重复的行。可以说是unique()函数在数据框上的扩展。 ## 删除重复的行 ## 这里没有重复的行 dplyr::distinct(sim.dat) sample_frac()函数可以随机选取一定比例的行。sample_n()函数可以随机选取一定数目的行。 dplyr::sample_frac(sim.dat, 0.5, replace = TRUE) dplyr::sample_n(sim.dat, 10, replace = TRUE) slice()可以选取指定位置的行。和sim.dat[10:15,]类似。 # 选取sim.dat的10到15行 dplyr::slice(sim.dat, 10:15) top_n()可以选取某变量取值最高的若干观测。如果有指定组的话，可以对每组选择相应变量取值最高的观测。 # 选取收入最高的两个观测 dplyr::top_n(sim.dat,2,income) 对列变量的选择使用的是select()函数。下面我展示一些代码，并在相应的注释中指出该代码的功能。大家自己运行下看看结果。更多信息，键入?select查阅该函数的帮助文档。 # 通过列名选取变量 # 选取 sim.dat数据框中的income，age和store_exp列 dplyr::select(sim.dat,income,age,store_exp) # 选取列名中含有某字符串（_）的列 # 该命令将选取store_exp，online_exp，store_trans和online_trans dplyr::select(sim.dat, contains(&quot;_&quot;)) # 选取以某字符串（e）结尾的列 # 结果选取了age，income和house # 类似的starts_with指以某字符串开始的列 dplyr::select(sim.dat, ends_with(&quot;e&quot;)) # 选取列Q1，Q2，Q3，Q4和Q5 select(sim.dat, num_range(&quot;Q&quot;, 1:5)) # 选取列名在某字符串中的列 dplyr::select(sim.dat, one_of(c(&quot;age&quot;, &quot;income&quot;))) # 选取两个列名之间的列，包含头尾两列 dplyr::select(sim.dat, age:online_exp) # 选出出了某列（age）以外的其它列 dplyr::select(sim.dat, -age) 6.2.3.3 数据总结 这里的操作类似于apply()和ddply()， 可以对数据框的每一列进行某个函数操作；或者按照某个分类变量将观测分组，然后对每组观测按列进行函数操作。 # 对列online_trans取均值，返回的是一个单一值 dplyr::summarise(sim.dat, avg_online = mean(online_trans)) ## avg_online ## 1 13.546 # 对数据框中的每一列应用函数anyNA() # 这里可以指定一个函数向量，如c(&quot;anyNA&quot;,&quot;is.factor&quot;) dplyr::summarise_each(sim.dat, funs_(c(&quot;anyNA&quot;))) ## age gender income house store_exp online_exp store_trans online_trans ## 1 FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 segment ## 1 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 若要根据某分类变量对观测进行分组总结，可以使用group_by()函数。比如： # 对每个消费者类别对应变量应用anyNA()函数 sim.dat %&gt;% group_by(segment) %&gt;% summarise_each(funs_(c(&quot;anyNA&quot;))) 你在数据总结操作中赋予各种总结函数，如mean()，sd()等。但注意这里的总结函数是作用于向量，返回单一值。比如函数is.na()，作用于向量，但返回的也是向量，就不可以在此使用。 6.2.3.4 生成新变量 dplyr包中的mutate()函数可以进行列计算，然后将结果添加到原数据集上。 dplyr::mutate(sim.dat, total_exp = store_exp + online_exp) 对每列应用窗口函数，它们作用于一个向量然后返回一个向量。回顾刚才介绍dplyr的总结功能时讲到总结函数作用于一个向量返回一个数值。注意理解这两者的不同。 # 这里的min_rank等价于rank(ties.method = &quot;min&quot;) # mutate_each()对每列应用指定的窗口函数 dplyr::mutate_each(sim.dat, funs(min_rank)) transmute()函数和mutate()类似，区别在于它只返回新生成的列，删除原始列。 dplyr::transmute(sim.dat, total_exp = store_exp + online_exp) 这里没有显示代码的结果，大家需要自己操作看看结果，这样对理解学习这些函数很有帮助。关于R中的窗口函数，大家可以自己查找相关资料。熟悉这些常见的函数及其功能，可以提高用R做数据变换的效率（不用总查帮助）。这个过程没有什么技巧可言，纯粹是熟能生巧。 6.2.3.5 合并数据集 这里先随机抽取两个小数据集来展示数据集合并。 x&lt;-data.frame(cbind(ID=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),x1=c(1,2,3))) y&lt;-data.frame(cbind(ID=c(&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),y1=c(T,T,F))) x ## ID x1 ## 1 A 1 ## 2 B 2 ## 3 C 3 y ## ID y1 ## 1 B TRUE ## 2 C TRUE ## 3 D FALSE 这里数据框x和y都非常简单，由一个ID变量和各自的观测变量组成。下面我们来介绍各种合并操作。 left_join()从y到x合并数据。结果保留了数据框x的3行。类似大家可以自行尝试right_join()。 left_join(x,y,by=&quot;ID&quot;) ## ID x1 y1 ## 1 A 1 &lt;NA&gt; ## 2 B 2 TRUE ## 3 C 3 TRUE inner_join()返回的是y和x中都可以匹配的观测。 inner_join(x,y,by=&quot;ID&quot;) ## ID x1 y1 ## 1 B 2 TRUE ## 2 C 3 TRUE full_join()返回的是y或者x中含有的观测。 full_join(x,y,by=&quot;ID&quot;) ## ID x1 y1 ## 1 A 1 &lt;NA&gt; ## 2 B 2 TRUE ## 3 C 3 TRUE ## 4 D &lt;NA&gt; FALSE semi_join()对x中的观测进行筛选，找到那些同时在y中可以匹配的观测，但并没有将y的变量y1合并进来。 semi_join(x,y,by=&quot;ID&quot;) ## ID x1 ## 1 B 2 ## 2 C 3 anti_join()同样对x中的观测进行筛选，找到那些在y中无法匹配的观测。 anti_join(x,y,by=&quot;ID&quot;) ## ID x1 ## 1 A 1 此外，dplyr包中还有各种针对数据框的交（intersect()）、并（union()）和补（setdiff()）运算，以及将一个数据框按照行或者列添加到另一个数据框上的操作（bind_rows()，bind_cols()）。这里就不一一介绍，大家自己用一个简单的数据框尝试下。 6.3 数据整形 6.3.1 reshape2包 终于到本章末尾了。之前提到过，如果我们希望有一个新的变量指示购买的渠道（是在线还是实体店），并且将这个变量用于建模，这时就需要对数据进行整形（也称作数据整理，或者揉数据），将在线购买的记录和实体店购买的记录逐行排列而非现在的逐列。我们可以用reshape2包中的相关函数实现这些操作。可能有的读者知道有个包叫做reshape，这是初版，后面的reshape2是重写升级版。这个数据整形的过程确实和揉面团有些类似，先将数据通过melt()函数将数据揉开，然后再通过dcast()函数将数据重塑成想要的形状，为了更清晰的展示函数对数据结构的影响，我们选取其中小部分列，和前5行： (sdat&lt;-sim.dat[1:5,1:6]) ## age gender income house store_exp online_exp ## 1 57 Female 120963.4 Yes 529.1344 303.5125 ## 2 63 Female 122008.1 Yes 478.0058 109.5297 ## 3 59 Male 114202.3 Yes 490.8107 279.2496 ## 4 60 Male 113616.3 Yes 347.8090 141.6698 ## 5 51 Male 124252.6 Yes 379.6259 112.2372 我们截取的子数据框一共5行，6列。 (mdat &lt;- melt(sdat, measure.vars=c(&quot;store_exp&quot;,&quot;online_exp&quot;))) ## age gender income house variable value ## 1 57 Female 120963.4 Yes store_exp 529.1344 ## 2 63 Female 122008.1 Yes store_exp 478.0058 ## 3 59 Male 114202.3 Yes store_exp 490.8107 ## 4 60 Male 113616.3 Yes store_exp 347.8090 ## 5 51 Male 124252.6 Yes store_exp 379.6259 ## 6 57 Female 120963.4 Yes online_exp 303.5125 ## 7 63 Female 122008.1 Yes online_exp 109.5297 ## 8 59 Male 114202.3 Yes online_exp 279.2496 ## 9 60 Male 113616.3 Yes online_exp 141.6698 ## 10 51 Male 124252.6 Yes online_exp 112.2372 我们将变量store_exp和online_exp揉合在一起，结果产生了新的两列，一列是变量variable，指代是哪个揉合变量，另外一列是取值value，即变量对应的值。我们也称这样逐行排列的方式称为长数据格式。由于这里我们并没有指定除了要揉合的变量外的id变量，于是函数默认将所有剩下的变量都当作id变量。对于这些变量保留原来对应的观测，只是对store_exp和online_exp分别重复一次。所以得到的结果有10行。如果我们要对消费量（value）建立线性模型，并且考虑购买渠道的效应的话就可以利用揉合后的数据： # 这里为了展示回归需要更多的数据，所以用原数据框的所有行 mdat&lt;-melt(sim.dat[,1:6], measure.vars=c(&quot;store_exp&quot;,&quot;online_exp&quot;)) fit&lt;-lm(value~gender+house+income+variable+age,data=mdat) summary(fit) ## ## Call: ## lm(formula = value ~ gender + house + income + variable + age, ## data = mdat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4208 -821 -275 533 44353 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -9.132e+02 1.560e+02 -5.855 5.76e-09 *** ## genderMale 3.572e+02 1.028e+02 3.475 0.000524 *** ## houseYes -5.687e+01 1.138e+02 -0.500 0.617275 ## income 2.834e-02 1.079e-03 26.268 &lt; 2e-16 *** ## variableonline_exp 8.296e+02 9.772e+01 8.489 &lt; 2e-16 *** ## age -2.793e+01 3.356e+00 -8.321 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1974 on 1626 degrees of freedom ## (368 observations deleted due to missingness) ## Multiple R-squared: 0.348, Adjusted R-squared: 0.346 ## F-statistic: 173.5 on 5 and 1626 DF, p-value: &lt; 2.2e-16 这里lm()函数自动将实体店消费store_exp设置成基准水平，只看对应的系数估计表明，在其它条件不变的情况下，在线购买的人比商店购买的人平均消费高出830元，而且购买渠道的效应非常显著。看到这样的结果，分析师需要考虑建议商家提高网上商城的购物体验，采取一些手段改变那些实体店为主的消费者改变消费习惯。当然，当靠一个线性回归系数就作出这样的建议有些仓促，还需要对模型的可靠性进行进一步检查。下一章就会讲到模型选择和评估。 如果我们将house和gender指定为id变量，结果为： # 这里用所用的数据 # 缺失值填补 demo_imp&lt;-impute(sim.dat,method=&quot;median/mode&quot;) mdat &lt;- melt(demo_imp, measure.vars=c(&quot;store_exp&quot;,&quot;online_exp&quot;),id.vars=c(&quot;house&quot;,&quot;gender&quot;)) head(mdat) ## house gender variable value ## 1 Yes Female store_exp 529.1344 ## 2 Yes Female store_exp 478.0058 ## 3 Yes Male store_exp 490.8107 ## 4 Yes Male store_exp 347.8090 ## 5 Yes Male store_exp 379.6259 ## 6 Yes Male store_exp 338.3154 melt()函数不仅能揉合数据框，还能揉合列表，矩阵，表格等。感兴趣的小伙伴可以自己在网上找相关的介绍，很容易找到案例代码，自己一步一步跟着运行一遍就很清楚了。这里揉合数据是为了建模需要，有的时候是为了进一步重塑数据结构。好比把一个积木房子拆开重新盖一个新的造型。这就要用到该包的第二个重要函数dcast()（这是升级版中的函数，初级版本的reshape包对应的是cast()函数）。比如，如果想知道对于有房和没有房的男性和女性，在线消费和实体店消费的总额分别是多少： dcast(mdat, house+gender~ variable, sum) ## house gender store_exp online_exp ## 1 No Female 171102.2 583492.4 ## 2 No Male 133130.8 332499.9 ## 3 Yes Female 355320.2 500856.9 ## 4 Yes Male 697297.3 703332.0 上面代码中~左边是你用来划分数据框的id变量，这里是house和gender，右边是你计算根据的变量（也必须是分类变量），真正用于计算的数值是你之前揉合过程中生成的value那列值。这两个函数确实不太好理解，大家需要对一个数据框自己实际操作才能真正理解。 6.3.2 tidyr包 R中还有一个能够用于数据整形的包tidyr。下面我们截取一个小数据框(sdat)展示包中一些主要函数的功能。 sdat&lt;-sim.dat[1:5,]%&gt;% dplyr::select(age,gender,store_exp,store_trans) sdat %&gt;% tbl_df() 首先是gather()函数。它的作用类似于reshape2中的melt()。下面这条命令的结果和melt(sdat, measure.vars=c(&quot;store_exp&quot;,&quot;store_trans&quot;))是一样的。其中variable和value是自定义的揉合生成的两列新变量的名字。variable列对应原数据中参与揉合的变量名，value列是参与揉合的变量的取值。store_exp,store_trans告诉R对那些变量进行揉合。 msdat&lt;-tidyr::gather(sdat,&quot;variable&quot;,&quot;value&quot;,store_exp,store_trans) msdat %&gt;% tbl_df() 如果用我们之前讲到的管道操作，上面代码可以等价的写成： # 这里不显示输出结果 sdat%&gt;%gather(&quot;variable&quot;,&quot;value&quot;,store_exp,store_trans) 和gather()相反的是spread()，前者将不同的列堆叠起来，后者将同一列分开。 msdat %&gt;% spread(variable,value) ## age gender store_exp store_trans ## 1 51 Male 379.6259 4 ## 2 57 Female 529.1344 2 ## 3 59 Male 490.8107 7 ## 4 60 Male 347.8090 10 ## 5 63 Female 478.0058 4 tidyr包中还有另外两个互补的函数，separate()和unite()。separate()函数可以将不同列分开成为多列。 sepdat&lt;- msdat %&gt;% separate(variable,c(&quot;Source&quot;,&quot;Type&quot;)) sepdat %&gt;% tbl_df() 可以看到，原来的变量variable被分成了两部分：Source和Type。你可以通过设置sep=来自定义用于划分字符的正则表达，默认是所有非字母和数字的字符。比如这里的“_”。 与separate()相反的函数是unite()， 它能将不同的列合并在一起。类似于paste()函数的数据框版本。 sepdat %&gt;% unite(&quot;variable&quot;,Source,Type,sep=&quot;_&quot;) ## age gender variable value ## 1 57 Female store_exp 529.1344 ## 2 63 Female store_exp 478.0058 ## 3 59 Male store_exp 490.8107 ## 4 60 Male store_exp 347.8090 ## 5 51 Male store_exp 379.6259 ## 6 57 Female store_trans 2.0000 ## 7 63 Female store_trans 4.0000 ## 8 59 Male store_trans 7.0000 ## 9 60 Male store_trans 10.0000 ## 10 51 Male store_trans 4.0000 上面的代码将原先分开的两列又合并回去了，并赋予的和之前一样的列名&quot;variable&quot;。 整形这部分可能是数据处理变换中最复杂的，这种复杂和证明数学定理不同，主要是需要时间熟悉。更像一门手艺，所以大家要发扬手艺人精神，多使用这些函数，把数据当面团一样揉来揉去的，也挺好玩的，不是么？觉得R太难有些犹豫需不需要学习的小伙伴们，磨刀不误砍柴工，再一次中国的老古话放在那里闪闪发光的有木有？ 6.4 本章总结 本章介绍数操作的方法，以及R中能够进行相应高效数据操作的包。 在介绍tibble的小节，我们学习了如何将传统数据框转化为tibble格式，这两种格式有什么不同，大家可以根据情况选择更利于之后分析过程的格式。 在数据读写的部分，我们介绍了一个新的包readr，这个包和基础包中的导入函数相比，在数据量大时效率显著提高，更重要的是它给你数据导入的进度条。此外，我们还介绍了一些处理特殊数据类型的方法，比如时间，介绍正则表达和因子变量的处理。 整合方法类似于excel中的透视表格，R中有一些功能强大的函数能够有效的进行各种数据整合。我们介绍了base包中的apply()函数，还有更加高级灵活的plyr包中ddply()函数的各种用法。由于实际工作中大部分时间是处理数据框，所以这里我们介绍了plyr包的一个专门针对数据框的强化包dplyr。该包对于数据的整合非常高效。 － 对于数据的整形（长型数据和宽型数据的转换），我们举例说明了由于模型需要将数据从宽型转化成长型的情况，并且用reshape2包实现了该过程。此外我们还介绍了另外一个数据整形的包tidyr，该包可以进行数据变量揉合，拆分，合并；还可以进行数据框的各种合并。 这些包的使用需要一些时间学习，实践尤其重要，大家需要多花功夫熟悉这些的操作，这是数据科学家的基本技能。这里说的“熟悉”是指成为第二天性，再应用时不需要占用大脑的工作记忆。 References "],
["section-7.html", "第7章 基础建模技术 7.1 有监督和无监督 7.2 误差及其来源 7.3 数据划分和再抽样 7.4 本章总结", " 第7章 基础建模技术 建模技术指代一系列用于理解数据的工具。本章介绍基本的统计学习术语，概念，以及一些辅助性的技能。后面章节会分别对一些特定模型进行展开。 7.1 有监督和无监督 建模技术可以粗略的分为有监督和无监督这两类。大部分统计学习方法都可以归于其中一种。广义上说有监督方法涉及根据一个或者多个输入变量（也称为自变量，解释变量，预测变量），估计或者预测一个结果变量（也称为因变量，响应变量）。而无监督方法只考虑自变量，没有应变量作为“监督”，我们通过这类方法探索观测数据中内在变量结构。我们在之前提到的方法中，袋状树，广义线性回归是有监督方法；主成分分析，探索性因子分析，对近0方差和高相关变量的筛选都是无监督方法。我们先介绍这里的数学公式表达。 我们用\\(n\\)表示样本量（或者观测数目）。\\(p\\)代表自变量数目。我们用\\(\\mathbf{X}\\)表示\\(n\\times p\\)观测矩阵： \\[ \\mathbf{X}=\\left[\\begin{array}{cccc} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1p}\\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{np} \\end{array}\\right] \\] 其中\\(x_{ij}\\)代表第i个样本第j个变量的观测，\\(i=1, \\ldots, n\\)，\\(j=1, \\ldots, p\\)。\\(\\mathbf{x_{i.}}\\)代表第i个样本的所有变量观测组成的向量，向量统一按列排： \\[ \\mathbf{x_{i.}}=\\left[\\begin{array}{c} x_{i1}\\\\ x_{i2}\\\\ \\vdots\\\\ x_{ip} \\end{array}\\right] \\] 类似的，\\(\\mathbf{x_{.j}}\\)代表第j个变量的所有样本观测组成的向量： \\[ \\mathbf{x_{.j}}=\\left[\\begin{array}{c} x_{1j}\\\\ x_{2j}\\\\ \\vdots\\\\ x_{nj} \\end{array}\\right] \\] 于是我们有： \\[ \\mathbf{X}=\\left[\\begin{array}{cccc} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1p}\\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{np} \\end{array}\\right]=\\left[\\begin{array}{c} \\mathbf{x_{1.}^{T}}\\\\ \\mathbf{x_{2.}^{T}}\\\\ \\vdots\\\\ \\mathbf{x_{n.}^{T}} \\end{array}\\right]=\\left[\\begin{array}{cccc} \\mathbf{x_{.1}} &amp; \\mathbf{x_{.2}} &amp; \\ldots &amp; \\mathbf{x_{.p}}\\end{array}\\right] \\] 其中\\(^{T}\\)代表矩阵转秩。我们用\\(y_{i}\\)代表第i个样本对应的响应变量。所有\\(n\\)个响应变量组成的向量为： \\[ \\mathbf{y}=\\left[\\begin{array}{c} y_{1}\\\\ y_{2}\\\\ \\vdots\\\\ y_{n} \\end{array}\\right] \\] 自变量和应变量的关系为： \\[\\mathbf{y}=f(\\mathbf{X})+\\mathbf{\\epsilon}\\] 有监督和无监督建模技术用上面的符号语言表达就是： 无监督建模：探索\\(\\mathbf{X}\\)中的自变量之间的关系 有监督建模：估计\\(\\mathbf{y}\\)和\\(\\mathbf{X}\\)之间的关系 \\(f(\\cdot)\\) 其中\\(\\mathbf{\\epsilon}\\) 是随机误差，均值为\\(\\mathbf{0}\\)。函数\\(f(\\cdot)\\)是我们的建模目标，代表X能够提供的关于Y的系统信息（和随机性相对应）。估计\\(f(\\cdot)\\)目的主要是推断或者预测，有时兼有两者。通常情况下，模型的灵活性和可解释性之间是一种此消彼长的关系——灵活性越高的模型可解释性越弱。因此数据科学家需要把握这两者间微妙的平衡。不同的建模目的对模型解释性的要求不同，因而极大影响了模型选择。如果预测是唯一目的，那么模型的解释性就不在考虑范围内，这种情况下可以使用一些复杂的灵活度高的“黑箱”模型，装袋，助推，非线性核函数支持向量机，神经网络和随机森林等。这些模型都非常灵活，但是很难解释自变量和应变量之间的关系。人们可能会觉得这些模型的预测精度通常更高，但就个人经验来说，那些灵活性不那么高的模型预测精度更高的情况时常发生。咋一看来好像不符合逻辑，但是认真想想也并不奇怪，这些模型之所以复杂，就在于它们极力拟合当前观测数据，因此它们更有可能过度拟合（把噪声也拟合进去了），这些模型在训练集上的表现可能更好，但预测未必更准确。 7.2 误差及其来源 7.2.1 系统误差和随机误差 假设我们对于\\(\\mathbf{X}\\)得到\\(f\\)的估计\\(\\hat{f}\\)，进而得到\\(\\mathbf{y}\\)的预测 \\(\\hat{\\mathbf{y}}=\\hat{f}(\\mathbf{X})\\)。预测的误差分成两部分，系统误差和随机误差： \\[ E(\\mathbf{y}-\\hat{\\mathbf{y}})^{2}=E[f(\\mathbf{X})+\\mathbf{\\epsilon}-\\hat{f}(\\mathbf{X})]^{2}=\\underset{\\text{(1)}}{\\underbrace{E[f(\\mathbf{X})-\\hat{f}(\\mathbf{X})]^{2}}}+\\underset{\\text{(2)}}{\\underbrace{Var(\\mathbf{\\epsilon})}} \\label{eq:error}\\] 其中（1）是系统误差， \\(\\hat{f}\\)通常不能彻底对\\(\\mathbf{X}\\)和\\(\\mathbf{y}\\)之间的“系统关系”建模，这里系统关系指的是在不同样本上存在的稳定关系。这一部分误差能通过改进模型得到提高；（2）是随机误差，这部分误差代表当前数据无法解释的部分，因此无法通过建立更复杂的模型来改进。那些拥有众多参数的复杂黑箱模型最大的问题就是试图通过自变量解释这部分误差，也就是过度拟合。随机误差的显著特点就是在不同的样本上是无法重复的，于是判断是否存在过度拟合的一个准则就是预留一部分样本作为测试集，然后检验训练出来的模型在测试集上的表现。这个我们随后会讲到。这里要澄清一点，过度拟合不只发生在这些黑箱模型上，其发生的根源在于参数个数太多（常超过观测个数），理论上说任何模型都可能过度拟合，只是因为黑箱模型的参数尤其多，其高灵活性和复杂度放大了过度拟合的问题。有些黑箱模型在训练的过程中会使用“袋外数据”（又称为Out of Bag [OOB]）来尽量避免过度拟合的影响。 如果建模的目的也包含推断，那么这些“黑箱”模型就不合适，这就需要在模型可以解释的范围内使用尽量灵活的模型，比如Lasso回归，多元自适应回归样条等。有人可能不同意Lasso回归是灵活的。从其本质还是传统回归的角度看，它确实没有那么灵活，受到很多模型假设的限制。但由于Lasso的罚函数能同时起到变量选择的作用，这个变量的选择的过程可以不依赖于p值之类的参数（这些参数基于数据分布假设因此具有局限性），而可以通过优化模型预测值和真实值的差距来进行变量选择，从这个角度上看，该模型是灵活的。根据笔者的应用经验，Lasso作为收缩（或变量选择）方法在实际应用中的效果非常好。对于一些市场营销或者社会心理学相关的抽样调查数据分析，分层贝叶斯可能是一种灵活有效的方法，但拟合所需的计算时间更长。 其中系统误差可以进一步分解： \\[ \\begin{array}{ccc} E[f(\\mathbf{X})-\\hat{f}(\\mathbf{X})]^{2} &amp; = &amp; E\\left(f(\\mathbf{X})-E[\\hat{f}(\\mathbf{X})]+E[\\hat{f}(\\mathbf{X})]-\\hat{f}(\\mathbf{X})\\right)^{2}\\\\ &amp; = &amp; E\\left(E[\\hat{f}(\\mathbf{X})]-f(\\mathbf{X})\\right)^{2}+E\\left(\\hat{f}(\\mathbf{X})-E[\\hat{f}(\\mathbf{X})]\\right)^{2}\\\\ &amp; = &amp; [Bias(\\hat{f}(\\mathbf{X}))]^{2}+Var(\\hat{f}(\\mathbf{X})) \\end{array} \\] 系统误差由两部分组成，估计的偏度\\(Bias(\\hat{f}(\\mathbf{X}))\\)和估计的方差\\(Var(\\hat{f}(\\mathbf{X}))\\)。上面公式告诉我们，如果要最小化系统误差，需要同时最小化估计偏度和估计方差。偏度代表用模型逼近现实情况导致的误差，这部分误差可能非常复杂。比如线性回归假设自变量和应变量之间是线性关系，但现实生活中完全的线性关系并不常见。下图中x和fx的关系就是非线性的。因此，观测样本量再大，也无法用线性回归给出准确的预测。换句话说，在这种情况下，线性回归模型的预测具有很高的偏度。 library(grid) library(lattice) library(ggplot2) # 可以从网站下载multiplot()函数代码 # 用该函数在同一张画布上放置多张ggplot图 # 需要用到grid包 source(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/R_Code/multiplot.r&quot;) # 随机抽取一些非线性样本 x=seq(1,10,0.01)*pi e=rnorm(length(x),mean=0,sd=0.2) fx&lt;-sin(x)+e+sqrt(x) dat=data.frame(x,fx) # 绘制线性拟合图 ggplot(dat,aes(x,fx))+ geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) 由于我们通常使用训练集进行参数估计，如果训练集不同，得到的参数估计也会不同。直观的讲，估计方差表示如果我们用不同的数据集拟合相同的模型，得到估计值的变化，理想的情况是估计值的变化不会太大。对于高方差的模型，训练集的微小变化会导致很不相同的估计值。通常情况下，灵活度高的模型方差也更高，比如树模型，以及最初的助推法，后来在此基础上的随机森林模型和梯度助推法这样的集成方法的重要目标之一，就是通过汇总不同样本上得到的结果来降低估计方差。下图中的蓝色曲线是用平滑方法对上面的非线性观测进行拟合得到的，该曲线的灵活性很高，能够高度拟合当前数据： ggplot(dat,aes(x,fx))+geom_smooth(span = 0.03) ## `geom_smooth()` using method = &#39;loess&#39; 但是该方法有很高的方差，如果我们随机抽取不同的样本子集，得到的拟合曲线会有明显变化： # 设置随机种子 set.seed(2016) # 抽取其中部分样本拟合模型 # 样本1 idx1=sample(1:length(x),100) dat1=data.frame(x1=x[idx1],fx1=fx[idx1]) p1=ggplot(dat1,aes(x1,fx1))+geom_smooth(span = 0.03) # 样本2 idx2=sample(1:length(x),100) dat2=data.frame(x2=x[idx2],fx2=fx[idx2]) p2=ggplot(dat2,aes(x2,fx2))+geom_smooth(span = 0.03) # 样本3 idx3=sample(1:length(x),100) dat3=data.frame(x3=x[idx3],fx3=fx[idx3]) p3=ggplot(dat3,aes(x3,fx3))+geom_smooth(span = 0.03) # 样本4 idx4=sample(1:length(x),100) dat4=data.frame(x4=x[idx4],fx4=fx[idx4]) p4=ggplot(dat4,aes(x4,fx4))+geom_smooth(span = 0.03) multiplot(p1,p2,p3,p4,cols=2) ## `geom_smooth()` using method = &#39;loess&#39; ## `geom_smooth()` using method = &#39;loess&#39; ## `geom_smooth()` using method = &#39;loess&#39; ## `geom_smooth()` using method = &#39;loess&#39; 对相同的4个子集拟合线性模型，变化非常小： p1=ggplot(dat1,aes(x1,fx1))+ geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) p2=ggplot(dat2,aes(x2,fx2))+ geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) p3=ggplot(dat3,aes(x3,fx3))+ geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) p4=ggplot(dat4,aes(x4,fx4))+ geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) multiplot(p1,p2,p3,p4,cols=2) 总体说来，方差随着模型灵活度的增加而增加，偏差随着模型的灵活度增加而降低。在方差和偏差的变化共同决定了系统误差（或者均方误差，MSE）的变化。当我们提高模型的灵活性，偏差减小的速度开始时会超过方差增大的速度，MSE随之减小。但到了一定程度以后，提高模型的灵活性对偏差的影响不大但是方差大幅度增加，MSE随之增加。在之后的章节我们会看到，对于那些有一个控制模型灵活性的调优参数的模型，随着调优参数的减小（参数越大灵活度越低），模型误差先升高，后降低。 模型选择向来是非常困难的，这种困难不是数据分析行业特有的，很多专业领域都有类似的情况，比如医生判断病人所患的疾病，并在众多治疗方案中选择最合适的，这不是答案一目了然的选择题，决策的过程需要很多权衡和妥协。模型选择也类似，在选择过程中需要考虑具体的情况：项目目的，客户要求的精确度（这点很重要），计算量等等。这个选择的过程很难白纸黑字的像食谱一样写下来，这里我们只是尽己所能的介绍模型选择过程中需要考虑的点，以及评估不同模型的辅助性技术。具体的应用和“数据科学思维”还需要大家在从业过程中通过实践思考不断学习打磨。 7.2.2 应变量误差 若应变量包含可观的测量误差，那么这部分误差将反映在随机误差（\\(\\mathbf{\\epsilon}\\)）中。这部分误差使得均方根误差（RMSE）和\\(R^2\\)有相应的上下限。RMSE和\\(R^2\\)是回归模型常用的表现度量方法，我们在本章后面部分会进行介绍。因此，随机误差项不仅仅代表模型无法解释的波动，还含有测量误差。《应用预测建模（Applied Predictive Modeling）》[13]的第20.2小节有一个例子展示了因变量的测量误差对模型表现（RMSE和\\(R^2\\)）的影响。作者在因变量上加入了不同强度的随机正态噪声，重复拟合不同的模型，研究模型均方根误差（RMSE）和\\(R^2\\)的变化。这里我们用服装消费者数据进行类似的展示。假设我们面对这样一个问题，实际中消费者的收入并不是那么容易收集，很多人不愿透露这样的私人信息。于是我们希望利用消费记录变量建立关于消费者收入的预测模型，模型可以对那些数据库中缺失收入信息的记录进行填补。我们建立下面模型： # 载入数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) ymad&lt;-mad(na.omit(sim.dat$income)) # 计算Z分值 zs&lt;-(sim.dat$income-mean(na.omit(sim.dat$income)))/ymad # which(na.omit(zs&gt;3.5)) 找到利群点 # which(is.na(zs)) 找到缺失值 idex&lt;-c(which(na.omit(zs&gt;3.5)),which(is.na(zs))) # 删除含有离群点和缺失值的行 sim.dat&lt;-sim.dat[-idex,] fit&lt;-lm(income~store_exp+online_exp+store_trans+online_trans,data=sim.dat) 由输出可见，在没有额外添加噪音时模型的均方根误差（RMSE）是 29567，\\(R^2\\)是 0.6。下面我们在应变量年收入（income）上添加不同程度的噪音（均方根误差的0到3倍）： \\[ RMSE \\times (0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0) \\] noise&lt;-matrix(rep(NA,7*nrow(sim.dat)),nrow=nrow(sim.dat),ncol=7) for (i in 1:nrow(sim.dat)){ noise[i,]&lt;-rnorm(7,rep(0,7),summary(fit)$sigma*seq(0,3,by=0.5)) } 我们接下来检查噪音强度对复杂度不同的模型拟合\\(R^2\\)的影响。 拟合的模型复杂度从低到高依次为：一般线性回归，偏最小二乘回归，多元自适应回归样条，支持向量机（核函数是径向基函数），随机森林。 # 拟合一般线性回归模型 rsq_linear&lt;-rep(0,ncol(noise)) for (i in 1:7){ withnoise&lt;-sim.dat$income+noise[,i] fit0&lt;-lm(withnoise~store_exp+online_exp+store_trans+online_trans,data=sim.dat) rsq_linear[i]&lt;-summary(fit0)$adj.r.squared } 下面我们接着拟合偏最小二乘回归（PLS）。偏最小二乘源自于Herman Wold的非线性迭代偏最小二乘（NIPALS）算法 [15, 16]，是一种通过隐层级将非线性关系线性化的方法。该方法和主成分回归类似，不同在于主成分回归在选择成分的时候没有考虑因变量的信息，其目的是找到最大程度概括自变量空间变异性的线性组合（即，是无监督方法）。当自变量和因变量相关时，主成分回归能够很好的识别出它们之间的系统关系。然而，当存在和因变量不相关的自变量时，该方法的效果就会受到影响。而PLS最大程度概括与因变量相关性的线性组合。推荐大家用PLS解决那些自变量之间存在相关性，但不确定所有自变量都和因变量有关，同时希望用线性回归来解决的问题。在当前情况下，更加复杂的PLS表现效果并不比简单线性好，因为这里几个自变量都和因变量有关的不同信息（从前面的拟合结果看到所有变量都是显著的）。 # pls: 进行偏最小二乘回归和主成分回归 library(pls) rsq_pls&lt;-rep(0,ncol(noise)) # 拟合PLS模型 for (i in 1:7){ withnoise&lt;-sim.dat$income+noise[,i] fit0&lt;-plsr(withnoise~store_exp+online_exp+store_trans+online_trans,data=sim.dat) # plsr函数结果是mvr对象，需要用特定函数提取模型解释的应变量方差 rsq_pls[i]&lt;-max(drop(R2(fit0, estimate = &quot;train&quot;,intercept = FALSE)$val)) } # earth: 拟合多元自适应回归样条 library(earth) rsq_mars&lt;-rep(0,ncol(noise)) # 拟合多元自适应回归样条 for (i in 1:7){ withnoise&lt;-sim.dat$income+noise[,i] fit0&lt;-earth(withnoise~store_exp+online_exp+store_trans+online_trans,data=sim.dat) # 提取模型解释的应变量方差 rsq_mars[i]&lt;-fit0$rsq } # caret: 用于建立预测模型的包，可以拟合多种模型 library(caret) rsq_svm&lt;-rep(0,ncol(noise)) # 拟合支持向量机 # 注意：运行需要一些时间 for (i in 1:7){ idex&lt;-which(is.na(sim.dat$income)) withnoise&lt;-sim.dat$income+noise[,i] trainX&lt;-sim.dat[,c(&quot;store_exp&quot;,&quot;online_exp&quot;,&quot;store_trans&quot;,&quot;online_trans&quot;)] trainY&lt;-withnoise fit0&lt;-train(trainX,trainY,method=&quot;svmRadial&quot;, tuneLength=15, trControl=trainControl(method=&quot;cv&quot;)) # 提取模型解释的应变量方差 rsq_svm[i]&lt;-max(fit0$results$Rsquared) } # randomForest: 拟合随机森林模型 library(randomForest) rsq_rf&lt;-rep(0,ncol(noise)) # 拟合随机森林模型 # ntree=500 用500棵树 # na.action = na.omit 忽略缺失值 for (i in 1:7){ withnoise&lt;-sim.dat$income+noise[,i] fit0&lt;-randomForest(withnoise~store_exp+online_exp+store_trans+online_trans,data=sim.dat,ntree=500,na.action = na.omit) # 提取模型解释的应变量方差 rsq_rf[i]&lt;-tail(fit0$rsq,1) } # reshape2在之前介绍过，用于数据整形 library(reshape2) rsq&lt;-data.frame(cbind(Noise=c(0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0),rsq_linear,rsq_pls,rsq_mars,rsq_svm,rsq_rf)) # 将数据转化成长型 rsq&lt;-melt(rsq,id.vars=&quot;Noise&quot;,measure.vars=c(&quot;rsq_linear&quot;,&quot;rsq_pls&quot;,&quot;rsq_mars&quot;,&quot;rsq_svm&quot;,&quot;rsq_rf&quot;)) # 功能强大的绘图包 library(ggplot2) # 用ggplot2包进行可视化 ggplot(data=rsq, aes(x=Noise, y=value, group=variable, colour=variable)) + geom_line() + geom_point()+ ylab(&quot;R2&quot;) Figure 7.1: 模型\\(R^2\\)随应变量噪音强度变化，rsq_linear是简单线性回归，rsq_pls是偏最小二乘回归，rsq_mars是多元自适应回归样条回归，rsq_svm是支持向量机，rsq_rf是随机森林。 由图7.1中可以看到： 所有模型拟合效果随着噪音强度的增加急剧下降。对变量测量系统的理解能够帮助我们更好的预期模型的表现。这是在之前“数据分析一般流程”中说过的从问题到数据这个环节需要弄清的问题。你应该清楚当前数据库中已有的数据的质量。如果客户提供给你额外的数据，或者需要你从其它地方获得数据，数据质量是必须交流清楚的问题，笔者就曾在这里栽过跟头，希望大家可以避免类似的错误。 使用更加复杂的模型的效果不一定更好，如复杂的随机森林和支持向量机表现居中，简单线性回归和偏最小二乘回归在噪音低的时候拟合效果最差。效果最好的是多元自适应回归样条回归，该模型比简单线性回归复杂，但比剩下其它的模型的解释性都更强。 噪音增加到一定程度，复杂的随机森林模型能够发现的潜在结构变得更加模糊，模型表现不如其它更简单的模型。因此系统测量误差较大时，使用更简单的易于解释的模型可能是更好的选择，大家建模的时候要尽量多尝试几种模型，在表现相当的情况下选择最简单的模型，模型的评估和选择很好的反应了一个数据科学家的职业“成熟度”。 7.2.3 自变量误差 传统的统计模型通常假设自变量的测量无误差（或者随机性），这在实际中是不可能的，所以我们需要考虑自变量观测的随机性。自变量观测中的随机性产生的影响取决于如下几个因素：随机性的强度，相应因变量在模型中的重要性，使用模型的类别。我们选取自变量“在线消费”（online_exp）为例，用和上面相似的方法在该自变量上添加不同程度的噪音看其对模型拟合情况的影响。我们在自变量online_exp和上添加如下不同程度的噪音（标准差的0到3倍）： \\[ \\sigma_{0} \\times (0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0) \\] 其中\\(\\sigma_{0}\\)是在线消费观测的标准差。 noise&lt;-matrix(rep(NA,7*nrow(sim.dat)),nrow=nrow(sim.dat),ncol=7) for (i in 1:nrow(sim.dat)){ noise[i,]&lt;-rnorm(7,rep(0,7),sd(sim.dat$online_exp)*seq(0,3,by=0.5)) } 同样的，我们检查噪音强度对复杂度不同的模型拟合\\(R^2\\)的影响。拟合的模型复杂度从低到高依次为：一般线性回归，偏最小二乘回归，多元自适应回归样条，支持向量机（核函数是径向基函数），随机森林。代码和之前类似，这里就不重复展示。 Figure 7.2: 模型\\(R^2\\)随自变量(在线消费)噪音强度变化，rsq_linear是简单线性回归，rsq_pls是偏最小二乘回归，rsq_mars是多元自适应回归样条回归，rsq_svm是支持向量机，rsq_rf是随机森林。 比较图7.2和图7.1，可以看到自变量的误差和应变量误差对模型拟合结果的影响很不相同。应变量误差是无法克服的，对任何模型来说都是个硬伤。而自变量误差确不一定。试想极端的情况，在线消费这个变量完全是随机噪音，也就是所说的无信息变量，随机森林和支持向量机受的影响并不太大。线性模型和偏最小二乘回归的结果依旧基本重合，而且随着噪音的增加拟合效果开始下降较快，到一定程度后趋于平稳，如果噪音不断增加，最后拟合的情况实际上会趋近于移除“在线消费”这个变量的结果。总体说来，如果某个自变量含有误差，其它与之相关的变量在某种程度上可以进行弥补。线性模型对于自变量的观测误差的抗性普遍较差。 7.3 数据划分和再抽样 模型训练和选择过程都离不开数据的划分和再抽样。数据划分是将一部分数据预留出来用于模型测试，只用另外的部分数据用于模型的训练。再抽样过程牵扯到重复的从训练集中抽取样本并且在不同的样本上拟合模型，以此来得到关于拟合模型的信息。假设我们想知道某线性模型拟合度\\(R^2\\)的稳定性（也可以用其它模型拟合度量），可以重复的抽取不同的样本，然后拟合相同的线性模型，检查这些模型对应\\(R^2\\)的变化。由于牵扯到使用随机样本重复拟合模型，这个过程有一定的计算量，最近五年里，数据处理工具和技术获得了飞速的发展。除非你需要处理PB（\\(2^{50}\\)比特）级别的数据，或者每天要处理千亿级的事件，现阶段大多数技术已经能轻松满足你的需求了。 你可能会问：为什么要对数据划分和再抽样？简单的回答是避免过度拟合。在预测问题中，有时拟合的模型能很好的描述现有数据中的变量关系，但是对新样本的预测有很大的偏差，这时就发生了过度拟合。很多领域都会讨论过度拟合，如医学研究，化学计量，气象，金融和社会学研究等等。现代很多含有调优参数的分类 和回归模型有高度的灵活性，如之前提到的随机森林、支持向量机等。它们能够对复杂的关系进行建模，但是很容易过度强调不可再现的数据关系。要注意，虽然过度拟合的问题在灵活度高的模型中更加突出，所有模型（包括简单线性回归）在应用中都可能出现该问题。建模的目的是找到可重复的数据关系， 这就需要将现有数据划分成不同的数据集来调试模型参数和评估模型表现。 划分和再抽样的一般过程如下： 将样本划分成训练集和测试集 使用训练集拟合模型 将拟合的模型应用于测试集评估模型表现 关于数据划分，我们会介绍3种划分数据的方法：（1）按照结果变量划分数据；（2）按照预测变量划分数据；（3）按照时间序列划分数据。之后我们会介绍两种主要的再抽样方法： bootstrap和交互校验。 7.3.1 划分训练集和测试集 关于数据划分大家可能主要会问这三个问题：（1）为什么要划分训练集和测试集？（2）多少比例的数据用于训练集？（3）具体如何划分？我们现在就对此逐一回答。 70%用于训练集，30%用于测试集数据划分示意图 刚接触数据科学的人常常会问为什么我们要预留一部分数据作为测试集而不是使用全部的数据用于训练。印象中传统商业智能声称的数据分析通常只是数据描述。通过从数据库中查询相关测量来回答简单的问题，如：2015年某产品每月销售量是多少？我们网站在过去一个月每天的访问量是多少？两种包装设计的同类产品在某大零售店上个月的销量差距多大？像这样的问题确实不用对数据进行划分，相反我们需要用尽可能完整的数据，然后对感兴趣的部分求和或者平均。假设数据观测准确，我们不需要怀疑问题的答案，因为这些问题本质上就是对数据进行某种描述总结，没有牵扯到任何分析推断。 数据科学家需要解决的不会是这样的问题，常是预测问题，或者同时还需要从预测模型中得到相应能够指导决策的推断。在这些情况下，分析的重心在于找到自变量\\(\\mathbf{X}\\)和应变量\\(\\mathbf{y}\\)之间的系统关系。这时我们就必须非常小心，因为我们在用一个样本得到一般化的结论，进而对将来可能出现的观测进行预测，这远远超越了描述统计的界限。根据彭加莱的理论，在预测未来的过程中，预测的越远的未来要求模型越精确，因为你的错误率会迅速上升。每向前预测一步，噪声会随着以一种非线性的方式迅速增加，因此我很难相信对5年以后某事件的定量预测。我们能够处理定性的事物，能够讨论系统的某些特点，但能够计算的东西是很局限的。在《黑天鹅》那本书中，作者以数学家Michael Berry的弹子球计算为例说明了这种放大效应。该实验是预测弹子球在球桌上的运动轨迹。如果弹子球的基本参数已知，你能够计算出桌面阻力，测量撞击量，那么就可以预测第1次撞击的结果。要预测第2次撞击就更为复杂一些，你需要小心确定球的初始状态，但不是不可能。如果要计算第9次撞击的结果你需要考虑某个站在桌子旁边的人的体重和产生的引力。要计算第56次撞击结果你需要考虑宇宙中的每一个基本粒子。注意这还只是单独的弹子球而没有牵扯到有着自由意志的人，以及不同人之间相互的影响。对现实世界的复杂局面，人的预测能力有着本质上的局限性。因此在实际预测分析当中，你需要很小心的界定这个可预测的边界，好比在弹子球实验中，你能预测第1次撞击的结果或者咬咬牙，再多杀一大片脑细胞做第2次撞击预测，但不要试图再进一步，承认自己的局限需要知识和勇气。回到实际分析中，如何找到预测的边界？（注：随着你经验的增长，你会遇到很多你无法预测（有时是分析）的情况。）目前我知道的方法就是在仔细确保当前情况基本符合假设的情况下，严格划分训练集和测试集，尽可能对模型的预测情况进行评估，检测预测模型的精确度和稳定性。划分背后隐含的假设是： 我们用于分析的数据展现的过程能够反应真实世界中事情的发展过程 我们想要对其建模的真实世界中事情的发展过程随着时间变化是相对稳定的。如，用上个月的数据建立的表现良好的模型，在接下来的一个月的观测上依旧能够有类似的良好表现 换句话说，我们想要知道如果我们用模型来对新样本进行预测时会发生什么。我们的预测和真实将观测到的值有多接近？预测值偏离真实值的误差大致是多少？模型的误差是不是单向的，即预测是不是总大于真实值？这些都是很自然的问题，但它们的答案并非那么容易获得。最简单的理解模型在将来数据集上表现的方法就是试图模拟这件事。虽然严格说来，在将来事件发生之前，我们不可能得到相应的数据，但是我们能够预留一部分当前的数据并将它们视为将来的观测。例如，如果我们要预测2016年哪些农民还会某品牌的种子，可以用之前到2015年的历史数据建立预测模型，然后预测2016年的购买情况。这是一个相当好的模拟，由于我们其实已经知道2016年实际购买情况，可以将预测和真实情况进行对比。 在商业促销活动和信用风险的案例中，我们得到的数据通常和某个时间点相连（或者时间区间：一周，一个月，一个促销活动期间）。通常称这样的数据有代表性（用某时间点或者时间段的数据代表普遍情况）。在这样的情况下我们通常将数据集随机分成不同部分，然后用一部分（训练集）建立模型，另外一部分（测试集）来评估模型表现，可能的话对模型做出调整。 如果这两条假设大致正确，那么当前数据就能够合理反映未来的情况。因此在这种情况下，预留一部分当前数据来估计模型在将来的表现是合理的。明确了预测模型的一些假设前提，以及划分训练集和测试集的必要性之后，下一个问题是我们该将多少比例的数据用于训练集。 一般这需要视具体情况而定。通常需要考虑的两个因素是：（1）样本量；（2）计算速度。当样本量较大时，在考虑计算速度的条件下，我一般会尝试60%，70％和80%这三个比例，看哪个效果更好。如果样本量很小，那么测试集其评估模型效果的能力将非常有限，并且在原本样本量就不大的情况下再分出一部分数据会极大影响模型拟合。这种情况下，使用再抽样技术更加有效。常用的再抽样方法有交互校验和Bootstrap。 我们可以用createResample()函数生成简单bootstrap样本，createFolds函数可以生成平衡的交互校验样本集。 具体如何划分? 划分训练集和测试集时需要小心避免两个数据集有系统差别。例如，我们不能简单的把前半部分数据当作训练集，后半部分当作测试集。因为数据有可能是以某种方式排列的，如，按收入从大到小，按访问次数多少排列等等。有一种避免数据集间随机差别的方法是用简单的随机抽样，如对每个样本我们都抛下硬币，人头面就归于训练集，菊花面就归于测试集。有时还有一些其它因素需要考虑，但本质都是随机抽样。要想真正理解划分数据背后的逻辑需要实践。下面我们介绍经常使用的几种划分方法。 按照结果变量划分数据 若结果变量\\(\\mathbf{y}\\)为分类变量，那么我们的到的测试集和训练集中结果变量各类的分布比例应该类似。可以使用caret包中的createDataPartition()函数平衡划分样本集。回到我们之前使用的服装消费者数据集，假设我们想要建立关于消费者类别（segment）的判别模型，这时结果变量为segment，我们用80%的样本训练模型，20%的样本做为测试集，且训练集和测试集中各类别的比例要尽可能相近。我们可以用如下R代码实现： # 载入数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 需要caret包 library(caret) # 设置随机种子这样能得到相同的抽样结果 set.seed(3456) trainIndex &lt;- createDataPartition(sim.dat$segment, p = .8, list = FALSE, times = 1) head(trainIndex) ## Resample1 ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 ## [5,] 6 ## [6,] 7 list = FALSE选项使得返回的值是数据框。该函数还有一个选项times，用于设置划分的次数，你可以一次返回多次划分的结果，函数会返回一个（或多个）整数向量（指针向量），指明归于训练集的行（你可以设置times＝2再运行一下上面的代码看看输出有什么不同）。下面我们通过返回的指针向量（trainIndex）得到训练集和测试集： # 得到训练集 datTrain &lt;- sim.dat[ trainIndex,] # 得到测试集 datTest &lt;- sim.dat[-trainIndex,] 按照设置，训练集中该有800个样本，测试集中有200个样本。我来看看两个集合中消费者类别的比例分布是否相似： library(plyr) ddply(datTrain,&quot;segment&quot;,summarise,count=length(segment), percentage=round( length(segment)/nrow(datTrain),2)) ## segment count percentage ## 1 Conspicuous 160 0.20 ## 2 Price 200 0.25 ## 3 Quality 160 0.20 ## 4 Style 280 0.35 ddply(datTest,&quot;segment&quot;,summarise,count=length(segment), percentage=round(length(segment)/nrow(datTest),2)) ## segment count percentage ## 1 Conspicuous 40 0.20 ## 2 Price 50 0.25 ## 3 Quality 40 0.20 ## 4 Style 70 0.35 很明显两个集合中消费者类别比例分布是一样的（实际应用中两个集合分布不一定严格相似，但应该非常接近）。 按照自变量划分 还可以使用最大差异度法[17]划分数据（maxDissim()函数）。假设样本集A中含有m个样本，样本集B含有n个样本，n&gt;m，且我们要从B中选出一些样本加到A中，该子集中的样本要尽量和A中的不同。要实现这一点，对B中的一个样本，计算A中样本和该样本的差异度（距离，这里会算出m个值，因为A中有m个样本）。然后将和A中样本最不相同的B的样本抽取出来加入A，重复这个过程，直到A的样本量达到要求。关于这么权衡这m个差异度找到和A“最不相似”的样本，有不同的方法，比如以最小的值为准，将所有距离求和等等。这里没有什么黄金法则，建议大家尝试几种方法，查看比较得到的训练/测试样本自变量分布，选取其中一种。用这种方式可以得到自变量分布相似的不同样本集。R中有不同的计算样本间差异度（基于自变量观测）的函数。caret包中调用的是proxy包中的函数。关于不同的差异度测量，见相关包的帮助文档。我们可以通过选项 obj设置和样本集A“最不相似”的样本的方式，其中minDiss表示以最小差异度为准，sumDiss表示使用差异度之和。 我们用服装数据的一个子集为例展示按照自变量抽样。这里选取年龄和收入这两个变量。 # 最大差异度抽样用到proxy包 library(proxy) # 用lattice包绘制散点图 library(lattice) # 选取年龄和收入这两个变量 testing&lt;-subset(sim.dat,select=c(&quot;age&quot;,&quot;income&quot; )) 我们先随机选取5个样本做为初始集（start），剩下的样本组成集合samplePool： set.seed(5) # 随机选取5个样本 startSet &lt;- sample(1:dim(testing)[1], 5) start &lt;- testing[startSet,] # 剩下的样本存在对象samplePool中 samplePool &lt;- testing[-startSet,] 通过maxDissim()函数从samplePool中抽取5个样本，这5个样本尽量和start中已有的样本不同。： # 通过最大化差异得到的样本存在数据框new内 # obj = minDiss 表示总体差异度以最小差异度为准 newSamp &lt;- maxDissim(start, samplePool,obj = minDiss, n = 5) new&lt;-samplePool[newSamp,] 我们再从samplePool中不用最大差异法，而是随机抽取5个样本，将这5个样本存在数据框new2中： newSet &lt;- sample(1:dim(samplePool)[1], 5) new2&lt;-testing[newSet,] 绘制散点图比较两种不同方法（new：用最大化差异法抽取的样本；new2：随机抽取的样本）抽取的样本和初始样本（start）有什么不同： start$group&lt;-rep(&quot;start&quot;,nrow(start)) new$group&lt;-rep(&quot;new&quot;,nrow(new)) new2$group&lt;-rep(&quot;new2&quot;,nrow(new2)) xyplot(age~income,data=rbind(start,new,new2),grid = TRUE, group = group, auto.key = TRUE ) Figure 7.3: 按自变量最大化差异抽样 由图7.3可见，通过最大化差异抽取的样本（new）和初始样本点（start）分布在图的不同位置。而随机抽取的新样本（new2）和原始样本更加接近。我们为什么希望每次抽取的样本和之前的不一样呢？因为我们希望最后得到的训练集和测试集覆盖的自变量观测区间相似。如果抽取的样本点都来自一个区域的话（比如全部都是年龄30以下，收入10万以下），如果讲这个样本用于训练的模型很可能不具有预测这个区域外样本的能力。反之要是用这个样本做为测试集，则无法检测模型在这个区域外样本上的表现。 按时间序列划分 对于时间序列数据，用简单随机抽样通常不是最好的方式。有一种按时间序列划分训练集和测试集的方法，关于该方法的讨论见[18]。我们临时抽取一个长度为100的来自1阶自回归模型［AR(1)］的时间序列样本，用来展示caret包中对时间序列样本划分测试集和训练集的函数createTimeSlices()。由于时间序列话题不在本书范围之内，这里不会进行过多讨论。 # 抽取符合AR(1)的时间序列向量 timedata = arima.sim(list(order=c(1,0,0), ar=-.9), n=100) # 对时间序列作图 plot(timedata, main=(expression(AR(1)~~~phi==-.9))) Figure 7.4: 时间序列样本图 图7.3展示了100个模拟的时间序列观测。对这样的数据，我们希望训练集和测试集都能覆盖到不同时段的观测。下面用createTimeSlices()函数对数据进行划分。该函数中有3个需要设置的参数： initialWindow: 初始训练集样本中的连续观测数目 horizon: 测试集中的观测数目 fixedWindow: 逻辑值，取值为FALSE时，训练集从第一个样本开始划分区间长度不固定。 timeSlices &lt;- createTimeSlices(1:length(timedata), initialWindow = 36, horizon = 12, fixedWindow = T) str(timeSlices,max.level = 1) ## List of 2 ## $ train:List of 53 ## $ test :List of 53 可以看到函数结果返回2个列表，分别含有训练集和测试集的样本索引。我们查看第一个训练集和测试集样本。 # 将训练集索引信息存在trainSlices对象内 trainSlices &lt;- timeSlices[[1]] # 将测试集索引信息存在testSlices对象内 testSlices &lt;- timeSlices[[2]] # 分别查看第一个训练集样本和测试集样本 trainSlices[[1]] ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ## [24] 24 25 26 27 28 29 30 31 32 33 34 35 36 testSlices[[1]] ## [1] 37 38 39 40 41 42 43 44 45 46 47 48 第一个训练集样本是原数据中第1个观测到第36个观测（因为initialWindow = 36），接下来从第37到48这12个观测被划分到第一个测试集（因为horizon = 12）。你可以通过head(trainSlices)查看后续的样本索引。尝试着改变fixedWindow =的设置，然后重复上面的代码得到新的trainSlices和testSlices，然后键入： head(trainSlices) head(testSlices) 比较两种结果的不同就能够很容易理解该选项的作用了。 训练集和测试集的划分很容易理解和实现。但注意其中两个潜在的缺陷： 由于训练集和测试集的划分是随机的，所以重复这一过程在测试集上得到的误差会有波动。 由于训练集中只包含原始观测的一个子集，拟合模型使用的是部分数据。通常当数据量不是非常大的时候，使用更少的观测多少会对模型拟合造成负面影响。这就意味着该过程可能过度估计模型误差（即，使用所有观测拟合的模型的误差应该比当前估计的要小）。 7.3.2 重抽样 重抽样即对样本进行重复划分，所以是建立在数据划分的基础上。其基本原理是：用部分样本拟合模型，用剩下的样本评估模型。多次重复这一过程，然后对结果进行汇总。进行重抽样的目的可能有： 对于有调优参数的模型，如支持向量机，罚函数模型等，必须通过重抽样估计调优参数。这时的目的是针对一个模型表现的度量（如RMSE），找到能够优化该度量的调优参数值。 对于不含有调优参数的模型，如普通线性回归，最小二乘回归等，就模型拟合本身不需要重抽样，但可以通过重抽样考察模型拟合结果的稳定性，也可以用于检验模型在和训练集无关的样本上的表现。 这一小节将介绍几种主要的重抽样方法。 7.3.2.1 k折交叉验证 k折交叉验证的主要过程如下： 将样本随机划分为\\(k\\)个大小相当的子集 对\\(i=1…k\\) 用除了第\\(i\\)个样本集之外的样本拟合模型\\(M_{i}\\) 将\\(M_{i}\\)用在第i个样本集上，对结果进行评估 5折交叉验证 这样会得到k个模型评估结果，将这些结果进行汇总（通常是计算均值和标准差），然后基于此了解调优参数和模型表现之间的关系。联系之前介绍的不同划分方法，可以将这些划分方法应用到k折交叉验证中，使k个子集中的因变量组成尽可能平衡。k折交叉验证的一个特定是k等于样本量，这时每次只有一个预留样本，该情况也称为留一交叉验证（LOOCV），注意在这种情况下模型最终的评估结果将根据所有的预测值进行计算。通常在样本量较小的时候使用LOOCV，道理很简单，样本量小的时候我们应该用尽可能多的样本拟合模型。关于交互校验的折数，很多R函数默认设置k=10，但没有黄金标准。折数越多，每次预留在外的样本就越少，模型表现估计值和真实值之间的差距就越小。但LOOCV的计算量最大，因为其模型拟合的次数等于样本量，且每次模型拟合使用的子集样本量几乎和训练集相同。另一方面，当k值很小时（2或者3），计算效率高但是结果的方差和偏差都会增加。这意味着如果重复抽样的过程得到的结果可能很不一样。当样本量足够大时，方差和偏差的潜在影响就可以忽略不计，在这种情况下可以使用折数较低的交叉验证。这里讲到的关于计算效率和偏差之间的权衡，需要读者自己反复实践才能真正理解。 caret包中有几个关于重抽样的函数。createFolds()函数用于k折交叉验证。我们按照 消费者类别变量对服装消费者数据抽取k折交叉验证样本。 library(caret) class&lt;-sim.dat$segment #k折校验重抽样 set.seed(1) cv&lt;-createFolds(class,k=10,returnTrain=T) str(cv) ## List of 10 ## $ Fold01: int [1:900] 1 2 3 4 5 6 7 8 9 10 ... ## $ Fold02: int [1:900] 1 2 3 4 5 6 7 9 10 11 ... ## $ Fold03: int [1:900] 1 2 3 4 5 6 7 8 10 11 ... ## $ Fold04: int [1:900] 1 2 3 4 5 6 7 8 9 11 ... ## $ Fold05: int [1:900] 1 3 4 6 7 8 9 10 11 12 ... ## $ Fold06: int [1:900] 1 2 3 4 5 6 7 8 9 10 ... ## $ Fold07: int [1:900] 2 3 4 5 6 7 8 9 10 11 ... ## $ Fold08: int [1:900] 1 2 3 4 5 8 9 10 11 12 ... ## $ Fold09: int [1:900] 1 2 4 5 6 7 8 9 10 11 ... ## $ Fold10: int [1:900] 1 2 3 5 6 7 8 9 10 11 ... 结果返回10个子样本集中样本对应的行数。我们可以通过交叉验证来估计调优参数。回忆之前应变量误差的小节中拟合支持向量机模型的代码： #这里只是截取了之前的代码用于展示，并不能独立运行 fit0&lt;-train(trainX,trainY,method=&quot;svmRadial&quot;, tuneLength=15, trControl=trainControl(method=&quot;cv&quot;)) 上面代码中“method=&quot;cv&quot;”告诉R进行交叉验证，这里默认\\(k=10\\)。 7.3.2.2 重复训练/测试集划分 该方法其实就是对数据集重复多次训练集／测试集划分，用训练集建立模型，用测试集评估模型。和k折交叉验证不同，该过程生成的测试集可能有重复的样本，其通常重复更多次。对于划分比例和重复次数没有固定法则，通常将总样本的75%到80%用于训练，剩下的用于测试，用于训练的样本越接近，得到模型估计的偏差就越小。该方法中重复的次数的增加可以减少模型评估结果的不确定性，当然代价就是在模型复杂时的计算时间。当然，重复的次数也和测试集的样本占总体比例有关，如果比例小，那么得到的预测评估结果的波动性就更大，这时就需要增加重复次数来见效评估结果的不确定性。 假设我们还是按照消费者类别（segment）划分数据，这依旧可以使用之前用于划分训练集和测试集的函数createDataPartition()。记得之前该函数中的选项设置times=1么？这里只要将其设置成你想要重复的次数即可。 trainIndex &lt;- createDataPartition(sim.dat$segment, p = .8, list = FALSE, times = 5) dplyr::glimpse(trainIndex) ## int [1:800, 1:5] 1 3 4 5 6 7 8 9 10 11 ... ## - attr(*, &quot;dimnames&quot;)=List of 2 ## ..$ : NULL ## ..$ : chr [1:5] &quot;Resample1&quot; &quot;Resample2&quot; &quot;Resample3&quot; &quot;Resample4&quot; ... 类似的，对于其它划分方式，只要大家知道如何划分，重复划分应该很容易。 7.3.2.3 Bootstrap 方法 Bootstrap是一种应用及其广泛而且强大的统计工具。它可以用来定量分析参数估计或统计模型的不确定性[19]。如，可以通过Bootstrap估计线性回归模型参数拟合的标准差，这是另外一种取代p值的方法。该方法的强大在于其可以很容易应用于每个模型（说白了就是是对数据重复进行有放回随机抽样，拟合的过程），有的模型要是用传统的统计推断方法很难得到标准差和置信区间。这是一个典型的听起来很高端，其实没太多技术含量的方法。但很多天才的想法不都是这样么？之前没有人想到，之后大家都觉得这么简单粗暴有效怎么会想不到。由于是有放回抽样，一个样本可能多次被选中，且Bootstrap样本量和原数据样本量一样。这些没有被选中的样本称为“袋外（out-of-bag）样本”。选中的样本用来建立模型，带外样本用来评估模型。Efron指出，一般情况下[20]，Bootstrap估计的模型错误率的不确定性更小。平均而言，63.2%的样本点在 Bootstrap 中出现过至少一次，因此其估计的偏差与2折交叉验证相似。如之前所述，折数越小，用于训练的样本数目越少，这意味着估计的偏差越大。增加样本量可以缓解该问题。总的来说，和交叉验证相比，Bootstrap偏差更大，不确定性更小。针对估计偏差问题，Efron对原始Bootstrap过程进行了改进，得到下面的632方法： \\[(0.632 × 原始 Bootstrap 估计错误率) + (0.368 ×显性错误率)\\] 其中显性错误率就是用所有样本进行建模，然后再作用于相同的样本集得到的模型错误率，该估计显然过度乐观。这一改进虽然在某种程度上降低了偏差，但在样本量小的时候依旧表现不佳。试想严重过度拟合的情况下显性错误率几乎是0，那么上面公式中的第二项也就不存在了，这个时候，632方法给出的错误率估计可能过度乐观。Efron 和 Tibshirani之后进一步改进了632方法，得到“632+ 方法”，进一步调整了Bootstrap 估计[21]。 7.4 本章总结 本章介绍了一些基础建模技术，包括有监督和无监督的概念。模型误差分类： 系统误差：能够通过改进模型减小这部分误差 随机误差：当前数据无法解释的部分，无法通过建立更加复杂的模型来改进 此外我们讲了误差的两个来源，应变量误差和自变量误差。其中应变量误差会反映在随机误差中，这是个硬伤，无法克服。而某些自变量的误差可能通过其它相关自变量得到弥补，其影响取决于随机性强度，相应变量在模型中的重要性，以及自变量之间的相关性。 最后，也是最重要的一个话题是数据的划分和再抽样。其主要目的是为了判断模型真实的表现。我们介绍了3种数据划分的方法： 按照结果变量划分数据； 按照预测变量划分数据； 按照时间序列划分数据。 我们还介绍了两种主要的再抽样方法：bootstrap和交互校验。重抽样是建立在数据划分的基础上，其主要目的有两个： 对于有调优参数的模型估计调优参数； 考察模型拟合结果的稳定性。 其中我们讨论了不同重抽样的影响，以及在方差，偏差和计算效率之间的权衡。这里讲的所有方法都需要大家在实践中总结，才能真正成为自己的技能。 References "],
["section-8.html", "第8章 模型评估度量 8.1 回归模型评估度量 8.2 分类模型评估度量 8.3 本章总结", " 第8章 模型评估度量 当我们问哪个模型拟合效果好的时候我们到底在问什么？很多看似明确合理的问题一旦究其细节就会发现，其定义非常模糊以至于无法直接回答。这个问题的模糊之处在于没有指明用什么来衡量“拟合效果”？要比较模型首要任务是确定一个模型表现的度量，即通过什么标准来决定两个模型谁更好。模型表现的度量方法有好几种，要想更加全面的了解模型的表现，有时需要结合多种度量方式。这里我们只是单独介绍模型表现评估的度量，真正对度量的使用是建立在数据划分和再抽样的基础上的，也就是拟合模型和评估模型使用的数据集应该不同，否则得到的度量估计将过度乐观。 8.1 回归模型评估度量 接下来我们会依次介绍下面几种回归模型的表现度量方式：RMSE、校正\\(R^2\\)、\\(C_{p}\\)、AIC和BIC。 当因变量是数值时，我们可以使用均方误差平方根（Root mean squared error, RMSE）为指标衡量模型的表现。 这个度量是模型残差的函数，其中残差即为观测值减去模型的预测值。 均方误差（Mean squared error, MSE）的计算方法是将残差平方然后取平均， 而RMSE则是取MSE的平方根，从而它与原始数据的单位相同。 \\[MSE=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}\\] \\[RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}}\\] 得到的RMSE取值通常解释为残差离0的平均距离，或者解释为观测值和模型预测值之间平均的距离。回到之前介绍误差来源时用过的例子，对服装消费者数据中的收入（income）建立一般线性模型，将消费记录变量作为自变量，结果如下所示： # 载入服装消费者数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) fit&lt;-lm(income~store_exp+online_exp+store_trans+online_trans,data=sim.dat) summary(fit) ## ## Call: ## lm(formula = income ~ store_exp + online_exp + store_trans + ## online_trans, data = sim.dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -128768 -15804 441 13375 150945 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 85711.6796 3651.5991 23.472 &lt; 2e-16 *** ## store_exp 3.1977 0.4754 6.726 3.28e-11 *** ## online_exp 8.9949 0.8943 10.058 &lt; 2e-16 *** ## store_trans 4631.7507 436.4777 10.612 &lt; 2e-16 *** ## online_trans -1451.1618 178.8355 -8.115 1.80e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 31530 on 811 degrees of freedom ## (184 observations deleted due to missingness) ## Multiple R-squared: 0.6018, Adjusted R-squared: 0.5998 ## F-statistic: 306.4 on 4 and 811 DF, p-value: &lt; 2.2e-16 拟合的线性模型fit的RMSE为3.15310^{4}（输出底部“Residual standard error:”后面的值）。 另一个常用的度量是R-Squared，通常写作\\(R^2\\)。它实际上是观测值和预测值的相关系数的平方。大家可能对线性回归中的\\(R^2\\)很熟悉，但它可以用于任何回归模型。通常解释成模型能够解释的应变量总变异的比例其中R-squared＝0.6 表示模型可以解释因变量总变异的四分之三。尽管这是一个易于解释的统计量，但要注意它是一种相关性而不是准确性的度量，它依赖于应变量方差。比如虽然fit的\\(R^2\\)不低，但是RMSE为0.6，说明预测的收入和真实收入之间的平均差距为3.15310^{4}，这样的精确度并不高。在应变量的取值很大时，即使&gt;90%的\\(R^2\\)也不一定代表足够的精确度，在对公司的销售总额进行建模就常是这样的情况。之前我们在展示自变量和应变量误差对模型表现影响的时候有用过\\(R^2\\)，那时并没有考虑变量个数对\\(R^2\\)的影响（因为变量个数和观测个数相比并不多）。但事实上\\(R^2\\)会随着变量个数的增加而增大。校正\\(R^2\\)就是针对该问题对原\\(R^2\\)进行改进。原始\\(R^2\\)的定义为： \\[R^{2}=1-\\frac{RSS}{TSS}\\] 其中\\(RSS=\\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^{2}\\)，\\(TSS=\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}\\)。 由于RSS总是随着变量个数的增加而降低，\\(R^2\\)也就相应随着变量个数增加而增加。对于有\\(p\\)个变量的最小二乘模型，校正\\(R^2\\)定义为： \\[校正R^{2}=1-\\frac{RSS/(n-p-1)}{TSS/(n-1)}\\] 最大化\\(校正R^{2}\\)等同于最小化\\(RSS/(n-p-1)\\)。由于考虑了变量个数\\(p\\)，\\(RSS/(n-p-1)\\)随着变量个数的增加可能增加或者减少。\\(校正R^{2}\\)的直观想法是当模型中已经包含所有有用的变量后继续加入噪音变量只能略微降低\\(RSS\\)，由于变量个数增加，\\(n-p-1\\)增加进而整体\\(RSS/(n-p-1)\\)反而增加了，于是\\(校正R^{2}\\)会降低。因此，从理论上讲对应最大\\(校正R^{2}\\)的模型只包含有效变量而没有噪音变量。模型每加入一个噪音变量都会受到“惩罚”。 对于含有\\(p\\)个变量的最小二乘拟合模型，\\(C_{p}\\)的定义如下： \\[C_{p}=\\frac{1}{n}(RSS+2p\\hat{\\sigma}^{2})\\] 其中\\(\\hat{\\sigma}^{2}\\)是对模型随机项\\(\\epsilon\\)的方差的估计。本质上\\(C_{p}\\)统计量就是在训练集的\\(RSS\\)上加上惩罚\\(2p\\hat{\\sigma}^{2}\\)，对基于训练集过度乐观的误差估计做出调整。很明显，当变量个数增加时，惩罚也随之加重，这可以抵消变量个数增加导致的\\(RSS\\)减小。用于模型选择时，我们选择对应\\(C_{p}\\)更小的模型。 AIC可以用于评估很多模型，它是基于最大似然值的。在线性回归的例子里，最大似然估计和最小二乘估计是一样的： \\[AIC=n+nlog(2\\pi)+nlog(RSS/n)+2(p+1)\\] BIC 也是基于最大似然值： \\[BIC=n+nlog(2\\pi)+nlog(RSS/n)+log(n)(p+1)\\] R中的函数AIC()和BIC()就是按上面的公式分别计算AIC和BIC的。在很多教科书里通常会省略常数项\\(n+nlog(2\\pi)\\)，且用\\(p\\)代替\\(p+1\\)。但不同的公式效果相同，因为使用时只考虑相对大小。和AIC相比，BIC对参数个数进行了更加严厉的惩罚。所以通过BIC选出的模型通常参数个数比AIC少。 模型评估和变量选择要求选取一个相应的选择标准，关于变量选择，在特征工程的章节中会详细介绍。 8.2 分类模型评估度量 本小节关注判别模型（即，应变量为分类变量）的表现度量。之前对连续型变量适用的RMSE和\\(R^2\\)不适用于分类模型。分类指对给定观测样本预测其所属类别，而且类别空间已知，所以是有监督学习。这个和聚类不同，聚类分析的目的是得到类别空间，是无监督学习，这在之后聚类和判别的部分还会更详细的介绍。通常遇到的问题是二分类，比如是否有某种疾病，垃圾邮件分类器等。也有多分类问题，比如服装消费数据中的消费者类别。这里我们用生猪疫情风险预测数据为例展示分类模型的评估度量。这里我们训练一个随机森林模型对农场疫情爆发概率进行评估，之后在树模型的章节中会对模型本身进行更详细的介绍。 library(dplyr) library(randomForest) library(caret) library(readr) # 读取数据 # 载入数据 disease_dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/sim1_da1.csv&quot;) # 可以用glimpse()函数查看数据 # glimpse(disease_dat) 划分训练集和测试集，在训练集（xTrain和yTrain）上得到模型，然后在测试集（xTest和yTest）上评估模型表现。70%的样本用于训练，剩下30%用于模型评估： # 划分训练集和测试集 set.seed(2016) trainIndex&lt;-createDataPartition(disease_dat$y,p=0.8,list=F,times=1) xTrain&lt;-disease_dat[trainIndex,]%&gt;% dplyr::select(-y) xTest&lt;-disease_dat[-trainIndex,]%&gt;% dplyr::select(-y) # 需要将应变量转化成因子类型 yTrain&lt;-disease_dat$y[trainIndex]%&gt;%as.factor() yTest&lt;-disease_dat$y[-trainIndex]%&gt;%as.factor() 训练随机森林模型： train_rf&lt;-randomForest(yTrain~.,data=xTrain,mtry=trunc(sqrt(ncol(xTrain)-1)),ntree=1000,importance=T) 为了展示不同的模型评估法则，我们将训练得到的随机森林模型应用到测试集，得到两种预测： 每个类别的概率预测（结果为0到1之间的连续值，可以通过在代码中添加选项prob得到预测，结果存在yhatprob对象中） 离散类别预测（结果为0/1形式，存在yhat对象中） 我们分别看看这两个预测结果： yhatprob&lt;-predict(train_rf,xTest,&quot;prob&quot;) set.seed(100) car::some(yhatprob) ## 0 1 ## 45 0.592 0.408 ## 158 0.455 0.545 ## 255 0.575 0.425 ## 291 0.513 0.487 ## 314 0.620 0.380 ## 392 0.538 0.462 ## 402 0.472 0.528 ## 443 0.542 0.458 ## 462 0.620 0.380 ## 626 0.586 0.414 yhat&lt;-predict(train_rf,xTest) car::some(yhat) ## 206 273 305 348 519 524 525 599 701 780 ## 1 0 0 0 0 0 0 0 1 0 ## Levels: 0 1 现在我们就用上面的两种预测结果为例介绍不同的预测类评估方法。 8.2.1 Kappa统计量 混淆矩阵（Confusion Matrix）是对分类结果进行详细描述的一个表，是简单的观测类和预测类的交叉表。在此例中，观测类是yTest，预测类是yhat，相应的混淆矩阵为： table(yhat,yTest) ## yTest ## yhat 0 1 ## 0 68 56 ## 1 3 33 表格中左上角和右下角分别代表预测正确的样本数目，左下角和右上角代表错误预测的样本数目。更一般的二分类混淆矩阵如下： 观测发生 观测不发生 预测发生 TP FP 预测不发生 FN TN 其中TP代表真阳性，FP代表假阳性，TN代表真阴性，FN代表假阴性。表格左上到右下对角线上的元素表示正确预测的样本数目，另一个方向的对角线上的元素代表误判的样本数。评估类预测最简单的指标是总体精确率，即预测正确的总体样本比例: \\[总体精确率=\\frac{TP+TN}{TP+TN+FP+FN}\\] 对类别数目大于2的情况，可以类似计算总体精确率。该统计量很直观，但有一些缺点，首先总体精确率没有区分错误类型。实际应用中，不同错误对应的损失可能不同，这时就无法用总体精确率衡量模型。 比如过滤垃圾邮件，误删一封重要的邮件带来的损失要高于收到一封垃圾邮件的损失。Provost等人[22]深入讨论了用精确率来比较不同的分类器存在的问题。其次总体精确率没有考虑真实频率。比如在保险风险分析中，有风险的概率可能只有千分之一或者更小，模型只要将所有样本都清一色判定为无风险就能达到几乎完美的精确率。有时我们将不用模型也能得到的精确率称为无信息率。这里将所有样本判定为无风险得到的无信息率至少是99.9%。在这种情况下模型的精确率需要高于无信息率才算合理。 还有一种一致性检验方法叫做Kappa统计量，最早由Cohen等人在1960年提出用于考察两个不同的诊断方法在结果上是否具有一致性[23]。Kappa考虑到简单由偶然情况产生的准确性。具体公式如下： \\[Kappa=\\frac{P_{0}+P_{e}}{1-P_{e}}\\] 假设\\(n=TP+TN+FP+FN\\)为总体样本数，其中\\(P_{0}=\\frac{TP+TN}{n}\\)为实际预测一致率，\\(P_{e}=\\frac{(TP+FP)(TP+FN)+(FN+TN)(FP+TN)}{n^{2}}\\)为由简单偶然情况产生的一致率。Kappa取值从-1到1，值越高一致性越强。 Kappa = 1 时，表明完全一致。 Kappa = 0 时，则一致性与偶然预期的相同。 Kappa &lt; 0 时，一致性比偶然预期的还要弱，不过这种情况很少发生。 一般说来，Kappa值在0.3到0.5之间代表合理的一致性。假定一个模型的精确度很高（90%），但偶然预期的精确度也很高（85%），Kappa统计量为\\(\\frac{1}{3}\\)，表明预测和观测适度一致。Kappa统计量也可以扩展至评估类别大于2的情形。fmsb包中的Kappa.test()函数能用于计算Cohen的Kappa统计量。该函数还能对Kappa统计量进行统计检验，并且给出置信区间。以上面观测类yTest和预测类yhat结果为例，可以通过如下代码计算Kappa统计量： kt&lt;-fmsb::Kappa.test(table(yhat,yTest)) # 统计量估值在函数返回值的Result对象中 kt$Result$estimate ## [1] 0.3054738 上面函数返回结果中包含一个Judgement对象: kt$Judgement ## [1] &quot;Fair agreement&quot; 这是基于Landis和Koch提出的Kappa统计量的一般性解释方法[24]： Kappa&lt; 0：无一致性（No agreement） Kappa在0-0.2之间：略微一致（Slignt agreement） Kappa在0.2-0.4之间：轻度一致（Fair agreement） Kappa在0.4-0.6之间：适度一致（Moderate agreement） Kappa在0.6-0.8之间：强一致（Substantial agreement） Kappa在0.8-1.0之间：几乎完全一致（Almost perfect agreement） 8.2.2 ROC曲线 相对与简单的类取值，类概率中含有更多的模型预测信息，比如之前得到的yhatprob就是连续的预测值。对于这样的预测结果，ROC曲线是一个通用评估方法。该方法确定一个有效的阈值，超过这个阈值的观测被标注为某类。比如所有yhatprob&gt;0.9的样本都判定为风格类。ROC曲线是基于灵敏度和特异度这两个统计量。考虑之前展示的二分类情况的混淆矩阵。模型的灵敏度为在所有真实观测到“发生”的样本中被准确预测为“发生”的比率： \\[灵敏度=\\frac{正确预测为“发生”的样本数目}{观测到“发生”的样本数目}=\\frac{TP}{TP+FN}\\] 特异度指的是观测到“不发生”的样本中准确预测为“不发生”的比率： \\[特异度=\\frac{正确预测为“不发生”的样本数目}{观测到“不发生”的样本数目}=\\frac{TN}{TN+FP}\\] 灵敏度也称为真阳性率，特异度也称为真阴性率。“1-特异度”为假阳性率。灵敏度和特异度对应的分母是固定的，当模型将更多样本判定为“发生”时，对应的灵敏度会增加，特异度会降低。根据不同错误类型导致的损失，通常需要建模者在灵敏度和特异度之间做出权衡。ROC曲线是权衡这二者的一个有效工具。ROC曲线是通过设定一系列预测结果阈值，得到相应的真阳性率（灵敏度）和假阳性率（1-特异度）绘制成的曲线。我们得到的关于农场疫情爆发预测概率结果yhatprob为例，展示如何用rROC包中的相应函数得到ROC曲线和相关统计量。yhatprob中的第2列代表将样本判定为疫情爆发的概率，其两列相加和为1。我们可以使用函数roc()得到相应的ROC对象rocCurve。然后将不同的函数应用在该对象上得到相应的图形结果或者统计量。下面的代码可以用来得到ROC曲线： library(pROC) rocCurve&lt;-roc(response=yTest,predictor=yhatprob[,2]) plot(rocCurve,legacy.axes=T) ## ## Call: ## roc.default(response = yTest, predictor = yhatprob[, 2]) ## ## Data: yhatprob[, 2] in 71 controls (yTest 0) &lt; 89 cases (yTest 1). ## Area under the curve: 0.8083 其中roc()函数中的第一个参数response是真实观测值，predictor是连续预测结果，这里赋予的是判定为爆发的预测概率。ROC曲线的横坐标是1-特异度，纵坐标是灵敏度。一个完美的模型能完全区分两个类，灵敏度和特异度均为100%。从图形上看，ROC曲线为通过(0,0)和(1,1)的曲线。完美模型对应的曲线还通过(0,1)点，对应的曲线下面积为1。完全无效的模型对应的曲线趋近于45度对角线，曲线下面积为0.5。可以将不同模型结果对应的ROC曲线放在一张图中，直观对比模型效果。或者通过曲线下面积（AUC）量化比较模型，对应面积越大的模型越有效。DeLong等提出了基于U统计量的估计和比较AUC的方法[25]，也可以通过bootstrap得到AUC的置信区间[26]。 在R中，我们可以通过如下代码得到基于DeLong提出的非参方法得到的AUC的估计和置信区间： # 得到AUC的估计 auc(rocCurve) ## Area under the curve: 0.8083 # DeLong方法得到的AUC置信区间 ci.auc(rocCurve) ## 95% CI: 0.7419-0.8746 (DeLong) ROC曲线和线下面积AUC是我最常用的评估分类模型的方式，由于它是灵敏度和特异度的函数，对类失衡有抗性[22, 27]。用AUC和其它单一度量类似，在用某个量总结曲线时会带来信息的损失，因为很可能没有某条曲线一致好于其它的曲线（曲线交叉）。如果我们对曲线特定的区域感兴趣，可以直接比较曲线。如果我们关心的是ROC曲线低的一端，可以使用ROC曲线下局部面积度量[28]，该度量关注曲线特定部分。ROC曲线主要针对二分类定义，但之后不同人将其扩展到多分类的情况[29–31]。 8.2.3 提升图 除了数值度量以外，还有一些对分类结果评估的可视化工具，如提升图。提升图以图形的形式表示模型预测比随机预测相比带来的改进，根据“提升”分数来选择模型，或者确定应该将数据中多大比例的样本视为目标群体可以从模型预测结果中获益。这样抽象的描述很难让大家理解提升图。因此我们将其放在应用的语境下。我们用猪场疫情数据为例。之前我们在训练集上训练随机森林模型，然后将模型应用在含有160个样本的测试集（xTest）上。我们对测试集样本的预测yhatprob来解释提升图。由于我们感兴趣的是疫情爆发的事件——yhatprob第二列（第一列是无疫情的概率）——我们将针对疫情爆发的连续概率预测存在一个新对象modelscore中。真实情况是有89个样本有疫情。如果我们将这160个样本按照模型预测分值modelscore从高到低排序，对于完美的模型，排序后的前89个样本应该正好就是那些疫情爆发的样本。当预测完全随机时，排序后前x％的样本中根据随机概率也该正好含有89个发生疫情的样本中的x％。提升图展示了通过模型预测排序筛选出的样本比随机样本对应目标类命中率的差别。 下面我们抽取了一些随机分值（randomscore），对其和模型预测结果（modelscore）绘制提升图，比较它们。 modelscore&lt;-yhatprob[,2] # 随机抽取一些分值 randomscore&lt;-rnorm(length(yTest)) labs&lt;-c(modelscore=&quot;Random Forest&quot;, randomscore=&quot;Random Number&quot;) 我们可以使用caret包中的lift()函数来绘制提升曲线。该函数用一个公式作为输入选项，公式左侧是真实类别，公式右侧是多个预测值。这里公式右侧是模型分值和随机分值： liftCurve&lt;-lift(yTest~modelscore+randomscore,class=&quot;1&quot;,labels=labs) 为了绘制多条提升图，使用lattice包中的xyplot()函数： xyplot(liftCurve,auto.key=list(columns=2,lines=T,points=F)) 提升图的横轴是累计样本百分比，纵轴是累计获取的目标类样本百分比。比如随机森林模型提升曲线上的点(6.25,11.24)表示：按照模型预测分值从高到低排序后的前6.25%的样本中含有160个疫情爆发样本中的0.1123596。和ROC曲线类似，我们可以通过比较不同模型的提升图来选择模型，曲线下面积也可作为模型效果的度量。此外我们也可能对曲线的某一部分特别感兴趣。比如在当前的例子中，如果判定一个农场在未来5年内可能爆发疫情，那么通常的措施是对该农场进行大规模的清洗消毒，这样的措施花费很高。假设我们只能对50%的农场进行清理，那么就该选择对应横坐标为50%，疫情爆发样本命中率最高的模型。在这个应用场景下，在支出预算一定时最大化效率。 8.3 本章总结 本章探讨了模型评估的度量。在数据分析项目中，评估模型是非常重要的。掌握本章和上一章介绍的数据划分和再抽样技术就具备评估模型的技术能力了。这里关于分类模型评估有一个重要话题由于篇幅所限没有介绍，就是预测概率校准和处理类失衡的问题。对此话题感兴趣的读者可以参考Max Kuhn 和 Kjell Johnston的书《Applied Predictive Modeling》中的第11章[13]，这本书的中文版已于2016年5月由电子工业出版社出版。模型选择和评估要求分析师将模型放在具体项目语境下。这是体现科学和艺术结合的典型环节。我们在本书之后讲具体模型的时候会给出几个完整的案例分析，其中包括用之前讲到的这些建模技术进行模型选择。关于模型评估最后总结几点： 尝试尽可能多的模型 当考虑该用什么模型解决某具体的问题时，应该考虑多个可能的模型。从最简单的模型开始直到你能达到的难度上限。真正尝试拟合模型时，根据个人喜好，你可以从最简单的模型开始，每拟合一次模型，对数据中变量关系的理解会有所加深，慢慢过渡到更加复杂的模型。或者从最复杂的模型开始，但要做好简化模型的准备，使得模型具有更强的解释性。实际应用中，你不知道什么模型对当前问题最有效，所以比较不同的模型对于一个合格的数据科学家来说是必须的。当然，这有一个隐藏的前提条件是你能够快速有效的拟合不同模型。如果你需要让计算机跑1个晚上的程序来拟合一个模型，尝试这样的模型不是一个好主意。 检查模型的稳定性 提高模型稳定性有各种可能的方法，收集更多的观测，除去冗余变量，如之前提到的近0方差变量和高度相关变量。检查模型拟合的稳定程度最常用的方法是再抽样。通过抽取不同的样本拟合相同的模型，然后查看拟合参数的变化范围。要是需要检查模型在某假设条件不满足的情况下的表现，可以通过模拟数据进行考察。 模型评估选择通常在模型精确度、稳定性和复杂度这三者之间权衡。某个模型在这三个方面都有绝对性优势的情况可能发生，但很少，大多数时候都需要有取舍，这就取决于你的建模目的。 最后我想用George Box的那句统计学界家喻户晓的名言结束这一章： 所有模型都是错的，但其中有一些是有用的。(All models are wrong, but some are useful.) References "],
["section-9.html", "第9章 特征工程 9.1 特征构建 9.2 特征提取 9.3 特征选择", " 第9章 特征工程 对自变量进行编码和筛选的过程称为特征工程（Feature Engineering），其目的就是获取更好的训练数据，提高模型表现。例如，有时用自变量的组合能够比使用单独的自变量更有效；用两个变量的比值可能比用两个单独的变量更有效等等。通常最有效的编码数据的方法来自于建模者对问题的理解，而不是通过任何数学方法。在原始数据基础上，通过该工程得到的优化特征可以更好的描述数据关系。从数学的角度上就是优化自变量矩阵\\(\\mathbf{X}\\)。 特征工程在机器学习中起着举足轻重的作用，如果你能找到有效的特征，其实未必需要复杂的算法。很遗憾，大多数的书中并没有专门花一章完整的讲特征工程，更常提到的是特征选择（Feature Selection）。很多机器学习的书都是以介绍算法为主，目的在于理解算法本身，所以特征工程通常不是重点。这和特征工程在实际应用中的重要性极不相称。所以在这里，我们专门花一章来介绍特征工程。在特征工程下面有3个主要的子问题，我们会依次讨论这三个问题： 特征构建（Feature Construction）：从原始数据中构建新变量 特征提取（Feature Extraction）：将原始变量按照某种标准变换得到能够更好反映数据关系的变量 特征选择（Feature Selection）：在整个自变量集中找到和因变量有关的变量子集，从而达到降维且增加模型估计稳定性和可解释性的效果 这三者的大概顺序是：特征构建 -&gt; 特征提取 -&gt; 特征选择。如果特征构建做的不好，那么它会直接影响特征提取，进而影响了特征选择，最终影响模型的性能。事实上，特征工程是一个迭代过程，我们需要不断的设计特征、选择特征、建立模型、评估模型，然后得到反馈在回头优化特征的设计。 9.1 特征构建 在实际应用中，显然是不可能凭空而来的，需要我们手工去构建特征。关于特征构建的定义，可以这么说：特征构建指的是从原始数据中人工的构建新的特征。我们需要人工的创建它们。这需要我们花大量的时间去研究真实的数据样本，思考问题的潜在形式和数据结构，同时能够更好地应用到预测模型中。 特征构建需要很强的洞察力和分析能力，要求我们能够从原始数据中找出一些具有物理意义的特征。假设原始数据是表格数据，一般你可以使用混合属性或者组合属性来创建新的特征，或是分解或切分原有的特征来创建新的特征。比如之前在数据预处理那章中讲编码名义变量时，我们将分类变量gender(性别)转化为两个名义变量：Female和Male。之后考虑收入和性别的交互效应(income:gender)也是一种特征构建。另外再举一个例子，假设你有一个日期时间 (2006-04-01 02:26:00)该如何转换呢？对于这种时间的数据，我们可以根据需求提取出多种属性。比如下面这个从农业论坛爬取的文本数据。 library(readr) library(dplyr) topic&lt;-read_csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/topic.csv&quot;) glimpse(topic) ## Observations: 209,607 ## Variables: 6 ## $ tid &lt;int&gt; 242, 259, 270, 281, 301, 312, 333, 367, 386, 387... ## $ fid &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, ... ## $ title &lt;chr&gt; &quot;0&quot;, &quot;Adobe Reader&quot;, &quot;? about this forum veiw?&quot;,... ## $ posted_at &lt;time&gt; 2006-04-01 02:26:00, 2006-04-01 08:39:00, 2006-... ## $ user_name &lt;chr&gt; &quot;Rich&quot;, &quot;Larry NCKS&quot;, &quot;Hay Hud Ohio&quot;, &quot;jakescia&quot;... ## $ user_location &lt;chr&gt; &quot;Kansas&quot;, &quot;Washington, Kansas &amp; Lincoln, Nebras... # 将发帖时间提取出来，存在posted_at2对象中 posted_at2&lt;-topic$posted_at 数据由6列，这里只解释其中2列。posted_at是发帖时间，user_name是论坛用户名。对于发帖时间，我们可以将其拆分成不同的变量，这个过程类似于探索性数据分析。这里时间观测是按照年、月、日、时、分、秒的顺序，以这样的格式2006-04-01 02:26:00排列的。在具体分析中，我们通常希望知道用户的发帖规律。在事先不知道怎样划分能够看到规律的情况下该怎么办？尝试不同的划分方法。比如我们可以研究每年的发帖量，可以通过substr()函数截取字符串的固定位置得到年份： # 将截取的年份存在名为year的列中 topic$year&lt;-substr(posted_at2,1,4) # 看下结果如何 car::some(topic$year) ## [1] &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; &quot;2013&quot; &quot;2013&quot; &quot;2013&quot; &quot;2014&quot; &quot;2014&quot; &quot;2014&quot; &quot;2015&quot; 接下来我们可以查看下每年发帖数目的变化情况： barplot(table(topic$year),family =&quot;Songti SC&quot;, main=&quot;年度发帖数目频数直方图&quot;) 图中我们可以看到，从2006年论坛创建以来，帖子的数目几乎呈指数上升，2015年貌似不符合规律，其实是因为当前数据中只饱含到2015年5月的论坛数据，也就是说如果我们由所有2015年的数据，最后的直方条应该会超过2014年。这么简单的统计能够告诉我们什么呢？这样的统计量对于公司的市场预算是很重要的。假如某农业公司要决定是否投入人力和财力去挖掘这个农业论坛数据，首先需要明确的就是这些数据是不是有代表性，该论坛是不是活跃。上图就表明该论坛是处在高速发展阶段的，而且考虑到论坛的用户是农民，这样的活跃度是非常高的。所以相关决策人员或许可以将该论坛当作一个消费者评论信息的来源。只考虑年是不够的，我们可能还想类似的检查下月度发帖分布，我们可以类似的截取时间字符串中的月份，绘制直方图： topic$month&lt;-substr(posted_at2,6,7) barplot(table(topic$month),family =&quot;Songti SC&quot;, main=&quot;月度发帖数目频数直方图&quot;) 大家可以看到明显的季节效应。通常北半球12-4月是农闲时节，这个时候发帖数远高于开春（5月）之后。基于此，我们可以假设12-4月的帖子或许更多的是关于去年购买的种子收获情况以及一些下一年的耕种计划的信息，5月到11月间或许更多的是当下遇到的问题，比如播种时种子发芽情况，生长中雨水，作物抗旱性能等等。这些为农业公司提供了消费者对其产品的体验信息。这样简单的统计能够给我们之后的分析指引放下。再次强调，分析的整个流程是个渐进且协同的过程，前一步中获得的信息可能有助于我们明确之后要如何进行分析，下一步分析的结果可能又让我们返回之前的步骤，比如收集构建新变量等等。 再看看每天发帖的规律： topic$time&lt;-substr(posted_at2,12,13) barplot(table(topic$time),family =&quot;Songti SC&quot;,main=&quot;每日不同时间段发帖频数直方图&quot;) 可以看到，每天有两个发帖高峰，中午一阵，晚上一阵（这里不考虑北美不同纬度的时差影响）。这能给我们什么信息呢？很有可能农民习惯于在这两个时间段上网查询信息等。如果农业公司想要发营销广告，这或许是最佳的时间。 上面是一个简单的关于构建特征的例子，在具体应用中特征构建的方法可以非常灵活，没有一个黄金标准。随着分析经验的增长，以及对相关领域的了解加深，构建有意义特征的能力也会随之提高。特征构建是特征工程中艺术成分最高的部分，接下来我们要介绍的特征提取和特征选择就有更强的技术性。 9.2 特征提取 特征提取是一项用不同变量的组合代替原变量的技术。它的目的是自动地构建新的特征，将原始特征转换为一组具有明显物理意义或者统计意义的特征。比如通过变换特征取值来减少原始数据中某个特征的取值个数等。我们考虑3个常用的可以对数据降维的特征提取方法。主成分分析（PCA）试图找到原变量的不相关线性组合，这些线性组合能够最大限度的解释原数据中变量方差。探索性因子分析（EFA）同样试图在尽量小的维度上解释原数据中尽可能多的方差。高维标度化（MDS）将观测见的相似度映射到低维度上，如2维平面。MDS能够作用于非数值型变量，如分类变量或者有序数据预测变量。接下来我们通过模拟的航空公司数据集来展示不同的特征提取方法。在市场营销中这类消费者调查问卷中，虽然初始问题很多，但通常存在多个调查项共同反应少数几个潜在因子。比如航空公司满意度调查数据中下面四个问题：购票容易度（Easy_Reservation）、座椅选择（Preferred_Seats）、航班选择（Flight_Options）和票价（Ticket_Prices）都和购票体验有关。 9.2.1 初步探索数据 我们先读入该数据： # 可以从网站下载该数据 airline&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/AirlineRating.csv&quot;) 可以用glimpse()函数检查该数据： glimpse(airline) ## Observations: 3,000 ## Variables: 17 ## $ Easy_Reservation &lt;int&gt; 6, 5, 6, 5, 4, 5, 6, 4, 6, 4, 5, 5, 6, 5, 5, ... ## $ Preferred_Seats &lt;int&gt; 5, 7, 6, 6, 5, 6, 6, 6, 5, 4, 7, 5, 7, 6, 6, ... ## $ Flight_Options &lt;int&gt; 4, 7, 5, 5, 3, 4, 6, 3, 4, 5, 6, 6, 6, 5, 6, ... ## $ Ticket_Prices &lt;int&gt; 5, 6, 6, 5, 6, 5, 5, 5, 5, 6, 7, 7, 6, 7, 7, ... ## $ Seat_Comfort &lt;int&gt; 5, 6, 7, 7, 6, 6, 6, 4, 6, 9, 7, 7, 6, 6, 6, ... ## $ Seat_Roominess &lt;int&gt; 7, 8, 6, 8, 7, 8, 6, 5, 7, 8, 8, 9, 7, 8, 6, ... ## $ Overhead_Storage &lt;int&gt; 5, 5, 7, 6, 5, 4, 4, 4, 5, 7, 6, 6, 7, 5, 4, ... ## $ Clean_Aircraft &lt;int&gt; 7, 6, 7, 7, 7, 7, 6, 4, 6, 7, 7, 7, 7, 7, 6, ... ## $ Courtesy &lt;int&gt; 5, 6, 6, 4, 2, 5, 5, 4, 5, 6, 4, 6, 4, 5, 5, ... ## $ Friendliness &lt;int&gt; 4, 6, 6, 6, 3, 4, 5, 5, 4, 5, 6, 7, 5, 4, 4, ... ## $ Helpfulness &lt;int&gt; 6, 5, 6, 4, 4, 5, 5, 4, 3, 5, 5, 6, 5, 4, 5, ... ## $ Service &lt;int&gt; 6, 5, 6, 5, 3, 5, 5, 5, 3, 5, 6, 6, 5, 5, 4, ... ## $ Satisfaction &lt;int&gt; 6, 7, 7, 5, 4, 6, 5, 5, 4, 7, 6, 7, 6, 4, 4, ... ## $ Fly_Again &lt;int&gt; 6, 6, 6, 7, 4, 5, 3, 4, 7, 6, 8, 6, 5, 4, 6, ... ## $ Recommend &lt;int&gt; 3, 6, 5, 5, 4, 5, 6, 5, 8, 6, 8, 7, 6, 5, 6, ... ## $ ID &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14... ## $ Airline &lt;fctr&gt; AirlineCo.1, AirlineCo.1, AirlineCo.1, Airli... 数据的前15列都是问卷调查的各种问题，问题格式如下：对该航空公司的你的满意度是？从1到9，分值越大满意度越高。可以看到前15列评分在1-9之间，是整数型了。ID代表受访者编号，不同编号代表不同受访者。每个受访者需要评估3家航空公司，列Airline指出相应的航空公司。一共有1000名受访者，因此观测的总行数为1000x3=3000。关于数据各列变量的解释，大家可以参考“数据集模拟和背景介绍”中相关小节。 我们用corrplot()函数检查问卷调查问题的相关性： library(corrplot) # 选取其中的问卷调查项 dplyr::select(airline,Easy_Reservation:Recommend)%&gt;% # 得到相关矩阵 cor()%&gt;% # 用corrplot()绘制相关图 # 选项order=&quot;hclust&quot;按照变量的相似度，基于系统聚类的结果对行列进行重新排列 corrplot(,order=&quot;hclust&quot;) 由相关矩阵图可以看到，这些问卷项大致分成3类： 空航服务相关 礼貌（Courtesy） 友善（Friendliness） 能够提供需要的帮助（Helpfulness） 食物饮料服务（Service） 购票体验相关 购票容易度（Easy_Reservation） 座椅选择（Preferred_Seats） 航班选择（Flight_Options） 票价（Ticket_Prices） 机舱设施和总体评估指数 座椅舒适度（Seat_Comfort） 位置前后空间（Seat_Roominess） 随机行李存放（Overhead_Storage） 机舱清洁（Clean_Aircraft） 总体满意度（Satisfaction） 再次选择次航空公司（Fly_Again） 向朋友推荐此航空公司（Recommend） 而且机舱设施和总体满意度相关性较高。空航服务和购票体验貌似负相关，也就是说航空公司目前没有做到让乘客对这两类体验都感到满意，这也可能是潜在需要提高的地方。这里简单的检查数据能够给我们一些基本的信息，让我们能够做出一些假设，然后在之后的分析中尝试证实这些假设。 对于这样的数据初步探索，一个非常自然的问题是：每个航空公司对应的各项评分均值是多少？我们可以用之前介绍的dplyr包中的各种函数，以及使用之前讲到的管道操作%&gt;%让代码更易读： # 选取其中的问卷调查项和航空公司因子信息 # 即删除ID项 airline.mean&lt;-dplyr::select(airline,-ID)%&gt;% # 按Airline对数据进行分组总结 group_by(Airline)%&gt;% # 对每个数值 summarise_each(funs(mean))%&gt;% # 显示数据 glimpse() ## Observations: 3 ## Variables: 16 ## $ Airline &lt;fctr&gt; AirlineCo.1, AirlineCo.2, AirlineCo.3 ## $ Easy_Reservation &lt;dbl&gt; 5.031, 2.939, 2.038 ## $ Preferred_Seats &lt;dbl&gt; 6.025, 2.995, 2.019 ## $ Flight_Options &lt;dbl&gt; 4.996, 2.033, 2.067 ## $ Ticket_Prices &lt;dbl&gt; 5.997, 3.016, 2.058 ## $ Seat_Comfort &lt;dbl&gt; 6.988, 5.009, 7.918 ## $ Seat_Roominess &lt;dbl&gt; 7.895, 3.970, 7.908 ## $ Overhead_Storage &lt;dbl&gt; 5.967, 4.974, 7.924 ## $ Clean_Aircraft &lt;dbl&gt; 6.947, 6.050, 7.882 ## $ Courtesy &lt;dbl&gt; 5.016, 7.937, 7.942 ## $ Friendliness &lt;dbl&gt; 4.997, 7.946, 7.914 ## $ Helpfulness &lt;dbl&gt; 5.017, 7.962, 7.954 ## $ Service &lt;dbl&gt; 5.019, 7.956, 7.906 ## $ Satisfaction &lt;dbl&gt; 5.944, 3.011, 7.903 ## $ Fly_Again &lt;dbl&gt; 5.983, 3.008, 7.920 ## $ Recommend &lt;dbl&gt; 6.008, 2.997, 7.929 上面的数值结果可以看到乘客对各个航空公司的满意度情况有明显的区别。总的来说购票体验相关的项满意度偏低（购票容易度（Easy_Reservation）、座椅选择（Preferred_Seats）、航班选择（Flight_Options）和票价（Ticket_Prices）），相较而言第1个航空公司在购票体验方面优于竞争对手，但在其它方面并没有优势。第2个航空公司在空航服务方面做的比较好，在其它方面也没有优势。第3个航空公司除了购票体验较差以外，在其它方面都至少和竞争对手相当，或者优于竞争对手。这里的数据分类和之前相关矩阵图展示出的信息有一致性，但也提醒我们各个航空公司对应的问卷回复项之间的关系可能不一样。对于上面各航空公司评分均值结果使用热图进行可视化是很好的方式。我们用gplots包中的heatmap.2()函数绘制热图，用RColorBrewer包对图形着色： # gplots是可视化包 library(gplots) # RColorBrewer包用于设计图形的调色盘 # 相关信息见：http://colorbrewer2.org library(RColorBrewer) # 将航空公司设置成行名称然后将对应的字符列删除 row.names(airline.mean)&lt;-airline.mean$Airline airline.mean&lt;-dplyr::select(airline.mean,-Airline) # 绘制热图 heatmap.2(as.matrix(airline.mean), col=brewer.pal(9,&quot;YlGn&quot;),trace=&quot;none&quot;,key=FALSE,dend=&quot;none&quot;,cexCol=0.6,cexRow =1) title(family =&quot;Songti SC&quot;, main=&quot;航空公司问卷调查均值热图&quot;) 在上面代码中，我们将数据框airline.mean转化成矩阵传递给heatmap.2()，因为函数要求。我们通过RColorBrewer包中的YlGn调色盘，用黄色和绿色对热图着色，并且取消了一些将热图变得复杂的选项（trace、key和dend）。在结果图中，绿色表示高观测值，黄色表示低观测值，处于中间的值对应的颜色较浅。乘客对不同航空公司的满意度分值分布很显然有区别。航空公司3和2有明显让人满意和不满意的地方，而公司1总体来说比较平均，除了乘客对其位置前后空间（Seat_Roominess）特别满意。如果考虑和竞争对手的差距，1和2需要改进的地方显然比3要多。 通过观测目前得到的一些探索性结果，我们可以猜测各个问题可能的聚类情况，以及它们之间的关系。但我们最好使用更严格正规的统计模型验证这些猜测。接下来我们就开始介绍模型。 9.2.2 主成分分析 主成分分析（PCA）是寻找变量的线性组合，得到新的组合变量叫做“成分”，其指导思想是尽量捕捉原数据中方差。在统计学中，方差通常也被认为是信息。第一个成分捕捉的方差最大。第二个成分尽可能多的捕捉前一个成分没有解释的方差。依次类推，直到成分的数目和原变量数目一样多。我们通过使用前几个成分取代原变量来达到降维的目的，同时要保证这些成分能够解释大部分原始数据集中的方差。这里要提醒一点，如果数据观测不在一个标度上时需要对数据进行标准化，因为PCA是基于变量协方差矩阵。这里因为各个变量的观测分布没有很大差异，是不是标准化没有太大的影响。 airline.pc&lt;-dplyr::select(airline,Easy_Reservation:Recommend)%&gt;% prcomp() summary(airline.pc) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 ## Standard deviation 4.693 4.2836 1.68335 1.03625 0.88896 0.82333 ## Proportion of Variance 0.435 0.3624 0.05596 0.02121 0.01561 0.01339 ## Cumulative Proportion 0.435 0.7974 0.85338 0.87458 0.89019 0.90358 ## PC7 PC8 PC9 PC10 PC11 PC12 ## Standard deviation 0.80349 0.78694 0.77536 0.77020 0.74612 0.71831 ## Proportion of Variance 0.01275 0.01223 0.01187 0.01172 0.01099 0.01019 ## Cumulative Proportion 0.91633 0.92856 0.94043 0.95215 0.96314 0.97333 ## PC13 PC14 PC15 ## Standard deviation 0.69417 0.66650 0.65131 ## Proportion of Variance 0.00952 0.00877 0.00838 ## Cumulative Proportion 0.98285 0.99162 1.00000 由上面输出结果的第一行是主成分的标准差，第二行对应成分单独解释方差的比例，第三行是累计解释方差。可见，前两个主成分解释的大部分原变量方差（80%）。plot()函数作用在PCA结果上默认绘制陡坡图，该图展示每个成分额外解释的方差。我们可用累计解释方差比例或者陡坡图来判断需要的主成分。我们通过下面代码绘制图形： plot(airline.pc,type=&quot;l&quot;,family =&quot;Songti SC&quot;,main=&quot;PCA陡坡图&quot;) 图的横坐标是主成分编号，纵坐标是该主成分解释的方差，即变量协方差矩阵单位正交特征向量对应的特征值。图中由陡到缓的转折点能告诉我们从哪个主成分开始，继续添加更多的成分对解释更多方差没有太大帮助，反而增加模型复杂度。关于拐点的判断是主观的。从第3个主成分开始，新的主成分解释的方差相对较小，因此我们可以取头2个主成分。将各个原始变量映射到前两个主成分张成的平面上能够揭示这些变量之间的关系。这样的图称为“双标图”，可以用biplot()函数绘制： biplot(airline.pc,family =&quot;Songti SC&quot;,main=&quot;PCA双标图&quot;,cex=c(0.5,1),xlim=c(-0.06,0.04)) 双标图的横坐标是第一个主成分（PC1），纵坐标是第二个主成分（PC2）。图中的点代表各个观测评分投影在这两个主成分张成的平面上。图中的箭头代表每个变量对应这两个主成分的载荷系数决定的方向。由于这两个主成分能够解释原始观测大部分的方差，在双标图中距离较近的点有相似的观测。 满意度评分PCA结果的双标图中红色的箭头中看到不同调查问题的聚类情况，并且可以大致感觉样本的聚类情况，大致成为3类，一个合理的猜测是针对3个不同的航空公司。从之前的热图可以看到，3个公司有各自的优势和劣势，评分分布显然是不同的。但这样的图有个问题：基于所有评分样本导致图形非常稠密，难以识别。如果是基于各个公司聚合后的数据，得到的图或许会更清晰。 airline.mean.pc&lt;-dplyr::select(airline.mean,Easy_Reservation:Recommend)%&gt;% prcomp() biplot(airline.mean.pc,family =&quot;Songti SC&quot;,main=&quot;聚合后PCA结果双标图&quot;, cex=0.7, expand=2,xlim=c(-0.8, 1),ylim=c(-0.7,0.8)) 按航空公司聚合后的结果双标图提供了可解释的乘客感知图，该图展示了各个航空公司在前两个主成分上的定位。我们先和聚合前后的感知图进行比较。注意，感知图的空间旋转是任意的，重要的是箭头的相对位置。比如，在两个感知图中，Courtesy、Friendliness、Service和Helpfulness都几乎重叠。 Seat_Comfort、Seat_Roominess、Overhead_Storage、Clean_Aircraft、Satisfaction、Fly_Again和Recommend大致指向相同的方向。剩下的Easy_Reservation、Preferred_Seats、Flight_Options和Ticket_Prices紧密相连。因此聚合后变量在主成分纬度上的分布位置和用原始观测得到的一致，但基于公司平均分值的结果更清晰的展示了公司相对定位情况。航空公司3在机舱设施、总体满意度和空航服务上得分都较高。航空公司2在空航服务方面得分较高。航空公司1在购票体验上表现较好。且在购票体验上满意度高的乘客更不满空航服务。如果你是航空公司3的商业数据分析师，看到这样的结果你可以得到什么结果？ 公司在很多方面具有竞争优势，客户满意度总体高于竞争对手 公司在购票体验上有明显劣势，这是需要努力改进的地方 我们为什么在购票体验上满意度高的乘客更不满空航服务？是因为乘客本身的特质，或是由于某种原因重视空航服务的公司容易忽视购票体验？ 需要进一步研究购票体验差的原因，以及评估其可能带来的影响：如果购票体验差并不会影响当前总体满意度以及票的销售情况，那我们需要投入多少改进该问题？ 如果航空公司1只是一个很小的公司，并不是主要竞争对手。你的主要竞争对手是航空公司2，那你可以进一步检查你们公司和航空公司2的得分差别： airline.mean[3,]-airline.mean[1,] ## Easy_Reservation Preferred_Seats Flight_Options Ticket_Prices ## 1 -2.993 -4.006 -2.929 -3.939 ## Seat_Comfort Seat_Roominess Overhead_Storage Clean_Aircraft Courtesy ## 1 0.93 0.013 1.957 0.935 2.926 ## Friendliness Helpfulness Service Satisfaction Fly_Again Recommend ## 1 2.917 2.937 2.887 1.959 1.937 1.921 从上面结果可以看出，和主要竞争对手相比，我们主要的劣势在于购票容易度（Easy_Reservation）、座椅选择（Preferred_Seats）、航班选择（Flight_Options）和票价（Ticket_Prices）上。在座椅舒适度（Seat_Comfort）、座椅空间（Seat_Roominess）、机舱清洁（Clean_Aircraft）和随机行李存放（Overhead_Storage）上两者相当。在剩余方面我们有优势。 通常情况下，对这样的问卷调查数据，你需要在不同维度上比较各个公司。可以通过陡坡图或者直接观察累计方差来决定该用多少的主成分。两个主成分张成的平面上绘制感知图能够解释观测在主成分维度上的分布。对这样多维度的市场调查数据，用PCA进行可视化是理解各个公司或者品牌在消费者认知中的分布的有效手段。关于该方法有几个需要注意的地方： 这里我们选择用均值对各个公司的评分进行聚合。但这并不是唯一的方式，取决于你的数据和问题，也可以使用中位数。在解释聚合后结果双标图之前，应该先确保聚合前后双标图上主成分相对位置分布一致。 这里所说的位置分布都是只相对位置，而不是具体的位置。主成分是基于所有变量的线性组合，因此从图上无法看出某个公司在特定问卷调查项上的具体强度。比如由图可以看出，公司3和公司2在机舱设施和总体满意度这个大方向上分布不同。检查具体的平均评分你会发现，总体上3确实在这两个方面好于2，但这并不代表3在其中每一个问卷调查项上都由明显优势，事实上，这三个公司在Clean_Aircraft这个选项上差别都不是很大。这里我们研究的是在一个更高层面上的消费者满意度分布。 这里得到的各项相对分布位置和你考虑的公司，还有问卷调查项有关。如果对另外3个不同的公司进行同样的问卷调查，可能结果会不同，或者添加新的调查项也可能改变原来调查项的相对位置。一个评估模型敏感性的方法是抽取一个样本子集进行类似分析，或者删除一些问卷调查项，看看结果是不是有很大变化。如果这些随机干扰下得到的双标图中各项的相对位置相似的话，你对在该项目中使用这个模型就更加自信。 最后一点和建模没有直接关系，但是在应用中很重要。问题出现在问卷调查上不代表问题就重要。取决于不同公司对定义“重要”的定义。通常情况下，在有限的市场研究经费下我们希望问和用户购买行为最相关的问题。比如在购票体验方面，对购买决定影响最大的可能是票价，而了解乘客是否对座椅选择满意本身当然没有坏处，但是考虑到进行调查研究的成本，我们不得不问：是不是需要问这个问题？有没有更好的问题取代当前问题？这需要你首先定义一个衡量“重要性”的标准（如，总体满意度，购买行为），然后据此尽量寻找对该标准影响最大的问题。 从上面的例子中我们可以看到调查项大致分成几个类，每类问题对应一个可能的潜在变量。比如购票容易度（Easy_Reservation）、座椅选择（Preferred_Seats）、航班选择（Flight_Options）和票价（Ticket_Prices）就和购票体验有关。接下来我们可能会想知道如何用更科学的方式分析出调查项背后的潜变量，以及衡量受访者对某公司或品牌针对某个潜变量的总体得分（比如对总体购票体验），如果需要提高消费者对某方面的认知，商家需要关注哪些具体问题（比如，提高价格竞争力可能对购票体验的提高帮助最大）。下面我们要讲的探索性因子分析就可以帮助我们实现这一点。 9.2.3 探索性因子分析 探索性因子分析（EFA）可以用来获取抽样调查中问题之间的构造。这里的因子就是无法观测到的潜变量，或者隐变量。因子分析的形成和早期发展一般认为是从Charles Spearman在1904年发表的文章开始[32]。关于因子分析的经典案例是心理学和教育学中的测试。例如“智力”，人格依恋类型（安全型，焦虑－矛盾型和回避型），人格特点（外倾性，宜人性，尽责性，神经质和开放性），这些都是抽象的概念或者说构造，它们都是无法直接观测到的。取而代之的，我们可以用不同的行为反映这些变量。这些观测到的行为变量称为显变量，比如测试分数，问卷调查回复以及其它观测到的行为。EFA的目标是找到能最大限度解释显变量方差的隐因子（即潜变量）。 比如在此例中，我们不能直接观测到客户总体满意度的构成，但我们可以通过问卷获知客户对各项具体活动的满意度，然后通过数据分析，尽可能的揭示导致客户总体印象背后的原因，这样可以将资金投入到能最有效改善客户满意度的项目。在本小节中，我们通过EFA进一步探索评分数据下的潜在机制，然后根据得到的隐因子估计比较不同的公司。 EFA的结果是一个因子矩阵，其目标是使一小部分变量对应较高的因子载荷，其余的因子载荷都很低。这样的因子能由少数几个变量解释。其通过旋转正交矩阵改变变量对应的因子载荷，在旋转过程中不改变解释方差。好比小时候切生日蛋糕，总想尽量保持蛋糕上图样的完整，坚决不要把奶油塑成的花对半切开，当然还有生肖图案，每次不得不切开的时候都无比纠结。这个纠结权衡的过程就喝EFA类似，这样旋转切分后得到的结果比随机切分要让强迫症患者舒服的多。其中一些每块蛋糕上面一朵完整的花，有一大块表面是完整的的生肖图案，有的上面是水果等等。这一块块蛋糕就好比隐因子，这些因子的定义不是唯一的，没有一种切分方式严格优于另外一种，但是总有一些比另外一些让你更舒服。对于EFA的结果，总有一些因子结果比另外一些更有用，能更好的解释实际现状。 和PCA相比，能产生可解释和实践的结果是EFA的一大优势。如果我们只对EFA得出的某因子感兴趣，可以保留该因子对应载荷高的问题，舍去其它问题，优化问卷调查。之后在例子中我们会展示EFA还能用来探索调查项相互联系的方式是不是符合我们的期待。可能真实的维度比我们想的少，也可能因子分析结果反映了一些我们不知道的维度。由于EFA是探索性的，没有非黑即白的标准答案，这里一定要特别关注结果的可解释性。如果结果难以解释，得到的因子对实际工作也没有作用。 下面我们还是以航空公司满意度调查的数据为例展示如何应用EFA。其中第一步就是决定要估计的因子数目。通常的方法是通过之前提到的陡坡图，或者根据对应特征值来决定因子数目（大于1的特征值数目）。R包nFactors中的函数nScree()能够应用几种方法通过陡坡检验估计因子数目。 library(nFactors) subset(airline,select=Easy_Reservation:Recommend)%&gt;% # 转化成数据框格式传递给nScree()函数 data.frame()%&gt;% nScree() ## noc naf nparallel nkaiser ## 1 2 2 2 2 结果显示，当前的4个方法建议的因子数目都是2。我们也可以通过特征值来决定因子数目。eigen()函数可以用来得到特征值： # 得到变量相关矩阵的特征值 eigenvalue&lt;-subset(airline,select=Easy_Reservation:Recommend)%&gt;% cor()%&gt;% eigen() eigenvalue$values ## [1] 6.13519681 5.47501966 0.94251965 0.46623604 0.26506447 0.22711198 ## [7] 0.21221230 0.21044797 0.19462556 0.17989084 0.16075997 0.15678382 ## [13] 0.15513097 0.13273209 0.08626788 可以看到开始2个特征值都大于1，因此，这里给出的因子数目建议还是2。再次强调，最后模型是不是有效取决于其可解释性。在实际应用中，最好检测多个因子数目。比如，2个或者3个。这里我们使用2个因子。接下来通过factanal()函数拟合EFA模型： airline%&gt;% subset(select=Easy_Reservation:Recommend)%&gt;% factanal(factors=2) 这里只截取输出的载荷部分： Loadings: Factor1 Factor2 Easy_Reservation -0.754 Preferred_Seats -0.831 Flight_Options -0.801 0.155 Ticket_Prices -0.819 Seat_Comfort 0.863 Seat_Roominess -0.346 0.846 Overhead_Storage 0.233 0.833 Clean_Aircraft 0.707 Courtesy 0.864 Friendliness 0.869 Helpfulness 0.867 Service 0.872 Satisfaction 0.921 Fly_Again 0.942 Recommend 0.941 其中factors=2设置因子数目为2. 我们看看结果输出的载荷Loadings，这是最需要解释的部分。结果中没有显示接近0的因子载荷。在此方案中，因子1对应载荷高的变量为： 购票体验相关变量：Easy_Reservation，Preferred_Seats，Flight_Options，Ticket_Prices 机舱服务相关变量：Courtesy，Friendliness，Helpfulness，Service 因子2对应载荷高的变量为： 机舱设施相关变量：Seat_Comfort，Seat_Roominess，Overhead_Storage，Clean_Aircraft 总体满意度相关变量：Satisfaction，Fly_Again，Recommend 也就是说这些结果大致反映出两类因子，其中一类和购票体验和机舱服务相关，另外一类和机舱设施和总体满意度相关。回忆之前得到的相关矩阵图，购票体验和机舱服务在图上强烈负相关，这里因子分析将它们看作受同一个因子影响，但载荷符号相反。这里很自然的提出一个实际问题，为什么对购票体验满意度高时对机舱服务满意度就低？这是需要和营销人员沟通的地方。同时，从统计的角度，我们可能会想，如果我们设置3个因子，是否会将购票体验和机舱服务分开呢？下面我们试着将因子个数设置成3个： airline%&gt;% subset(select=Easy_Reservation:Recommend)%&gt;% factanal(factors=3) Loadings: Factor1 Factor2 Factor3 Easy_Reservation -0.318 0.814 Preferred_Seats -0.422 0.815 Flight_Options 0.163 -0.419 0.759 Ticket_Prices -0.406 0.813 Seat_Comfort 0.864 Seat_Roominess 0.847 -0.286 0.189 Overhead_Storage 0.832 0.160 -0.172 Clean_Aircraft 0.706 Courtesy 0.786 -0.403 Friendliness 0.813 -0.385 Helpfulness 0.854 -0.342 Service 0.842 -0.362 Satisfaction 0.921 Fly_Again 0.942 Recommend 0.941 结果如我们所料，将之前机舱服务和购票体验对应的因子进一步分开成为两个因子。这个结果和之前基于主成分分析得到的双标图中问题对应箭头方向的聚类情况一致。 了解一些关于EFA背后理论的读者应该知道，因子载荷估计并不是唯一的，我们可以通过旋转产生新的载荷，所谓旋转，就是只用一个矩阵右乘因子载荷矩阵。当你使用的是正交矩阵时，就是正交旋转，否者是斜交旋转。比如有一种常用的正交旋转叫做方差最大正交旋转（varimax rotation），其目的是使得旋转后的各因子载荷的平方按列向0和1两级分化，以便每个因子具有实际的解释，该方法寻找的是不相关的因子。斜交旋转的方法允许因子之间相关。基于之前的讨论可知，购票体验和机舱服务是负相关的，更合理的方法是允许各因子间相关。下面我们用一种常见的斜交变换（oblimin）重复3因子模型： library(GPArotation) airline%&gt;% subset(select=Easy_Reservation:Recommend)%&gt;% factanal(factors=3,rotation=&quot;oblimin&quot;) Loadings: Factor1 Factor2 Factor3 Easy_Reservation 0.941 Preferred_Seats 0.880 Flight_Options 0.167 0.803 Ticket_Prices 0.887 Seat_Comfort 0.865 Seat_Roominess 0.844 -0.242 Overhead_Storage 0.833 0.137 -0.142 Clean_Aircraft 0.708 Courtesy 0.818 Friendliness 0.868 Helpfulness 0.953 Service 0.922 Satisfaction 0.921 Fly_Again 0.943 Recommend 0.942 从载荷中可以看到，允许因子之间相关更好的区分了购票体验和机舱服务，这样能够更加清晰的解释这两个感知项。这里就牵扯到一个问题，我们如何决定因子是该独立还是相关呢？你可能觉得这是数据决定的。但其实各因子间的相关性不是一个数据问题，而是你对潜因子的构想，或者假设。从认知概念的角度，你觉得在当前语境下因子独立有意义还是相关有意义？ 因子分析在特征提取方面的优势体现在下面3个方面： 我们可以用维度更低的因子分值取代大量原始调查问题 将反映相同认知维度的问卷分值联合起来比使用其中任何一项含有更多的信息。也在某种程度上缓解单个变量评分中的不确定性。从人脑认知的角度看，我们的购买决策常取决于一个总体的印象，而我们自己也无法解释其中具体的组成成分。所以在比较不同的公司或品牌时，应该关注总体感知。 通常人们会有一些感兴趣的因子，通过因子载荷，我们可以删除贡献小的变量从而简化收集过程。 9.2.4 高维标度化 高维标度化（Multi-Dimensional Scaling）是一类用来寻找原数据低维表达的方法。其目标和主成分双标图以及因子分析类似，但达成目标的方法不同。MDS没有提取潜在成分或者潜因子，而是试图将原数据投影到一个更低的维度，同时保持各项之间的距离。对于航空公司评分数据，你在使用MDS之前需要先计算出各个观测之间的距离。这里是数值型的观测，可以用dist()函数计算欧几里德距离，如果是排序，分类观测，可以使用不同的方法计算距离。 var.dist&lt;-airline%&gt;% subset(select=Easy_Reservation:Recommend)%&gt;% # 用dist()函数计算评分之间的距离 dist() 接下来我们通过cmdscale()函数对得到的距离矩阵寻找MDS方案： var.mds&lt;-cmdscale(var.dist)%&gt;% data.frame() # 重新为列命名 names(var.mds)&lt;-c(&quot;Score1&quot;,&quot;Score2&quot;) 我们可以看下得到的结果： head(var.mds) ## Score1 Score2 ## 1 -0.04272332 -4.919362 ## 2 2.81785655 -5.743754 ## 3 1.91700905 -3.993620 ## 4 2.46725348 -5.297467 ## 5 -0.23900139 -7.659147 ## 6 1.10832836 -5.605850 函数cmdscale()返回的是一个2列的数据框，分别对应不同样本两个坐标的取值。也就是将原本15列的数据降到2维平面上，和之前在头两个主成分张成的平面投影很类似。我们可以按照这些坐标值，用plot()函数进行基础可视化： plot(var.mds) 这些点聚类的情况和我们在之前没有聚合的双标图类似。下面我们同样将观测按照不同航空公司聚合后重复相同的分析，看看结果如何： mean.dist&lt;-airline.mean%&gt;% dist() mean.mds&lt;-cmdscale(mean.dist)%&gt;% data.frame() # 重新为列命名 names(mean.mds)&lt;-c(&quot;Score1&quot;,&quot;Score2&quot;) plot(mean.mds,type=&quot;n&quot;,xlim=c(-8,6),ylim=c(-5,6)) text(mean.mds,row.names(mean.mds),cex=1) 上面代码中，plot(..., type=&quot;n&quot;,...)是告诉R不要用任何符号绘制数据点，然后用text()函数将航空公司名作为数据点绘制在图上。这里的结果类似于之前聚合后的双标图。 对于分类或者排序变量，你可以使用不同的方法计算距离，比如cluster包中的daisy()可以用来计算排序变量之间的距离。我们们将聚合后的数据转换为排序来展示MDS在这种情况下的使用。 mean.rank&lt;-lapply(airline.mean,function(x) factor(rank(x),ordered=T))%&gt;% data.frame() glimpse(mean.rank) ## Observations: 3 ## Variables: 15 ## $ Easy_Reservation &lt;ord&gt; 3, 2, 1 ## $ Preferred_Seats &lt;ord&gt; 3, 2, 1 ## $ Flight_Options &lt;ord&gt; 3, 1, 2 ## $ Ticket_Prices &lt;ord&gt; 3, 2, 1 ## $ Seat_Comfort &lt;ord&gt; 2, 1, 3 ## $ Seat_Roominess &lt;ord&gt; 2, 1, 3 ## $ Overhead_Storage &lt;ord&gt; 2, 1, 3 ## $ Clean_Aircraft &lt;ord&gt; 2, 1, 3 ## $ Courtesy &lt;ord&gt; 1, 2, 3 ## $ Friendliness &lt;ord&gt; 1, 3, 2 ## $ Helpfulness &lt;ord&gt; 1, 3, 2 ## $ Service &lt;ord&gt; 1, 3, 2 ## $ Satisfaction &lt;ord&gt; 2, 1, 3 ## $ Fly_Again &lt;ord&gt; 2, 1, 3 ## $ Recommend &lt;ord&gt; 2, 1, 3 我们接下来用daisy()中的gower度量[33]，它可以用于虚拟变量，非对称二项变量，以及排序变量。 library(cluster) mean.rank.gower&lt;-daisy(mean.rank,metric=&quot;gower&quot;) 然后用MASS包中的isoMDS()来标度化数据，对结果绘制基本图形： library(MASS) mean.mds.gower&lt;-isoMDS(mean.rank.gower) ## initial value 0.000000 ## final value 0.000000 ## converged plot(mean.mds.gower$points,type=&quot;n&quot;,xlim=c(-0.5,0.5),ylim=c(-0.2,0.4)) text(mean.mds.gower$points,row.names(mean.mds),cex=1) 函数isoMDS()的坐标结果存在返回对象的points矩阵中，所以我们通过mean.mds.gower$points获取该矩阵。我们和之前基于欧几里德距离的结果比较可以发现，这两个结果中3个航空公司的分布并不相同。和之前相比，现在3个航空公司的分布更加对称，基本在一个等边三角形的3个顶点上，任意两个航空公司之间的距离都差不多。但之前欧几里德距离下的结果显示航空公司1和3更加接近。对于这两者结果差别我们并不感到意外，因为当你将具体分值转成排序的时候损失了一些信息。在有具体分值观测的情况下用欧几里德距离就可以了。这里只是为了展示isoMDS()的用法所以将其转化为排序变量。 总体来说在当前例子中，和PCA相比，MDS得到的信息更少。但是在处理文本数据时，比如用户反馈评论MDS就显示出优势了。比如你可以检查不同品牌名称在多少评论中的同时出现，出现的频数矩阵可以用来衡量不同品牌的分布[34]。 9.2.5 知识扩展 之前只介绍如何应用主成分分析和因子分析。虽然我尽量用非技术的语言解释模型背后的思想，但要很好的解释模型结果，还是需要对理论背景有所了解。本小节主要介绍这两种方法背后的数学理论，建议有一定数学基础的读者能够花些时间理解这些知识。 9.2.5.1 主成分分析 假设我们有随机变量组成的向量\\(\\mathbf{X}=[X_{1},X_{2},...,X_{p}]^{T}\\)，其对应的协方差矩阵为\\(\\Sigma\\)。 主成分分析的目的就是通过对原变量进行线性组合找到彼此不相关的新变量 \\((Z_{1} , Z_{2} , \\ldots , Z_{p})\\)，依次最大化每个变量的方差: \\[ \\begin{array}{ccccc} Z_{1} &amp; = &amp; \\mathbf{a_{1}^{T}X} &amp; = &amp; a_{11}X_{1}+a_{12}X_{2}+\\cdots+a_{1p}X_{p}\\\\ Z_{2} &amp; = &amp; \\mathbf{a_{2}^{T}X} &amp; = &amp; a_{21}X_{1}+a_{22}X_{2}+\\cdots+a_{2p}X_{p}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots\\\\ Z_{P} &amp; = &amp; \\mathbf{a_{p}^{T}X} &amp; = &amp; a_{p1}X_{1}+a_{p2}X_{2}+\\cdots+a_{pp}X_{p} \\end{array} \\] 其中： \\[Var(Z_{i})=\\mathbf{a_{i}^{T}\\Sigma a_{i}},\\ \\ \\ \\ \\ \\ \\ \\ \\ i=1...p\\] \\[Cov(Z_{i},Z_{k})=\\mathbf{a_{i}^{T}\\Sigma a_{k}},\\ \\ \\ \\ \\ \\ \\ \\ \\ i,k=1...p\\] 从几何学上讲，主成分分析中生成各个主成分的过程可以看成是将\\((X_{1},X_{2},\\ldots,X_{p})\\)定义的坐标系旋转成新坐标系。新坐标的坐标轴代表了观测方差最大的方向。主成分的推导依赖于 \\(\\mathbf{X}\\)的相关矩阵\\(\\Sigma\\)，这是典型的无监督学习，并且不要求变量服从多元正态分布。PCA过程按如下依次寻找主成分： 在控制条件\\(\\mathbf{a_{1}^{T}a_{1}}=1\\)下，通过最大化方差\\(Var(Z_{1})=\\mathbf{a_{1}^{T}\\Sigma a_{1}}\\)得到第一个主成分\\(Z_{1}\\) 在控制条件\\(\\mathbf{a_{2}^{T}a_{2}}=1\\)和\\(Cov(Z_{1},Z_{2})=0\\)下，通过最大化\\(Var(Z_{1})=\\mathbf{a_{1}^{T}\\Sigma a_{1}}\\)得到第二个主成分\\(Z_{2}\\) 依次类推，对第i个主成分，在控制条件\\(\\mathbf{a_{i}^{T}a_{i}}=1\\)和\\(Cov(Z_{i},Z_{k})=0\\)（任意\\(k&lt;i\\)）下，通过最大化\\(Var(Z_{i})=\\mathbf{a_{i}^{T}\\Sigma a_{i}}\\)得到第二个主成分\\(Z_{i}\\) 对于上面第1条，可以证明 \\[Var(Z_{1})=\\mathbf{a_{1}^{T}\\Sigma a_{1}}=\\underset{\\mathbf{e^{T}e=1}}{max} \\mathbf{e^{T}\\Sigma e}=\\lambda_{1}\\] 其中，\\(\\lambda_{1}\\geqslant\\lambda_{2}\\geqslant...\\geqslant\\lambda_{p}\\)是\\(\\Sigma\\)的特征值， \\(\\mathbf{a_{1},a_{2},...,a_{p}}\\)是相应的单位正交特征向量。证明需要用到谱分解定理，但并不复杂。 由于主成分分析基于变量协方差矩阵\\(\\Sigma\\)，我们需要特别注意各个变量的标度，如果差别很大（比如年龄和收入），那需要将观测标准化后再进行分析。关于如何用R进行数据标准化，我们在之前数据预处理的部分已经详细介绍过了。当前例子中所有问题的回复都在1-9分的量表上，所以是不是标准化差别不太大。注意，这里我们说所的\\(\\mathbf{X}=[X_{1},X_{2},...,X_{p}]^{T}\\)是随机变量组成的向量，这是一个理论设定。在具体应用中，我们有的是对每个变量的观测，然后用观测的样本协方差矩阵来估计变量协方差矩阵。之所以这里用理论上的随机变量的表达方式是为了简便，不然用真实的样本观测矩阵解释会有很多矩阵转秩，即使背后的理论简单，这样的数学表达也能让人看晕。要想把这样的数理知识解释的有趣实在超出我的能力范围，这里我只是尽量使得讲解清晰，减少不必要的混淆。但我知道这部分终归是让人抓狂的，小伙伴们忍忍吧！ 9.2.5.2 因子分析 因子分析是研究相关阵或者协方差矩阵的内部关系，它将多个变量综合为少数几个因子，以再现原始变量和因子之间的相关关系。因子分析和主成分分析有联系，是其推广和发展。1904年Charles Spearman指出，如果第i个变量（第i门功课）上的分数由两部分组成的： \\[X_{i}=l_{i}F+\\epsilon_{i}\\] 其中F是对所有变量都起作用的公因子，那么就可以说明各门功课相关的“效应”。每门课程的考试成绩可以看作由一个公因子（智力因子）和一个特殊因子之和组成。这是最早的最简单的因子模型。可以将这个因子模型进一步推广到多个因子的情况，即全体科目所共有的因子有m个，如数学推导因子、记忆因子、计算因子等，分别记为\\(F_{1},...,F_{m}\\)： \\[ \\begin{array}{ccc} X_{1}-\\mu_{1} &amp; = &amp; l_{11}F_{1}+l_{12}F_{2}+\\cdots+l_{1m}F_{m}+\\epsilon_{1}\\\\ X_{2}-\\mu_{2} &amp; = &amp; l_{21}F_{1}+l_{22}F_{2}+\\cdots+l_{2m}F_{m}+\\epsilon_{2}\\\\ \\vdots &amp; \\vdots &amp; \\vdots\\\\ X_{p}-\\mu_{p} &amp; = &amp; l_{p1}F_{1}+l_{p2}F_{2}+\\cdots+l_{pm}F_{m}+\\epsilon_{p} \\end{array} \\] 其中\\(l_{ij}\\)就是因子载荷，第i个变量在第j个因子上的载荷。\\(\\mathbf{X}=[X_{1},...,X_{p}]^{T}\\)是p个观测属性组成的向量，均值向量为\\(\\mathbf{\\mu}\\)，协方差矩阵为\\(\\Sigma\\)。用矩阵标记表示就是： \\[\\mathbf{(X}-\\mathbf{\\mu)_{p\\times1}}=L_{p\\times m}\\mathbf{F}_{m\\times1}+\\mathbf{\\epsilon_{p\\times1}}\\] 其中\\(L\\)是因子载荷矩阵，\\(\\mathbf{F}\\)是\\(m\\)个无法观测到的潜因子组成的向量。这里模型看上去有点像一般线性回归。由于在这里等式右边是无法观测到的，如果我们没有其它的限制条件的话无法给出任何载荷估计。正交因子模型假设： \\[E(\\mathbf{F})=\\mathbf{0}\\] \\[Var(\\mathbf{F})=E(\\mathbf{FF^{T}})=I\\] \\[E(\\mathbf{\\epsilon})=\\mathbf{0}\\] \\[Var(\\mathbf{\\epsilon})=E(\\mathbf{\\epsilon\\epsilon^{T}})=\\Psi=diag(\\psi_{i}),\\ \\ i=1,\\cdots,p\\] \\[cov(\\mathbf{F},\\mathbf{\\epsilon})=0\\] 这里假设每个因子的方差都是1不是一个限制条件，因为我们总是可以通过放大缩小因子载荷进行调整。正交因子模型真正的限制条件是假设各个因子之间不相关，且共因子和特殊因子之间不相关。这些假设暗示了\\(\\Sigma\\)的结构。如果： \\[\\mathbf{(X}-\\mathbf{\\mu)_{p\\times1}}=L_{p\\times m}\\mathbf{F}_{m\\times1}+\\mathbf{\\epsilon_{p\\times1}}\\] 那么： \\[ \\begin{array}{ccc} \\mathbf{(X}-\\mathbf{\\mu)\\mathbf{(X}-\\mathbf{\\mu)^{T}}} &amp; = &amp; (L\\mathbf{F}+\\mathbf{\\epsilon})(L\\mathbf{F}+\\mathbf{\\epsilon})^{T}\\\\ &amp; = &amp; (L\\mathbf{F}+\\mathbf{\\epsilon})(\\mathbf{F^{T}L^{T}}+\\mathbf{\\epsilon^{T}})\\\\ &amp; = &amp; \\mathbf{LFF^{T}L^{T}+LF\\epsilon^{T}+\\epsilon F^{T}L^{T}+\\epsilon\\epsilon^{T}} \\end{array} \\] 对上述等式两边取期望可以得到： \\[ \\begin{array}{ccc} \\Sigma &amp; = &amp; E\\{\\mathbf{(X}-\\mathbf{\\mu)\\mathbf{(X}-\\mathbf{\\mu)^{T}}}\\}\\\\ &amp; = &amp; E\\{LFF^{T}L^{T}+LF\\epsilon^{T}+\\epsilon F^{T}L^{T}+\\epsilon\\epsilon^{T}\\}\\\\ &amp; = &amp; \\mathbf{LL^{T}+\\Psi} \\end{array} \\] 因为 \\(E(\\mathbf{FF^{T}})＝Var(\\mathbf{F})=I\\)并且\\(E(\\mathbf{\\epsilon^{T}F})=cov(\\mathbf{F},\\mathbf{\\epsilon})=0\\)。此外还有： \\[\\mathbf{(X-\\mu)F^{T}=LFF^{T}+\\epsilon F^{T}}\\] \\[cov(\\mathbf{X,F})=E[(\\mathbf{X-\\mu})F^{T}]=L\\] 因此在正交因子模型中，进一步有： \\[Var(X_{i})=\\sigma_{ii}=l_{i1}^{2}+l_{i2}^{2}+\\cdots+l_{im}^{2}+\\psi_{i}\\] \\[Cov(X_{i},X_{K})=\\sigma_{ik}=l_{i1}l_{k1}+l_{i2}l_{k2}+l_{im}l_{km}\\] 我们将方差\\(\\sigma_{i}\\)分解成两部分： \\[\\sigma_{ii}=l_{i1}^{2}+l_{i2}^{2}+\\cdots+l_{im}^{2}+\\psi_{i}=h_{i}^{2}+\\psi_{i}\\] \\(h_{i}^{2}\\)是全部公因子对变量\\(X_{i}\\)的总方差所作出的贡献，称为公因子方差（共同度） \\(\\psi_{i}\\)由特殊因子\\(\\epsilon_{i}\\)产生的方差，它仅与变量\\(X_{i}\\)，也称为剩余方差 \\(h_{i}^{2}\\)反映了变量\\(X_{i}\\)对公因子F的依赖程度。拟合模型的目标就是是的公因子增大，剩余方差减小。 模型假设\\(\\mathbf{X}\\)的\\(\\frac{p(p+1)}{2}\\)个方差和协方差参数可以通过\\(p(m+1)\\)个因子载荷和\\(p\\)个特殊因子方差得到。理想的情况是用尽可能少的公因子表示原变量。在之前的例子中\\(p=12\\)，\\(m=3\\)，原来协方差矩阵中的78个元素可以用有\\(12\\times(3+1)=48\\)个未知数的因子模型表示。这里要注意，并非所有的协方差矩阵都能用\\(\\mathbf{\\mathbf{LL^{T}+\\Psi}}\\)的因子模型表示。比如下面这个例子： 假设 \\(p=3\\)，\\(m=1\\)，且\\([X_{1},X_{2},X_{3}]\\)的协方差矩阵是\\[\\Sigma=\\left[\\begin{array}{ccc} 1 &amp; 0.9 &amp; 0.7\\\\ 0.9 &amp; 1 &amp; 0.4\\\\ 0.7 &amp; 0.4 &amp; 1 \\end{array}\\right]\\] 正交因子模型要求\\(\\Sigma=\\mathbf{LL^{T}+\\Psi}\\)。加上其它因子模型的条件，我们可以得到下面方程组： \\[\\begin{array}{ccc} 1=l_{11}^{2}+\\psi_{1} &amp; 0.9=l_{11}l_{21} &amp; 0.7=l_{11}l_{31}\\\\ &amp; 1=l_{21}^{2}+\\psi_{2} &amp; 0.4=l_{21}l_{31}\\\\ &amp; &amp; 1=l_{31}^{2}+\\psi_{3} \\end{array}\\] 由上面方程组可得：\\(l_{21}=(0.4/0.7)l_{11}\\)。又因为\\(0.9=l_{11}l_{21}\\)，我们可以得到\\(l_{11}^{2}=1.575\\)，也就是\\(l_{11}=\\pm1.255\\)。这里就有问题了。根据假设条件，\\(Var(F_{1})=1\\)且\\(Var(X_{1})=1\\)，于是\\(Cov(X_{1},F_{1})=Corr(X_{1},F_{1})=l_{11}\\)。 而相关系数的绝对值是不能大于1的。此外： \\[1=l_{11}^{2}+\\psi_{1}\\Longrightarrow\\psi_{1}=1-l_{11}^{2}=-0.575\\] 这也不可能，因为\\(\\psi=Var(\\epsilon_{1})\\)，因此不能小于0。因此，在这个例子中，我们无法得到有意义的单因子模型的参数估计。 当\\(m&gt;1\\)时，未知数个数大于等式个数，因子模型的没有唯一的解。 如何解决因子模型解的不唯一问题呢？通过因子载荷旋转。我们先得到一个可能的因子载荷解（不唯一），然后对该载荷进行旋转直到旋转后的载荷满足一定附加条件。这里又牵扯到两个问题：1. 什么是载荷旋转？2.什么是附加条件。下面我们逐一回答这两个问题： 载荷旋转其实就是用载荷矩阵乘一个正交矩阵。假设\\(\\mathbf{U}\\)是一个\\(m \\times m\\)的正交矩阵，即\\(\\mathbf{UU^{T}=U^{T}U=I}\\)。我们可以将模型写成下面形式： \\[\\mathbf{X-\\mu=LF+\\epsilon=LUU^{T}F+\\epsilon=L^{*}F^{*}+\\epsilon}\\] 其中\\(\\mathbf{L^{*}=LU,\\ F^{*}=U^{T}F}\\)。这里只要\\(\\mathbf{U}\\)是正交矩阵就有： \\[E\\mathbf{(F^{*})=U^{T}}E(\\mathbf{F})=\\mathbf{0}\\] \\[Var(\\mathbf{F^{*}})=\\mathbf{U^{T}}Var(\\mathbf{F})\\mathbf{U=I}\\] 因此，\\(\\mathbf{L}\\)和\\(\\mathbf{L^{*}}\\)是等价的，当前的条件无法区分两者，这两个载荷矩阵对应相同的协方差矩阵。之前也提到，如果我们认为因子相关，也就是说\\(\\mathbf{FF^{T}}\\)不是单位矩阵，可以对原载荷进行斜交变换（注意这里不是旋转）。也就是用载荷矩阵乘斜交矩阵。 而因子载荷不唯一的情况通过添加额外的标准来解决。比如方差最大旋转（varimax rotation）旋转的目的是通过坐标变换使各个因子载荷的方差之和最大。通俗地说就是， 任何一个变量只在一个因子上有高贡献率，而在其它因子上的载荷几乎为0 任何一个因子只在少数变量上有高载荷, 而在其它变量上的载荷几乎为0 果满足这个条件的因子载荷矩阵称为具有“简单结构”。方差最大化旋转[35]就是用来将载荷矩阵旋转到尽量接近简单结构的方法。从这组变量代表的样本看来，方差最大化旋转找到了一种表示样本的最简单的方法，即每个样本可以用少数变量的函数的线性组合表示。 \\[U_{varmax}=\\underset{U}{argmax}\\left(\\Sigma_{j=1}^{m}\\Sigma_{i=1}^{p}(LU)^{4}-\\frac{1}{p}\\Sigma_{j=1}^{m}\\left(\\Sigma_{i=1}^{p}(LU)_{ij}^{2}\\right)^{2}\\right)\\] 斜交变换更加复杂，感兴趣的读者可以参考Edward Jackson书中的[36]的第8章。 9.2.5.3 高维标度化 这里我们回到之前样本观测矩阵的数学表达方式。用\\(n\\)表示样本量（或者观测数目）。\\(p\\)代表自变量数目。我们用\\(\\mathbf{X}\\)表示\\(n\\times p\\)观测矩阵： \\[ \\mathbf{X}=\\left[\\begin{array}{cccc} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1p}\\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{np} \\end{array}\\right]=\\left[\\begin{array}{c} \\mathbf{x_{1.}^{T}}\\\\ \\mathbf{x_{2.}^{T}}\\\\ \\vdots\\\\ \\mathbf{x_{n.}^{T}} \\end{array}\\right]=\\left[\\begin{array}{cccc} \\mathbf{x_{.1}} &amp; \\mathbf{x_{.2}} &amp; \\ldots &amp; \\mathbf{x_{.p}}\\end{array}\\right] \\] 其中\\(x_{ij}\\)代表第i个样本第j个变量的观测，\\(i=1, \\ldots, n\\)，\\(j=1, \\ldots, p\\)。\\(\\mathbf{x_{i.}}\\in\\mathbb{R}^{p}\\)代表第i个样本的所有变量观测组成的向量，向量统一按列排： \\[ \\mathbf{x_{i.}}=\\left[\\begin{array}{c} x_{i1}\\\\ x_{i2}\\\\ \\vdots\\\\ x_{ip} \\end{array}\\right] \\] 假设第i和第j个观测之间的距离是\\(d_{ij}=\\Vert\\mathbf{x_{i.}-x_{j.}}\\Vert\\)。通常情况下使用欧几里德距离，有的时候也会用其它距离。此外，在有些情况下，我们并没有直接的样本观测，而是一些差异度测量。比如让每个人品尝不同的酒，然后用\\(d_{ij}\\)表示红酒品牌\\(i\\)和品牌\\(j\\)之间的差别，受访者对不同的品牌组合\\(ij\\)进行差异度评定。MDS只要求差异度\\(d_{ij}\\)，如果直接拿到这样的信息，就不需要计算距离矩阵了，这和PCA和EFA很不一样。MDS寻找能最小化下面“压力函数”的新变量\\(\\mathbf{z_{1},z_{2},...,z_{n}}\\in\\mathbb{R}^{k}\\)： \\[S_{M}(\\mathbf{z_{1},z_{2},...,z_{n}})=\\Sigma_{i\\neq j}(d_{ij}-\\Vert\\mathbf{z_{i}-z_{j}}\\Vert)^{2}\\] 该方法叫做最小二乘标度化。其主导思想是寻找原数据的低维表示，同时尽量保存各对观测之间的距离。通过一种梯度下降算法最小化\\(S_{M}\\)。最小二乘标度化的一个变体是塞曼映射（Sammon mapping），它最小化下面这个方程： \\[S_{Sm}(\\mathbf{z_{1},z_{2},...,z_{n}})=\\Sigma_{i\\neq j}\\frac{(d_{ij}-\\Vert\\mathbf{z_{i}-z_{j}}\\Vert)^{2}}{d_{ij}}\\] 通过除以\\(d_{ij}\\)，该方法提高了距离较短的观测对的权重。cmdscale()函数是按照Mardia论文中的分析方法得到的新标度[37]。关于各种其它标度化的方法，可以参考Borg等所著的入门教材《Applied multidimensional scaling》[38]。更多的统计学知识细节可以参考Borg和Groenen的《Modern Multidimensional Scaling》[39]。 9.3 特征选择 我们建立统计模型常常会对下面的几个问题感兴趣： 模型拟合情况如何？ 模型在新样本上预测的情况如何？ 所有的自变量都有助于解释应变量（\\(\\mathbf{y}\\)），还是只有其中部分重要的自变量？ 回答这三个问题的共同前提是得先有一个评判模型“好”和“坏”的标准。前两个问题在建模技术那章已经给出了一般性的解答，通常使用数据划分和再抽样的方式，根据建模目的不同，选择不同的评判标准，在此基础上检验模型拟合和预测情况。这章我们主要回答第3个问题。虽然所有自变量对于解释因变量来说都是重要的这样的情况可能发生，但更常见的是因变量只和一部分自变量有关。特征选择的主要目的是删除无信息变量或冗余变量，从而达到降维的效果。 《应用预测建模》书中[13]第19章的第1小节以一个化学物质溶解度的数据为例，研究了冗余预测变量产生的影响。其中比较了下面模型：线性回归、偏最小二乘、单一回归树、多元自适性样条回归、随机森林、神经网络、径向基函数的支持向量机。结果显示，回归树和MARS模型由于自带的特征选择功能不受（额外无信息变量的）影响。随机森林虽然效果随着无信息变量个数的增加略有下降，但影响并不大，这是因为该算法随机选择预测变量作为分裂点会强制模型使用一些不重要的预测变量。受无信息影响最大的是线性回归、偏最小二乘和神经网络。问题最严重的是神经网络，这可能是因为模型中加入了过多的无信息变量。特征选择不仅仅对模型预测效果有好处，也使得模型更加简单且易于解释。 其实寻找全局最优解的方法理论上很简单，但是实际操作是不可能的。就是在所有可能的变量子集上拟合模型，找到最优的子集。所有特征选择的方法严格上说都是在一定条件下的局部最优解。 特征选择的方法主要可以分成3类： 过滤法（filter） 绕封法（wrapper） 内嵌法（embeded） 这里我们介绍前两种。内嵌法是将特征选择的过程内嵌如建模的过程，它是学习器自身自主选择特征，如lasso，或者使用决策树思想的方法。我们在讲相应模型时再介绍。 9.3.1 过滤法 它主要侧重于单个特征跟目标变量的关系，在建模前对每个特征（或者自变量）进行评估，选择“重要”的变量进行建模。这里自然有一个问题就是:怎么定义变量重要性？这里所说的重要性指的是一个量化预测变量和结果变量之间关系的粗略度量。注意这里的“粗略”这个词，因为这样的重要性衡量并无法给出如“某变量增加会导致结果变量减少”这样细节的关系，这样的关系只能通过更复杂，严格控制，评估后的建模过程得到，如各种回归模型。下面要介绍的重要性衡量方法是通过逐一变化特征，然后测量该特征在与不在时模型表现的差别。如果缺失某特征导致模型表现大幅度下降，表明变量重要性大。这在有时是一个有效的方式，尤其当一开始变量数目太多时，这些测量能够指导建模者关注一些特别的特征，或对某些特征进行可视化，否者在一开始变量太多的时候是无从着手的。 该方法的优点是计算时间上较高效。缺点就是倾向于选择冗余的特征,因为他们不考虑特征之间的相关性,如果某一个特征重要性较高，所有和该特征高相关的特征重要性都会很高，。Guyon 和Elisseeff讨论了过滤过程中的冗余变量问题[40]。当然也有可能错过重要的特征，比如某一个特征的分类能力很差，但是它和某些其它特征组合起来会得到不错的效果。 9.3.1.1 特征重要性度量 特征重要性度量的方式和其类型有关，分类型和连续型特征度量差别很大，这和之间讲模型表现评估度量类似。这里我们按照不同的特征和应变量类型来介绍相应的常用度量。 当应变量和特征都是数值型时，最常用的就是简单相关性统计量。我们可以通过Pearson相关系数衡量线性相关，用Spearman相关系数衡量曲线相关。Kendall相关系数用来衡量两个变量观测排序的一致性。关于这些相关性的定义以及其它的相关性，大家可以很容易在网上找到。基于相关性过滤变量非常主观，你可以自己决定一个阈值，比如你重点研究哪些相关性大于0.5的变量，或者对相关性大于0.8的变量进一步可视化，这可以指导我们进行探索性数据分析。用基础包中的cor()函数可以很容易计算这些相关性： dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数 dat&lt;-subset(dat,store_exp&gt;0 &amp; online_exp&gt;0 &amp; age&lt;100) # 计算Pearson相关性 cor(dat$age,dat$store_exp) ## [1] 0.05760738 上面的代码并没有明确指定某种相关系数，这是cor()函数默认设置是计算年龄和在线消费量的Pearson相关性。如果要计算Pearson相关系数只要添加method=设置就可以： cor(dat$age,dat$online_exp,method=&quot;spearman&quot;) ## [1] -0.3682889 类似的可以计算Kendall相关系数： cor(dat$age,dat$online_exp,method=&quot;kendall&quot;) ## [1] -0.2019283 大家可以看到，这里Pearson相关系数和另外两个很不一样，因为年龄和在线消费量并不是线性的，而Pearson衡量的是线性关系，另外两个都没有线性的要求，所以更加接近。在这种情况下用非线性的相关系数更加合理。这里也可以很清楚的看到，这样过滤变量的方式非常粗糙，只能作为探索性的方法，对于复杂的关系并不适用。 用一个相关性度量丢失了太多的信息，还有一个方法是适用局部加权回归模型（LOESS），该方法和滑动平均类似，对一系列局部区域样本应用多项式回归[41]。这类局部回归的方法有极强的适应性，可以有效得到平滑的回归趋势。基础包中的loess()函数可以进行LOESS平滑。用如下语句指定模型： # 建立loess模型 smoother &lt;- loess(dat$online_exp ~ dat$age) # 计算loess估值 pred.smoother&lt;-predict(smoother, dat$age) # 计算loess对应的RSS rss&lt;-sum((dat$online_exp-pred.smoother)^2) # 计算因变量的TSS tss&lt;-sum((dat$online_exp-mean(dat$online_exp))^2) # 通过RSS和TSS计算R-squared (r2&lt;-1-rss/tss) ## [1] 0.5126091 基于该拟合结果(pred.smoother)，通过残差可以计算\\(R^{2}\\)统计量，我们可以用其作为相应变量重要性的度量。年龄变量对应的LOESS的\\(R^{2}\\) 值是0.51。lattice 包中的函数 xyplot() 可以很方便的用来对LOESS结果进行可视化： library(lattice) xyplot(dat$online_exp ~ dat$age, type = c(&quot;p&quot;, &quot;smooth&quot;), xlab = &quot;age&quot;, ylab = &quot;online_exp&quot;) 此外，ggplot2包也可以很方便的对多种平滑方法进行可视化： library(ggplot2) ggplot(dat,aes(age,online_exp))+geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; 其中geom_smooth()默认设置是使用LOESS平滑，所以你不用进行额外的设置。其中蓝色的线代表LOESS平滑器拟合结果。 可以通过caret包中的函数filterVarImp对每个预测变量建立LOESS模型，并且定量分析其与结果变量之间的关系。这里我们将10个问卷调查变量当作自变量，将实体店消费量和在线消费之和当作应变量，重新得到一个数据框，然后用其进行展示： TrainXtrans&lt;-dat[,grep(&quot;Q&quot;,names(dat))] TrainY&lt;-dat$store_exp+dat$online_exp 然后用filterVarImp()函数： # 选项设置`nonpara = TRUE` (对于非参数回归) loessResults &lt;- filterVarImp(x = TrainXtrans, y = TrainY, nonpara = TRUE) head(loessResults) ## Overall ## Q1 0.43921457 ## Q2 0.58319421 ## Q3 0.57849504 ## Q4 0.19425985 ## Q5 0.22560965 ## Q6 0.09568796 该函数返回每个特征用LOESS方法得到的重要性度量。上面这些评估特征的方法只是单独考虑每一个特征，而没有考虑特征之间的关系。这里考虑的是特征和应变量都是数值型的情况。如果特征是分类变量时该怎么办呢（比如服装消费者数据中的性别（gender）变量）？这种情况很自然的会想到t检验，寻找p&lt;0.05的变量： t.test(online_exp~gender,data=dat) ## ## Welch Two Sample t-test ## ## data: online_exp by gender ## t = -3.1471, df = 784.02, p-value = 0.001711 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -579.1784 -134.2047 ## sample estimates: ## mean in group Female mean in group Male ## 1957.417 2314.109 当预测变量大于2时，可以使用方差分析（ANOVA）。我们用客户分组变量为例展示代码： anova(lm(online_exp~segment,data=dat)) ## Analysis of Variance Table ## ## Response: online_exp ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## segment 3 2457017793 819005931 1560.8 &lt; 2.2e-16 *** ## Residuals 994 521588437 524737 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 这里要注意，如之前所说，p值并不是一个很好的筛选变量的标准。但是有时我们需要对大量的变量进行筛选，找到需要进一步重点研究的候选变量，用p&lt;0.05作为一个标准确实是一个快速的方法。这里个人不建议大家在需要高精确度的模型中使用这样的变量筛选方式，但是在市场调查问卷中，可以用p值来大致判断那些问题在不同受访者群体中有显著差别。另外需要注意的是，p值小于0.05这个阈值不是不可改变的，事实上，你很可能会遇到重复检验的问题，我们需要对p值进行调整来缓解该问题，比如Bonferroni校正[42]。如果要做k次统计检验，定义统计显著性p值的原始阈值为a，那么将该值调整为\\(\\frac{a}{k}\\)能提高检验的可信度。但该校正方法可能过度保守。 对于特征是数值型，应变量是分类型的情况，我们可以使用ROC曲线下面积量化特征和应变量的相关性。之前在模型评估的部分中我们已经讲过ROC曲线下面积。这里我们将服装消费者数据中的是否有房的指示变量当作应变量，其它一些数值特征当作自变量展示如何使用filterVarImp()函数实现重要性分值的计算： vars&lt;-c(&quot;age&quot;,&quot;income&quot;,&quot;store_exp&quot;,&quot;online_exp&quot;) x&lt;-subset(dat,select=vars) y&lt;-dat$house rocValues &lt;- filterVarImp(x = x, y = y) rocValues ## No Yes ## age 0.7968303 0.7968303 ## income 0.7590159 0.7590159 ## store_exp 0.7985940 0.7985940 ## online_exp 0.4339279 0.4339279 如果某特征能够完美的将两类样本分离，那么存在一个阈值能够给出100%的敏感度和特异度，这时曲线下面积是1。如前所述，一个和结果变量全不相关的预测变量对应的曲线下面积大概是0.5。上面结果显示在线消费量（online_exp）对区分有房和无房的人没有帮助。 当有三个或三个以上类别的时候，我们可以使用ROC曲线的推广[25, 43, 44]。或则我们可以将除某一类外的其它类合并在一起,这样对每一类我们都会得到相应的AUC（曲线下面积）值。总体区分度可以量化为这些类AUC的平均。filterVarImp()函数能够分别计算其中任何两类之间的ROC曲线然后给出最大的线下面积: y&lt;-dat$segment rocValues &lt;- filterVarImp(x = x, y = y) rocValues ## Conspicuous Price Quality Style ## age 0.999457286 0.99945729 0.2787940 0.05644699 ## income 0.079660533 0.07966053 0.9637399 0.96373994 ## store_exp 0.005701862 0.05052000 0.0505200 0.03369628 ## online_exp 0.028566903 1.00000000 1.0000000 1.00000000 一个更简单的方法是检测不同类样本对应某预测变量的观测平均值是否有差别。这和前一小节提到的方法类似，不同的是在这里预测变量的观测被当作“结果”。 如果特征和应变量都是分类型，有几种用于测量变量重要性的方法。对于二分类预测变量，一个 有效的方式是是使用让步比。 一个概率为p的事件的发生比是\\(\\pi=\\frac{p}{1-p}\\) （是该事件发生和不发生的比率）。预测变量每个类对应一个概率，如果将其记为\\(p_{1}\\)和\\(p{2}\\)，对应的发生比为\\(\\pi_{1}\\)和\\(\\pi_{2}\\)，那么让步比[45, 46]： \\[让步比＝\\frac{\\pi_{1}}{\\pi_{2}}\\] 让步比表明从预测变量的第一类到预测变量第二类，对应事件发生比的变化。 当类的个数超过2或者预测变量有2个以上层级时，可以使用其它方法。在这种情况下依旧可以使用Fisher确切检验来测量预测变量和相应结果类别的联系。 9.3.1.2 Relief 算法 Relief为一系列算法，最早由Kira和Rendell[47]提出。和其它重要性衡量的方法类似，算法给出的是一个重要性分值，将分值低于某个阈值的特征移除。这里可以将阈值当作调优参数通过划分测试集和训练集，基于一个模型表现的度量进行选择。该算法最初用于二分类判别分析，适用于连续预测变量和虚拟变量，能够识别预测变量和结果变量之间的非线性关系。之后被扩展到应变量为连续值的情况。 原始的Relief算法的基本原理是通过特征对近距离样本的区分能力来估计重要性。沿用之前高维标度化中的公式表达，假设有n个样本观测和p个变量，对应应变量为\\(\\mathbf{y}\\)（或者目标变量），观测矩阵为\\(\\mathbf{X}_{n\\times p}\\)。特征向量为： \\[\\mathbf{x_{.1}}, \\mathbf{x_{.2}},...,\\mathbf{x_{.p}}\\] 算法从训练集中随机选择一个样本R，然后从和R同类的样本中寻找最近的同类（称为“hit”，之后用H表示）和不同类的样本（称为“miss”，之后用M表示），然后根据以下规则更新每个特征的权重：如果R和H在某个特征上的距离小于R和M的距离，则说明该特征对区分R附近同类和不同类样本是有益的，因此增加该特征的权重；反之，如果R和H在某个特征的距离大于R和M的距离，说明该特征对区分附近同类和不同类样本起负面作用，随即降低该特征的权重。将上面过程重复m次，最后得到各特征的平均权重。特征的权重越大，表示该特征的分类能力越强，反之，表示该特征分类能力越弱。对连续型特征的距离，Kira和Rendell建议用两点之间的距离除以该特征的观测极差: \\[diff(x_{ij}, x_{kj}) = \\frac{x_{ij} − x_{kj}}{C}\\] 这里常数\\(C=max(\\mathbf{x_{.j}})-min(\\mathbf{x_{.j}})\\)将差别标准化到\\([0,1]\\) 区间。对于二项数据 (即, 0/1)， 可以简单使用绝对值： \\[diff(x_{ij}, x_{kj}) = |x_{ij} − x_{kj}|\\] 这样值域即为[0,1]。对于二分类问题具体算法如下所示： 将预测变量分值\\(S_{j}\\)初始值设为0 （j=1,…,p） 对 i=1…m随机抽取训练集样本\\(R_{i}\\)执行 找到最近的同类（H）和不同类（M）样本 对 预测变量 j=1…p 执行 基于\\(R_{i}\\)与最近的同类和不同类样本的距离，按如下方式调整分值： \\(S_{j}=S_{j}-diff_{j}(R_{i},H)^{2}/m + diff_{j}(R_{i},M)^{2}/m\\) 结束 结束 Relief算法的运行时间随着样本的抽样次数m和原始特征个数p的增加线性增加，因而运行效率非常高。之后Kononenko改进了该算法，改进后的算法称为ReliefF[48]，其使用多个邻近点和不同的差别计算方式，并且能用于类数目大于2和有观测缺失的情况。之后Robnik-Sikonja和Kononenko进一步改进该方法使之适于回归（即，数值型结果变量）[49]。关于这几种Relief算法的一个比较完整的介绍可以参考Marko Robnik-Sikonja和Igor Kononenko的文章[50]。 Relief 统计量的计算可以使用CORElearn包。其中函数attrEval()能计算几个不同版本的Relief值(使用estimator选项)。回归模型对应的estimator的参数设置可以通过下面代码查看： # 需要事先安装CORElearn包 library(CORElearn) infoCore(what=&quot;attrEvalReg&quot;) ## [1] &quot;RReliefFequalK&quot; &quot;RReliefFexpRank&quot; &quot;RReliefFbestK&quot; ## [4] &quot;RReliefFwithMSE&quot; &quot;MSEofMean&quot; &quot;MSEofModel&quot; ## [7] &quot;MAEofModel&quot; &quot;RReliefFdistance&quot; &quot;RReliefFsqrDistance&quot; 类似的，分类模型对应的estimator的参数设置为： infoCore(what=&quot;attrEval&quot;) ## [1] &quot;ReliefFequalK&quot; &quot;ReliefFexpRank&quot; &quot;ReliefFbestK&quot; ## [4] &quot;Relief&quot; &quot;InfGain&quot; &quot;GainRatio&quot; ## [7] &quot;MDL&quot; &quot;Gini&quot; &quot;MyopicReliefF&quot; ## [10] &quot;Accuracy&quot; &quot;ReliefFmerit&quot; &quot;ReliefFdistance&quot; ## [13] &quot;ReliefFsqrDistance&quot; &quot;DKM&quot; &quot;ReliefFexpC&quot; ## [16] &quot;ReliefFavgC&quot; &quot;ReliefFpe&quot; &quot;ReliefFpa&quot; ## [19] &quot;ReliefFsmp&quot; &quot;GainRatioCost&quot; &quot;DKMcost&quot; ## [22] &quot;ReliefKukar&quot; &quot;MDLsmp&quot; &quot;ImpurityEuclid&quot; ## [25] &quot;ImpurityHellinger&quot; &quot;UniformDKM&quot; &quot;UniformGini&quot; ## [28] &quot;UniformInf&quot; &quot;UniformAccuracy&quot; &quot;EqualDKM&quot; ## [31] &quot;EqualGini&quot; &quot;EqualInf&quot; &quot;EqualHellinger&quot; ## [34] &quot;DistHellinger&quot; &quot;DistAUC&quot; &quot;DistAngle&quot; ## [37] &quot;DistEuclid&quot; 我们用服装消费者数据为例，假设感兴趣的是收入，特征是所有问卷的问题。 dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 删除应变量缺失的行 dat=filter(dat,!is.na(income)) # 选取需要的变量 # 特征矩阵 xtrain=dat%&gt;% dplyr::select(num_range(&quot;Q&quot;, 1:10)) # 应变量 ytrain=dat$income # 实践Relief算法 reliefValues = attrEval(ytrain ~ ., data = xtrain, ## 有许多计算Relief的方法，这里将k个邻近样本设置为等权重 ## 更多信息键入?attrEval estimator = &quot;RReliefFequalK&quot;, ## 测试的数目： ReliefIterations = 50) 得到的分值如下： head(reliefValues) ## Q1 Q2 Q3 Q4 Q5 ## -0.009624742 -0.031902397 0.005705953 -0.016508364 0.034252308 ## Q6 ## -0.007082354 该函数也能用来计算其它分值，如增益比，基尼系数等。要用置换检验观测到的Relief分值可以使用AppliedPredictiveModeling包中的permuteRelief()函数： library(AppliedPredictiveModeling) perm = permuteRelief(x = xtrain, y = ytrain, nperm = 500, estimator = &quot;RReliefFequalK&quot;, ReliefIterations = 50) 置换得到的Relief分值存在叫做permutations的子对象里： head(perm$permutations) ## Var1 Predictor value ## 1 1 Q1 0.005194469 ## 2 2 Q1 -0.035755040 ## 3 3 Q1 -0.006193998 ## 4 4 Q1 -0.004264219 ## 5 5 Q1 0.004122471 ## 6 6 Q1 -0.009931796 重要性分值的置换分布非常有帮助，能够让我们直观的了解分值的随机性，我们可以用下面方式对置换分值分布进行可视化： lattice::histogram(~ value|Predictor,data = perm$permutations) 标准化后的分值存在叫做standardized的子对象里，其代表了观测到的Relief分值（无置换）离置换分布中心的距离与标准差的比值： head(perm$standardized) ## Q1 Q2 Q3 Q4 Q5 Q6 ## -1.25769126 -1.27600996 1.97581995 -2.13350438 -0.62782489 -0.04602102 上面讲到的各种通过对每个特征计算重要性分值，然后在建模时只包括满足一定条件的特征。该方法是在建模过程之前先对特征进行选择，选择标准和模型效果没有直接关系，计算更快，但比较粗糙，选出来的变量不一定能很好的优化模型效能。下面我们介绍另外一类基于模型效果的特征选择方法。 9.3.2 绕封法 绕封法按照一定规律不断增加或者删除变量，通过评估不同特征组合得到的模型拟合结果寻找能够最优化模型拟合的特征组合。其本质是搜索算法，将不同的特征子集当作输入，然后将模型评估结果作为需要优化的输出。 9.3.2.1 穷举法 最简单直接的是通过穷举得到所有可能的特征子集，然后找到优化模型拟合的组合。比如对于一个含有p个特征的最小二乘回归，我们可以先拟合p个只有一个特征的模型，然后拟合所有可能的\\(\\left(_{2}^{p}\\right)=\\frac{p(p-1)}{2}\\)个含有两个特征的模型，依次类推搜索所有的模型。算法如下： 用\\(M_{0}\\)代表没有特征的模型，该模型用样本均值预测每个观测 对\\(k=1,2,...,p\\): 拟合所有\\(\\left(_{k}^{p}\\right)\\)个含有k个特征的模型 选择其中最优的模型，记为\\(M_{k}\\)。这里，最优指\\(MSE\\)最小或者\\(R^{2}\\)最大 选择\\(M_{0},M_{1},...,M_{p}\\)中最优的模型，选择标准可以是交互校验预测误差，\\(C_{p}\\)，AIC，BIC或者调整后的\\(R^{2}\\) 我们下面对服装消费者数据中的收入（income）建立一般线性模型，将消费记录变量和问卷调查回复变量作为因变量。通过leap包中的regsubsets()函数进行穷举变量选择。该函数可以给出对不同变量个数对应的最优模型，这里默认最优的标准是误差平方和。函数的语法和lm()函数相同。 # 需要先安装包 library(leaps) # 载入服装消费者数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) ytrain&lt;-sim.dat$income xtrain&lt;-dplyr::select(sim.dat,store_exp,online_exp,store_trans,online_trans, Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q8,Q9,Q10) # 先用所有变量拟合全模型 regfit.full=regsubsets(ytrain~.,xtrain) 用summary()函数可以得到不同变量个数对应的模型选择结果： summary(regfit.full) ## Subset selection object ## Call: regsubsets.formula(ytrain ~ ., xtrain) ## 14 Variables (and intercept) ## Forced in Forced out ## store_exp FALSE FALSE ## online_exp FALSE FALSE ## store_trans FALSE FALSE ## online_trans FALSE FALSE ## Q1 FALSE FALSE ## Q2 FALSE FALSE ## Q3 FALSE FALSE ## Q4 FALSE FALSE ## Q5 FALSE FALSE ## Q6 FALSE FALSE ## Q7 FALSE FALSE ## Q8 FALSE FALSE ## Q9 FALSE FALSE ## Q10 FALSE FALSE ## 1 subsets of each size up to 8 ## Selection Algorithm: exhaustive ## store_exp online_exp store_trans online_trans Q1 Q2 Q3 Q4 Q5 ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; ## 3 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 4 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 5 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 6 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 7 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; ## 8 ( 1 ) &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; ## Q6 Q7 Q8 Q9 Q10 ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 3 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 4 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 5 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 6 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 7 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 8 ( 1 ) &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; 结果中星号表示对应特征被选中。例如，第3行对应有3个“*”号，代表相应被选中的3个特征，该特征组合在所有可能的3特征模型中表现最好。默认设置下，函数只会返回1到8个特征对应的最优模型。但你可以通过设置nvmax选项来改变特征个数。下面我们将特征个数改成10： regfit.full=regsubsets(ytrain~.,xtrain,nvmax=10) reg.summary=summary(regfit.full) summary()函数也会返回\\(R^{2}\\)、RSS、调整\\(R^{2}\\)、\\(C_{p}\\)以及BIC这些模型评估统计量。同门可以通过这些统计量来得到最好的模型。 names(reg.summary) ## [1] &quot;which&quot; &quot;rsq&quot; &quot;rss&quot; &quot;adjr2&quot; &quot;cp&quot; &quot;bic&quot; &quot;outmat&quot; &quot;obj&quot; 例如，我们可以看到当模型从1个特征到2个特征，\\(R^{2}\\)统计量从60%上升到73%，之后增加特征变化不是太大。 reg.summary$adjr2 ## [1] 0.5992310 0.7313060 0.7417694 0.7486184 0.7505515 0.7515352 0.7518327 ## [8] 0.7519945 0.7521044 0.7522297 对所有模型绘制RSS、调整\\(R^{2}\\)、\\(C_{p}\\)以及BIC统计量图能够帮助选择最优模型。 par(mfrow=c(2,2)) plot(reg.summary$adjr2,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;调整R2&quot;,type=&quot;l&quot;) # 用which.max()函数找到调整R2最大的点 idx&lt;-which.max(reg.summary$adjr2) # 用points()函数将调整R2最大的点在图上标出 points(idx,reg.summary$adjr2[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$cp,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;Cp&quot;,type=&quot;l&quot;) # 类似的找到Cp最小的点 idx&lt;-which.min(reg.summary$cp) # 将Cp最小的点在图上标出 points(idx,reg.summary$cp[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$bic,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;BIC&quot;,type=&quot;l&quot;) # 找到BIC最小的点 idx&lt;-which.min(reg.summary$bic) # 将Cp最小的点在图上标出 points(idx,reg.summary$bic[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$rss,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;RSS&quot;,type=&quot;l&quot;) # 找到RSS最小的点 idx&lt;-which.min(reg.summary$rss) # 将Cp最小的点在图上标出 points(idx,reg.summary$rss[idx],col=&quot;red&quot;,cex=2,pch=20) Figure 9.1: 穷尽法选择结果。 该方法的问题在与要拟合和评估所有可能的特征子集，这想起来容易，但对于稍微大一点的p来说计算量大的难以实施。这种穷尽的方法也会导致统计问题，比如过度拟合和参数估计的高方差。考虑到这点，逐步回归是比穷尽所有特征子集更好的方法，此类方法的搜索领域小的多。逐步回归有向前选择，向后选择和双向选择。 9.3.2.2 向前选择 向前选择考虑的特征子集数目小多了。其从没有特征的模型开始逐一加入特征，直到所有的特征都在模型当中。当加入一个变量对模型提升有很大帮助时，就将该变量保留在模型中。具体算法如下： 用\\(M_{0}\\)代表没有特征的模型，该模型用样本均值预测每个观测 对\\(k=0,1,...,p-1\\): 依次在\\(M_{k}\\)中加入剩下的\\(p-k\\)个特征，每次加入1个特征，然后放回加入另外一个，逐一衡量每个特征对模型表现的提升 选择\\(p-k\\)个模型中最优的模型，记为\\(M_{k+1}\\)。这里，最优指\\(MSE\\)最小或者\\(R^{2}\\)最大 选择\\(M_{0},M_{1},...,M_{p}\\)中最优的模型，选择标准可以是交互校验预测误差，\\(C_{p}\\)，AIC，BIC或者调整后的\\(R^{2}\\) 和穷举法不同，向前选择先拟合一个初始模型\\(M_{0}\\)，然后对第\\(k\\)次迭代，拟合\\(p-k\\)个模型，这里\\(k=0,1,...,p-1\\)，这样一共拟合的模型数目是：\\(1+\\Sigma_{k=0}^{p-1}(p-k)=1+\\frac{p(p-1)}{2}\\)个。和穷举法的\\(2^{p}\\)个模型相比，差太多的。当\\(p=20\\)时，穷举法要拟合1048576个模型，而向前选择只需要拟合211个模型。上面算法的第2步得到了不同大小的特征集合对应的最优模型，然后在第3步中从\\(p+1\\)个特征个数不同的模型中选出最优的模型。这里要注意一点，就是RSS随着特征个数的增加而增加，\\(R^{2}\\)随着特征个数的增加而单调下降。因此在第2步中，我们在特征数目相同的模型中进行选择时可以直接使用训练集的拟合优度统计量。但在第3步中，我们要在特征个数不同的模型中选择，这时就需要使用交互校验。关于交互校验，大家可以参考之前的基础建模技术那一章。 我们可以继续使用regsubsets()这个函数进行向前选择，只需要设置method=&quot;forward&quot;。沿用之前小节的例子： # 需要先安装包 library(leaps) # 载入服装消费者数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) ytrain&lt;-sim.dat$income xtrain&lt;-dplyr::select(sim.dat,store_exp,online_exp,store_trans,online_trans, Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q8,Q9,Q10) # 先用所有变量拟合全模型 regfit.fwd=regsubsets(ytrain~.,xtrain,nvmax=10,method=&quot;forward&quot;) # 可以用summary()函数得到模型选择 reg.summary=summary(regfit.fwd) 类似的，我们可以对向前选择结果进行可视化，得到最优的变量个数。这里的个数选择和穷尽法相同。从图中可以看出，当变量个数超过4时，模型表现的变化很小。 par(mfrow=c(2,2)) plot(reg.summary$adjr2,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;调整R2&quot;,type=&quot;l&quot;) # 用which.max()函数找到调整R2最大的点 idx&lt;-which.max(reg.summary$adjr2) # 用points()函数将调整R2最大的点在图上标出 points(idx,reg.summary$adjr2[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$cp,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;Cp&quot;,type=&quot;l&quot;) # 类似的找到Cp最小的点 idx&lt;-which.min(reg.summary$cp) # 将Cp最小的点在图上标出 points(idx,reg.summary$cp[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$bic,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;BIC&quot;,type=&quot;l&quot;) # 找到BIC最小的点 idx&lt;-which.min(reg.summary$bic) # 将Cp最小的点在图上标出 points(idx,reg.summary$bic[idx],col=&quot;red&quot;,cex=2,pch=20) plot(reg.summary$rss,xlab=&quot;变量个数&quot;,family =&quot;Songti SC&quot;,ylab=&quot;RSS&quot;,type=&quot;l&quot;) # 找到RSS最小的点 idx&lt;-which.min(reg.summary$rss) # 将Cp最小的点在图上标出 points(idx,reg.summary$rss[idx],col=&quot;red&quot;,cex=2,pch=20) Figure 9.2: 向前选择结果。 9.3.2.3 向后选择 和向前选择类似，向后选择考虑的特征子集数目比穷尽法小多了。和向前选择不同的是，向后选择从含有所有p个特征的全模型开始，然后迭代逐一删除最无效的特征。具体算法如下： 用\\(M_{p}\\)代表含有所有\\(p\\)个特征的全模型 对\\(k=p,p-1,...,1\\): 依次在\\(M_{k}\\)中移除某个特征，评估得到的\\(k\\)个含有\\(k-1\\)个特征的模型 在\\(k\\)个模型中选择最优的模型，记为\\(M_{k-1}\\)。这里，最优指\\(MSE\\)最小或者\\(R^{2}\\)最大 选择\\(M_{0},M_{1},...,M_{p}\\)中最优的模型，选择标准可以是交互校验预测误差，\\(C_{p}\\)，AIC，BIC或者调整后的\\(R^{2}\\) 向后选择评估的模型个数和向前选择一样，也是\\(1+\\frac{p(p+1)}{2}\\)个，但它也无法保证选出的模型是全局最优的。这些不同的选择算法本质上都是搜索算法，只是搜索的路径不同。由于向后选择从全模型开始，因此要求观测的个数大于变量的个数（即\\(n&gt;p\\)），这点和向前选择不同。 我们可以regsubsets()这个函数进行向后选择，只需要设置method=&quot;backward&quot;。也可以类似对其可视化。这里就不重复展示代码了。 regfit.bwd=regsubsets(ytrain~.,xtrain,nvmax=10,method=&quot;backward&quot;) # 可以用summary()函数得到模型选择 reg.summary=summary(regfit.bwd) 9.3.2.4 双向选择 总体说来，穷举法，向前和向后回归给出的特征选择结果类似。另外一个方法是向前和向后选择的结合，也就是双向选择。和向前选择类似，模型从0个特征开始向里加特征，但不同的是，没次加入特征之后算法会重新评估模型，看是否有些特征可以移除。R中的MASS包的函数stepAIC()可以根据AIC进行双向选择。示例代码如下，这里不展示结果： library(MASS) fit=lm(ytrain~.,data=xtrain) stepAIC(fit) 此外，基础包中的step()函数也可以用来进行向前、向后和双向选择，大家可以键入?step()查看相应的帮助文档。 这些方法没有哪个一定是最好的，在建模过程中，如果特征过多导致之后的模型无法拟合，那么建议大家用多种方法比较结果，删除那些总显示不重要的变量。特征选择和模型选择一样，最好是多管齐下，比较不同方法的结果。根据个人经验，最好的特征选择方法是内嵌在模型中，之前的章节曾提到过，很多模型本身就能够测量预测变量的重要性，如MARS以及许多基于树的模型会监测每加入一个预测变量时模型表现的提升。有的模型本身有特征选择的功能，如lasso。这里我们先不介绍，等到相应的模型章节中再进行介绍。 References "],
["section-10.html", "第10章 线性回归极其衍生 10.1 普通线性回归 10.2 收缩方法 10.3 知识扩展：Lasso的变量选择功能 10.4 主成分和偏最小二乘回归", " 第10章 线性回归极其衍生 本章主要讲线性回归和它的衍生，顺序由易到难。先介绍普通线性回归（也称为最小二乘回归），这是非常简单的（可能是最简单的）有监督方法，相对于其它方法，普通线性回归可谓历史悠久，声名远扬。很多非理工科专业的小伙伴也都听过或者用过该模型。虽然和很多我们将要介绍的更新的模型比起来，普通线性回归太过低端，但它依旧是有用并且被广泛使用，此外，很多新模型其实是普通线性模型的衍生。因此理解普通线性模型对理解后面更加复杂的模型非常重要。之后我们会讲到两个收缩方法：岭回归和Lasso回归。和普通最小二乘估计相比，收缩方法可以将参数估计向0“收缩”，当观测量少时（相对于变量个数而言），这种方法有助于减少估计方差，稳定参数估计。接下来我们会介绍分层线性回归，和贝叶斯框架下的分层线性回归。R有强大的拟合线性模型的功能。我们先回顾一些基本知识，展示如何用R展示拟合相应模型，但是本章不会介绍所有实践中需要知道的知识。我们鼓励想进一步了解模型的读者参考我们在介绍该部分时列出的参考资料。本章中我们还是使用服装消费者数据解释线性模型。我们需要回答类似这样的问题：“那些变量是总消费量（线上和实体店消费额之和）的驱动因子？”这个问题的答案可以帮助公司知道需要将钱投到产品的哪个方面（如服装的设计，服装质量等）。 这里特别要注意的一点是，驱动因子不意味着原因。线性模型只假设变量之间存在关联性。如果某汽车客户问卷调查结果显示满意度和价格之间正相关，难道商家为了提高消费者满意度而刻意提高汽车价格？貌似不符合常识。更可能的情况是因为价格更高的汽车质量也更好，客户真正满意的是汽车的质量。因果关系在分析实践中是个很大的坑，在解释结果的时候一定要小心再小心，一定要将问题放在相应的语境中。 10.1 普通线性回归 虽然最小二乘线性回归看起来太过简单粗暴，但现在很多更复杂的模型其基本形式也是线性的。比如逻辑回归，就是对因变量的均值进行逻辑变换后再拟合线性模型。通常我们都将神经网络模型归于非线性模型，但神经网络中的每个潜变量都是某些预测变量的线性组合。日光之下，并无新事。在大量新技术不断涌入更新换代的今天，人的思维更加容易见树不见林。很多事物本质上是有相似性的，找到光怪陆离的表象下的实质是一种重要的能力。在学习了很多不同的方法之后应该退后一步，看看这些方法的演变联系，对背后的知识进行提取抽象，触及本质，时不时停下来问自己：这些模型背后的根本思想是什么？ 在R实现这些模型也类似，不同的模型在R中的表达方法都是模仿线性模型的拟合语句。因此，只要理解了如何使用R拟合，解释和诊断线性模型，你能够举一反三的应用其它更加复杂的模型。本节主要介绍用R中lm()拟合最小二乘线性模型，以及该函数中的不同选项。然后我们将会讲到线性模型的诊断方法，它们用于检测模型的假设是否成立，或者我们拟合的结果是否充分。 10.1.1 最小二乘线性模型 在线性模型中， \\[f(\\mathbf{X})=\\mathbf{X}\\mathbf{\\beta}=\\beta_{0}+\\sum_{j=1}^{p}\\mathbf{x_{.j}}\\beta_{j}\\] 其中\\(\\mathbf{\\beta}\\)是长度为\\(p+1\\)的参数向量。这里的数学公式表达和之前6.1中介绍的一致。最小二乘估计就是选择\\(\\mathbf{\\beta^{T}}=(\\beta_{0},\\beta_{1},...,\\beta_{p})\\)最小化下面残差平方和： \\[RSS(\\beta)=\\sum_{i=1}^{N}(y_{i}-f(\\mathbf{x_{i.}}))^{2}=\\sum_{i=1}^{N}(y_{i}-\\beta_{0}-\\sum_{j=1}^{p}x_{ij}\\beta_{j})^{2}\\] 我们还是从载入数据开始。 dat&lt;-read.csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;) 在我们开始之前，还需要对数据进行一些清理，删除错误的样本观测，消费金额不能为负数。 dat&lt;-subset(dat,store_exp&gt;0 &amp; online_exp&gt;0) 我们将10个问卷调查变量当作自变量。 modeldat&lt;-dat[,grep(&quot;Q&quot;,names(dat))] 将实体店消费量和在线消费之和当作应变量。 # 得到总消费量=实体店消费+在线消费 modeldat$total_exp&lt;-dat$store_exp+dat$online_exp 我们先检查一下数据，看是不是有缺失值或者离群点： # 这里没有展示输出结果 summary(modeldat) par(mfrow=c(1,2)) hist(modeldat$total_exp,main=&quot;&quot;,xlab=&quot;total_exp&quot;) boxplot(modeldat$total_exp) 数据集modeldat中没有缺失值，但是明显有离群点，而且应变量total_exp分布明显偏离正态。我们删除离群点，然后对应变量进行对数变换。 我们用之前数据预处理章节介绍的Z分值的方法查找并删除离群点。这里不重复解释，不明白的读者可以返回复习相应的章节。 y&lt;-modeldat$total_exp # 求Z分值 zs&lt;-(y-mean(y))/mad(y) # 找到Z分值大于3.5的离群点，删除这些观测 modeldat&lt;-modeldat[-which(zs&gt;3.5),] 这里我们先不对应变量进行对数变换，之后在回归函数的公式里对应变量进行变换。接下来检查变量的共线性： library(corrplot) correlation&lt;-cor(modeldat[,grep(&quot;Q&quot;,names(modeldat))]) corrplot.mixed(correlation,order=&quot;hclust&quot;,tl.pos=&quot;lt&quot;,upper=&quot;ellipse&quot;) Figure 10.1: 自变量相关矩阵图 由图10.1 可以看到，变量之间有很强的相关性。我们用之前在预处理章节中提到的删除高度相关变量的算法，设置阈值为0.75： library(caret) highcor&lt;-findCorrelation(correlation,cutoff=.75) modeldat&lt;-modeldat[,-highcor] 现在我们可以拟合线性模型。标准的模型公式表达是在“~”号的左边指定因变量，右边指定自变量。“.”表示数据集modeldat中除了因变量之外的所有变量都被当作自变量。这里我们没有考虑交互效应，如果要添加Q1和Q2的交互效应，只要在“~”右边加上“Q1*Q2”即可。注意下面的代码中我们对原始变量进行了对数变换（log(total_exp)）。 lmfit&lt;-lm(log(total_exp)~.,data=modeldat) summary(lmfit) ## ## Call: ## lm(formula = log(total_exp) ~ ., data = modeldat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.17494 -0.13719 0.01284 0.14163 0.56227 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.098314 0.054286 149.177 &lt; 2e-16 *** ## Q1 -0.145340 0.008823 -16.474 &lt; 2e-16 *** ## Q2 0.102275 0.019492 5.247 1.98e-07 *** ## Q3 0.254450 0.018348 13.868 &lt; 2e-16 *** ## Q6 -0.227684 0.011520 -19.764 &lt; 2e-16 *** ## Q8 -0.090706 0.016497 -5.498 5.15e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2262 on 805 degrees of freedom ## Multiple R-squared: 0.8542, Adjusted R-squared: 0.8533 ## F-statistic: 943.4 on 5 and 805 DF, p-value: &lt; 2.2e-16 从模型结果总结中我们可以看到各个自变量的参数估计（Estimate列）、标准差（Std. Error），t统计量（t value）和p值（Pr(&gt;|t|)）。在输出的底部包含了残差标准误，即RMSE（Residual standard error），\\(R^2\\)（Multiple R-squared）和调整后的\\(R^2\\)（Adjusted R-squared），模型的F统计量（F-statistic）以及相应F检验的显著性p值（p-value）。 关于p值的讨论 谈到p值，不能不提美国统计协会在2016年2月发表的关于P值的声明 “Position on p-values: context, process, and purpose” [51] ，统计之都有一篇对该声明的中文总结1。关于p值弊端的讨论在统计学领域已经不是新鲜事。其中一些抨击言辞比较激烈的是 Siegfried： 这是科学中最肮脏的秘密：使用统计假设检验的“科学方法”建立在一个脆弱的基础之上。——ScienceNews（Siegfried, 2010） 假设检验中用到的统计方法……比Facebook隐私条款的缺陷还多。——ScienceNews（Siegfried, 2014） 尽管争议已经持续了很久，但这是第一次统计协会对该话题给出郑重的声明，其主要目的不是解决该问题，而是对这些批评和讨论作一个回应，讨论发表一些关于p值的普遍共识，唤起大家对科学研究可重复性的重要性。声明中概括了关于p值的6个准则： P值可以表达的是数据与一个给定模型不匹配的程度。 P值并不能衡量某条假设为真的概率，或是数据仅由随机因素产生的概率。 科学结论、商业决策或政策制定不应该仅依赖于P值是否超过一个给定的阈值。 合理的推断过程需要完整的报告和透明度。 P值或统计显著性并不衡量影响的大小或结果的重要性。 P值就其本身而言，并不是一个非常好的对模型或假设所含证据大小的衡量。 在文章末尾列举了一些其他替代手段，其中之一就是报告置信区间而非p值。 回到当前的例子，这里我们不去讨论参数估计的对应p值，而是使用各个参数估计的置信区间。在R中可以用下面代码得到置信区间： confint(lmfit,level=0.9) ## 5 % 95 % ## (Intercept) 8.00891811 8.18771037 ## Q1 -0.15986889 -0.13081186 ## Q2 0.07017625 0.13437445 ## Q3 0.22423576 0.28466333 ## Q6 -0.24665434 -0.20871330 ## Q8 -0.11787330 -0.06353905 上面的输出就是参数的90%置信区间。其中level=0.9将置信度设置为0.9。 拟合线性模型是非常容易的，以致于很多分析师拟合了模型之后不考虑模型是否合理，直接撰写结果报告。其实我们可以很容易用R从不同方面检查模型的拟合情况和假设条件。下面的几个小节中我们将介绍一些常用的线性模型诊断方法。 10.1.2 回归诊断 拟合线性模型是非常容易的，以致于很多分析师拟合了模型之后不考虑模型是否合理，直接撰写结果报告。其实我们可以很容易用R从不同方面检查模型的拟合情况和假设条件。下面的几个小节中我们将介绍一些常用的线性模型诊断方法。我们希望需要最小二乘估计（OLS）同时也是最优线性无偏估计（BLUE）。换句话说，我们希望得到的估计的期望即为真实值（无偏），且最小化残差方差（最优）。根据高斯-马尔可夫定理（Gauss-Markov theorem），OLS在下面条件满足时是BLUE: 自变量（\\(\\mathbf{x_{.j}}\\)）和随机误差（\\(\\mathbf{\\epsilon}\\)）不相关，即：\\(cov(\\mathbf{x_{.j},\\epsilon})=0\\) 对 \\(\\forall j=j\\in1...p\\) 随机误差均值为0：\\(E(\\mathbf{\\epsilon|X})=0\\) 随机误差方差一致且相互独立：\\(Var(\\mathbf{\\epsilon})=\\sigma^{2}I\\)，其中\\(\\sigma\\)是正实数，\\(I\\)是\\(n\\times n\\)的单位矩阵 下面介绍4种图形诊断。 残差图（Residuals vs Fitted） 残差图分析法是一种直观、方便的分析方法。它以残差\\(\\epsilon_{i}\\)为纵坐标，以样本拟合值为横坐标画散点图（也可以绘制横坐标为任意自变量的残差散点图）。正常情况下残差分布应该是随机的。我们要检查残差图的如下几个方面： 残差是否在0附近分布 残差分布是否随机，如果呈现出某种特定分布模式（如：随横坐标的增大而增大或减小）的话，说明当前模型关系的假设不充分 残差是否存在异方差性，比如随着拟合值增大残差分布方差增加，这就说明残差分布有异方差性。如前所述，当存在异方差时，参数估计值虽然是无偏的，但不是最小方差线性无偏估计。由于参数的显著性检验是基于残差分布假设的，所以在该假设不成立的情况下该检验也将失效。如果你用该回归方程来预测新样本，效果很可能极不理想。 Q-Q图（Norm Q-Q） Q-Q图是一种正态分布检测。对于标准状态分布，Q-Q图上的点分布在Y=X直线上，点偏离直线越远说明样本偏离正态分布越远。 标准化残差方根散点图（Scale-Location） 和残差图类似，横坐标依旧是样本拟合值，纵坐标变为了标准化残差的绝对值开方。 Cook距离图（Cook’s distance） 该图用于判断观测值是否有异常点。一般认为 当D&lt;0.5时认为不是异常值点；当D&gt;0.5时认为是异常值点。 对回归结果应用plot()函数可以得到不同的图形诊断。 par(mfrow=c(2,2)) plot(lmfit,which=1) plot(lmfit,which=2) plot(lmfit,which=3) plot(lmfit,which=4) Figure 10.2: 一般线性回归残差图 从回归的四个图形结果（图10.2）来看： 残差图：数据点都基本均匀地分布在直线y=0的两侧, 无明显趋势，满足线性假设。 标准Q-Q图：图上的点基本都在y=x直线附件，可认为残差近似服从正态分布； 标准化残差方根散点图：若满足不变方差假设，则在该图中水平线周围的点应随机分布，最高点为残差最大值点。该图显示基本符合方差齐性的要求。 Cook距离图：最大的Cook距离为0.05左右，可以认为没有异常值点。 10.1.3 离群点，高杠杆点和强影响点 关于一般线性回归，最好检查下是否有观测会强烈影响线性模型拟合结果。如果一个或者几个观测对模型结果有决定性的影响，那么用这些观测得到的模型是具有误导性的。这里我们介绍这三类观测点的检测：离群点，高杠杆点和强影响点。 离群点 刚才介绍的Cook距离图，以及之前讲到的Z分值都可以用来检测线性模型中的离群点。注意，Z分值仅仅是针对应变量观测而言，和使用的模型无关，即其并未考虑模型的拟合情况。下面我们用car包[52]中的outlierTest()函数对拟合模型对象检测是否存在离群点，和Z分值方法鉴别的离群点不同，这里的离群点指的是那些模型预测效果不佳的观测点，通常有很大的、或正或负的残差，正残差说明模型低估了响应值，负残差说明高佑了响应值。这里使用的是Bonferroni离群点检验，该检验也可作用于广义线性模型。对于一般线性模型使用的是t检验，对于广义线性模型使用的是正态检验。关于该检验相关知识见 [53–56]。 library(car) outlierTest(lmfit) #Bonferroni离群点检验 ## rstudent unadjusted p-value Bonferonni p ## 960 -5.295504 1.533e-07 0.00012432 outlierTest()函数是根据单个最大（或正或负）残差值的显著性来判断是否有离群点，若不显著，则说明数据集中没有离群点，若显著，则建议删除该离群点，然后再检验是否还有其他离群点存在。这里我们删除第960个被认为是离群点的观测。 outlierTest(lmfit) ## rstudent unadjusted p-value Bonferonni p ## 960 -5.295504 1.533e-07 0.00012432 # 这里数据modeldat的行名是原数据集的行号，所以是字符类型 # 找到相应的观测 idex&lt;-which(row.names(modeldat)==&quot;960&quot;) # 删除离群观测 modeldat=modeldat[-idex,] 接下来我们再拟合一次模型然后检测看看是否还有离群点： lmfit&lt;-lm(log(total_exp)~.,data=modeldat) outlierTest(lmfit) ## ## No Studentized residuals with Bonferonni p &lt; 0.05 ## Largest |rstudent|: ## rstudent unadjusted p-value Bonferonni p ## 155 -3.818112 0.00014483 0.11731 可以看到现在没有检测出显著离群点。 高杠杆值点是与其他预测变量有关的离群点，即它们是由许多异常的预测变量组合起来的，与响应变量值没有关系。 高杠杆值的观测点可通过帽子矩阵的值（hat statistic）判断。对于一个给定的数据集，帽子均值为\\(p/n\\)，其中p是模型估计的参数数目（包含截距项），n是样本量。一般来说，若观测点的帽子值大于帽子均值的2或3倍，则可认定为高杠杆值点。 10.2 收缩方法 之前特征工程的章节中讲到各种变量选择方法，其中我们对内嵌法没有详细展开。内嵌法是将特征选择的过程内嵌如建模的过程，它是学习器自身自主选择特征，这里我们要讲的收缩方法就属于内嵌法。我们可以通过对模型参数进行限制或者规范化来达到变量选择的效果，这些方法能将一些参数估计朝着0收缩。使用收缩方法提高模型拟合表现的原理可能不那么显而易见，但是收缩方法的效果是非常好的，这也是我最常使用的方法，尤其是项目要求使用可以解释的模型时。收缩方法不仅仅限于线性回归，之后我们在讲判别分析时会介绍将lasso用于逻辑回归。最常用的收缩方法是岭回归（ridge regression）、lasso以及弹性网络（elastic net）。弹性网络结合了岭回归和lasso中的罚函数，可以说是它们的一般化版本。 对于一般线性回归，在标准模型假设下最小二乘估计号称是方差最小无偏估计，这里的方差最小是在所有线性无偏估计当中最小。之间在介绍误差来源时讲过MSE是方差和偏差的一个组合。当预测变量存在高度相关时，估计量的方差可能会非常大，偏差的微小增加可能使得方差大幅度下降，因此对于回归模型中的多重共线性问题，有偏模型也可能得到具有竞争力的MSE取值。构建有偏回归模型的一种方法是在误差平方和的基础上加上一个惩罚项。 10.2.1 岭回归 回顾最小二乘模型，它的目的是寻找参数的估计，以使得误差平方（RSS）和达到最小： \\[RSS=\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij})^{2}\\] 岭回归[57]和最小二乘回归有类似之处，不同在于优化的方程略有变化。岭回归寻找的是优化下面方程的\\(\\hat{\\beta}^{R}\\)： \\[\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij})^{2}+\\lambda\\Sigma_{j=1}^{p}\\beta_{j}^{2}=RSS+\\lambda\\Sigma_{j=1}^{p}\\beta_{j}^{2}\\] 其中\\(\\lambda &gt;0\\)是需要额外估计的调优参数。上式是在两个不同的准则间权衡。和最小二乘回归类似，岭回归考虑了最小化RSS，但其还有一个称为收缩惩罚的项\\(\\lambda\\Sigma_{j=1}^{p}\\beta_{j}^{2}\\)，该项在参数\\(\\beta_{1},...,\\beta_{p}\\)趋近于0的时候变小，因此有向0收缩参数估计的用处。调优参数\\(\\lambda\\)用来调整这两个部分对最后参数估计的影响。当\\(\\lambda=0\\)时，惩罚项对结果没有影响，这时岭回归等同于最小二乘回归。当\\(\\lambda\\rightarrow\\infty\\)时，惩罚项的影响增大，岭回归系数估计趋近于0。这里惩罚只针对\\(\\beta_{1},...,\\beta_{p}\\)，对截距项\\(\\beta_{0}\\)并没有惩罚。每个\\(\\lambda\\)值都对应一组参数估计，通过尝试不同的调优参数值，找到最优的模型。通常使用交互校验来选择调优参数，关于交互校验，我在之前基础建模技术那一章节已经讲过了。 有许多R函数可以进行岭回归。MASS包中的lm.ridge()函数，以及elasticnet包中的enet()函数，如果你知道调优参数的值，可以直接使用这两个函数拟合岭回归模型。如果你要对参数进行调优，最方便的函数是caret包中的train()函数。还是以服装消费者数据为例展示这些函数的使用，自变量为10个问卷调查问题以及年龄、性别、收入和房产情况，应变量为总体花销（在线花销和实体店花销的总和）。 dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数 dat&lt;-subset(dat,store_exp&gt;0 &amp; online_exp&gt;0) # 将10个问卷调查变量当作自变量 trainx&lt;-dat[,grep(&quot;Q&quot;,names(dat))] # 将实体店消费量和在线消费之和当作应变量 # 得到总消费量=实体店消费+在线消费 trainy&lt;-dat$store_exp+dat$online_exp 先用train()函数对参数进行调优。首先设置交互校验和参数调优范围，这里我们使用10层交互校验。岭回归在回归系数的平方和前加调优参数，因此最好对自变量进行标准化，这条准则适用于所有罚函数包含回归系数的方法。这里因为10个问题分值的范围是一致的，是否标准化并不太影响分析结果，但保险起见，建议大家在用此类方法前都先进行标准化： ctrl &lt;- trainControl(method = &quot;cv&quot;, number = 10) ridgeGrid &lt;- data.frame(.lambda = seq(0, .1, length = 20)) set.seed(100) ridgeRegTune &lt;- train(trainx, trainy, method = &quot;ridge&quot;, ## 用不同的罚函数值来拟合模型 tuneGrid = ridgeGrid, trControl = ctrl, ## 中心化和标度化变量 preProc = c(&quot;center&quot;, &quot;scale&quot;)) ## Loading required package: elasticnet ## Loading required package: lars ## Loaded lars 1.2 ## ## Attaching package: &#39;lars&#39; ## The following object is masked from &#39;package:psych&#39;: ## ## error.bars ridgeRegTune ## Ridge Regression ## ## 999 samples ## 10 predictor ## ## Pre-processing: centered (10), scaled (10) ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 899, 899, 899, 899, 899, 899, ... ## Resampling results across tuning parameters: ## ## lambda RMSE Rsquared ## 0.000000000 1763.347 0.7896421 ## 0.005263158 1762.683 0.7898448 ## 0.010526316 1762.469 0.7899844 ## 0.015789474 1762.589 0.7900829 ## 0.021052632 1762.975 0.7901534 ## 0.026315789 1763.584 0.7902040 ## 0.031578947 1764.388 0.7902401 ## 0.036842105 1765.368 0.7902652 ## 0.042105263 1766.510 0.7902819 ## 0.047368421 1767.804 0.7902919 ## 0.052631579 1769.243 0.7902967 ## 0.057894737 1770.821 0.7902971 ## 0.063157895 1772.532 0.7902938 ## 0.068421053 1774.373 0.7902876 ## 0.073684211 1776.339 0.7902788 ## 0.078947368 1778.429 0.7902677 ## 0.084210526 1780.638 0.7902547 ## 0.089473684 1782.964 0.7902399 ## 0.094736842 1785.406 0.7902237 ## 0.100000000 1787.959 0.7902060 ## ## RMSE was used to select the optimal model using the smallest value. ## The final value used for the model was lambda = 0.01052632. 训练出的模型调优参数为0.01，对应RMSE和\\(R^{2}\\)分别为1762.469和80%。从交互校验的RMSE结果图中可以看到，随着调优参数增加，RMSE有一个略微减小然后增加的过程。 训练出调优参数之后，很多函数都可以用来拟合岭回归。这里展示如何使用elasticnet包中的enet()函数： ridgefit = enet(x = as.matrix(trainx), y = trainy, lambda = 0.01, # 这里设置将自变量标准化 normalize = TRUE) 这里注意ridgefit只指定了岭回归的罚函数，由于弹性网模型同时具有岭回归和lasso罚函数，我们需要进一步通过predict()函数得到相应的拟合系数和拟合结果。针对enet对象的predict()函数可以通过参数s和mode来指定在lasso罚参数下的拟合，这里我们需要“屏蔽”lasso的罚函数参数，这可以通过设置s = 1 和 mode = &quot;fraction&quot;得到。我们在之后讲lasso的时候会进一步讲解： ridgePred &lt;- predict(ridgefit, newx = as.matrix(trainx), s = 1, mode = &quot;fraction&quot;, type = &quot;fit&quot;) 注意上面type = &quot;fit&quot;返回的结果是一个列表，其中fit项包含预测结果： names(ridgePred) ## [1] &quot;s&quot; &quot;fraction&quot; &quot;mode&quot; &quot;fit&quot; head(ridgePred$fit) ## 1 2 3 4 5 6 ## 1290.4697 224.1595 591.4406 1220.6384 853.3572 908.2040 如果要得到参数拟合结果，需要在predict()函数中设定type=&quot;coefficients&quot;： ridgeCoef&lt;-predict(ridgefit,newx = as.matrix(trainx), s=1, mode=&quot;fraction&quot;, type=&quot;coefficients&quot;) 返回的结果依旧是一个列表，其中coefficients项包含各个变量的参数估计： # 这里不显示结果 RidgeCoef=ridgeCoef$coefficients 岭回归和原始最小二乘回归相比优势在于偏差和方差之间的权衡。之前讲过，一般线性回归中的最小二乘估计在无偏估计中是最优的，但是通常估计方差会很大。这意味着训练集数据的微小变化可能导致参数估计较大的变化。而岭回归估计就是通过牺牲一点点“无偏性”，换取估计方差的减小。因此，岭回归适合在普通最小二乘回归参数估计方差很大的情况下使用。 10.2.2 Lasso 虽然岭回归可以将参数估计值向0进行收缩，但对于任何调优参数值，它都不能将系数取值变为严格的0。尽管某些参数估计值变得非常小以至于可以忽略，但事实上岭回归并没有进行变量选择。这可能对预测精确度来说不是问题，但却对模型解释提出了挑战，尤其在变量个数大的时候。一种流行的用来替代岭回归的模型是“最小绝对收缩与选择算子”模型，通常被称为lasso[58]。这个模型使用了与岭回归类似的惩罚项，lasso的回归参数估计\\(\\hat{\\beta}_{\\lambda}^{L}\\)最小化如下方程： \\[\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij})^{2}+\\lambda\\Sigma_{j=1}^{p}|\\beta_{j}|=RSS+\\lambda\\Sigma_{j=1}^{p}|\\beta_{j}|\\] lasso和岭回归很相似，唯一的不同在于罚函数。岭回归中的\\(\\beta_{j}^{2}\\)在lasso中变为\\(|\\beta_{j}|\\)。用统计术语讲就是岭回归是在结构风险最小化的正则化因子上使用模型参数向量的二阶范数形式，lasso使用的是一阶范数形式。lasso不仅将参数估计向0收缩，当调优参数足够大时，一些参数估计将直接缩减为零，这可以达到特征提取的作用。这样一来，lasso回归的结果更易于解释。和其它有调优参数的模型类似，lasso也需要通过交互校验进行参数调优。下面我们展示在R中如何进行调优和拟合。 先用train()函数对参数进行调优。首先设置交互校验和参数调优范围，这里我们使用10层交互校验。建议大家在用此类方法前都先进行标准化： ctrl &lt;- trainControl(method = &quot;cv&quot;, number = 10) lassoGrid &lt;- data.frame(fraction = seq(.8, 1, length = 20)) set.seed(100) lassoTune &lt;- train(trainx, trainy, method = &quot;lars&quot;, ## 用不同的罚函数值来拟合模型 tuneGrid = lassoGrid, trControl = ctrl, ## 中心化和标度化变量 preProc = c(&quot;center&quot;, &quot;scale&quot;)) lassoTune ## Least Angle Regression ## ## 999 samples ## 10 predictor ## ## Pre-processing: centered (10), scaled (10) ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 899, 899, 899, 899, 899, 899, ... ## Resampling results across tuning parameters: ## ## fraction RMSE Rsquared ## 0.8000000 1778.817 0.7872676 ## 0.8105263 1776.714 0.7875679 ## 0.8210526 1774.842 0.7878315 ## 0.8315789 1773.090 0.7880823 ## 0.8421053 1771.293 0.7883477 ## 0.8526316 1769.551 0.7886105 ## 0.8631579 1767.924 0.7888577 ## 0.8736842 1766.442 0.7890909 ## 0.8842105 1765.127 0.7893044 ## 0.8947368 1763.960 0.7894958 ## 0.9052632 1762.974 0.7896597 ## 0.9157895 1762.165 0.7897985 ## 0.9263158 1761.540 0.7899101 ## 0.9368421 1761.212 0.7899582 ## 0.9473684 1761.076 0.7899771 ## 0.9578947 1761.121 0.7899701 ## 0.9684211 1761.350 0.7899381 ## 0.9789474 1761.839 0.7898641 ## 0.9894737 1762.492 0.7897668 ## 1.0000000 1763.347 0.7896421 ## ## RMSE was used to select the optimal model using the smallest value. ## The final value used for the model was fraction = 0.9473684. 训练出的模型调优参数为0.95，对应RMSE和\\(R^{2}\\)分别为1761和79%，和之间岭回归几乎相同。从交互校验的RMSE结果图中可以看到，随着调优参数增加，RMSE有一个减小然后增加的过程。 plot(lassoTune) lasso模型可以用许多不同的函数进行拟合。lars包中的lars()函数，elasticnet包的enet()函数，glmnet包的glmnet()函数都可以拟合lasso，它们的语法非常相似。我们还是使用enet()函数，其要求自变量必须是一个矩阵对象，因此要将数据框trainx转换成矩阵。此外，预测变量在建模之前需要中心化和标准化，函数中的normalize参数可以自动完成这一过程lambda参数控制了岭回归的罚参数，因此将该值设为0即为拟合lasso模型。 lassoModel&lt;- enet(x = as.matrix(trainx), y = trainy, lambda = 0, normalize = TRUE) lasso模型在进行预测之前不需要进行指定： lassoFit &lt;- predict(lassoModel, newx = as.matrix(trainx),s = .95, mode = &quot;fraction&quot;,type = &quot;fit&quot;) 类似，这里type = &quot;fit&quot;返回的结果是一个列表，其中fit项包含预测结果： head(lassoFit$fit) ## 1 2 3 4 5 6 ## 1371.6160 308.6984 702.2026 1225.5508 832.0466 1028.9785 如果要得到参数拟合结果，需要在predict()函数中设定type=&quot;coefficients&quot;： lassoCoef&lt;-predict(lassoModel,newx = as.matrix(trainx),s=0.95, mode=&quot;fraction&quot;, type=&quot;coefficients&quot;) 返回的结果依旧是一个列表，其中coefficients项包含各个变量的参数估计： # 这里不显示结果 LassoCoef=lassoCoef$coefficients 这类规则化方法的研究现在非常活跃。很多学者将lasso模型嫁接到其它方法上，比如线性判别[59]，偏最小二乘回归[60]。但由于一阶范数不是连续可导的，lasso回归的计算过程更复杂。很多学者对相应的优化算法进行了研究，其中最重要的改进是Bradley Efron等[61]提出的最小角回归(Least Angle Regression［LARS］)算法，该算法很好地解决Lasso的计算问题，尤其在维度高的时候。 10.2.3 弹性网络 弹性网络是lasso的一般化版本[62]，该模型结合了两种罚函数，参数估计最小化如下方程： \\[\\Sigma_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}+\\lambda_{1}\\Sigma_{j=1}^{p}\\beta_{j}^{2}+\\lambda_{2}\\Sigma_{j=1}^{p}|\\beta_{j}|\\] lasso对应的估计方差较大，而岭回归又没有特征选择的功能，弹性网络的优点在于利用了岭回归的罚函数，同时又有lasso的特征选择功能。Zou和Hastie[62]指出该模型能够更有效的处理成组的高度相关变量。 还是先用train()函数对参数进行调优。首先设置交互校验和参数调优范围，这里我们使用10层交互校验，并且对变量标准化： enetGrid &lt;- expand.grid(.lambda = seq(0,0.2,length=20), .fraction = seq(.8, 1, length = 20)) set.seed(100) enetTune &lt;- train(trainx, trainy, method = &quot;enet&quot;, tuneGrid = enetGrid, trControl = ctrl, preProc = c(&quot;center&quot;, &quot;scale&quot;)) 训练出的模型对应的lasso调优参数为0.958，岭回归调优参数为0.01。相应RMSE和\\(R^{2}\\)分别为1760和79%，在这里这三种方法的效果并没有很大的不同。这里展示如何使用elasticnet包中的enet()函数： enetfit = enet(x = as.matrix(trainx), y = trainy, lambda = 0.01, # 这里设置将自变量标准化 normalize = TRUE) 和之前一样，enetfit只指定了岭回归的罚函数，由于弹性网模型同时具有岭回归和lasso罚函数，我们需要进一步通过predict()函数得到相应的拟合系数和拟合结果。针对enet对象的predict()函数可以通过参数s和mode来指定在lasso罚参数下的拟合，和之前不同的是，这里我们对应的lasso的罚函数参数设置为s = 0.958 和 mode = &quot;fraction&quot;： enetPred &lt;- predict(enetfit, newx = as.matrix(trainx), s = 0.958, mode = &quot;fraction&quot;, type = &quot;fit&quot;) 注意上面type = &quot;fit&quot;返回的结果是一个列表，其中fit项包含预测结果。如果要得到参数拟合结果，需要在predict()函数中设定type=&quot;coefficients&quot;： enetCoef&lt;-predict(ridgefit,newx = as.matrix(trainx), s=0.958, mode=&quot;fraction&quot;, type=&quot;coefficients&quot;) 返回的结果依旧是一个列表，其中coefficients项包含各个变量的参数估计。 10.3 知识扩展：Lasso的变量选择功能 可能有人会问从岭回归到lasso，只是罚函数从二阶范数变成一阶范数，为什么lasso就能够将参数估计收缩成0而岭回归不能呢？要回答这个问题，我们先看下lasso和岭回归分别对应的另一版本的等价优化方程。对于lasso而言，优化下面两个方程是等价的： \\[\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij})^{2}+\\lambda\\Sigma_{j=1}^{p}|\\beta_{j}|=RSS+\\lambda\\Sigma_{j=1}^{p}|\\beta_{j}|\\] \\[\\underset{\\beta}{min}\\left\\{ \\Sigma_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij}\\right)^{2}\\right\\} ,\\ \\Sigma_{j=1}^{p}|\\beta_{j}|\\leq s\\] 也就是说，对每个调优参数\\(\\lambda\\)的取值，都存在相应的\\(s\\)值，使得上面两个方程优化后得到的参数估计相同。类似的，对于岭回归，下面两个方程等价： \\[\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij})^{2}+\\lambda\\Sigma_{j=1}^{p}\\beta_{j}^{2}=RSS+\\lambda\\Sigma_{j=1}^{p}\\beta_{j}^{2}\\] \\[\\underset{\\beta}{min}\\left\\{ \\Sigma_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\Sigma_{j=1}^{p}\\beta_{j}x_{ij}\\right)^{2}\\right\\} ,\\ \\Sigma_{j=1}^{p}\\beta_{j}^{2}\\leq s\\] 当p＝2时，lasso的参数估计是所有满足\\(|\\beta_{1}|+|\\beta_{2}|\\leq s\\)的\\(\\beta_{1}\\)和\\(\\beta_{2}\\)取值中最小化\\(RSS\\)的。岭回归是估计所有满足\\(\\beta_{1}^{2}+\\beta_{2}^{2}\\leq s\\)的参数取值中最小化\\(RSS\\)的。当s很大时，相应的限制条件几乎是无效的，只要参数估计能够最小化\\(RSS\\)即使绝对值很大也没有问题。只要s所定义的区域包含最小二乘解，那么收缩方法得出的参数估计和一般最小二乘回归就相同。相反，如果s很小，那么可能的参数取值范围就很有限。 了解这样的等价表达之后，我们再看看岭回归和lasso的不同之处。 左边是lasso对应的误差等位线和正方形限制区域，右边是岭回归对应的等位线和圆形限制区域。 上面图中围绕在\\(\\hat{\\beta}\\)周围的椭圆表示有相同RSS的参数估计。随着椭圆的扩大，对应的RSS增加。lasso和岭回归的估计值就是在一定的限制区域下，椭圆不断扩张的过程中和限制区域的第一个接触点。大家想想看，如果有某个参数的估计是0的话，那么这个接触点该在哪里？一定在某条坐标轴上。由于岭回归的限制区域是圆形，所以真正的触点无法落在坐标轴上，可能无限接近，但就是到不了。这就是求之而不可得的数学诠释。所以岭回归无法将参数收缩成0，而lasso可以。 上面是2个参数的情况。如果参数个数是3的话，那么lasso的限制区域就是一个三位空间的多面体，而岭回归的限制区域就是个球。参数个数再增加的话，就得让科幻小说家来描述了。希望大家理解lasso可以进行变量选择，而岭回归不行的几何解释。 10.4 主成分和偏最小二乘回归 在实际应用中，自变量之间通常是彼此相关的，包含相似的信息。比如我们在建模技术那章用消费记录变量建立关于消费者收入的预测模型，其中实体店花销（store_exp），在线花销（online_exp），实体店交易次数（store_trans），在线交易次数（online_trans）这几个变量之间有不同程度的相关性，尤其是交易次数和对应花销相关性较高。如果自变量之间相关性较大， 那么多元线性回归的最小二乘估计将会很不稳定。有的时候，自变量的数目会高于观测，这时通常意义上的最小二乘将同样无法得到一组唯一的最小化SSE的回归系数。在这些情况下进行回归，通常的解决办法是对自变量进行预处理，包括数据预处理章节讲到的删除高度相关的自变量算法，移除高度相关的预测变量可以保证它们两两间的相关系数不超过一个给定的阈值。然而，这一过程并不能保证某些预测变量的线性组合与其他变量是不相关的。如果情况如此，那么最小二乘的解将依然是不稳定的。因此特别需要注意的是，移除两两之间高度相关的预测变量并不能保证一个稳定的解。你也可以参考特征工程那章讲到的特征提取方法，比如对预测变量进行主成分分析（PCA），让后用主成分进行回归。这种方法得到的主成分是彼此不相关的。但存在的弊端是得到的新自变量是原变量的线性组合，因此使得模型难以解释。 对自变量进行主成分分析，然后用得到得主成分进行回归的方法称为主成分回归（PCR）[63]。 这项技术在自变量内在强相关或者变量个数大于观测个数时可以使用。然而，尽管这样先降维然后回归的方法可以在理论上建立回归模型，但结果可能并不理想。因为PCA降维得到的新变量并不一定能很好地解释因变量，因为这个过程是无监督的，在降维的时候并没有考虑到因变量的信息，它只是简单地追踪自变量空间的方差。如果自变量自身的变异恰好与因变量相关，那么PCR或许能很好地识别出它们之间的关系。 然而，如果自变量自身方差大，但其变化并不影响因变量，那么PCR或许就无法识别出真实存在的关系。还有需要注意的一点是，虽然PCR是降维的方法，但它并不是变量选择的方法，因为它是所有的自变量的线性组合。 偏最小二乘回归（PLS）可以说是PCR的有监督版本。像PCR，PLS也是一种降维方法，而且也受变量方差的影响，因此通常需要在建模前对变量进行标准化。假设我们有随机变量组成的向量\\(\\mathbf{X}=[X_{1},X_{2},...,X_{p}]^{T}\\)，其对应的协方差矩阵为\\(\\Sigma\\)。PLS也需要通过对原变量进行线性组合找到彼此不相关的新变量 \\((Z_{1} , Z_{2} , \\ldots , Z_{m})\\)来代替原变量，且当\\(m=p\\)时，PLS的结果和普通最小二乘的结果相同。这和PCA类似，且生成的线性组合通常被称为主成分或者潜变量。但其不同在于，PCA的线性组合将最大程度地概括预测变量空间的变异性， 而PLS的线性组合则是最大化其与因变量的协方差。PLS在构建自变量线性组合的过程中考虑了自变量和应变量的关系，赋予和应变量相关性高的自变量更高的权重。PLS是在两个目标之间达到一个平衡：对预测变量空间进行降维， 以及保持预测变量与因变量之间的预测关系。 PLS流程图 PLS源自于Herman Wold的非线性迭代偏最小二乘（NIPALS）算法[64, 65]。 该算法被用来对那些参数非线性的模型进行线性化。之后NIPALS方法被应用在变量之间彼此相关的回归问题中，称其为“PLS”[66]。简单来说，NIPALS算法会迭代地寻找高度相关的预测变量与因变量之间潜在的关系。 对于单因变量问题而言，算法的每一次迭代都会评价自变量（\\(\\mathbf{X}\\)）与因变量（\\(\\mathbf{y}\\)）之间的关系，并将这种关系用一个权重向量（\\(\\mathbf{\\varphi}\\)）表达，该向量被称为一个方向。接下来，自变量将被正交地投影到这个方向上，从而生成这个方向上的分值（\\(\\mathbf{z}\\)），接着用这个分值生成载荷（\\(\\mathbf{\\theta}\\)），载荷代表了得分向量与原自变量之间的相关系数。每经过一次迭代，自变量和因变量将被“缩减”，意思是它们将分别减去当前对自变量和因变量结构的估计值。缩减后的自变量和因变量信息将被用来生成下一组权重、得分和载荷。PLS的具体算法如下（这里我们默认将所有的\\(\\mathbf{x}\\)标准化为均值0方差1的向量）： 设置初始值\\(\\mathbf{\\hat{y}^{0}}=\\bar{y}\\mathbf{1}\\)，\\(\\mathbf{x_j^{0}}=\\mathbf{x_j},\\ j=1,\\dots,p\\)； 对\\(m=1,2,...,p\\): \\(\\mathbf{z_{m}}=\\Sigma_{j=1}^p \\hat{\\varphi}_{mj}\\mathbf{x_j^{m-1}}\\)，其中\\(\\hat{\\varphi}_{mj}=&lt;\\mathbf{x_j^{m-1},y}&gt;\\)； \\(\\mathbf{\\hat{\\theta}_m}=\\frac{&lt;\\mathbf{z_{m},y}&gt;}{&lt;\\mathbf{z_{m},z_{m}}&gt;}\\)； \\(\\mathbf{\\hat{y}^m}=\\mathbf{\\hat{y}^{m-1}}+\\hat{\\theta}_{m}\\mathbf{z_m}\\)； 每个\\(\\mathbf{x_j^{m-1}}\\)对\\(\\mathbf{z_{m}}\\)的方向正交化：\\(\\mathbf{x_{j}^{m}}=\\mathbb{x_j^{m-1}}-\\frac{&lt;\\mathbf{z_m,x_j^{m-1}}&gt;\\mathbf{z_m}}{&lt;\\mathbf{z_m,z_m}&gt;},\\ j=1,2,\\dots, p\\)； 输出一系列的\\(\\mathbf{\\hat{y}^{m}}, m=1,\\dots, p\\)。由于所有的\\(\\mathbf{z_m}\\)都是\\(\\mathbf{x_j}\\)的线性组合，所以\\(\\mathbf{\\hat{y}^{m}}=\\mathbf{X}\\hat{\\beta}^{pls}(m)\\)也是\\(\\mathbf{x_j}\\)的线性组合。 下面我们以服装消费者数据中的10个问卷调查回复为自变量（Q1-Q10），收入（income）为应变量展示如何用R中的caret包训练PCR和PLS模型。 先载入相应的包和数据，并且对数据进行适当预处理： library(lattice) library(caret) library(dplyr) library(elasticnet) library(lars) # 载入数据 sim.dat&lt;-read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) ymad&lt;-mad(na.omit(sim.dat$income)) # 计算Z分值 zs&lt;-(sim.dat$income-mean(na.omit(sim.dat$income)))/ymad # which(na.omit(zs&gt;3.5)) 找到利群点 # which(is.na(zs)) 找到缺失值 idex&lt;-c(which(na.omit(zs&gt;3.5)),which(is.na(zs))) # 删除含有离群点和缺失值的行 sim.dat&lt;-sim.dat[-idex,] 选取10个问卷调查变量作为自变量矩阵xtrain，收入作为应变量存在ytrain中： xtrain=dplyr::select(sim.dat, Q1:Q10) ytrain=sim.dat$income 设置随机种子，以及交互校验的方式为10层交互校验： set.seed(100) ctrl &lt;- trainControl(method = &quot;cv&quot;, number=10) 先训练PLS模型，这里的调优参数为使用潜变量的个数，因为这里最多只有10个变量，设置调优参数值为1-10： plsTune &lt;- train(xtrain, ytrain, method = &quot;pls&quot;, # 设置调优参数值 tuneGrid = expand.grid(.ncomp = 1:10), trControl = ctrl) plsTune ## Partial Least Squares ## ## 772 samples ## 10 predictor ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 695, 694, 694, 694, 694, 695, ... ## Resampling results across tuning parameters: ## ## ncomp RMSE Rsquared ## 1 27761.47 0.6487324 ## 2 24493.98 0.7280445 ## 3 23222.55 0.7561373 ## 4 23068.86 0.7595387 ## 5 23034.38 0.7604738 ## 6 23035.39 0.7604228 ## 7 23034.19 0.7604444 ## 8 23034.85 0.7604287 ## 9 23034.69 0.7604318 ## 10 23034.70 0.7604316 ## ## RMSE was used to select the optimal model using the smallest value. ## The final value used for the model was ncomp = 7. 可以看到，调优的结果是选取7个主成分。但如果大家注意输出模型中成分数目对应的RMSE的值可以发现，其实在成分数目5之后RMSE变化就不太大了。 从PLS调优过程中还可以得到变量的重要性排序，我们可以通过下面代码得到各个变量的重要性并且对其可视化： plsImp &lt;- varImp(plsTune, scale = FALSE) plot(plsImp, top = 10, scales = list(y = list(cex = .95))) 可以看到，Q1、Q2、Q3和Q6的重要性明显高于其它变量。下面我们对主成分回归进行调优，调优参数仍旧是模型中成分的数目： # 设置随机种子 set.seed(100) pcrTune &lt;- train(x = xtrain, y = ytrain, method = &quot;pcr&quot;, # 设置调优参数值 tuneGrid = expand.grid(.ncomp = 1:10), trControl = ctrl) pcrTune ## Principal Component Analysis ## ## 772 samples ## 10 predictor ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 695, 694, 694, 694, 694, 695, ... ## Resampling results across tuning parameters: ## ## ncomp RMSE Rsquared ## 1 45915.48 0.03427177 ## 2 32495.72 0.51800996 ## 3 23280.82 0.75489255 ## 4 23307.53 0.75429987 ## 5 23215.51 0.75599048 ## 6 23191.55 0.75656906 ## 7 23174.19 0.75701726 ## 8 23164.03 0.75748073 ## 9 23058.54 0.76014078 ## 10 23034.70 0.76043161 ## ## RMSE was used to select the optimal model using the smallest value. ## The final value used for the model was ncomp = 10. 结果建议的调优参数的个数是10，同样的，如果大家观察输出中RMSE的变化可以发现，其实在成分数目为5之后变化就开始趋于平缓了。这里的两种情况下，选择5个成分用于建模都是合理的。我们比较下两个模型调优的过程： # 将PLS模型调优返回对象中需要的模型调优部分信息存在对象plsResamples里 plsResamples &lt;- plsTune$results plsResamples$Model &lt;- &quot;PLS&quot; # 将PCR模型调优返回对象中需要的模型调优部分信息存在对象plsResamples里 pcrResamples &lt;- pcrTune$results pcrResamples$Model &lt;- &quot;PCR&quot; # 合并二者得到用于作图的数据集 plsPlotData &lt;- rbind(plsResamples, pcrResamples) # 用lattice包中的xyplot()函数对两个模型结果可视化比较 xyplot(RMSE ~ ncomp, data = plsPlotData, #aspect = 1, xlab = &quot;# Components&quot;, ylab = &quot;RMSE (Cross-Validation)&quot;, auto.key = list(columns = 2), groups = Model, type = c(&quot;o&quot;, &quot;g&quot;)) 之前我们通过观察RMSE得出结论可以取前5个成分，这里的图形表明用前3个成分给出的模型效果和用更多成分给出的模型效果已经没有太大差别了。 References "],
["section-11.html", "第11章 广义线性模型压缩方法 11.1 初识glmnet 11.2 收缩线性回归 11.3 逻辑回归 11.4 收缩多项回归 11.5 泊松收缩回归 11.6 本章总结", " 第11章 广义线性模型压缩方法 之前只是对线性回归使用罚函数。不难理解，这样的罚函数可以用于很多其它回回归函数的优化上，比如逻辑回归，泊松回归等。glmnet包能够通过罚极大似然函数拟合广义线性回归，也就是在似然函数上加上罚函数，和之间在RSS上加罚函数类似。之前的线性回归的情况是广义线性回归的一个特例。和之前一样，罚函数的选择可以是一阶范数和二阶范数的一个组合。glmnet包可以对一系列调优参数值同时计算参数估计。除了线性回归外，该包可以拟合的广义线性模型还有：逻辑回归、多项式回归，泊松回归，cox回归。glmnet包的作者是Jerome Friedman、Trevor Hastie、Rob Tibshirani和Noah Simon，当前的R包由Trevor Hastie维护。该包还有一个matlab版本。 广义线性模型压缩方法可以表达成优化下面方程： \\[\\underset{\\beta_{0},\\mathbf{\\beta}}{min}\\frac{1}{N}\\Sigma_{i=1}^{N}w_{i}l(y_{i},\\beta_{0}+\\mathbf{\\beta^{T}x_{i}})+\\lambda[(1-\\alpha)\\parallel\\mathbf{\\beta}\\parallel_{2}^{2}/2+\\alpha\\parallel\\mathbf{\\beta}\\parallel_{1}]\\] 其中需要对一定范围内的\\(\\lambda\\)值进行调优。其中： \\[l(y_{i},\\beta_{0}+\\mathbf{\\beta^{T}x_{i}})=-log[\\mathcal{L}(y_{i},\\beta_{0}+\\mathbf{\\beta^{T}x_{i}})]\\] 也就是似然函数\\(\\mathcal{L}(y_{i},\\beta_{0}+\\mathbf{\\beta^{T}x_{i}})\\)取对数后再加负号，最大化似然函数即等价于最小化\\(l(y_{i},\\beta_{0}+\\mathbf{\\beta^{T}x_{i}})\\)。参数\\(\\alpha\\)控制了弹性网络罚函数，即在岭回归（\\(\\alpha=0\\)）和lasso（\\(\\alpha=1\\)）之间权衡。\\(\\lambda\\)控制了罚函数的总体权重，其值越大，罚函数相对于似然函数的权重越高。 之前我们已经讲过，岭回归的罚函数能够将参数估计向0收缩，但是不能收缩为0。而lasso的罚函数能够将参数严格收缩为0，因而具有变量选择功能。弹性网络的罚函数结合了这两者。这里的\\(\\alpha\\)也是需要估计的参数。glmnet包使用的是循环坐标下降法（cyclical coordinate descent），这是一种非梯度优化算法。算法每次针对一个参数优化目标方程，固定所有其它参数，然后转向另外一个参数，如此循环直到收敛。 11.1 初识glmnet 在介绍具体不同的广义线性模型压缩方法之前，先让大家熟悉一下这个R包的基本使用方式。我会简单的介绍下其中的主要函数，功能，和输出。这样大家对这个包能做什么有个大致的概念。后面的小节会分别介绍不同模型。 默认设置下的模型是高斯线性回归或者最小二乘模型，也就是之前几个小节介绍的模型，只是参数化的方式略有不同，但都是RSS加上一个罚函数。所以我们还是从之前服装消费者数据集中的自变量和应变量开始： library(glmnet) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数 dat &lt;- subset(dat, store_exp &gt; 0 &amp; online_exp &gt; 0) # 将10个问卷调查变量当作自变量 trainx &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 将实体店消费量和在线消费之和当作应变量 # 得到总消费量=实体店消费+在线消费 trainy &lt;- dat$store_exp + dat$online_exp glmfit = glmnet(as.matrix(trainx), trainy) 这里函数glmnet()返回的对象glmfit中含有所有之后可能进一步会用到的模型拟合信息。大家并不需要手动的检查glmfit中都有那些信息，然后提取相应的部分，而是可以通过plot()、coef()、predict()这类耳熟能详的函数来得到相应的信息。比如我们可以用如下方式绘制lasso的参数选择路径图： plot(glmfit, label = T) 图中每种颜色的线代表对应一个自变量，展示的是随着lasso罚函数（也就是一阶范数，有时也称为\\(l_{1}-norm\\)）对应调优参数\\(\\lambda\\)变化，各个变量对应的参数估计路径（注：当\\(\\alpha=1\\)时，优化方程里就只有lasso罚函数，这是默认设置）。图中有上下两个x轴标度，下x轴是\\(\\lambda\\)变化对应最优解的一阶范数值（也就是\\(\\parallel\\mathbf{\\beta}\\parallel_{1}\\)），上x轴是相应\\(\\lambda\\)值对应的非0参数估计个数，也就是lasso模型的自由度。我们可以查看路径的具体每一步信息： print(glmfit) Call: glmnet(x = as.matrix(trainx), y = trainy) Df %Dev Lambda [1,] 0 0.0000 3042.000 [2,] 2 0.1038 2771.000 [3,] 2 0.1919 2525.000 [4,] 2 0.2650 2301.000 [5,] 3 0.3264 2096.000 [6,] 3 0.3894 1910.000 [7,] 3 0.4417 1741.000 [8,] 3 0.4852 1586.000 [9,] 3 0.5212 1445.000 [10,] 3 0.5512 1317.000 [11,] 3 0.5760 1200.000 [12,] 3 0.5967 1093.000 [13,] 3 0.6138 996.000 [14,] 3 0.6280 907.500 ... 这里第一列Df表示非零估计的参数个数，%Dev解释的方差百分比，以及Lambda调优参数\\(\\lambda\\)的取值。虽然在默认设置下，glmnet会尝试100个不同的\\(\\lambda\\)取值，但如果随着\\(\\lambda\\)的减小，%Dev百分比只发生微小变化的时候，算法也会提前停止，上面的例子算法就只计算了68个不同的调优参数取值。我们也可以通过指定一个\\(\\lambda\\)的取值来得到对应的参数估计，其中s=用来指定调优参数值： coef(glmfit, s = 1200) ## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) 2255.2221 ## Q1 -390.9214 ## Q2 653.6437 ## Q3 624.4068 ## Q4 . ## Q5 . ## Q6 . ## Q7 . ## Q8 . ## Q9 . ## Q10 . 在\\(\\lambda=1200\\)时，只有3个变量（Q1、Q2和Q3）的参数估计非0。你也可以用新数据对一个或多个\\(\\lambda\\)值进行预测。我们随机抽取3个观测作为新数据，然后用predict()函数得到针对多个\\(\\lambda\\)值的预测： newdat = matrix(sample(1:9, 30, replace = T), nrow = 3) predict(glmfit, newdat, s = c(1741, 2000)) ## 1 2 ## [1,] 3337.144 3394.986 ## [2,] 6559.382 6186.969 ## [3,] 6831.266 6765.357 结果中每列分别对应一个\\(\\lambda\\)取值的预测。这里需要通过交互校验进行参数（\\(\\lambda\\)）调优。glmnet包中的cv.glmnet()可以实现这一目标。 cvfit = cv.glmnet(as.matrix(trainx), trainy) cv.glmnet()会返回一个列表，其中包括交互校验过程的结果，我们将该结果存在cvfit这个对象里。 我们可以对交互校验结果可视化： plot(cvfit) 红色的点是不同\\(\\lambda\\)取值对应的交互校验均方误差，灰色的线是相应置信区间。两条虚线表示选中的两个调优参数。左边的那个调优参数值对应的是最小的交互校验均方误差，右边的那个调优参数值是离最小均方误差一个标准差的调优参数值。我们可以通过下面代码查看根据两种不同规则选中的调优参数值： # 最小均方误差对应的参数值 cvfit$lambda.min ## [1] 7.893144 # 一个标准差原则下对应的参数值 cvfit$lambda.1se ## [1] 1199.688 我们也可以按如下方式查看不同调优参数值对应的回归参数（注意这里不是调优参数估计）估计： # 一个标准差原则下对应的回归参数估计 coef(cvfit, s = &quot;lambda.1se&quot;) ## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) 2255.3136 ## Q1 -391.0562 ## Q2 653.7079 ## Q3 624.5119 ## Q4 . ## Q5 . ## Q6 . ## Q7 . ## Q8 . ## Q9 . ## Q10 . 11.2 收缩线性回归 普通线性回归是广义线性回归框架下的一种特殊情况。这里将要介绍的是之前章节中线性回归的收缩方法的另外一种实现方式。之后我们会介绍广义框架下更多模型的收缩方法：逻辑回归，多项回归和泊松回归。 线性回归有两种，一种是我们已经介绍过的属于高斯（gaussian）家族的模型，其中应变量是一个向量。另外一种是多元高斯（multivariate gaussian），也就是多元响应变量的情况，这时应变量是一个矩阵，参数也是矩阵。我们着重介绍用glmnet包实现普通高斯收缩回归。 假定自变量观测\\(\\mathbf{x_{i}}\\in \\mathbb{R}^{p}\\)，应变量\\(y_{i} \\in \\mathbb{R},\\ i=1,\\dots,n\\)。这里的收缩线性回归目标是找到能够优化下面方程的参数估计，这和前一章参数化的方式略有不同，但本质是相同的： \\[\\underset{(\\beta_{0},\\mathbf{\\beta})\\in \\mathbb{R}^{p+1}}{min}\\frac{1}{2n}\\Sigma_{i=1}^{n}(y_{i}-\\beta_{0}-\\mathbf{x_{i}^{T} \\beta)}^2+\\lambda [(1-\\alpha)]\\Vert\\beta\\Vert_2^2/2+\\alpha\\Vert\\beta\\Vert_1\\] 其中\\(\\lambda&gt;0\\)是总体的复杂度参数，\\(0\\leq\\alpha\\leq1\\)是权衡lasso（\\(\\alpha=1\\)）和ridge（\\(\\alpha=0\\)）罚函数的参数。glmnet提供了定义各种参数设置的选项。下面是一些通常需要用到的参数设置： alpha：上面优化函数中的\\(\\alpha\\)，默认设置是\\(\\alpha=1\\)，也就是lasso回归，你可以将其设置为0进行岭回归。\\(\\alpha\\in[0,1]\\)。 weights： 每个观测的权重，默认设置下每个观测的权重都是1，权重总和就是参数个数n。你也可以自定义每个观测的权重，但是glmnet包会自动将你设置的权重标准化，使得权重之和总是n。 nlambda：调优参数\\(\\lambda\\)的取值个数，默认设置是100。函数会自行生成一个含有nlambda个\\(\\lambda\\)取值的向量进行调优。这些值的选取基于两个量：lambda.max和lambda.min.ratio。前者是最大的lambda值，在\\(\\alpha\\)不为0的情况下，一阶范数罚\\(\\Vert\\beta\\Vert_1\\)使得存在一个\\(\\lambda\\)取值时所有的参数估计都收缩为0，也就是模型中只有截距项。这个取值就是lambda.max。当\\(\\alpha＝0\\)的时候，lambda.max将是无穷大，因此在这种情况下，函数会自动选择一个很小的\\(\\alpha\\)值用来计算lambda.max。具体背后的数学原理，可以参考上一章的“知识扩展：Lasso的变量选择功能”小节。lambda.min.ratio是向量中最小的\\(\\lambda\\)取值与最大\\(\\lambda\\)取值的比例。如果lambda.min.ratio＝0，表明调优参数\\(\\lambda\\)的取值向量分布从0到lambda.max。 lambda：如果不用设定nlambda的方式，你也可以通过设定lambda这个参数自己定义调优参数值向量。 standardize：用来告诉函数是否标准化自变量的逻辑值。默认设置为standardize=TRUE。 作为例子，这里设置alpha=0.2，nlamdba=10。在实际应用中，通常会尝试100-150个不同的\\(\\lambda\\)取值，这里为了避免过多的输出，只设置20个值。 # 这里要用as.matrix(xtrain)将自变量输入转化成矩阵 fit = glmnet(as.matrix(trainx), trainy, alpha = 0.2, nlambda = 20) # 这里digits=2限制了输出中的小数位数 print(fit, digits = 4) ## ## Call: glmnet(x = as.matrix(trainx), y = trainy, alpha = 0.2, nlambda = 20) ## ## Df %Dev Lambda ## [1,] 0 0.0000 15210.000 ## [2,] 4 0.2502 9366.000 ## [3,] 6 0.4590 5768.000 ## [4,] 7 0.5848 3552.000 ## [5,] 9 0.6502 2188.000 ## [6,] 9 0.6823 1347.000 ## [7,] 9 0.6967 829.700 ## [8,] 9 0.7033 511.000 ## [9,] 9 0.7064 314.700 ## [10,] 9 0.7080 193.800 ## [11,] 9 0.7088 119.300 ## [12,] 9 0.7093 73.500 ## [13,] 9 0.7095 45.270 ## [14,] 9 0.7096 27.880 ## [15,] 9 0.7096 17.170 ## [16,] 9 0.7096 10.570 ## [17,] 10 0.7096 6.511 ## [18,] 10 0.7096 4.010 关于输出中各列代表什么，参考之前的解释。大家可能会发现，之前设置了20个调优参数值，这里只输出了18个。其原因在于算法中设置了停止条件。根据默认设置，在下面两种情况下计算会停止： 解释的方差百分比（%Dev）的变化小于\\(10^{-5}\\)时 解释的方差百分比本身大于\\(0.999\\) 这里停止是因为遇到了第一种情况，\\(\\lambda\\)的取值变化几乎不会对解释的方差百分比造成影响。更多关于算法的控制条件，可以键入help(&quot;glmnet.control&quot;)。 我们可以用plot()绘制拟合过程的参数估计路径图。图的x坐标轴有3个设置： norm：参数估计的一阶范数，这是默认设置 lambda：\\(log(\\lambda)\\)值 dev：解释方差的百分比，即之前结果输出中的%Dev 我们之前展示了默认设置下的参数估计路径图（norm）。现在绘制另外两种情况。设置xvar = &quot;lambda&quot;可以得到对应\\(log(\\lambda)\\)的路径图： plot(fit, xvar = &quot;lambda&quot;, label = T) 可以看到，随着\\(\\lambda\\)值的增大，参数逐步向0收缩。Q1、Q2、Q3和Q8的参数估计都差不多在最后才收缩为0。说明这几个变量对解释应变量最重要。下面我们看看对于解释方差的百分比的路径图： plot(fit, xvar = &quot;dev&quot;, label = T) 横坐标为解释方差的百分比时的路径图和之前的不太一样。非0参数个数越多，解释的方差百分比就越大。到最右端的时候，解释方差变化很小，但是参数估计确急剧增大。由图中我们可以看出，Q7对模型拟合几乎起不了作用。观察这些图能够帮助我们将注意力放在一些重要的变量上。 如果确定了调优参数\\(\\lambda\\)的取值，我们便可以进一步得到相应的参数估计并预测新数据。在之前“初识glmnet”那一小节中，我们展示了在默认设置（alpha = 1，即只有lasso罚函数的情况下）下如何得到调优参数\\(\\lambda\\)的某个取值下的拟合结果。这里和之前的情况稍有不同，因为我们设置alpha=0.2，也就是说现在lasso和岭回归的罚函数同时存在。我们可以在fit=glmnet(as.matrix(trainx),trainy,alpha=0.2,nlambda=20)结果的基础上得到相应\\(\\lambda\\)取值的调优参数。从输出结果看，若考虑解释方差的变化情况，\\(\\lambda \\in [829.7, 1347]\\)之间比较妥当。这里我们选择\\(\\lambda ＝ 1000\\)，这里为了展示一些函数的用法，特意选择了不在调优过的\\(\\lambda\\)取值中的数，也可以通过下面这行简短的代码查看你想要的取值是不是已经调优拟合过： any(fit$lambda == 1000) ## [1] FALSE 可以看到返回的是FALSE，即\\(\\lambda ＝ 1000\\)这个取值不在调优取值内。于是有两种方法可以得到相应的参数估计。第一种是重新用\\(\\lambda ＝ 1000\\)更新拟合模型，这时我们想要得到的是确切的拟合值，可以设置exact = T，再次强调注意在函数中\\(\\lambda\\)对应的设置是s： coef.exact = coef(fit, s = 1000, exact = T) 你也可以不要再次拟合模型，那么我们可以设置exact = F（这是函数的默认设置），这样函数会用插值法得到相应的近似结果： coef.apprx = coef(fit, s = 1000, exact = F) 我们可以看看这两种情况下参数估计有何不同： cbind2(coef.exact, coef.apprx) ## 11 x 2 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 1 ## (Intercept) 1208.75790 1177.37262 ## Q1 -485.44857 -483.29175 ## Q2 852.41149 850.50376 ## Q3 645.89607 645.89528 ## Q4 59.16109 60.82823 ## Q5 161.48707 163.98503 ## Q6 188.02162 192.23258 ## Q7 . . ## Q8 -196.29622 -193.76827 ## Q9 196.35592 198.42621 ## Q10 -129.38656 -132.20608 输出的左边那列是确切拟合，右边的是插值近似，可以看到它们非常相近，所以通常情况下直接用线性插值就可以，不一定要重新拟合模型。同样我们可以在新的数据集上预测结果： # 和之前一样，我们抽取一个小样本最为新自变量观测 newdat = matrix(sample(1:9, 30, replace = T), nrow = 3) predict(fit, newdat, type = &quot;response&quot;, s = 1000) ## 1 ## [1,] 6664.514 ## [2,] 9799.426 ## [3,] 2430.454 这里的type选项设置有3种，上面的type = &quot;response&quot;也就是直接得到预测的应变量估计。如果type = &quot;coefficients&quot;，等价与之前的coef.apprx = coef(fit, s = 1000, exact = F)，得到的是线性插值参数估计： predict(fit, newdat, type = &quot;coefficients&quot;, s = 1000) ## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) 1177.37262 ## Q1 -483.29175 ## Q2 850.50376 ## Q3 645.89528 ## Q4 60.82823 ## Q5 163.98503 ## Q6 192.23258 ## Q7 . ## Q8 -193.76827 ## Q9 198.42621 ## Q10 -132.20608 type = &quot;nonzero&quot; 将会返回一个向量告诉你那些自变量的参数估计非0： predict(fit, newdat, type = &quot;nonzero&quot;, s = 1000) ## X1 ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## 7 8 ## 8 9 ## 9 10 此外，你也可以自定义k层交互校验的层数。glmnet()中的参数在cv.glmnet()中都有，后者还多了参数nfolds用来定义层级的数目，foldid让用户自定义层级，以及type.measure评估标准：方差（deviance）或者绝对误差均值（mae）。不同类型的的模型有不同的评估标准。比如type.measure=&quot;class&quot;仅仅适用于二项回归和多项逻辑回归，其使用的是误判率。type.measure=&quot;auc&quot;只针对二分类逻辑回归，使用的是ROC线下面积。刚才提到的绝对误差均值type.measure=&quot;mae&quot;可以用与除了cox模型之外的其它所有模型。我们会在之后介绍其它模型。对于高斯族类的模型，默认设置是type.measure=&quot;deviance&quot;。这里我们修改下设置，用绝对误差均值： cvfit = cv.glmnet(as.matrix(trainx), trainy, type.measure = &quot;mae&quot;, nfolds = 20) 这里顺便提一下，cv.glmnet()函数能够支持并行计算，这用到doMC包。 # 抽取一个大样本来展示并行计算对效率的提高 X = matrix(rnorm(1e5*200), 1e5, 200) Y = rnorm(1e5) # 不用并行计算 system.time(cv.glmnet(X, Y)) user system elapsed 26.476 1.423 27.918 library(doMC) # 我的电脑是4核的，所以设置cores = 4 registerDoMC(cores = 4) # 用并行计算 system.time(cv.glmnet(X, Y, parallel = T)) user system elapsed 15.574 1.047 12.603 大家可以看到用并行计算在数据量大的时候能够节省好多时间。函数coef()和predict()用于cv.glmnet对象的方式和glmnet相似，只是前者多了两个关于\\(\\lambda\\)参数值s的字符串设置：lambda.min（对应最小均方误差的\\(\\lambda\\)值）和lambda.1se（对应最小均方误差1个标准差的\\(\\lambda\\)值）： # 这里不展示输出结果 cvfit = cv.glmnet(as.matrix(trainx), trainy, type.measure = &quot;mse&quot;, nfolds = 20) # 最小均方误差对应的参数值 cvfit$lambda.min # 预测新样本 predict(cvfit, newx = newdat, s= &quot;lambda.min&quot;) # 得到参数估计 coef(cvfit, s = &quot;lambda.min&quot;) 如果你不仅想要选择\\(\\lambda\\)，还要尝试不同的\\(\\alpha\\)的参数值，可以自己指定交互校验的样本分层情况。 # 自定义层级 foldid = sample(1:10, size = length(trainy), replace = T) # 尝试3个不同的alpha取值：1、0.5、0.2和0 cv1 = cv.glmnet(as.matrix(trainx), trainy, foldid = foldid, alpha = 1) cv.2 = cv.glmnet(as.matrix(trainx), trainy, foldid = foldid, alpha = .2) cv.5 = cv.glmnet(as.matrix(trainx), trainy, foldid = foldid, alpha = .5) cv0 = cv.glmnet(as.matrix(trainx), trainy, foldid = foldid, alpha = 0) plot(log(cv1$lambda), cv1$cvm, pch = 19, col = 2, xlab = &quot;log(Lambda)&quot;, ylab = cv1$name) points(log(cv.5$lambda), cv.5$cvm, col = 1) points(log(cv.2$lambda), cv.2$cvm, col = 3) points(log(cv0$lambda), cv0$cvm, col = 4) legend(&quot;topleft&quot;, legend = c(&quot;alpha = 1&quot;, &quot;alpha = 0.5&quot;, &quot;alpha = 0.2&quot;, &quot;alpha = 0&quot;), pch = 19, col = c(2, 1, 3, 4)) 可以看到，不同 alpha的取值对应的最优均方误差几乎相同，只是在\\(\\lambda\\)值大的时候（图的右端），\\(\\alpha\\)值的变化会对模型拟合结果产生影响。 在实际应用中，基于问题的背景需要对参数进行一些限制。回顾下面三个问卷调查的问题（小伙伴们可以到“数据集模拟和背景介绍”那一章中查看所有问卷调查的问题）： -（Q3）：品牌的知名度对我来说非常重要 -（Q8）：价格对我来说很重要 其中问题Q3和消费金额应该是正相关的，对品牌知名度在意的人，很可能是土豪或者国民老公一类的，反正相对不差钱，衣着对于这部分群体而言满足的需求已经从马斯洛的需求金字塔底端升级到顶端。而Q8的回复和消费金额应该是负相关的，对价格越是在意的人，花销很可能越小，屌丝群体，动不动就得卖肾，生活不易，且花且珍惜。好啦，人艰不拆，我们从残酷的现实世界回到美好的数据世界。在这里，我们需要限定参数估计的区间，Q3的参数估计是正数，Q8的参数估计是负数。在glmnet()函数中，我们可以对每个参数设置可能的限制区间，如果不知道区间的，可以用很小或者很大的上下限。这里需要赋予一个长度为10的向量，其中每个元素对应一个变量的上（或下）限值： # 先得到一个下限向量，设置成负无穷大 # 这时等于没有下限 lower.limits &lt;- rep(-Inf, ncol(trainx)) # 在将需要的下限值加入 # Q3的估计是正数，所以下限为0 lower.limits[3] &lt;- 0 # 类似的设置上限向量 upper.limits &lt;- rep(Inf, ncol(trainx)) upper.limits[8] &lt;- 0 boundfit = glmnet(as.matrix(trainx), trainy, lower.limits = lower.limits, upper.limits = upper.limits) 注意，这里下限lower.limits的值必须是负数或者0，上限upper.limits的值必须是正数或者0。 11.3 逻辑回归 逻辑回归是非常流行的判别方法，尤其对于二分类问题。我们以生猪疫情数据为例来讲解模型以及实践代码。关于数据的模拟和背景介绍，可以参考之前“数据集模拟和背景介绍”章节中相应小节。研究目标是对农场爆发疫情建模。假设样本量为\\(n\\)，对应\\(G\\)个自变量（也就是农场问卷调查的问题），每个问题对应3个选项（A、B和C），因此每个分类自变量将转化为3个虚拟变量，不知道大家是不是记得，我们在数据模拟的部分讲过选项C作为基准选项，因为某个回复一定是A、B和C中的一种，所以有一列包含重复信息，我们任意选择一个作为基准列从自变量矩阵中删去。假设第\\(i\\)个受访农场（\\(i=1,\\dots,n\\)）对应第\\(g\\)个问题（\\(g=1,\\dots,G\\)）回复编码后的虚拟变量观测是\\(\\mathbf{x_{ig}}\\)（如果第1个农场在第2个问题中选择B，那么对应的观测就是\\(\\mathbf{x_{12}}=(0,1)^{T}\\)），这种情况下第\\(g\\)个问题对应的自由度就是2，我们将自由度一般化的记为\\(df_g\\)。第\\(i\\)个农场对应疫情发生实际观测情况就是应变量\\(y_i \\in \\{0,1\\}\\)，其中1代表发生疫情，0代表没有发生疫情。第\\(i\\)个农场疫情发生的概率是\\(\\theta_i\\in [0,1]\\)。 11.3.1 普通逻辑回归 基于上述数学符号定义，对于普通逻辑回归： \\[y_{i}\\sim Bounoulli(\\theta_{i})\\] \\[log\\left(\\frac{\\theta_{i}}{1-\\theta_{i}}\\right)=\\eta_{\\mathbf{\\beta}}(x_{i})=\\beta_{0}+\\sum_{g=1}^{G}\\mathbf{x_{i,g}}^{T}\\mathbf{\\mathbf{\\beta_{g}}}\\] 其中 \\(\\beta_{0}\\) 是截距项，且\\(\\mathbf{\\beta_{g}}\\)是第\\(g\\)个问题观测转化成的虚拟变量对应的参数估计。在当前例子中，每个问题有3个选项，所以每个问题对应3-1=2个虚拟变量（其中选项C是基准项，之前已经讲过了），\\(\\mathbf{\\beta_{g}}\\)就是长度为2的向量。 一般逻辑回归就是通过最大化下面的极大似然函数的对数估计\\(\\mathbf{\\beta}=(\\beta_{0}^{T},\\mathbf{\\beta_{1}}^{T},\\mathbf{\\beta_{2}}^{T},...,\\mathbf{\\beta_{G}}^{T})^{T}\\)： \\[ \\begin{eqnarray*} l(\\mathbf{\\beta})&amp;=&amp;log[\\prod_{i=1}^{n}\\theta_{i}^{y_{i}}(1-\\theta_{i})^{1-y_{i}}]\\\\ &amp;=&amp;\\sum_{i=1}^{n}\\{y_{i}log(\\theta_{i})+(1-y_{i})log(1-\\theta_{i})\\}\\\\ &amp;=&amp;\\sum_{i=1}^{n}\\{\\ y_{i}\\eta_{\\mathbf{\\beta}}(\\mathbf{x_{i}})-log[1+exp(\\eta_{\\mathbf{\\beta}}(\\mathbf{x_{i}}))]\\ \\}. \\end{eqnarray*} \\] 在逻辑回归中，当变量个数相对观测较大时，很容易发生完全分离或者准完全分离的现象，这时候没有唯一的极大似然估计，因此参数估计的方差极大。关于逻辑回归这样的对数线性模型参数极大似然估计的存在性，唯一性的讨论可以参考[67]和[68]。这种情况时常出现，比如疾病预测数据： library(MASS) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/sim1_da1.csv&quot;) fit &lt;- glm(y~., dat, family = &quot;binomial&quot;) glm.fit: algorithm did not convergeglm.fit: fitted probabilities numerically 0 or 1 occurred 大家可以看到，函数报错说无法收敛，这里就是发生了完全分离的情况。这时收缩方法就可以解决这个问题。 11.3.2 收缩逻辑回归 我们可以类似的在逻辑回归的似然函数后添加罚函数来收缩参数估计： \\[ \\underset{\\mathbf{\\beta}\\in \\mathbb{R}^{p+1}}{min} -\\sum_{i=1}^{n}\\{\\ y_{i}\\eta_{\\mathbf{\\beta}}(\\mathbf{x_{i}})-log[1+exp(\\eta_{\\mathbf{\\beta}}(\\mathbf{x_{i}}))]\\ \\}+\\lambda [(1-\\alpha) \\parallel \\mathbf{\\beta}\\parallel _{2}^{2}/2] + \\alpha \\parallel \\mathbf{\\beta}\\parallel _{1} ] \\] dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/sim1_da1.csv&quot;) trainx = dplyr::select(dat, -y) trainy = dat$y fit &lt;- glmnet(as.matrix(trainx), trainy, family = &quot;binomial&quot;) 可以看到，这里没有错误信息。和之前类似，我们可以绘制参数收缩的路径图，提取某个\\(\\lambda\\)取值对应的参数估计，并且进行预测。比如我们可以绘制下面的解释方差比例的参数路径图，绘制图形的语法和之前高斯的情况一样： plot(fit, xvar = &quot;dev&quot;) 预测函数predict()和之前的高斯族情况有所不同，主要在于type选项。在二项应变量的情况下，函数的type选项有如下几种： link：返回链结函数的拟合值 response：返回拟合的概率值 class：返回预测的类别（0/1）值 coefficients：返回相应的参数估计 nonzero：返回估计非0的参数指针向量（即告诉你模型选择了哪些参数） 函数默认的这些估计针对的是因子型应变量中第二个层级。比如这里的应变量trainy对应的因子层级是： levels(as.factor(trainy)) ## [1] &quot;0&quot; &quot;1&quot; 这里的预测概率针对的是第二个因子层级，也就是“1”的概率。这里用3个观测行和两个\\(\\lambda\\)的取值为例，展示predict()函数的用法： newdat = as.matrix(trainx[1:3, ]) predict(fit, newdat, type = &quot;link&quot;, s = c(2.833e-02, 3.110e-02)) ## 1 2 ## 1 0.1943472 0.1442796 ## 2 -0.9913159 -1.0076600 ## 3 -0.5840566 -0.5496074 上面输出中第1列对应的是\\(\\lambda=0.02833\\)时3个样本的链结函数预测值。第2列对应的是\\(\\lambda=0.0311\\)时的链结函数预测值。类似的，大家可以自己改变type的设置看结果输出。对逻辑回归我们也可以类似的使用cv.glmnet()函数通过交互校验对参数进行调优。参数和高斯的情况基本相同，不同的地方在于type.measure参数的设置。因为这里应变量是分类变量而非连续变量，在之前的“模型评估度量”章节里详细的介绍过应变量为分类和连续时模型评估方法的差异。在分类情况下，模型评估方法的常用设置type.measure有： class：计算误判率 auc：仅对于二分类的情况，计算ROC曲线下面积 例如： # 老用as.matrix(trainx)确实有些烦人，但是函数要求时矩阵格式。 # 小伙伴可以在一开始选择将trainx直接转化成矩阵格式。 # 这里不这么做的原因是矩阵格式下有的数据框的操作又无法进行 # 且一些数据框的行列信息可能在转化过程中丢失。 # 所以在每次拟合模型的时候临时转化而不更改原数据框 cvfit = cv.glmnet(as.matrix(trainx), trainy, family = &quot;binomial&quot;, type.measure = &quot;class&quot;) plot(cvfit) 上面使用的是误判率作为标准，进行10层交互校验。同样你可以得到对应最小误判率的\\(\\lambda\\)取值，以及距离最小误判率一个标准差的\\(\\lambda\\)取值： cvfit$lambda.min ## [1] 8.856624e-05 cvfit$lambda.1se ## [1] 0.001315181 至于获取参数估计以及对新样本进行预测之前已经讲过，在此就不赘述。 11.3.3 知识扩展：群组lasso逻辑回归 下面我进一步讲一个相对较新的方法：群组lasso逻辑回归。该方法最早由Meier等人在2008年提出的[69]。它在普通lasso逻辑回归的基础上加上了变量的分组信息。比如在疾病预测的例子中，每个问题的回复对应两个虚拟变量，来自同一个问卷调查问题的虚拟变量在反映的信息上有相似性，可以归为一组。这样分组在当前应用例子中是必须的。因为增加分组信息之后，模型不仅可以在组内选择变量，而且可以对不同的组进行选择，也就是说属于同一组的变量参数同时为0或者同时不为0。此例子中，不同组代表不同的问题。这里变量选择的目标主要是从问卷中选择重要的对疾病爆发有预测性的问题，而非问题中的具体选项，所以群组lasso逻辑回归对解决这样的问题非常有效。群组逻辑回归最小化下面方程： \\[ S_{\\lambda}(\\mathbf{\\beta})=-l(\\mathbf{\\beta})+\\lambda\\sum_{g=1}^{G}s(df_{g})\\parallel\\mathbf{\\beta_{g}}\\parallel_{2} \\] 其中\\(\\lambda\\)是调优参数，\\(s(\\cdot)\\)调整罚函数大小的系数，[69]最初提出\\(s(df_g)=df_g^{0.5}\\)，因为这样能够保证每个组参数估计对应的罚函数值和该组含有的变量数目同阶。\\(l(\\mathbf{\\beta})\\) 是普通逻辑回归的似然函数。这里需要对\\(\\lambda\\)进行调优，范围在0到\\(\\lambda_{max}\\)之间。这里的\\(\\lambda_{max}\\)定义如下[69]： \\[ \\lambda_{max}=\\underset{g\\in\\{1,...,G\\}}{max}\\left\\{\\frac{1}{s(df_{g})}\\parallel \\mathbf{x}_{g}^{T}(\\mathbf{y}-\\bar{\\mathbf{y}})\\parallel_{2}\\right\\}, \\] 当\\(\\lambda=\\lambda_{max}\\)时，模型中只有截距项存在，也就是说除了\\(\\beta_0\\)以外所有其它变量参数估计都是0。当\\(\\lambda=0\\)时，模型等价于普通逻辑回归。我们通常取如下m个\\(\\lambda\\)值进行调优： \\[\\{0.96\\lambda_{max},0.96^{2}\\lambda_{max},0.96^{3}\\lambda_{max},...,0.96^{m}\\lambda_{max}\\}\\] 这里的m表示你想要调优的参数个数，通常在100到150之间比较合适。参数的选择还是需要交互校验。有3种调优准则，其中之一是已经讲过的AUC，在此不赘述。除了AUC之外，还有两种准则：对数似然函数值[69]和最大相关系数。每个调优参数对应的对数似然函数值是其在不同交互校验拟合得到的对数似然函数的平均，这个很容易理解。最大相关系数来自Yeo和Burge的论文，其定义如下[70]： \\[ \\rho_{max}=max\\{\\rho_{\\tau}|\\tau\\in(0,1)\\}, \\] 其中\\(\\tau\\in(0,1)\\) 是划分预测概率的截断点，概率大于\\(\\tau\\)的判定为1，否者为0。\\(\\rho_\\tau\\)是观测到的真实应变量和相应截断点\\(\\tau\\)下得到的预测结果的Pearson相关系数。我正在开发的一个R包中有实现群组lasso逻辑回归调优拟合的函数。可以通过下面代码安装该包： devtools::install_github(&quot;happyrabbit/DataScienceR&quot;) 安装好了之后载入该包： library(DataScienceR) ## ## Attaching package: &#39;DataScienceR&#39; ## The following object is masked _by_ &#39;.GlobalEnv&#39;: ## ## multiplot 该包中含有这里使用的疾病预测数据，只需要用下面代码载入数据： data(&quot;sim1_da1&quot;) 包中的函数cv_glasso()可以用来对不同的参数进行调优： # sim1_da1中最后一列y是应变量，其余的都是自变量 # trainx是自变量矩阵，去除应变量列 trainx = dplyr::select(sim1_da1, -y) # 将应变量存在trainy中 trainy = sim1_da1$y # 得到关于群组的指针 index &lt;- gsub(&quot;\\\\..*&quot;, &quot;&quot;, names(trainx)) 可以看到，每个问题对应的虚拟变量属于同一组： index[1:50] ## [1] &quot;Q1&quot; &quot;Q1&quot; &quot;Q2&quot; &quot;Q2&quot; &quot;Q3&quot; &quot;Q3&quot; &quot;Q4&quot; &quot;Q4&quot; &quot;Q5&quot; &quot;Q5&quot; &quot;Q6&quot; ## [12] &quot;Q6&quot; &quot;Q7&quot; &quot;Q7&quot; &quot;Q8&quot; &quot;Q8&quot; &quot;Q9&quot; &quot;Q9&quot; &quot;Q10&quot; &quot;Q10&quot; &quot;Q11&quot; &quot;Q11&quot; ## [23] &quot;Q12&quot; &quot;Q12&quot; &quot;Q13&quot; &quot;Q13&quot; &quot;Q14&quot; &quot;Q14&quot; &quot;Q15&quot; &quot;Q15&quot; &quot;Q16&quot; &quot;Q16&quot; &quot;Q17&quot; ## [34] &quot;Q17&quot; &quot;Q18&quot; &quot;Q18&quot; &quot;Q19&quot; &quot;Q19&quot; &quot;Q20&quot; &quot;Q20&quot; &quot;Q21&quot; &quot;Q21&quot; &quot;Q22&quot; &quot;Q22&quot; ## [45] &quot;Q23&quot; &quot;Q23&quot; &quot;Q24&quot; &quot;Q24&quot; &quot;Q25&quot; &quot;Q25&quot; 下面我们设置调优参数，nlam是调优参数个数，也就是\\(\\{0.96\\lambda_{max},0.96^{2}\\lambda_{max},0.96^{3}\\lambda_{max},...,0.96^{m}\\lambda_{max}\\}\\)中的m。调优过程中会有很多输出，这里省略这些输出： # 对100个调优参数值进行调优 nlam &lt;- 100 # 设置调优过程中模型的预测类型 # - `link`：返回链结函数的拟合值 # - `response`：返回拟合的概率值 # # 这和之前的 type = &quot;link&quot; # number of cross-validation folds kfold &lt;- 10 cv_fit &lt;- cv_glasso(trainx, trainy, nlam = nlam, kfold = kfold) # 只展示部分结果 str(cv_fit) 这里由于篇幅所限，只展示部分cv_fit的结果： ... $ auc : num [1:100] 0.573 0.567 0.535 0.484 0.514 ... $ log_likelihood : num [1:100] -554 -554 -553 -553 -552 ... $ maxrho : num [1:100] -0.0519 0.00666 0.04631 0.0486 0.06269 ... $ lambda.max.auc : Named num [1:2] 0.922 0.94 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;lambda&quot; &quot;auc&quot; $ lambda.1se.auc : Named num [1:2] 16.74 0.81 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;&quot; &quot;se.auc&quot; $ lambda.max.loglike: Named num [1:2] 1.77 -248.86 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;lambda&quot; &quot;loglike&quot; $ lambda.1se.loglike: Named num [1:2] 9.45 -360.13 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;lambda&quot; &quot;se.loglike&quot; $ lambda.max.maxco : Named num [1:2] 0.922 0.708 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;lambda&quot; &quot;maxco&quot; $ lambda.1se.maxco : Named num [1:2] 14.216 0.504 ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;lambda&quot; &quot;se.maxco&quot; 结果中 $ auc对应100个调优参数值对应的AUC值 $ log_likelihood是调优参数对应的对数似然函数值 $ maxrho是调优参数对应的最大相关性 $ lambda.max.auc 对应两个值，最优化auc的\\(\\lambda\\)取值以及该取值下的auc值 $ lambda.1se.auc 对应的两个值分别是离最大auc值1个标准差的值，和其对应的\\(\\lambda\\)值 $ lambda.max.loglike 对应两个值，最优化对数似然函数的\\(\\lambda\\)取值以及该取值下的对数似然函数值 $ lambda.1se.loglike 对应的两个值分别是离最大对数似然函数值1个标准差的值，和其对应的\\(\\lambda\\)值 $ lambda.max.maxco 对应两个值，最优化最大相关性的\\(\\lambda\\)取值以及该取值下的最大相关性 $ lambda.1se.maxco 对应的两个值分别是离最优最大相关性1个标准差的值，和其对应的\\(\\lambda\\)值 一般情况下我们主要用auc值作为标准，但是可以比较不同标准对应的调优参数选择，如果一致，我们会对调优参数的选择更有信心。如果差别很大，那我们可能需要进一步考虑参数选择的过程是不是稳定。那么什么时候用最优化相应准则的调优参数，什么时候用1标准差调优参数呢？以auc为例，如果auc从最优值到1标准差值变化非常平缓，比如从0.8降低到0.78，但放松标准可以极大的改变选择的调优参数，如果我们牺牲一点auc，模型中的参数数量可能大量降低（这种情况我经常遇到），那模型的解释性大大提高，这时就可以适当放松标准。 也可以对交互校验拟合结果绘图： plot(cv_fit) 其中横坐标是调优参数值，纵坐标是auc。两条虚线分别对应的是最优化auc的\\(\\lambda\\)取值和1标准差\\(\\lambda\\)取值。一旦确定调优参数的值，可以用fitglasso()重新拟合相应模型，比如我们取最优化auc的调优参数值\\(\\lambda=0.922\\)： fitgl &lt;- fitglasso(trainx, trainy, lambda = 0.922, na_action = na.pass) Lambda: 0.922 nr.var: 229 类似的可以使用coef()函数： coef(fitgl) 0.922 Intercept -5.318039e+01 Q1.A 1.756672e+00 Q1.B 1.719050e+00 Q2.A 2.169919e+00 Q2.B 6.939251e-01 Q3.A 2.102014e+00 Q3.B 1.358941e+00 Q4.A 1.561528e+00 Q4.B 5.539396e-01 ... 对新样本预测有一些不同，得用predict_glasso()函数： prey &lt;- predict_glasso(fitgl, trainx) 11.4 收缩多项回归 对类数目超过2的情况需要使用多项回归，比如服装消费者分为：价格敏感（Price），炫耀性消费（Conspicuous），质量（Quality），风格（Style）这四类。这里一般性的假设应变量有K个类别，\\(\\mathbb{G}=\\{1,2,\\dots,K\\}\\)。这里的目标是找到样本属于每个类别的概率： \\[Pr(G=k|\\mathbf{X=x})=\\frac{e^{\\beta_{0k}+\\mathbf{\\beta_{k}^{T}\\mathbf{x}}}}{\\Sigma_{l=1}^{K}e^{\\beta_{0l}+\\mathbf{\\beta_{l}^{T}x}}}\\] 这里的应变量可以转化成虚拟变量的矩阵，每一列代表一个类别。假设\\(\\mathbf{Y}\\)是应变量转化成的\\(N\\times K\\)的0/1矩阵，其中\\(y_{il}=I(g_{i}=l)\\)，也就是某个观测\\(i\\)从属的类别\\(l\\)的位置上观测是1，其余是0。此时弹性网络模型优化的是如下方程： \\[l({\\beta_{0k}, \\mathbf{\\beta_{k}}_{1}^{K}})= - \\left[ \\frac{1}{N}\\Sigma_{i=1}^N \\left( \\Sigma_{k=1}^K y_{il}(\\beta_{0k} + \\mathbf{x_i^T\\beta_{k}}) - log(\\Sigma_{k=1}^{K}e^{\\beta_{0k}+\\mathbf{x_i^T\\beta_{k}}}) \\right) \\right]+\\lambda\\left[ \\frac{(1-\\alpha)\\parallel \\beta \\parallel_F^2}{2} + \\alpha \\Sigma_{j=1}^p \\parallel \\beta_j \\parallel_q\\right]\\] 这个式子有些复杂，稍微解释一下。其实思路和之前是一样的，上式的前半部分是应变量矩阵中对应\\(l\\)类那列的对数似然函数取负号，第二部分是罚函数。第一部分\\(y_{il}(\\beta_{0k} + \\mathbf{x_i^T\\beta_{k}})\\)中，\\(y_{il}\\)和\\(\\mathbf{x_i^T\\beta_{k}}\\)是取乘积因为\\(y_{il}\\)的取值是0/1，否则应该是\\(log(y_{il})+\\beta_{0k} + \\mathbf{x_i^T\\beta_{k}}\\)的形式。此外，罚函数中\\(\\parallel\\beta\\parallel_{F}^{2}\\)的\\(\\beta\\)是一个矩阵而非向量，因为这里每个类别都对应一个参数向量，所以所有类别的参数向量集结成了一个矩阵\\(\\beta\\)。罚函数中的另外一项\\(\\parallel \\beta_j \\parallel_q\\)中的q可以有两个取值：\\(q\\in \\{1, 2\\}\\)。当\\(q=1\\)时，是对每个类对应的参数应用lasso罚，当\\(q=2\\)时，相当于是群组lasso罚，和之前“知识扩展：群组lasso逻辑回归”这个小节的方法非常类似，这时观测j对应的所有K个群组的参数同时为0或者同时不为0。 这里严格使用标准的牛顿迭代算法优化起来非常繁琐。glmnet包使用了一种叫做偏牛顿优化算法（Partial Newton Algorithm）的方法。该方法对对数似然函数进行偏二项逼近，即对某一类别每次只允许对应的参数\\((\\beta_{0k}, \\mathbf{\\beta_{k}})\\)变化，其余参数保持不变。关于该算法更加详细的介绍，可以参考Noah Simon, Jerome Friedman和Trevor Hastie的论文[71]。 下面还是用服装消费者数据展示如何通过glmnet包实现该方法，这里自变量依旧和之前一样是问卷调查的问题，应变量变成是消费者类别： library(glmnet) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 将10个问卷调查变量当作自变量 trainx &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 将消费者类别当作应变量 trainy &lt;- dat$segment 对于多项回归中有一个关于罚函数的选项type.multinomial，这是用来指定在上面提到过的\\(\\parallel \\beta_j \\parallel_q\\)部分。如果type.multinomial = &quot;group&quot;对应的就是\\(q=2\\)的情况，也就是群组lasso。默认设置是非群组，也就是\\(q=1\\)。 fit &lt;- glmnet(as.matrix(trainx), trainy, family = &quot;multinomial&quot;) 可以对拟合对象进行绘图： plot(fit, xvar = &quot;lambda&quot;, label = T, type.coef = &quot;2norm&quot;) 其中参数有： xvar和label和之前相同，用来指定横坐标的变量和是否标出自变量名字 type.coef和之前不同，如果type.coef = &quot;coef&quot;，那么对因变量的每个类别都会返回一幅图，此例子中会返回4幅图，各自对应一个类别的参数估计。如果type.coef = &quot;2norm&quot;，那么只会返回1幅图，纵坐标是所有类别参数的二阶矩 也可以用cv.glment()函数进行交互校验： cvfit &lt;- cv.glmnet(as.matrix(trainx), trainy, family = &quot;multinomial&quot;) plot(cvfit) 同样你可以得到最优的lambda取值然后用该取值拟合模型： cvfit$lambda.min ## [1] 0.0005155172 newdat = matrix(sample(1:9, 60, replace = T), nrow = 6) predict(cvfit, newdat, s = &quot;lambda.min&quot;, type = &quot;class&quot;) ## 1 ## [1,] &quot;Conspicuous&quot; ## [2,] &quot;Conspicuous&quot; ## [3,] &quot;Quality&quot; ## [4,] &quot;Quality&quot; ## [5,] &quot;Style&quot; ## [6,] &quot;Style&quot; 11.5 泊松收缩回归 关于广义收缩方法中我们要介绍的最后一个是泊松模型。泊松回归处理的是应变量为计数的情况，比如消费者光顾实体店的次数。或者其它应变量非负，并且均值和方差成比例的情况。这里对应变量的要求是大致服从泊松分布的假设。泊松分布也是指数分布家族中的一员。通常对应变量进行对数变换： \\[log (\\mu_{x})=\\beta_{0}+\\mathbf{\\beta^{T}x}\\] 这时的对数似然函数是： \\[l(\\mathbf{\\beta|X,y})=\\Sigma_{i=1}^{N}\\left(y_i(\\beta_0+\\mathbf{\\beta^Tx_i})-e^{\\beta_0+\\mathbf{\\beta^Tx_i}} \\right)\\] 和之前类似，我们需要优化的加上罚函数后的式子： \\[\\underset{\\beta_{0},\\mathbf{\\beta}}{min}\\left\\{ -\\frac{1}{N}l(\\mathbf{\\beta|X,y})+\\lambda\\left((1-\\alpha)\\Sigma_{i=1}^{N}\\frac{\\mathbf{\\beta_{i}^{2}}}{2}+\\alpha\\parallel\\mathbf{\\beta}\\parallel_{1}\\right)\\right\\} \\] 下面继续用服装消费者数据展示如何通过glmnet包实现该方法，这里自变量依旧和之前一样是问卷调查的问题，应变量变成是实体店消费次数： library(glmnet) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 将10个问卷调查变量当作自变量 trainx &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 实体店消费次数当作应变量 trainy &lt;- dat$store_trans # 拟合泊松模型 fit &lt;- glmnet(as.matrix(trainx), trainy, family = &quot;poisson&quot;) 可以类似的使用plot()函数检查参数收缩的轨迹： plot(fit, label = T) 可以看到（Q2）：我喜欢买同一个品牌的服装和（Q6）：我喜欢在实体店购买的参数估计到很后面才收缩为0，之间表明是否喜欢实体店购买和真实实体店消费次数之间有关是很符合逻辑的，有意思的是，是否喜欢买同一个品牌的服装也和实体店消费次数有关。如果知道具体问题和实体店购买次数之间关系的正负性需要得到相应的回归系数。我们可以类似用cv.glment()函数进行交互校验： cvfit &lt;- cv.glmnet(as.matrix(trainx), trainy, family = &quot;poisson&quot;) plot(cvfit) 这里用来调优的准则是泊松离差。同样你可以得到最优的lambda取值然后用该取值拟合模型： coef(fit, s=cvfit$lambda.min) ## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) 0.134542659 ## Q1 -0.002966470 ## Q2 0.112332909 ## Q3 . ## Q4 -0.001188666 ## Q5 0.128028742 ## Q6 0.318738648 ## Q7 -0.023964782 ## Q8 0.027572033 ## Q9 0.020892375 ## Q10 . 可见，那些喜欢买同一个服装品牌的，明确表明喜欢实体店购买以及有明确风格偏好的人会更多的光顾实体店。 11.6 本章总结 这里我们系统性的介绍了常用的广义回归收缩模型，以及如何用R实施这些模型。glmnet包能够通过罚极大似然函数拟合广义线性回归，也就是在似然函数上加上罚函数，和之间在RSS上加罚函数类似。之前的线性回归的情况是广义线性回归的一个特例。和之前一样，罚函数的选择可以是一阶范数和二阶范数的一个组合。glmnet包可以对一系列调优参数值同时计算参数估计。 我们介绍了线性回归，逻辑回归、多项式回归和泊松回归的收缩方法。此外对于逻辑回归，我们补充介绍了群组逻辑回归，该方法在自变量有明显群组效应的时候非常有效。 References "],
["section-12.html", "第12章 树模型 12.1 分裂准则 12.2 树的修剪 12.3 回归树和决策树 12.4 装袋树 12.5 随机森林 12.6 助推法 12.7 知识扩展：助推法的可加模型框架 12.8 知识扩展：助推树的数学框架 12.9 本章总结", " 第12章 树模型 树模型可以用于回归和判别。这类模型常被称为决策和回归树（CART：Classification And Regression Trees），是经典的机器学习算法，也是最广泛使用的工具。和线性模型相比，树模型能够较好的捕捉到非线性关系。 CART可以用来指代广义的树模型，有时也特别指代Breiman最初提出的建立分类回归树的算法[72]。在Breiman之后又有很多新的算法出现，比如ID3、C4.5和C5.0，这几个都是Ross Quinlan提出的。是C4.5的改进版本，但由于C5.0还没有开源，因此C4.5算法依然非常流行。原始的CART算法只针对二分类的应变量，但是C4.5能处理多分类结果。CART使用Gini系数准则，C4.5使用熵。CART通过复杂性成本模型来对树进行剪枝，通过交互校验来估计参数；C4.5使用的是一个从二项置信区间衍生出的单通算法。在对缺失值的处理上，CART使用的是代理切分。对于每一个切分，模型会计算一系列的备选方案（称为代理切分）。代理切分是指与树中实际切分结果相类似的备选切分方案，如果一个代理切分对原始切分的近似效果良好，那么当原始切分的预测变量有缺失值时，代理切分就可以发挥作用。在实际应用中，树中的每一个切分都可以事先计算一些代理切分。C4.5算法不是直接填充缺失值或寻找替代，而是用概率知识把信息增益率的求解进行一些变化。 不太大的决策树简洁明了，容易解释。但是简单的树表现不一定好，复杂的树（比如之后会讲到的集成方法）效果大为提高，但过程如同黑箱，无法解释。所以建模者需要在解释性和精确性之间进行权衡。之所以称其为“树”当然因为结构有类似之处，只是决策树的方向和真实的树相反，根在上，叶在下。一棵决策树从单个根节点开始划分为几个不同的枝桠，从⽽产生更多的节点,在每个节点都可以决定是不是要继续划分，如果停止则该节点就是叶节点，若继续就是枝节点接着分裂产生下一层新节点。每个⾮叶节点都牵扯到决定接下来选择哪根树枝。叶节点包含 最终“决策”，将该样本归于哪个最终类或者取值。树模型中有如下几个重要的定义： 男神分类器 分类树：用于预测离散型结果的树 回归树：用于预测连续型结果的树 分裂点：每个非叶节点的处都有一个分裂点用来决定样本的走向（如：年龄&lt;=25；2535） 根节点：最开始的包含所有观测的节点 叶节点（或者终节点）：包含样本的最终“决策”，没有分裂点 节点的度：一个节点含有的子树的个数称为该节点的度； 树的度：一棵树中，最大的节点的度称为树的度； 修剪：移除一些不必要的分裂点的过程，这是和分裂相反的过程 树枝（或子树）：非终节点下的一个完整旁支 亲节点和子节点：亲节点分裂后得到子节点 比如上面的简易男神分类器（分类器纯属虚构，如有雷同，纯属巧合）：长相是根节点同时也是分裂点；年龄和经济状况是分裂点; 长相这个节点的度是2；整棵树的度是4；最后小鲜肉等所在的那些节点是终节点；如果我们将王XX那个枝桠移除，就是修剪；长相是年龄和经济状况的亲节点，反之年龄和经济状况是长相的子节点。 树模型和规则模型之所以成为非常流行的建模工具有下面几个原因： 能处理变量个数相对于观测个数很大情况 对冗余变量具有抗性 小型的树非常容易解释（但一旦树结构复杂或者使用集成方法时模型变得无法解释） 根据它们建立模型时采用的逻辑，它们能有效地处理各种类型的预测变量（稀疏的，偏态的，连续的，分类的，等等），而不需要对这些变量事先进行预处理。此外，这些模型没有任何变量分布的假设，而在回归模型中通常有分布假设 这些模型可以有效地处理缺失值，并内嵌有特征选择的功能，这一点在很多实际建模问题中非常有用 单棵树或简单规则模型具有局限性，其中最重要的就是模型不稳定以及预测能力比较差。数据中的微小变动可能会引起树或规则结构的巨大变化。单棵树定义的一系列的矩形区域过于简单，一旦因变量与预测变量之间的关系不能充分地通过矩形子空间来进行表达， 那么树模型和规则模型将产生比其他模型更大的预测误差。为了克服这些缺点，研究者提出了集成模型，它们将许多棵树（或规则）进行组合。集成模型通常具有比单一的树模型好得多的预测表现。我们在之后会做介绍。 12.1 分裂准则 分裂节点的方式能够极大的影响树的精确度。回归树和分类树所使用的分裂准则非常不同。与回归树一样，分类树的目标是把数据划分为更小、同质性更强的组。在这里同质意味着分裂的节点更纯（即在每个节点有一个类的样本比例很大）。最原始的CART算法使用基尼系数作为分裂准则；ID3、C4.5以及C5.0使用交叉熵，也被称为信息或散度作为标准。下面逐一介绍这三个标准。 Gini系数 基尼（Gini）系数[72]用来衡量一个集合样本的杂质（我们希望的是更高的纯度，更少的杂质）。对于二分类问题，给定节点的基尼系数定义为： \\[p_{1}(1-p_{1})+p_{2}(1-p_{2})\\] 其中\\(p_{1}\\)和\\(p_{2}\\)分别为类1、类2的概率。不难看出，当集合样本纯度很高时，某一类概率趋近于0，基尼系数最小。相反，当\\(p_{1}=p_{2}=0.5\\)时基尼系数最大，在这种情况下，节点的纯度最小。我们来看一个例子，假设我们想要判定哪些学生是计算机专业的，下面是用性别这个变量得到的简单分类树结果。 用性别判定计算机专业的学生 现在我们来计算用性别变量划分对应的Gini系数： 计算女生对应的Gini系数=\\(\\frac{1}{6}\\times\\frac{5}{6}+\\frac{5}{6}\\times\\frac{1}{6}=\\frac{5}{18}\\) 计算男生对应的Gini系数=\\(0\\times1+1\\times 0=0\\) 可以用如下加权计算性别这个分裂总体的Gini系数： \\[\\frac{3}{5}\\times\\frac{5}{18}+\\frac{2}{5}\\times 0=\\frac{1}{6}\\] 亲节点中50个观测的Gini系数是：\\(\\frac{1}{2}\\)。很容易得出，经过性别这个分裂点后Gini系数从原来的\\(\\frac{1}{2}\\)降至\\(\\frac{1}{6}\\)，该分裂点对降低Gini的贡献就是\\(\\frac{1}{3}\\)。算法会选择对Gini系数减小最有效的的分裂。 信息增益 看下面二分类问题中三个节点内的样本，哪个最容易描述？显然是C，因为C中所有的样本都是一类的，这样描述起来需要的信息最少。相反B需要更多的信息，A需要的信息最多。换句话说，C的纯度最高，B次之，A的纯度最差。我们可以这么说，纯度更高的节点描述起来需要的信息更少。反之，纯度更低的节点描述起来需要的信息更多。 信息理论就是为了衡量系统的无序度的，无序的度量也叫做熵。如果某个节点对应的样本全都是一类（如C）,其熵就是0。如果某个节点中各类样本比例是50%－50%，那么熵就是1。熵自然是越小越好。 熵（Entropy）的计算公式如下： \\[Entropy=-plog_{2}p-(1-p)log_{2}(1-p)\\] 这里p是其中一类样本的比例。熵也能用来分裂分类树节点。其选择和亲节点以及其它分裂点相比熵最小的那个分裂。计算某个分裂的熵也是对每个分裂后子节点熵的加权平均。比如之前对50个学生的分类树： 亲节点中50个学生对应的熵是：\\(-\\frac{25}{50}log_{2}\\frac{25}{50}-\\frac{25}{50}log_{2}\\frac{25}{50}=1\\)，这里1表明节点纯度是最低的，也就是各类样本占一半。 对应性别这个分裂的熵计算分为3步： 女生对应的熵：\\(-\\frac{5}{30}log_{2}\\frac{5}{30}-\\frac{25}{30}log_{2}\\frac{25}{30}=0.65\\) 男生对应的熵为0，因为\\(p=1\\) 性别这个分裂对应的熵为上述两个的加权平均：\\(\\frac{3}{5}\\times 0.65+\\frac{2}{5}\\times 0=0.39\\) 可以看到，分裂将原先的熵从1降到0.39。 最小化SSE 目前为止我们讨论了对于分类树（离散应变量）情况的分裂准则。下面我们介绍回归树使用的分裂准则。构建回归树有许多不同的准则，其中最古老也最常用的是最小化SSE。对于回归问题，假设要将数据集\\(S\\)分成两组\\(S_{1}\\)和\\(S_{2}\\)，其中\\(S_{1}\\)和\\(S_{2}\\)的选取需要使得整体的误差平方和达到最小： \\[SSE=\\Sigma_{i\\in S_{1}}(y_{i}-\\bar{y}_{1})^{2}+\\Sigma_{i\\in S_{2}}(y_{i}-\\bar{y}_{2})^{2}\\] 式中\\(\\bar{y}_{1}\\)和\\(\\bar{y}_{1}\\)是\\(S_{1}\\)和\\(S_{2}\\)组内训练集因变量的的平均值。接下来分别在\\(S_{1}\\)和\\(S_{2}\\)中， 模型继续搜索预测变量和切分点，以使得SSE达到最大的缩减。由于回归树的这一过程本质上是递归的切分，因此这种方法也通常称为递归划分。 看看下面这个简单的回归树，对10个学生以性别为分裂点，对身高做回归： 女生对应身高测量的SSE为：136 男生对应身高测量的SSE为：32 性别这个分裂对应的SSE为这两个SSE之和：168 亲节点中10个观测的SSE是：522.9。经过性别这个分裂点后SSE从原来的522.9降至168。 如果还有另外一种可能的分裂方式，用专业来划分，结果如下： 这种情况下： 女生对应身高测量的方差为：184 男生对应身高测量方差为：302.8 专业这个分裂对应的方差为之前两个方差的加权和：486.8 比较性别和专业两个不同的分裂，之前性别这个分裂点将SSE从原来的522.9降至168；专业这个分裂点将SSE降至486.8。如果用最小化SSE准则，应该选择使用性别为分裂点。 上面提到的这三种分裂准则是建立树模型的基础。 12.2 树的修剪 树模型面对的主要挑战是过度拟合。假设我们对决策树的参数没有任何限制，那么得到的树模型在训练集上的准确度将会是100%，因为每个终结点将只对应一个样本。因此，防止过度拟合是创建树模型的关键所在。总的说来可以通过下面两种方法来实现这一点： 对树的大小进行限制 对树进行修剪 现在我们对上面两点逐一展开。 限制树的大小 可以通过一些参数来限制树的大小。 每个节点处的最小样本量：通过定义节点处的最小样本量可以防止终结点只有一个样本的情况。这里样本量的设置可以作为调优参数。如果设置的样本量太大，那么会导致拟合不足，如果样本量太小，又会过度拟合。在严重类失衡的情况下，最小样本量的设置可能需要小一些，因为某一类样本本身数目就很少。 最大树深度：如果树生长的过深，那么模型就会过度拟合特定的样本。这也是一个需要调优的参数。 最大终结点数目：对终结点数目的限制和对树深度的限制是类似的，可以取代使用。因为这两者是成正比的。 每个分裂考虑的变量个数：在每一层级寻找最优分裂点的时候使用的变量是随机抽取的。通常情况下，取变量个数的平方根效果最好，这也是R种函数的默认设置。但我们还是应该对该参数在变量个数的30%~40%区间内调优。 另外一种方法是先让树充分生长，然后再回过头移除一些不显著的树枝，以回到一个较小的深度。背后原理是先让树在训练集上过度拟合，然后通过测试集对树进行调整以校正过度拟合，这里树模型在测试集上的表现代表了其在新样本上的表现。下面介绍实现这一目的几种常见方法。 代价-复杂度调优 Breiman等的论文中采用的剪枝过程称为代价-复杂度调优[72]。这是针对回归问题的修剪方法。也就是在原来SSE的基础上加上一个关于终节点数目的罚函数，通过一个调优参数控制罚函数的权重： \\[SSE_{c_{p}}=SSE+c_{p}\\times 终节点数目\\] 其中\\(c_{p}\\)被称为复杂度参数。该方法对于一个给定的\\(c_{p}\\)值，我们希望寻找最小的剪枝后的树，以使得惩罚后的误差达到最小。 给定\\(c_{p}\\)的取值时，Breiman等给出了寻找最优树的理论和算法[72]。与之前讨论过的收缩方法类似，较小的罚倾向于产生较大的树。\\(c_{p}\\)取值很大时生成的树可能只有一次分裂，甚至根本没有分裂。后一种情况意味着在当前选择的复杂度参数下， 没有任何一个预测变量能充分地解释因变量的变异。 为了找到最优的剪枝树，需要在一系列的\\(c_{p}\\)取值上对数据进行计算， 这一过程会对每一个\\(c_{p}\\)值计算一个 SSE。但我们知道的是，当选择了一个不同的样本时，SSE的数值也会有所变化。为了体现每一个\\(c_{p}\\)取值下 SSE 的变异，Breiman等建议使用类似于第四章中的交叉验证方法[72]。他们还提出了一倍标准差准则作为优化准则，来给出最简单的树：在一倍的标准差之内，找到最简单的使得绝对误差最小的树。另外一些方法则是选择使得数值上误差达到最小的树尺寸[73]。 降低误判率修剪 该修剪方法最早由Quinlan提出[74]。这是最容易理解的修剪方法。树的所有分裂点都纳入修剪的候选名单，对某个分裂点进行修剪意味着将该分裂点下的整个子树都去掉，将该节点设置为叶节点（或者终节点）。这里数据集将被分成3个子集： （1）用于训练完整的树； （2）用于修剪； （3）用于测试最终模型。 如果对某个节点修剪后的的树在第（2）个子集上得到的准确度不小于原来完整的树在（2）上的精确度，那么就将该节点设置为叶节点。否则保留该节点。该算法的好处在于计算上较简单。当子集（2）的样本量比用于训练的子集（1）小很多时，该方法存在过度修剪的风险。许多研究人员发现，这类基于判别误差的修剪方法得到的模型准确度比那些基于树大小得到的模型高[75]。 误判率-复杂度修剪 由于每个分裂节点对降低误判率有潜在的作用，但节点越多，意味着树越复杂。该方法就是在这两者之间权衡。假设某个分裂节点\\(t\\)，该节点对应的整个子树为\\(T\\)。该节点修剪后在降低误判率上的损失可以用下面的误判率损失衡量： \\[R(t)=r(t)\\times p(t)\\] 其中\\(r(t)\\)是某个节点的误判率： \\[r(t)=\\frac{该节点下误判样本的数目}{该节点下所有样本的数目}\\] \\(p(t)\\)是该节点样本占总样本的比例： \\[p(t)=\\frac{该节点的样本数目}{总体样本数目}\\] 根植于节点\\(t\\)的子树\\(T\\)对应的误判率损失是： \\[R(T)=\\Sigma_{i是子树T的叶节点}R(i)\\] 该节点对应的误判率-复杂度定义为： \\[a(t)=\\frac{R(t)-R(T)_{t}}{子树T的叶节点数目-1}\\] \\(a(t)\\)可以看成是子树\\(T\\)对应价值的衡量。基于上面介绍的一些度量，该修剪过程大致如下[76]： 对每个分裂节点计算对应的价值度量\\(a\\) 剪去价值最低的节点 不断重复上面的过程，每次都产生一棵修剪后的树，这些树组成“森林” 在这片森林中选出精确度最高的树 最小化误判率修剪 该方法由Niblett和Brotko在1991年提出[77]。这是一个自下而上的过程，目的在于寻找能够最小化模型在新数据上预期误判率的树。对于某个分裂点t，如果该节点修剪成叶节点后，其下所有的样本都被预测为c类，那么该节点对应的修剪预期误判率为： \\[E(t)=\\frac{n_{t}-n_{t,c}+k-1}{n_{t}+k}\\] 其中： \\[k=类别数目\\] \\[n_{t}=节点t的样本总数\\] \\[n_{t,c}=节点t下c类样本的数目\\] 基于上述定义，该修剪算法过程如下[75]： 在树的每个非叶节点处，计算对该节点修剪后的预期误判率 计算如果该节点下的子树未经修剪得到的预期误判率 如果修剪使得预期误判率提高，那不修剪，否则修剪 12.3 回归树和决策树 12.3.1 回归树 我们现在进一步介绍回归树的构建过程[78]。建立回归树大致分两步： 将自变量\\(X_1,X_2,\\dots,X_p\\)所有可能取值构成的自变量空间划分成\\(J\\)个彼此不重叠的区域：\\(R_1,R_2,\\dots,R_J\\) 落入某个区域\\(R_j\\)的新样本对应相同的预测值，即训练集中\\(R_j\\)内所有观测的平均 一个及其简化的例子，假设我们就用性别划分成两个区域\\(R_1\\)（女）和\\(R_2\\)（男）： 那么，落入\\(R_1\\)的训练集样本均值为163，落入\\(R_2\\)的训练集样本均值为176。那么对新样本，如果是女生，树模型预测的身高就是163，男生则为176。第2步其实很好理解。现在我们更详细的讲解第1步，也就是怎么划分出区域\\(R_1,R_2,\\dots,R_J\\)。 理论上说，划分的区域可以是任何形状，但这里为了简化问题便于解释，我们选择将自变量空间划分成高维矩形，或者说高维盒子。对于回归模型划分目标是最小化之前讲过的RSS。考虑所有可能的划分在现实问题中几乎不可能，这和之前特征选择中讲到的穷举法是一个道理，理论上最优但是实际不可操作。所以建造树模型的时候使用的是从上到下（top-down）的贪婪算法——递归二元分割。该方法从树的根节点开始逐步向下分割自变量空间。每次分裂都产生2条树枝，所以叫做“二元分割”。之所以说该算法贪婪是因为在建造树过程中的每一步，都只是针对当前情况寻找最优分割方式而没有考虑之后在这之后的分裂。 首先在根节点处选择一个变量\\(X_j\\)和分裂点\\(s\\)，将自变量空间划分成下面两个空间： \\[R_{1}(j, s)=\\{X|X_j&lt;s\\}\\ 和\\ R_{2}(j, s)=\\{X|X_j\\geq s\\}\\] 计算相应分裂后RSS的减少量。对不同的\\((j,s)\\)搜索能最大程度减少RSS的组合，也就是最小化下面式子： \\[\\Sigma_{i:x_i\\in R_1(j,s)}(y_i-\\hat{y}_{R_{1}})^2+\\Sigma_{i:x_i\\in R_2(j,s)}(y_i-\\hat{y}_{R_{2}})^2\\] 其中\\(\\hat{y}_{R_1}\\)是\\(R_1\\)中训练样本的应变量均值，\\(\\hat{y}_{R_2}\\)是\\(R_2\\)中训练样本的应变量均值。优化上面的式子很容易，尤其当\\(p\\)不是很大的时候。 接下来就在这两个生成的子区域中按照同样的方式继续寻找最优化该区域RSS的分裂。注意这里只在新的子区域内优化。这个过程一直延续到满足设定的停止准则，比如区域内的样本量少于5，或者RSS降低的百分比小于1%。大家可以脑补下这个动态的过程，节点不断分裂出两个新的子节点直到所有的节点满足停止条件。这就好像一棵树在不断生长。 在R中有好几个包能够用来建造回归树，如ctree、rpart和tree。rpart是广为使用的一个建造单棵树的包，切分方法基于CART，使用rpart()函数，用公式表达法。rpart()有若干调节参数，可以通过rpart.control选项设定。或者你可以使用之前反复讲到的神器caret包的train()函数，通过其为接口调用rpart()函数，方便进行交互校验。 train()在此情况下常用的函数设定的参数是复杂度参数（cp）和最大节点深度（maxdepth）。为了对 CART树的复杂度参数进行调优，train()中的方法选项应该设定为method = &quot;rpart&quot;。为了对最大深度进行调优，方法选项则应为method = &quot;rpart2&quot;： library(rpart) library(tree) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数 dat &lt;- subset(dat, store_exp &gt; 0 &amp; online_exp &gt; 0) # 将10个问卷调查变量当作自变量 trainx &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 将实体店消费量和在线消费之和当作应变量 # 得到总消费量=实体店消费+在线消费 trainy &lt;- dat$store_exp + dat$online_exp set.seed(100) rpartTune &lt;- train(trainx, trainy, method = &quot;rpart2&quot;, tuneLength = 10, trControl = trainControl(method = &quot;cv&quot;)) plot(rpartTune) 最大树的深度大于2貌似RMSE就不再变化了。这里我们就用深度为2来建立树： rpartTree &lt;- rpart(trainy ~ ., data = trainx, maxdepth = 2) 你可以通过print()查看相应的规则： print(rpartTree) ## n= 999 ## ## node), split, n, deviance, yval ## * denotes terminal node ## ## 1) root 999 15812720000 3479.113 ## 2) Q3&lt; 3.5 799 2373688000 1818.720 ## 4) Q5&lt; 1.5 250 3534392 705.193 * ## 5) Q5&gt;=1.5 549 1919009000 2325.791 * ## 3) Q3&gt;=3.5 200 2436211000 10112.380 * 可见，Q3和Q5被最终用来预测总花销。要对rpart生成的树绘制图形，可以使用partykit包先将rpart对象转换成party对象，然后再使用plot()： library(partykit) rpartTree2 &lt;- as.party(rpartTree) plot(rpartTree2) 12.3.2 决策树 决策树和回归树的思想是类似的，目标是把数据划分为更小、同质性更强的组。不同在于应变量是个分类变量而不是数值。这时，预测就不是基于平均而是基于每个类别样本的频数。叶节点的预测值就是落入相应区域训练集样本中频数最高的类别。决策树的分裂准则不是RSS，而是之间介绍的熵（Entropy）或者Gini系数。CART使用Gini系数准则，C4.5使用熵。CART通过复杂性成本模型来对树进行剪枝，通过交互校验来估计参数；C4.5使用的是一个从二项置信区间衍生出的单通算法。在对缺失值的处理上，CART使用的是代理切分。对于每一个切分，模型会计算一系列的备选方案（称为代理切分）。C4.5算法不是直接填充缺失值或寻找替代，而是用概率知识把信息增益率的求解进行一些变化。 当自变量是连续型时，确定最佳分裂点的划分过程很直接。当自变量是分类型时有两种处理方式： 不对分类变量进行变换，每个分类型自变量作为单独的个体输入到模型当中以便模型决定如何对值进行分组或分裂。这时可以对数据做更为动态的分裂，如分裂点一侧有两个或更多的组。为了进行这样的分裂，算法需要对自变量的类别按照某种方式进行排序。 分类型自变量先被重新编码为二元虚拟变量，这样将类别信息分解成独立信息块。每一个虚拟变量都融入各自的模型中。这样一来评估每个这些新自变量的方法就很简单，因为每个自变量仅有一个分裂点。 如果某些类对结果有强预测性，第一种方法可能更合适。然而，正如我们后面看到的，该选择会对模型的复杂度和模型性能有显著影响。在接下来的章节，我们将使用上面说的两种方法构建模型，以便评估那种方法更优。从业者需要根据哪一种方法更合适当前的问题来进行选择。 下面我们用不同的方法对服装消费者性别进行判定（这里是分类模型而非回归模型）： library(caret) library(pROC) dat &lt;- read.csv(&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;) # 将10个问卷调查变量当作自变量 trainx1 &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 将类别也作为自变量 # 这里用两种方法编码分类变量 # trainx1 不对消费者类别进行变换 trainx1$segment &lt;- dat$segment # trainx2 中的消费者类别被转化成虚拟变量 dumMod&lt;-dummyVars(~., data=trainx1, # 用原变量名加上因子层级的名称作为新的名义变量名 levelsOnly=F) trainx2 &lt;- predict(dumMod,trainx1) # 性别作为应变量 trainy &lt;- dat$gender 构建分类树的R包也有很多，这里讲主要的rpart包。 library(rpart) > cartModel rpart(Class ~ NumCI + Weekday, data = training[pre2008,]) --> caret包中的train()函数将建立单棵树的一些函数包装起来，我们可以用它来训练树模型。我们分别对分类变量两种编码方法进行建模比较： set.seed(100) rpartTune1 &lt;- caret::train(trainx1, trainy, method = &quot;rpart&quot;, tuneLength = 30, metric = &quot;ROC&quot;, # 规定了预留数据集以及需要计算那些模型表现度量（如敏感度，特异度和AUC）。 trControl = trainControl(method = &quot;cv&quot;, summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)) rpartTune1 ## CART ## ## 1000 samples ## 11 predictor ## 2 classes: &#39;Female&#39;, &#39;Male&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 899, 900, 900, 899, 899, 901, ... ## Resampling results across tuning parameters: ## ## cp ROC Sens Spec ## 0.000000000 0.7005168 0.6498377 0.7062626 ## 0.008350085 0.7086874 0.6297727 0.7354040 ## 0.016700170 0.6856826 0.5411688 0.8026768 ## 0.025050255 0.6801479 0.5106494 0.8496465 ## 0.033400340 0.6801479 0.5106494 0.8496465 ## 0.041750425 0.6801479 0.5106494 0.8496465 ## 0.050100510 0.6801479 0.5106494 0.8496465 ## 0.058450595 0.6801479 0.5106494 0.8496465 ## 0.066800680 0.6801479 0.5106494 0.8496465 ## 0.075150765 0.6801479 0.5106494 0.8496465 ## 0.083500850 0.6801479 0.5106494 0.8496465 ## 0.091850936 0.6801479 0.5106494 0.8496465 ## 0.100201021 0.6801479 0.5106494 0.8496465 ## 0.108551106 0.6801479 0.5106494 0.8496465 ## 0.116901191 0.6801479 0.5106494 0.8496465 ## 0.125251276 0.6801479 0.5106494 0.8496465 ## 0.133601361 0.6801479 0.5106494 0.8496465 ## 0.141951446 0.6801479 0.5106494 0.8496465 ## 0.150301531 0.6801479 0.5106494 0.8496465 ## 0.158651616 0.6801479 0.5106494 0.8496465 ## 0.167001701 0.6801479 0.5106494 0.8496465 ## 0.175351786 0.6801479 0.5106494 0.8496465 ## 0.183701871 0.6801479 0.5106494 0.8496465 ## 0.192051956 0.6801479 0.5106494 0.8496465 ## 0.200402041 0.6801479 0.5106494 0.8496465 ## 0.208752126 0.6801479 0.5106494 0.8496465 ## 0.217102211 0.6801479 0.5106494 0.8496465 ## 0.225452296 0.6553102 0.5427922 0.7678283 ## 0.233802381 0.6553102 0.5427922 0.7678283 ## 0.242152466 0.5609993 0.7828571 0.3391414 ## ## ROC was used to select the optimal model using the largest value. ## The final value used for the model was cp = 0.008350085. 上面是不对分类变量进行编码的情况。这里cp指的是复杂度参数（complexity parameter）。是树生长的停止准则，cp = 0.01意味者相应分裂度量（Gini，熵等）每一步分裂都需要比之前提高0.01，在交互校验结果中不满足0.01提升的部分会被修剪掉。 下面我们接着对将分类变量进行编码后的数据集进行训练： rpartTune2 &lt;- caret::train(trainx2, trainy, method = &quot;rpart&quot;, tuneLength = 30, metric = &quot;ROC&quot;, # 规定了预留数据集以及需要计算那些模型表现度量（如敏感度，特异度和AUC）。 trControl = trainControl(method = &quot;cv&quot;, summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)) rpartRoc &lt;- roc(response = rpartTune1$pred$obs, predictor = rpartTune1$pred$Female, levels = rev(levels(rpartTune1$pred$obs))) rpartFactorRoc &lt;- roc(response = rpartTune2$pred$obs, predictor = rpartTune2$pred$Female, levels = rev(levels(rpartTune1$pred$obs))) plot(rpartRoc, type = &quot;s&quot;, print.thres = c(.5), print.thres.pch = 3, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2, col = &quot;red&quot;, legacy.axes = TRUE, print.thres.col = &quot;red&quot;) ## ## Call: ## roc.default(response = rpartTune1$pred$obs, predictor = rpartTune1$pred$Female, levels = rev(levels(rpartTune1$pred$obs))) ## ## Data: rpartTune1$pred$Female in 13380 controls (rpartTune1$pred$obs Male) &lt; 16620 cases (rpartTune1$pred$obs Female). ## Area under the curve: 0.667 plot(rpartFactorRoc, type = &quot;s&quot;, add = TRUE, print.thres = c(.5), print.thres.pch = 16, legacy.axes = TRUE, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2) ## ## Call: ## roc.default(response = rpartTune2$pred$obs, predictor = rpartTune2$pred$Female, levels = rev(levels(rpartTune1$pred$obs))) ## ## Data: rpartTune2$pred$Female in 13380 controls (rpartTune2$pred$obs Male) &lt; 16620 cases (rpartTune2$pred$obs Female). ## Area under the curve: 0.6547 legend(.75, .2, c(&quot;Grouped Categories&quot;, &quot;Independent Categories&quot;), lwd = c(1, 1), col = c(&quot;black&quot;, &quot;red&quot;), pch = c(16, 3)) 可以看到，对于使用CART构建的树，对消费者类别变量编码或者不编码并不影响对受访者性别做预测。同样也可以通过partykit包对最终的模型绘制图形。这里不展示结果： library(partykit) plot(as.party(rpartTune1$finalModel)) 单棵树很直观，容易解释。但它有两个缺点： 和很多回归模型相比精确度差 非常不稳定，数据微小的变化会导致模型结果很大的变化 将不同的决策树聚合起来能够解决这两个问题，比如下面要介绍的装袋树，随机森林和助推树就是这样的思想。这些模型的表现和单棵树相比显著提高。 12.4 装袋树 Bootstrap 样本是对数据进行有放回随机抽样得到的样本[79]。这意味着，当一个样本点被选中时，它有可能会在将来的抽取中继续被选中。Bootstrap 样本和原数据的样本量一样。因此，一些样本可能被抽到过很多次，而另一些则可能没有被选到。没有被选到的样本被称为“袋外样本“（out-of-bag）。这在统计学史上是一个看似平淡无奇，但实际上具有突破性意义的思想。在很多难以甚至不可能直接计算标准差的情况下能够用bootstrap来对估计标准差。很长一段时间我并不理解这样一种流氓的方法怎么会大受追捧，这里追捧的人指的不是一般群众，而是象牙塔里那些根正苗红的统计教授。这个方法就像聚宝盆，一直不停的有放回抽样。一个极端的情况，假如你只有1个样本，难道你不停有放回抽样就能得到大样本了？当然不是，这是对该方法的扭曲。bootstrap要在样本量足够多的时候才最有效。 bootstrap示意图 之前介绍的单棵树最大的问题就是结果不稳定。直观的说，假如你把样本随机分成两部分，用各个子集建造树模型，得到的两棵树可能大相径庭。相反，对于一个稳定的模型，其在这两个数据集上拟合结果应该是很相近的。传统的参数回归模型相对稳定性高，比如线性回归。 在20世纪90年代，集成方法（即将许多模型组合起来进行预测的模型）开始出现。但当样本量n较之于变量个数p而言比较大时，该方法可以作为降低模型方差的一般方法。装袋法（Bagging，bootstrap aggregation 的缩写）最初由 Leo Breiman 提出，它是最早发展起来的集成方法之一（Breiman 1996a）。装袋法是一种利用 bootstrap的通用方法，可用于任何回归（或分类）模型来构建集成组合。 假设n个独立随机变量\\(Z_1,\\dots,Z_n\\)，每个的方差是\\(\\sigma^2\\)。那么它们的均值\\(\\bar{Z}\\)对应的方差为\\(\\frac{\\sigma^2}{n}\\)。这个统计学中的基本性质大家应该都很熟悉。也就是说，对观测取平均可以减小方差。因此一个很自然的减小模型估计方差，增加模型预测精确度的方法就是让模型作用与不同的训练集，然后将模型结果取平均。假设我们将模型应用于B个训练集，得到估计\\(\\hat{f}^1(x),\\hat{f}^2(x)\\dots,\\hat{f}^B(x)\\)，我们可以用： \\[\\hat{f}_{avg}(x)=\\frac{1}{B}\\Sigma^B_{b=1}\\hat{f}^b(x)\\] 作为最终模型结果。当然这严格说来无法实现，因为我们只有一个训练集。这就是需要bootstrap的地方了。我们将每个bootstrap样本当作训练集合。这种方法的构建非常简单，它包含下面算法中所述的步骤： 算法：装袋法 对 i=1 到 B 执行 从原数据中生成bootstrap样本 在生成的bootstrap样本上建立未修剪的树 终止 集成组合中的每一个模型都对新样本进行一次预测，然后将这些预测进行平均。每一次bootstrap重抽样迭代中，选中的样本点被用来建立模型，而袋外样本则被用于预测。对于回归树，装袋法很好理解，就是将不同预测值平均。那么分类树呢？在这种情况下有若干可能的办法。这里讲最简单的一种。对于测试集的某个样本，我们可以记录下每棵树对其判定的类别，这样我们得到B个判定类别，然后取票数最高的那个。很自然，这里树的数目B是一个需要调优的重要参数。 装袋树示意图 装袋法的优势 装袋法模型相对于没有装袋的模型具有若干优势。 首先，装袋法通过模型的聚集过程有效地降低了预测的方差。对于那些预测值不稳定的模型，例如回归树，将不同版本的训练集进行聚集，可以减小预测的方差，从而使得预测值更加稳定。假设我们有10个bootstrap样本各自生成了一棵最大深度的树。这些树在结构上有所差异，每棵树对新样本的预测都有所不同。如果将这10棵树的预测结果进行平均作为新样本的预测，那么这一平均值将比单棵树的预测方差更小。这意味着，如果我们产生另一组bootstrap样本，在其中每一个样本上建立一个模型，然后对所有模型的预测值进行平均，那么得到的结果将与前一个装袋模型的结果相类似。 装袋模型比未装袋的模型具有更好的预测效能。如果建模的目标是得到最优的估计而不是解释树的结构，那么装袋法更有优势。对稳定、方差小的模型（如回归，MARS）进行装袋则只会对其预测效能带来较小的改进。在预测结果具有内在的不稳定性的情况下，可以用装袋法进行改进。虽然理论上装袋法不仅限于树模型，但是其对树模型的改进效果最好，尤其是决策树，这就是对症下药。 其次，装袋法模型的另一个优势是它可以提供内在的预测效能估计。因为这里用的是bootstrap过程中剩下的袋外样本，它们并没有参与建模于是扮演着测试集的角色，可以用来评估模型的预测效能。因此，集成组合中的每个模型都可以通过袋外样本计算得到一个预测效能的估计，而对所有袋外效能估计进行平均就能计算出整个集成组合的预测效能。 这一结果通常与交叉验证或测试集验证的结果非常吻合，该误差估计称为袋外估计。平均说来，每棵树大约使用了2/3的样本，另外1/3的样本是袋外数据。这意味着，对于每个样本，在B次抽样中，大约会有B/3次是袋外数据，因而有对应的预测值。让这些预测值投票得到每个样本对应的预测。进一步可以计算所有样本的误差。可以证明当抽样的次数B足够大时，袋外样本误差几乎等价于留一校验误差。 对于基本的装袋法，用户可以选择bootstrap样本的数目。《应用预测模型（Applied Predictive Modeling）》[13]的作者指出， 通常模型的预测效能与迭代次数之间会出现指数递减的关系； 大部分预测效能的提升是由少数几棵树实现的。根据他们的经验，一直到50个bootstrap样本，模型都可能还会有微小的改进，如果迭代了50次代后模型的表现还是不令人满意，那就需要尝试使用其他更强大的集成预测方法，如随机森林和助推。 装袋法的局限 尽管装袋法通常都能改进不稳定模型的预测效能，但它同样有一些缺陷。 首先，是计算量。随着bootstrap 样本数目的增多，计算成本和内存需求也会相应增加。这一劣势可以通过并行计算来得到大部分的消减，原因是装袋的过程是非常容易并行化的。 回顾之前的介绍可以发现，每一个 boostrap 样本和相应的模型都是独立于其他样本和模型的。 这意味着每个模型都可以单独进行建模， 而只需在最后将所有模型的结果组合起来以生成最终的预测。类似能够并行化的还有随机森林模型。但是助推树不能，因为其集成方式不是独立的。 装袋法的另一个劣势在于解释性差，这是所有类似集成模型共同的劣势。通常也被称为黑箱模型。我们无法在装袋法中得到之前单棵回归树给出的简洁且易于描述的规则。然而，变量重要性依旧可以通过将单个模型的重要性得分集合起来得到。比如，我们可以记录有将某个变量用于分裂点的树中其导致RSS的减小，然后在所有的树上取平均。 下面我们展示如何用R建立装袋树，先得到自变量和应变量： library(caret) library(pROC) dat &lt;- read.csv(&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;) # 将10个问卷调查变量当作自变量 trainx &lt;- dat[, grep(&quot;Q&quot;, names(dat))] # 将类别也作为自变量 # 不对消费者类别进行变换 trainx$segment &lt;- dat$segment # 性别作为应变量 trainy &lt;- dat$gender 大家可以自己对树的数目进行调优，这里我们用1000棵树： set.seed(100) bagTune &lt;- caret::train(trainx, trainy, method = &quot;treebag&quot;, nbagg = 1000, metric = &quot;ROC&quot;, trControl = trainControl(method = &quot;cv&quot;, summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)) 调优的结果如下： bagTune ## Bagged CART ## ## 1000 samples ## 11 predictor ## 2 classes: &#39;Female&#39;, &#39;Male&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 900, 899, 901, 900, 900, 900, ... ## Resampling results: ## ## ROC Sens Spec ## 0.7016242 0.6642532 0.6522727 ## ## 可以看到，最优的ROC比之前单棵树有所改进。ROC曲线上的最优点，也就是最靠近左上角的点对应敏感度（Sens）为0.66，特异度（Spec）为0.65。这里因为变量的个数并不多，所以改进不那么明显，在变量多的时候装袋树的表现可能远好过单棵树。 12.5 随机森林 我们已经知道装袋树使用了boostrap样本，但这些树之间并不是独立的，因为这些树的每个分裂点上都考虑了所有的自变量。可以想象，如果初始的样本量足够大，而且树模型可以充分刻画预测变量与因变量之间的关系，那么不同bootstrap样本生成的树应该具有类似的结构（特别是在树顶部分），因为它们背后的关系是相近的。这一特点被称为树相关性，它会使得装袋法不能最大限度地减少预测值的方差。这说明，装袋法对方差的缩减还可以进一步通过减小树之间的相关性得以提升。对树相关现象的数学解释，可以参见[73]。随机森林就是通过减少树的相关性在装袋树的基础上进行提高的。 从统计的角度来看，要减小预测变量之间的相关性，可以在建立树的过程中引入一定的随机性，使得每一棵树使用的变量有些不同。在Breiman发明装袋法后，有一些其他的作者通过在训练过程中加入随机性来进一步优化模型算法。由于树是装袋法中一个常见的模型，Dietterich[80]提出了随机选择切分点的想法，即在树的每一个分裂点处随机选择\\(m\\)个变量来生成树。另一种方法是随机选择变量的子集来构建整棵树[81, 82]。Breiman同样尝试了在响应变量中加入噪声来对树的结构进行扰动[83]。在对这些各种升级改版的装袋法进行研究之后，Breiman于2001年提出了随机森林[84]。随机森林建造树的时候，每个分裂处都会从所有\\(p\\)个变量中随机抽取\\(m\\)个，然后在其中选出最优的一个变量用于分裂。 通常情况下\\(m=\\sqrt{p}\\)。比如这里是10个问卷调查的问题，那么每个分裂点出随机抽取用于候选的变量大约为4。在考虑每个分裂点的时候，算法都会随机挑选新变量，通过这种方式减小树之间的相关性。这对于变量数目多的情况更加有效，这里由于我们一共只有10个变量，大家之后会看到，随机森林算法对结果的改进并不是很明显。这里每次选择变量的个数也是一个调优参数。在数据集合很大变量个数又很多的时候，对该参数调优的过程计算量比较大。这里建议在\\(m=\\sqrt{p}\\)附近取5个值先初步调优。森林中树的棵树是另外一个需要调优的参数。由于森林的规模越大，计算量就越大，通常情况下需要至少1000棵树，逐渐增加直到模型的效果没有改进。当模型表现趋于稳定后，增加更多的树没有什么帮助。 一般的基于树的随机森林算法如下： 基本的随机森林算法 选择模型数目B 对 i=1 到 B 执行 从原数据中生成一个bootstrap样本 在该样本上训练一个树模型 对每个分裂点执行 随机抽取m（&lt;p）个预测变量 在这k个变量中选择能用于划分数据的最优变量 终止 使用通常的终止树模型的规则决定何时让树停止生长（不要修剪） 终止 随机森林和树的主要不同在于随机抽取m个预测变量。如果\\(m=p\\)，那么随机森林等同于装袋。当我们有大量相关的变量时，通常选择较小的m比较好。下面我们用caret包调优随机森林模型： # 对入选的变量个数参数进行调优 mtryValues &lt;- c(1:5) set.seed(100) rfTune &lt;- train(x = trainx, y = trainy, # 指定随机森模型 method = &quot;rf&quot;, ntree = 1000, tuneGrid = data.frame(.mtry = mtryValues), importance = TRUE, metric = &quot;ROC&quot;, trControl = trainControl(method = &quot;cv&quot;, summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)) 随机森林调优结果，在这个例子中，变量的数目不多，随机森林调优过程得到的每次考虑的变量数目是1。最优的曲线下面积和装袋树相比又有所提高但是提高的程度不大： rfTune ## Random Forest ## ## 1000 samples ## 11 predictor ## 2 classes: &#39;Female&#39;, &#39;Male&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 899, 900, 900, 899, 899, 901, ... ## Resampling results across tuning parameters: ## ## mtry ROC Sens Spec ## 1 0.7169190 0.5340584 0.8204545 ## 2 0.7136964 0.6333766 0.7174747 ## 3 0.7149947 0.6477922 0.6995455 ## 4 0.7113993 0.6550325 0.6950000 ## 5 0.7092069 0.6514286 0.6882323 ## ## ROC was used to select the optimal model using the largest value. ## The final value used for the model was mtry = 1. 得到调优参数之后也可以通过randomForest包拟合随机森林。由于装袋树只是随机森林的一种特殊情况，所以当你在随机森林函数中设置\\(mtry=p\\)时，就能得到装袋树。 library(randomForest) rfit = randomForest(trainy ~ ., trainx, mtry = 1, ntree = 1000) 可以通过importance()函数得到变量的重要性： importance(rfit) ## MeanDecreaseGini ## Q1 9.403995 ## Q2 7.402103 ## Q3 8.145370 ## Q4 10.976084 ## Q5 5.351417 ## Q6 9.440028 ## Q7 6.341507 ## Q8 7.988312 ## Q9 5.853341 ## Q10 4.017603 ## segment 13.228502 这里对于分类的情况，重要性的衡量基于预测袋外数据时基尼系数减小的均值。可以用varImpPlot()函数对重要性绘图： varImpPlot(rfit) 可以看到，平均考虑所有的树，变量segment和Q4最重要对于区分用户性别最重要。 12.6 助推法 助推法最早发明于20世纪80年代[85, 86]，是用来解决分类问题。其被证明是一种强大的预测工具，被广泛地应用于基因表达[87, 88]、化学计量学[89]、音乐流派识别[90]等各个领域中。其大致思想是组合一系列的弱分类器（仅比随机猜测的预测效果好一些的分类器），使总体的误判率有所改进。 研究者花费了一段时间来寻找一种有效实现助推理论的算法，最后终于在1996年，Yoav Freund和Robert Schapire合作提出了自适助推（AdaBoost）算法[91]，这是Adaptive Boosting的缩写。在自适助推算法的成功问世之后，一些研究者[92]开始将自适助推算法与一系列的统计学概念联系起来，如损失函数，可加模型，逻辑回归等，并且指出助推法可以被解释为最小化指数损失的向前逐步可加模型。这用一个新的视角理解助推法的本质，使得助推法扩展至回归的问题。助推算法有好几种，这里我们介绍两种主要的方法：自适助推和随机梯度助推。 自适助推（AdaBoost） 我们从有名的“AdaBoost.M1.”算法开始，其由Yoav Freund和Robert Schapire的[93]提出。该算法考虑二分类问题，应变量编码为\\(Y \\in \\{-1, 1\\}\\)。对于自变量\\(X\\)，对应的分类器\\(G(X)\\)输出的预测值是1或者－1。在训练集样本上的误判率为： \\[\\bar{err}=\\frac{1}{N}\\Sigma_{i=1}^NI(y_i\\neq G(x_i))\\] 对于自适助推生成一系列弱分类器\\(G_m(x),\\ m=1,2,...,M\\)，每次迭代，算法都会基于当前样本权重发现最佳的分类器。在第m轮迭代中被误分的样本在m+1轮迭代中将赋予更高的权重，被正确分类的样本在下一轮迭代中权重会降低。这意味着分类困难的样本的权重会不断加大直至算法识别出能正确分类这些样本的模型。因此，该算法要求每轮迭代学习数据的不同方面，着眼于包含难以分类的样本区域。每一次迭代中都会基于误差率计算一个阶段权重。最后的预测是将这些弱分类器通过这些阶段权重进行加权平均： \\[G(x)=sign ( \\Sigma_{m=1}^M \\alpha_{m}G_m(x))\\] 这里\\(\\alpha_1,\\alpha_2,...,\\alpha_M\\)是每个阶段的权重。 AdaBoost.M1算法 一类样本值标记为+1，另一类样本值为-1 每个样本有着相同的起始权重（\\(w_i=\\frac{1}{N},i=1,...,N\\)） 对 m = 1到M 执行: 用\\(w_i\\)加权后的样本拟合一个弱分类器\\(G_m(x)\\) 计算出第M个模型的误判率（\\(err_m=\\frac{\\Sigma_{i=1}^Nw_i I(y_i\\neq G_m(x_i))}{\\Sigma_{i=1}^Nw_i}\\)） 计算第m轮迭代的权重值\\(\\alpha_m=ln\\frac{1-err_m}{err_m}\\) 更新样本权重\\(w_i = w_i\\cdot exp[\\alpha_m\\cdot I(y_i \\neq G_m(x_i))],\\ i=1,2,\\dots,N\\) 通过下面方式计算助推分类器对每个样本的预测：\\(G(x)=sign[\\Sigma_{m=1}^M\\alpha_mG_m(x)]\\)，\\(sign(\\cdot)\\)表示如果\\(\\cdot\\)是正数，那么将样本判定为+1类，反之为-1类 AdaBoost.M1算法也称为“离散AdaBoost”算法，因为迭代产生的分类器\\(G_m(x)\\)返回的是离散的标签，如果分类器返回的是数值，比如一个概率值，可以对上面算法进行适当修改[92]。助推可应用于任何分类技术，但是分类树是助推的一个常用方法，因为分类树可以通过限制树的深度减少分裂数目制造弱分类器。Breinman[94]解释了为什么分类树在助推上表现良好。由于分类树是一种低偏差/高方差的技术，树的集合有助于降低方差，产生一个低方差低偏差的结果。助推无法显著改进低方差的模型。因此，助推对诸如LDA或KNN等的改善程度不像其对神经网络[95]和朴素贝叶斯方法那样显著[96]。 随机梯度助推 Friedman等[92]提供了自适助推算法的统计学见解，并且指出助推法可以被解释为最小化指数损失的向前逐步可加模型。该框架产生了一些泛化算法，如Real AdaBoost、Gentle AdaBoost和LogitBoost。随后，这些算法被统一放入一个称为梯度助推器的框架内。本章最后的知识扩展小节介绍了将助推放在向前逐步可加模型框架内，希望有一定数学基础的小伙伴能花些时间理解背后的基本原理。 对二分类问题的简单梯度助推 设定样本预测初始值为对数发生： 对 j=1到M 执行 计算残差（即，梯度）\\(z_i=y_i-\\hat{p}_i\\) 对训练集随机抽样 基于随机样本，将之前得到的残差作为结果变量训练树模型 计算终节点Pearson残差的估计：\\(r_i=\\frac{1/n\\Sigma_i^n(y_i-\\hat{p}_i)}{1/n\\Sigma_i^n\\hat{p}_i(1-\\hat{p}_i)}\\) 更新当前模型为：\\(f_i=f_i+\\lambda f_i^{(j)}\\) 结束 在回归中，当树模型用作基础的学习器，基本的梯度助推有两个调优参数：树深度（或交互深度）和迭代的次数。随机梯度助推对事件概率建模的公式为，与我们在逻辑回归中见到的类似： \\[\\hat{p}_i=\\frac{1}{1+exp[-f(x)]}\\] 上式中，\\(f(x)\\)为在的模型预测值。举例来说，模型的初始估计可能是样本的对数发生比，公式中p为训练集中一个类的样本比例。 使用者可以通过选择合适的损失函数和对应的梯度来使算法更具有针对性[73]。收缩可以在算法最后一步实现。若在该算法第一步内循环前添加一个随机抽样方案，则其可以归入随机梯度助推框架。 助推方法在分类问题中变量重要性的计算方式和在回归问题中类似：对于集合中任何一棵树，每个变量带来的分裂准则的改进（对于所有使用该变量的分裂点）的累加得到一个重要性值（这个值是某个变量在某个树上的重要性累加值）。集合内所有树上的重要性值的平均就是相应变量重要性。 自从助推法问世以来一直很受青睐，尤其是在分类问题上，常常被用来当作基础学习器。很多崇尚“拿来主义”的分析师通常将助推树当成一切问题的万精油。目前为止，这个方法在大多数情况下都能够给出合理的结果，虽然并不总是最优的模型。对于那些对模型背景知识不了解，只知道通过使用相应代码实践模型的分析人员，助推树确实是很好的“现成模型”，因为它不需要对数据进行预处理，也不要求你解释变量。但对于想要更近一步的小伙伴们，我建议大家还是努力了解背后的原理，这样一来能够知道在什么场合其它模型可能会给出更好的结果。使用一个你完全不了解的东西不仅仅有风险，也不符合匠人精神。个人认为，模型和分析的美，都在于其背后的原理和思想，而数学只是表达这个思想的一种方式。 下面我们展示如何用R拟合助推树。 gbmGrid &lt;- expand.grid(interaction.depth = c(1, 3, 5, 7, 9), n.trees = 1:5, shrinkage = c(.01, .1), n.minobsinnode = c(1:10)) set.seed(100) gbmTune &lt;- train(x = trainx, y = trainy, method = &quot;gbm&quot;, tuneGrid = gbmGrid, metric = &quot;ROC&quot;, verbose = FALSE, trControl = trainControl(method = &quot;cv&quot;, summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)) 得到的调优结果显示，最优的参数设置是n.trees = 4，interaction.depth = 3，shrinkage = 0.01以及n.minobsinnode = 6。 # 由于篇幅所限，这里只展示部分输出 gbmTune ... ROC was used to select the optimal model using the largest value. The final values used for the model were n.trees = 4, interaction.depth = 3, shrinkage = 0.01 and n.minobsinnode = 6. 我们来比较下各种树模型给出的结果： treebagRoc &lt;- roc(response = bagTune$pred$obs, predictor = bagTune$pred$Female, levels = rev(levels(bagTune$pred$obs))) rfRoc &lt;- roc(response = rfTune$pred$obs, predictor = rfTune$pred$Female, levels = rev(levels(rfTune$pred$obs))) gbmRoc &lt;- roc(response = gbmTune$pred$obs, predictor = gbmTune$pred$Female, levels = rev(levels(gbmTune$pred$obs))) plot(rpartRoc, type = &quot;s&quot;, print.thres = c(.5), print.thres.pch = 16, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2, col = &quot;black&quot;, legacy.axes = TRUE, print.thres.col = &quot;black&quot;) ## ## Call: ## roc.default(response = rpartTune1$pred$obs, predictor = rpartTune1$pred$Female, levels = rev(levels(rpartTune1$pred$obs))) ## ## Data: rpartTune1$pred$Female in 13380 controls (rpartTune1$pred$obs Male) &lt; 16620 cases (rpartTune1$pred$obs Female). ## Area under the curve: 0.667 plot(treebagRoc, type = &quot;s&quot;, add = TRUE, print.thres = c(.5), print.thres.pch = 3, legacy.axes = TRUE, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2, col = &quot;red&quot;, print.thres.col = &quot;red&quot;) ## ## Call: ## roc.default(response = bagTune$pred$obs, predictor = bagTune$pred$Female, levels = rev(levels(bagTune$pred$obs))) ## ## Data: bagTune$pred$Female in 446 controls (bagTune$pred$obs Male) &lt; 554 cases (bagTune$pred$obs Female). ## Area under the curve: 0.7 plot(rfRoc, type = &quot;s&quot;, add = TRUE, print.thres = c(.5), print.thres.pch = 1, legacy.axes = TRUE, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2, col = &quot;green&quot;, print.thres.col = &quot;green&quot;) ## ## Call: ## roc.default(response = rfTune$pred$obs, predictor = rfTune$pred$Female, levels = rev(levels(rfTune$pred$obs))) ## ## Data: rfTune$pred$Female in 2230 controls (rfTune$pred$obs Male) &lt; 2770 cases (rfTune$pred$obs Female). ## Area under the curve: 0.7113 plot(gbmRoc, type = &quot;s&quot;, add = TRUE, print.thres = c(.5), print.thres.pch = 10, legacy.axes = TRUE, print.thres.pattern = &quot;&quot;, print.thres.cex = 1.2, col = &quot;blue&quot;, print.thres.col = &quot;blue&quot;) ## ## Call: ## roc.default(response = gbmTune$pred$obs, predictor = gbmTune$pred$Female, levels = rev(levels(gbmTune$pred$obs))) ## ## Data: gbmTune$pred$Female in 223000 controls (gbmTune$pred$obs Male) &lt; 277000 cases (gbmTune$pred$obs Female). ## Area under the curve: 0.69 legend(0.2, 0.5, cex = 0.8, c(&quot;Single Tree&quot;, &quot;Bagged Tree&quot;, &quot;Random Forest&quot;, &quot;Boosted Tree&quot;), lwd = c(1, 1, 1, 1), col = c(&quot;black&quot;, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;), pch = c(16, 3, 1, 10)) 这里由于数据集中的变量并不多，各个模型的差异并不是那么明显，但是集成方法还是优于单棵树。在很多实际应用中，集成方法通常远好于单棵树。树模型还有一个作用，就是能很快的给你一个模型表现的基准线。也就是说在你刚拿到数据时，可以运行一个随机森林模型看看精确度如何，这可以给你一个大致模型可能表现的概念。之后可以探索不同的模型在此基础上进行精度优化。倘若随机森林给出的模型精度和随机猜测差不多，那你可能需要考虑收集更多的数据，或者重新审视商业问题了。因为在这种情况下，即使你找到更好的模型，精度也未必能够高出太多。这个诀窍可以让你避免很多不必要的模型探索时间。 想要了解助推方法更多理论背景的小伙伴可以花时间阅读知识扩展小节，这些小节要求一定的数学背景。 12.7 知识扩展：助推法的可加模型框架 助推法其实没有想象中的那么神秘。如前所述，Friedman[92]将自适助推算法与一系列的统计学概念联系起来，并且指出助推法可以被解释为最小化指数损失的向前逐步可加模型。本小节将介绍可加模型框架下的助推法，理解这一点有助于大家理解该模型的本质。 很多看似不同的模型，其本质都是基扩展模型。回顾AdaBoost.M1算法最终得到的分类器： \\[G(x)=sign ( \\Sigma_{m=1}^M \\alpha_{m}G_m(x))\\] 其实上面式子就符合基扩展模型： \\[ \\begin{equation} f(x)=\\Sigma_{m=1}^M \\beta_m b(x,\\gamma_m) \\label{eq:basisexp} \\end{equation} \\] 其中\\(\\beta_m,\\ m=1,\\dots,M\\)是扩展系数，\\(b(x,\\gamma)\\in \\mathbb{R}\\)就是基函数，通常是x的函数，其中\\(\\gamma\\)是定义函数的参数。很多常见的方法都可以表达为这种基扩展模型的形式，由于篇幅所限，本书并没有讲到所有的方法，这里列举几个这类模型，感兴趣的小伙伴可以参考相关资料： 对于单层级神经网络（可参考[73]的第11章），\\(b(x;\\gamma)=\\sigma(\\gamma_0+\\mathbf{\\gamma_1^{T}x})\\)，其中\\(\\sigma(t)=\\frac{1}{1+e^{-t}}\\)是一个S型曲线函数，\\(\\mathbf{\\gamma}\\)是自变量\\(\\mathbf{x}\\)线性组合的参数。 多元自适应回归样条（MARS）法中（可参考[73]的9.4小节），其中\\(b(x;\\gamma)=(x_j-\\gamma_m)_{+}\\)或者\\(b(x;\\gamma)=(\\gamma_m-x_j)_{+}\\)。 对于树模型，参数\\(\\gamma\\)控制了每个节点使用的变量和分裂点，以及最后的总节点的预测。 这些模型本质上其实是最小化在训练集样本上的损失函数： \\[\\underset{\\{\\beta_m,\\gamma_m\\}_i^M}{min}\\Sigma_{i=1}^N L\\left(y_i,\\Sigma_{m=1}^M\\beta_{m}b(x_i;\\gamma_m)\\right)\\] 对于不同的模型，基础函数\\(b(x_i;\\gamma_m)\\)不同，同时损失函数\\(L(\\cdot)\\)也有很多不同的选择，比如平方误差，或者基于似然函数的损失函数。不管怎么选择这两个函数，通常情况下在整个训练集样本上最优化上式的计算量都非常大。好消息是，通常问题可以简化为优化单一迭代的损失： \\[\\underset{\\beta,\\gamma}{min}=\\Sigma_{i=1}^N L(y_i,\\beta b(x_i;\\gamma))\\] 向前逐步可加模型算法可以用来逼近上面优化解，该算法在原基底上迭代加上新的基函数。具体算法如下： 向前逐步可加模型算法 初始化函数\\(f_0(x)=0\\) 对于\\(m=1,\\dots,M\\)： 计算 \\[(\\beta_m,\\gamma_m)=\\underset{\\beta,\\gamma}{argmin}\\Sigma_{i=1}^NL(y_i,f_{m-1}(x_i)+\\beta b(x_i;\\gamma))\\] 设置\\(f_m(x)=f_{m-1}(x)+\\beta_m b(x;\\gamma_m)\\) 在每次迭代m中，算法会在之前基底\\(f_{m-1}(x)\\)上寻找最优的基函数\\(b(x;\\gamma_m)\\)和\\(\\beta_m\\)，基底加上新的基函数能够最小化损失函数。随后更新得到新的基底\\(f_m(x)\\)。 如果我们使用平方误差损失： \\[L(y,f(x))=(y-f(x))^2\\] 对应可以得到： \\[L(y_i,f_{m-1}(x_i)+\\beta b(x_i;\\gamma))=(y_i-f_{m-1}(x_i)-\\beta b(x_i;\\gamma))^2\\] 其中\\(y_i-f_{m-1}(x_i)\\)是当前模型下第i个样本对应的残差。也就是说，在平方误差损失下，每一步迭代其实是在拟合之前模型的残差。这也是最小二乘助推回归的基本思想。但平方损失并不是一个好的选择，用于回归问题时容易受离群点的影响，所以我们通常会选择其它损失函数。 类似的，之前的AdaBoost.M1算法是向前逐步可加模型算法取下面损失函数时的一个特例： \\[L(y,f(x))=exp(-yf(x))\\] 在AdaBoost.M1算法中，基函数是每次迭代得到的分类器\\(G_m(x)\\in \\{-1,1\\}\\)。如果使用上面指数损失函数，相应优化问题为： \\[\\begin{array}{ccc} (\\beta_m,G_m) &amp; = &amp; \\underset{\\beta,G}{argmin}\\Sigma_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\\beta G(x_i))]\\\\ &amp; = &amp; \\underset{\\beta, G}{argmin}\\Sigma_{i=1}^N exp[-y_i \\beta G(x_i)]\\cdot exp[-y_if_{m-1}(x_i)]\\\\ &amp; = &amp; \\underset{\\beta, G}{argmin}\\Sigma_{i=1}^N w_i^m exp[-y_i\\beta G(x_i)] \\end{array} \\] 其中\\(w_i^m= exp[-y_if_{m-1}(x_i)]\\)，其并不依赖于\\(\\beta\\)和\\(G(x)\\)，因此可以看成对每个观测赋予的权重。该权重和\\(f_{m-1}(x_i)\\)有关，因此每次迭代权重也会相应变化。我们可以进一步分解上面优化函数： \\[\\begin{array}{ccc} (\\beta_{m},G_{m}) &amp; = &amp; \\underset{\\beta,G}{argmin}\\Sigma_{i=1}^{N}w_{i}^{m}exp[-y_{i}\\beta G(x_{i})]\\\\ &amp; = &amp; \\underset{\\beta,G}{argmin}\\Sigma_{i=1}^{N}\\left\\{ w_{i}^{m}e^{-\\beta}I(y_{i}=G(x))+w_{i}^{m}e^{\\beta}I(y_{i}\\neq G(x))\\right\\} \\\\ &amp; = &amp; \\underset{\\beta,G}{argmin}\\Sigma_{i=1}^{N}\\left\\{ w_{i}^{m}e^{-\\beta}[1-I(y_{i}\\neq G(x))]+w_{i}^{m}e^{\\beta}I(y_{i}\\neq G(x))\\right\\} \\\\ &amp; = &amp; \\underset{\\beta,G}{argmin}\\left\\{ (e^{\\beta}-e^{-\\beta})\\cdot\\Sigma_{i=1}^{N}w_{i}^{m}I(y_{i}\\neq G(x_{i}))+e^{-\\beta}\\cdot\\Sigma_{i=1}^{N}w_{i}^{m}\\right\\} \\end{array}\\] 当\\(\\beta &gt;0\\)时，上式的解为： \\[G_{m} = \\underset{G}{argmin}\\Sigma_{i=1}^{N}w_{i}^{m}I(y_{i}\\neq G(x))\\] 也就是寻找最小化加权误判率的判别器。将上面\\(G_m\\)代入优化函数，对\\(\\beta\\)求导设置其为0，可以解出： \\[\\beta_m =\\frac{1}{2}ln\\frac{1-err_m}{err_m}\\] 其中 \\[err_m = \\frac{\\Sigma_{i=1}^N w_i^{m}I(y_i \\neq G_m(x_i))}{\\Sigma_{i=1}^N w_i^{m}}\\] 根据向前逐步可加模型算法，结果更新为： \\[f_m(x)=f_{m-1}(x)+\\beta_m G_m(x)\\] 进而我们可以得到下一次迭代的权重： \\[\\begin{array}{ccc} w_i^{m+1} &amp; = &amp; exp[-y_if_m (x_i)]\\\\ &amp; = &amp; exp[-y_if_{m-1}(x)-y_i \\beta_m G_m(x)]\\\\ &amp; = &amp; w_{i}^{m}\\cdot exp[-\\beta_m y_i G_m(x_i)] \\end{array}\\] 由于\\(-y_i G_m(x_i)=2\\cdot I(y_i \\neq G_m(x_i))-1\\)，上式可以进一步写为： \\[w_i^{m+1}=w_i^m \\cdot exp[\\alpha_mI(y_i\\neq G_m(x_i))] \\cdot exp[-\\beta_m]\\] 其中\\(\\alpha_m=2\\beta_m=ln\\frac{1-err_m}{err_m}\\)，和之前AdaBoost.M1算法中的\\(\\alpha_m\\)一样。因此，AdaBoost.M1算法实际上是向前逐步可加模型算法的一个特例。关于损失函数的选择和比较，大家可以参考[73]的10.5和10.6小节。 12.8 知识扩展：助推树的数学框架 12.8.1 数学表达 之前介绍简单回归和分类树时讲过，建立树的目的是找到自变量区域的划分\\(R_j,\\ j=1,2,\\dots,J\\)，对每个划分区域内的样本指定一个拟合值\\(\\gamma_j\\)： \\[x\\in R_j \\Rightarrow f(x)=\\gamma_j\\] 树模型可以用如下方式表达： \\[ \\begin{equation} T(x;\\Theta)=\\Sigma_{j=1}^J\\gamma_j I(x\\in R_j) \\label{eq:btree} \\end{equation} \\] 这里\\(\\Theta=\\{R_j,\\gamma_j\\}_i^J\\)。通常将J视为元参数。我们通过最小化下面的损失函数来估计参数： \\[ \\begin{equation} \\hat{\\Theta}=\\underset{\\Theta}{argmin}\\Sigma_{j=1}^J \\Sigma_{x_i\\in R_j}L(y_i,\\gamma_i) \\label{eq:theta} \\end{equation}\\] 之前讲过，这个优化几乎不可能实现。我们只能通过某种算法逼近局部最优解。将这个复杂优化问题拆分成两部分可能有助于理解： 给定\\(R_j\\)的请况下优化\\(\\gamma_j\\)：如果给定了\\(R_j\\)，那么估计\\(\\gamma_j\\)就是分分钟的事情。对于回归，我们通常取每个区域的训练样本均值\\(\\hat{\\gamma}_j=\\bar{y}_j\\)。对于分类问题，我们就选择对应样本最多的类别。 寻找\\(R_j\\)：这才是真正困难的部分，也是需要设计算法逼近局部最优解的地方。注意在搜索\\(R_j\\)的过程也包含了估计\\(\\gamma_j\\)。典型的方法就是我们之前介绍过的从上到下（top-down）的递归贪婪算法。此外，为了逼近\\(\\eqref{eq:theta}\\)，我们通常需要选择一个平滑且方便的损失函数来优化\\(R_j\\)： \\[\\begin{equation} \\tilde{\\Theta}=\\underset{\\Theta}{argmin}\\ \\Sigma_{i=1}^N\\tilde{L}(y_i, T(x_i,\\Theta)) \\label{eq:ttheta} \\end{equation}\\] 给定\\(\\hat{R_j}=\\tilde{R_j}\\)可以得到\\(\\gamma_j\\)的估计。这样可能非常抽象，举个例子。对于二分类问题之前讲到过3个用来衡量节点杂合度的度量，它们都可以在这种情境下作为损失函数： 误判率：\\(\\frac{1}{N_m}\\Sigma_{i\\in R_m}I(y\\neq k(m))=1-\\hat{p}_{mk(m)}\\)（\\(k(m)=argmax_k\\hat{p}_{mk}\\)，也就是节点m中的样本观测频数最多的类） Gini系数：\\(\\Sigma_{k\\neq k^{&#39;}}\\hat{p}_{mk}\\) 熵：\\(-\\Sigma_{k=1}^K \\hat{p}_{mk}log(\\hat{p}_{mk})\\) 在二分类的情况下，如果\\(p\\)是其中某类样本的比例，对应3个损失函数值分别是：\\(1-max(p,1-p)\\)，\\(2p(1-p)\\)和\\(-plog(p)-(1-p)log(1-p)\\)。可以看到，后两者是连续可导的，这大大方便了优化。所以我们通常使用Gini系数或者熵，而不用误判率来优化。 之前讲过，助推符合基扩展模型\\(\\eqref{eq:basisexp}\\),其是对树的求和： \\[ \\begin{equation} f_M(x)=\\Sigma_{m=1}^M T(x;\\Theta_m) \\label{eq:btree2} \\end{equation} \\] 在向前逐步可加模型算法中的每一步迭代，都在当前模型\\(f_{m-1}(x)\\)的条件下，计算下一棵树对应的\\(\\Theta_m=\\{R_{jm}, \\gamma_{jm}\\}_1^{J_{m}}\\)： \\[ \\begin{equation} \\hat{\\Theta}_m=\\underset{\\Theta_m}{argmin}\\Sigma_{i=1}^N L(y_i, f_{m-1}(x_i)+T(x_i;\\Theta_m)) \\label{eq:gb} \\end{equation} \\] 给定\\(R_{jm}\\)很容易估计\\(\\gamma_{jm}\\)： \\[ \\begin{equation} \\hat{\\gamma}=\\underset{\\gamma_{jm}}{argmin}\\ \\Sigma_{x_i\\in R_{jm}}L(y_i,f_{m-1}(x_i)+\\gamma_{jm}) \\label{eq:gamma} \\end{equation} \\] 优化\\(R_{jm}\\)是困难的。对于平方误差损失，\\(\\eqref{eq:gb}\\)其实就是对当前残差\\(y_i-f_{m-1}(x_i)\\)拟合回归树，且\\(\\hat{\\gamma}_{jm}\\)是当前每个区域对应的训练样本均值。 对于使用指数损失的二分类问题，当我们将\\(T(x;\\Theta_m)\\)的取值限定在\\(\\{1,-1\\}\\)上时，我们在前一个知识扩展小节已经证明过，逐步可加算法就是自适助推。用当前的表达就是寻找优化下面加权错误率的树： \\[\\Sigma_{i=1}^N\\ w_i^m I(y_i\\neq T(x_i;\\Theta_m))\\] 其中\\(w_i^m=e^{-y_if_{m-1}(x_i)}\\)，这里应变量的取值被标度化了，即\\(\\gamma_{jm}\\in \\{-1,1\\}\\)。这里即使不标度化，在指数损失的情况下\\(\\eqref{eq:gb}\\)仍然能够简化成一个对指数加权和的优化： \\[\\begin{array}{ccl} \\hat{\\Theta}_{m} &amp; = &amp; \\underset{\\Theta}{argmin}\\Sigma_{i=1}^{N}exp\\{-y_{i}[f_{m-1}(x_{i})+T(x_{i};\\Theta_{m})]\\}\\\\ &amp; = &amp; \\underset{\\Theta}{argmin}\\Sigma_{i=1}^{N}exp\\{-y_{i}f_{m-1}(x_{i})\\}\\cdot exp\\{-y_{i}T(x_{i};\\Theta_{m})\\}\\\\ &amp; = &amp; \\underset{\\Theta}{argmin}\\Sigma_{i=1}^{N}w_{i}^{m}exp\\{-y_{i}T(x_{i};\\Theta_{m})\\} \\end{array}\\] 使用上面加权指数损失为分裂准则，应用贪婪递归算法，对于每个\\(R_{jm}\\)，\\(\\hat{\\gamma}_{jm}\\)的估计为： \\[\\begin{array}{ccl} \\hat{\\gamma}_{jm} &amp; = &amp; \\underset{\\gamma_{jm}}{argmin}\\Sigma_{x_{i}\\in R_{jm}}exp\\{-y_{i}[f_{m-1}(x_{i})+\\gamma_{jm}]\\}\\\\ &amp; = &amp; \\underset{\\gamma_{jm}}{argmin}\\Sigma_{x_{i}\\in R_{jm}}exp\\{-y_{i}f_{m-1}(x_{i})\\}\\cdot exp\\{-y_{i}\\gamma_{jm}\\}\\\\ &amp; = &amp; \\underset{\\gamma_{jm}}{argmin}\\Sigma_{x_{i}\\in R_{jm}}w_{i}^{m}exp\\{-y_{i}\\gamma_{jm}\\}\\\\ &amp; = &amp; \\underset{\\gamma_{jm}}{argmin}\\left\\{ \\left[\\Sigma_{x_{i}\\in R_{jm}}w_{i}^{m}I(y_{i}=1)\\right]e^{-\\gamma_{jm}}+\\left[\\Sigma_{x_{i}\\in R_{jm}}w_{i}^{m}I(y_{i}=-1)\\right]e^{\\gamma_{jm}}\\right\\} \\end{array}\\] 假设\\(Q(\\gamma_{jm})=\\left\\{ \\left[\\Sigma_{x_{i}\\in R_{jm}}w_{i}^{m}I(y_{i}=1)\\right]e^{-\\gamma_{jm}}+\\left[\\Sigma_{x_{i}\\in R_{jm}}w_{i}^{m}I(y_{i}=-1)\\right]e^{\\gamma_{jm}}\\right\\}\\)。通过求解\\(\\frac{\\partial Q}{\\partial\\gamma_{jm}}=0\\)可以得到： \\[\\hat{\\gamma}_{jm}=\\frac{1}{2}ln\\frac{\\Sigma_{x_i\\in R_{jm}}w_i^mI(y_i=1)}{\\Sigma_{x_i\\in R_{jm}}w_i^mI(y_i=-1)}\\] 对于回归的情况，用Huber损失函数（绝对值损失）取代平方误差损失。对于分类情况，用 \\[L(y,p(x))=-\\Sigma_{k=1}^K I(Y=G_k)\\frac{e^{f_k(x)}}{\\Sigma_{l=1}^ke^{f_l(x)}}\\] 作为损失函数取代指数损失得到的助推树更加稳定。但是用这些损失函数并不能加速助推算法。对于一般的损失函数，给定\\(R_{jm}\\)的情况下\\(\\eqref{eq:gamma}\\)的解只不过是一个给定区域的位置估计，很容易得到。对于绝对值误差，这只不过是每个划分区域内相应样本残差的中位数。对于其它损失函数，也很能有迭代算法很快的得出相应区域的最优\\(\\gamma\\)取值。这里困难的依旧是寻找相应的划分区域\\(R_{jm}\\)。对于更加一般的损失函数，没有简单快速的求解\\(\\eqref{eq:gb}\\)的算法。因此我们需要用一种尽量逼近解的算法。 12.8.2 梯度助推数值优化 对于任何可微的损失函数，我们可以用类似于传统梯度优化的方法来逼近\\(\\eqref{eq:gb}\\)。假设在训练集上用\\(f(x)\\)来预测变量\\(y\\)，那么需要优化的就是如下损失函数: \\[ \\begin{equation} L(f)=\\Sigma_{i=1}^N L(y_i, f(x_i)) \\label{eq:generalLf} \\end{equation} \\] 我们需要最小化\\(L(f)\\)。在助推树中，\\(f\\)是一系列树的和： \\[f_{M}=\\Sigma_{m=0}^M h_m\\ h_m\\in R^N\\] 设定一个初始值\\(f_0=h_0\\)，接下来的每一次迭代中的\\(f_m\\)都是基于之前得到的\\(f_{m-1}\\)推导而来。不同的优化逼近的方法的差异就在于计算每一次迭代中的增量\\(h_m\\)。梯度下降法是非常流行的一种优化逼近算法，通常也称为最速下降法。该算法非常贪婪，要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。这里的每一步选择： \\[h_m=-\\rho_m g_m\\] 其中\\(\\rho_m\\)是一个标量，\\(g_m\\in R^N\\)是损失函数\\(L(f)\\)在当前值\\(f=f_{m-1}\\)时的梯度： \\[ \\begin{equation} g_{im}=\\left[\\frac{\\partial L(y_{i},f(x_{i}))}{\\partial f(x_{i})}\\right]_{f(x_{i})=f_{m-1}(x_{i})} \\label{eq:gradienm} \\end{equation} \\] 每一步乘的标量\\(\\rho_m\\)通过如下式子得到： \\[ \\begin{equation} \\rho_{m}=\\underset{\\rho}{argmin}L(f_{m-1}-\\rho g_{m}) \\label{eq:rhom} \\end{equation} \\] 于是当前迭代更新为： \\[ \\begin{equation} f_m=f_{m-1}-\\rho_m g_m \\label{eq:fm} \\end{equation} \\] 向前逐步助推（在二分类问题中，当使用指数损失且将结果限定在{-1,1}上时就是自适助推）也是一种非常贪婪的算法。每一步迭代都力图最大程度的拟合当前残差。因此该过程可以类比于\\(\\eqref{eq:gradienm}\\)。向前逐步助推和梯度助推的主要不同在于，逐步助推中最后组成结果的树是不独立的： \\[t_{m}=\\{T(x_{1};\\Theta_{m}),\\dots,T(x_{N};\\Theta_{m})\\}^{T}\\] 这里的\\(\\Theta_{m}=\\{R_{jm},\\gamma_{jm}\\}_{1}^{Jm}\\)的估计有个限制，就是终结点的数目是\\(J_m\\)个。而梯度助推没有这样的限定，该方法只是寻找最快速的下降路径。 通过逐步可加算法求解\\(\\eqref{eq:gamma}\\)的思想可以类比于通过\\(\\eqref{eq:rhom}\\)寻找最快速的下降路径。不同在于\\(\\eqref{eq:gamma}\\)是在不同的区域\\(R_{jm}\\)分别搜寻。如果最小化训练集上的损失\\(\\eqref{eq:generalLf}\\)是唯一目标的话，梯度下降法是很好的选择。对于任何可微的损失函数\\(L(y,f(x))\\)，梯度\\(\\eqref{eq:gradienm}\\)都很容易计算。 不幸的是，这里梯度\\(\\eqref{eq:gradienm}\\)仅仅在训练集数据上定义，然而我们的最终目标是能够预测新样本。一个解决方法是我们在第m次迭代中建立树\\(T(x;\\Theta_m)\\)来拟合基于训练集样本得出的负梯度。这里树的建造使用的是平方误差： \\[ \\begin{equation} \\hat{\\Theta}_{m}=\\underset{\\Theta}{argmin}\\Sigma_{i=1}^{N}(-g_{im}-T(x_{i};\\Theta))^{2} \\label{eq:negradient} \\end{equation} \\] 存在能够快速建立最小二乘回归树的算法。这里要特别注意一点，得到树之后我们使用的是推导出的划分区域\\(R_{jm}\\)，之后在该划分区域上继续沿用可加模型算法的思想。虽然\\(\\eqref{eq:negradient}\\)得到的划分区域和\\(\\eqref{eq:theta}\\)得到的划分区域不同，但通常很相近。下面是一般的梯度助推回归树算法： 梯度助推回归树 设置初始\\(f_0(x)=\\underset{\\gamma}{argmin}\\Sigma_{i=1}^{N}L(y_{i},\\gamma)\\) 对\\(m=1\\dots M\\)： 对\\(i=1\\dots N\\)，计算\\(-g_{im}=-\\left[\\frac{\\partial L(y_{i};f(x_{i}))}{\\partial f(x_{i})}\\right]_{f=f_{m-1}}\\) 对\\(-g_{im}\\)拟合回归树，得到终结点划分区域\\(R_{jm},\\ j=1,2,\\dots,J_m\\) 对\\(j=1,2,\\dots,J_m\\)，计算\\(\\gamma_{jm}=\\underset{\\gamma}{argmin}\\Sigma_{x_{i}\\in R_{jm}}L(y_{i},f_{m-1}(x_{i})+\\gamma)\\) 更新\\(f_{m(x)}=f_{m-1}(x)+\\Sigma_{j=1}^{J_{m}}\\gamma_{jm}I(x\\in R_{jm})\\) 输出\\(\\hat{f}(x)=f_M(x)\\) 对于分类的情况算法也类似，只是损失函数不同。如果类别数目\\(K&gt;2\\)，那么在每次迭代m内都需要对各个类别分别建立\\(K\\)棵树，即最后我们会得到\\(f_{kM},\\ k=1,\\dots,K\\)。 12.9 本章总结 预测建模是数据挖掘的一个重要话题。每个特定的方法都有适用和不适用的时候。但在实际应用中，事先很少知道哪个过程对于给定的问题将表现最好或甚至良好。 工业和商业数据挖掘应用在对学习过程的要求方面往往特别具有挑战性。因为现实情况可能有各种问题。数据集可能很大，所以需要考虑计算量的问题。而且数据通常不那么干净：自变量可能有多种类型，数值，二项以及多分类变量。而且时常发生数据缺失，完整无缺失的数据很少出现。数值型的变量观测常是长尾而且高度有偏的，而且还有离群值。变量的取值范围也不一样。 此外，通常自变量集合中只有很小一部分真正对应变量有预测作用。和模式识别的问题不同，在预测问题中通常无法通过相关应用领域的知识来筛选变量。和应变量无关的预测变量会影响很多模型的表现。如果应用的语境要求模型可解释，比如在市场营销中需要知道具体那些变量如何影响消费者行为，以便营销人员能够采取相应的行动，而不仅仅是预测，这时很多黑箱模型，如神经网络，就无法给出答案。 这些对计算机速度，结果可解释性的要求，以及不干净的数据使得很多模型不能拿来就用。那些“现成”模型指的是不需要数据预处理以及仔细的模型调试就能应用的模型。在所有模型中，树模型最接近“现成”的模型。 树模型可以处理不同类型的变量，对缺失值和离群值也稳健，如果对数值型变量进行单调变换的话不会影响模型拟合结果。由于其内在过程中有对变量进行选择（选择那些能够最优化相应准则的变量，如Gini系数，熵等），即使不能说完全不受冗余变量的影响，至少对无信息变量具有抗性。当树很小的时候可能还好解释，但前所述，单棵树通常非常不稳定，因此广泛使用的是集成方法。这导致模型难以解释（除了能够给出变量重要性排序以外）。总的来说，上面的这些特性使得树模型成为最受欢迎的模型。 References "],
["section-13.html", "第13章 深度学习 13.1 介绍 13.2 R中深度学习包", " 第13章 深度学习 13.1 介绍 深度神经网络（Deep Neural Network [DNN]）是人工智能神经网络（Artificial Neural Network [ANN]）的一种。DNN比ANN有更多的隐层级。和ANN一样，DNN也可以对复杂的非线性关系建模。DNN最主要的应用是图像物体识别，其本质上是一个组合模型，将图形对象当成许多基本图像元素层级叠加的结果。额外的层级使得模型能够包含更低层级的特征。 DNN的设计主要是前馈网络（feedforward networks）但也有成功应用递归神经网络（recurrent neural networks）的研究，尤其是LSTM，其主要应用于自然语言处理。卷积深度神经网络（Convolutional deep neural networks [CNNs]）成功的应用在计算机视觉方面。CNNs在声学模型（比如自动话语识别）上的效果也超过其它模型。 我们会在这一章中简要介绍下深度学习。在此之前，我们得先从浅度学习开始。 历史 可能大部分人都不会想到，最早的神经网络实际上是用硬件实施的而非软件。1943神经生理学家Warren McCulloch和数学家Walter Pitts写了一篇关于神经潜在工作原理的论文。为了描述脑中的神经元是如何工作的，他们用电路模拟了一个简单的神经网络。 反向传播（backpropagation） 反向传播是常见的训练神经网络的方法，通常和某个最优化的方法联合使用，比如梯度下降法。该方法对网络中的某权重设置计算相应的损失函数梯度。然后再用这个梯度信息更新权重设置，持续迭代达到最小化损失函数的作用。 架构 多层感知器（Multilayer Perceptron） 多层感知器（MLP）是一个前馈（feed-forward）人工神经网络模型。恰如其名，MLP由多个节点层级组成，除了初始的输入层级，其余每个层级都和下一个充分连接。也就是说，下一个层级中的每个节点都和之前层级中的每个节点之间有联系。输入层级以外的每个层级节点都是一个神经元（或者处理单元）。MLP就是用之前讲到的反向传播训练神经网络，它是在标准线性感知器基础上的改进，能够识别线性不可分的数据。 递归神经网络（recurrent neural network） 递归神经网络（RNN）是单元间连接能够组成定向圆圈的这类人工神经网络。 和前馈式神经网络不同，RNN可以通过其形成的内部记忆处理任意指定的一系列输入。这种特性使其适合用于手写识别和语音识别。有一些Twitter机器人用的就是时间递归神经网络（RNN）中的长短期记忆人工神经网络（Long-Short Term Memory, LSTM），比如@DeepDrumpf和@DeepLearnBern，创建者是MIT的Brad Hayes。 卷积神经网络（CNN或ConvNet） 卷积神经网络（CNN或者ConvNet）是一种前馈人工神经网络。其中神经元之间的连接模式设计是模仿动物视觉皮质的构造。动物视觉皮质中单独神经元按照平铺视野的重叠区域排列。卷积神经网络的思想是受生物生物过程的启发。它使用多层感知器，尽量最小化对预处理的要求。该模型广泛应用于图像、视频识别、推荐系统和自然语言处理。 13.2 R中深度学习包 这里我们简单展示一下R中用于深度学习的几个包。这里的展示涉及CPU而非GPU。当然，当数据集大时可能需要使用GPU。 这里主要还是针对结构化数据（数据框）。有一些深度挖掘的软件可以直接处理图像数据，但我们不会在这里介绍。 mxnet包 下面的代码展示如何通过mxnet包（http://mxnet.readthedocs.io/en/latest/how_to/build.html#rpackageinstallation）训练充分连接的前馈ANN模型。该包后端代码基于C++，用来实现深度神经网络模型。下面MXNet案例代码是在此博（http://www.rbloggers.com/deeplearningwithmxnetr/）代码基础上修改而来。 "],
["references.html", "第14章 References", " 第14章 References "]
]
