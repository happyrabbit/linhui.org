<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.0.60 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-04-04">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-4.html">
<link rel="next" href="section-6.html">

<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 模拟服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 问题到数据</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 数据到信息</a></li>
<li class="chapter" data-level="3.4" data-path="section-3.html"><a href="section-3.html#section-3.4"><i class="fa fa-check"></i><b>3.4</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据预处理</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#-1"><i class="fa fa-check"></i><b>4.1</b> 介绍</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据清理</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="4.3.1" data-path="section-4.html"><a href="section-4.html#section-4.3.1"><i class="fa fa-check"></i><b>4.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="4.3.2" data-path="section-4.html"><a href="section-4.html#k-"><i class="fa fa-check"></i><b>4.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="4.3.3" data-path="section-4.html"><a href="section-4.html#section-4.3.3"><i class="fa fa-check"></i><b>4.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="section-4.html"><a href="section-4.html#section-4.4"><i class="fa fa-check"></i><b>4.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="4.5" data-path="section-4.html"><a href="section-4.html#section-4.5"><i class="fa fa-check"></i><b>4.5</b> 有偏分布</a></li>
<li class="chapter" data-level="4.6" data-path="section-4.html"><a href="section-4.html#section-4.6"><i class="fa fa-check"></i><b>4.6</b> 处理离群点</a></li>
<li class="chapter" data-level="4.7" data-path="section-4.html"><a href="section-4.html#section-4.7"><i class="fa fa-check"></i><b>4.7</b> 共线性</a></li>
<li class="chapter" data-level="4.8" data-path="section-4.html"><a href="section-4.html#section-4.8"><i class="fa fa-check"></i><b>4.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="4.9" data-path="section-4.html"><a href="section-4.html#section-4.9"><i class="fa fa-check"></i><b>4.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="4.10" data-path="section-4.html"><a href="section-4.html#section-4.10"><i class="fa fa-check"></i><b>4.10</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="4.10.1" data-path="section-4.html"><a href="section-4.html#apply"><i class="fa fa-check"></i><b>4.10.1</b> apply()函数</a></li>
<li class="chapter" data-level="4.10.2" data-path="section-4.html"><a href="section-4.html#ddply"><i class="fa fa-check"></i><b>4.10.2</b> ddply()函数</a></li>
<li class="chapter" data-level="4.10.3" data-path="section-4.html"><a href="section-4.html#section-4.10.3"><i class="fa fa-check"></i><b>4.10.3</b> 数据整形</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="section-4.html"><a href="section-4.html#section-4.11"><i class="fa fa-check"></i><b>4.11</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 建模技术简介</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 误差及其来源</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#section-5.3.2"><i class="fa fa-check"></i><b>5.3.2</b> 拟合模型</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 评估模型表现</a></li>
<li class="chapter" data-level="5.3.4" data-path="section-5.html"><a href="section-5.html#section-5.3.4"><i class="fa fa-check"></i><b>5.3.4</b> 失衡数据</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 特征工程</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 变量选择</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 主成分分析</a></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 因子分析</a></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#section-6.4"><i class="fa fa-check"></i><b>6.4</b> 高维标度化</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 普通线性回归</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 收缩方法</a></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 分层线性回归</a></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#section-7.4"><i class="fa fa-check"></i><b>7.4</b> 贝叶斯线性回归</a></li>
<li class="chapter" data-level="7.5" data-path="section-7.html"><a href="section-7.html#section-7.5"><i class="fa fa-check"></i><b>7.5</b> 贝叶斯分层线性回归</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 树模型</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 基本树模型</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 装袋树</a></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> 随机森林</a></li>
<li class="chapter" data-level="8.4" data-path="section-8.html"><a href="section-8.html#section-8.4"><i class="fa fa-check"></i><b>8.4</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 聚类分析</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 判别分析</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 关联法则分析</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 关联法则简介</a></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 案例：商业购物篮分析</a></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 关联法则可视化</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 数据可视化和结果展示</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#r-markdown"><i class="fa fa-check"></i><b>11.1</b> R Markdown</a><ul>
<li class="chapter" data-level="11.1.1" data-path="section-11.html"><a href="section-11.html#what-is-r-markdown"><i class="fa fa-check"></i><b>11.1.1</b> What is R Markdown?</a></li>
<li class="chapter" data-level="11.1.2" data-path="section-11.html"><a href="section-11.html#how-to-start"><i class="fa fa-check"></i><b>11.1.2</b> How to Start?</a></li>
<li class="chapter" data-level="11.1.3" data-path="section-11.html"><a href="section-11.html#interactive-r-markdown-document"><i class="fa fa-check"></i><b>11.1.3</b> Interactive R Markdown Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 数据科学的科学</a></li>
<li class="chapter" data-level="13" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-5" class="section level1">
<h1><span class="header-section-number">第5章</span> 建模技术简介</h1>
<p>建模技术指代一系列用于理解数据的工具。本章介绍基本的统计学习术语，概念，以及一些辅助性的技能。后面章节会分别对一些特定模型进行展开。</p>
<div id="section-5.1" class="section level2">
<h2><span class="header-section-number">5.1</span> 有监督和无监督</h2>
<p>建模技术可以粗略的分为有监督和无监督这两类。大部分统计学习方法都可以归于其中一种。广义上说<strong>有监督方法</strong>涉及根据一个或者多个输入变量（也称为自变量，解释变量，预测变量），估计或者预测一个<strong>结果变量</strong>（也称为因变量，响应变量）。而<strong>无监督方法</strong>只考虑自变量，没有应变量作为“监督”，我们通过这类方法探索观测数据中内在变量结构。我们在之前提到的方法中，袋状树，广义线性回归是有监督方法；主成分分析，探索性因子分析，对近0方差和高相关变量的筛选都是无监督方法。</p>
<p>下面我们先对本书之后的数学公式表达进行统一。</p>
<p>我们用<span class="math">\(n\)</span>表示样本量（或者观测数目）。<span class="math">\(p\)</span>代表自变量数目。我们用<span class="math">\(\mathbf{X}\)</span>表示<span class="math">\(n\times p\)</span>观测矩阵：</p>
<p><span class="math">\[
\mathbf{X}=\left[\begin{array}{cccc}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{array}\right]
\]</span></p>
<p>其中<span class="math">\(x_{ij}\)</span>代表第i个样本第j个变量的观测，<span class="math">\(i=1, \ldots, n\)</span>，<span class="math">\(j=1, \ldots, p\)</span>。<span class="math">\(\mathbf{x_{i.}}\)</span>代表第i个样本的所有变量观测组成的向量，向量统一按列排：</p>
<p><span class="math">\[
\mathbf{x_{i.}}=\left[\begin{array}{c}
x_{i1}\\
x_{i2}\\
\vdots\\
x_{ip}
\end{array}\right]
\]</span></p>
<p>类似的，<span class="math">\(\mathbf{x_{.j}}\)</span>代表第j个变量的所有样本观测组成的向量：</p>
<p><span class="math">\[
\mathbf{x_{.j}}=\left[\begin{array}{c}
x_{1j}\\
x_{2j}\\
\vdots\\
x_{nj}
\end{array}\right]
\]</span></p>
<p>于是我们有：</p>
<p><span class="math">\[
\mathbf{X}=\left[\begin{array}{cccc}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{array}\right]=\left[\begin{array}{c}
\mathbf{x_{1.}^{T}}\\
\mathbf{x_{2.}^{T}}\\
\vdots\\
\mathbf{x_{n.}^{T}}
\end{array}\right]=\left[\begin{array}{cccc}
\mathbf{x_{.1}} &amp; \mathbf{x_{.2}} &amp; \ldots &amp; \mathbf{x_{.p}}\end{array}\right]
\]</span></p>
<p>其中<span class="math">\(^{T}\)</span>代表矩阵转秩。我们用<span class="math">\(y_{i}\)</span>代表第i个样本对应的响应变量。所有<span class="math">\(n\)</span>个响应变量组成的向量为：</p>
<p><span class="math">\[
\mathbf{y}=\left[\begin{array}{c}
y_{1}\\
y_{2}\\
\vdots\\
y_{n}
\end{array}\right]
\]</span></p>
<p>有监督和无监督建模技术用上面的符号语言表达就是：</p>
<ol style="list-style-type: decimal">
<li>无监督建模：探索<span class="math">\(\mathbf{X}\)</span>中的自变量之间的关系</li>
<li>有监督建模：估计<span class="math">\(\mathbf{y}\)</span>和<span class="math">\(\mathbf{X}\)</span>之间的关系 <span class="math">\(f(\cdot)\)</span></li>
</ol>
<p>其中<span class="math">\(\mathbf{\epsilon}\)</span> 是随机误差，均值为<span class="math">\(\mathbf{0}\)</span>。函数<span class="math">\(f(\cdot)\)</span>是我们的建模目标，代表X能够提供的关于Y的系统信息（和随机性相对应）。估计<span class="math">\(f(\cdot)\)</span>目的主要是推断或者预测，有时兼有两者。通常情况下，模型的灵活性和可解释性之间是一种此消彼长的关系——灵活性越高的模型可解释性越弱。因此数据科学家需要把握这两者间微妙的平衡。不同的建模目的对模型解释性的要求不同，因而极大影响了模型选择。如果预测是唯一目的，那么模型的解释性就不在考虑范围内，这种情况下可以使用一些复杂的灵活度高的“黑箱”模型，装袋，助推，非线性核函数支持向量机，神经网络和随机森林等。这些模型都非常灵活，但是很难解释自变量和应变量之间的关系。人们可能会觉得这些模型的预测精度通常更高，但就个人经验来说，那些灵活性不那么高的模型预测精度更高的情况时常发生。咋一看来好像不符合逻辑，但是认真想想也并不奇怪，这些模型之所以复杂，就在于它们极力拟合当前观测数据，因此它们更有可能过度拟合（把噪声也拟合进去了），这些模型在训练集上的表现可能更好，但预测未必更准确。</p>
</div>
<div id="section-5.2" class="section level2">
<h2><span class="header-section-number">5.2</span> 误差及其来源</h2>
<p>假设我们对于<span class="math">\(\mathbf{X}\)</span>得到<span class="math">\(f\)</span>的估计<span class="math">\(\hat{f}\)</span>，进而得到<span class="math">\(\mathbf{y}\)</span>的预测 <span class="math">\(\hat{\mathbf{y}}=\hat{f}(\mathbf{X})\)</span>。预测的误差分成两部分，系统误差和随机误差：</p>
<p><span class="math">\[
E(\mathbf{y}-\hat{\mathbf{y}})^{2}=E[f(\mathbf{X})+\mathbf{\epsilon}-\hat{f}(\mathbf{X})]^{2}=\underset{\text{(1)}}{\underbrace{[f(\mathbf{X})-\hat{f}(\mathbf{X})]^{2}}}+\underset{\text{(2)}}{\underbrace{Var(\mathbf{\epsilon})}}
  \label{eq:error}\]</span></p>
<p>其中（1）是系统误差， <span class="math">\(\hat{f}\)</span>通常不能彻底对<span class="math">\(\mathbf{X}\)</span>和<span class="math">\(\mathbf{y}\)</span>之间的“系统关系”建模，这里系统关系指的是在不同样本上存在的稳定关系。这一部分误差能通过改进模型得到提高；（2）是随机误差，这部分误差代表当前数据无法解释的部分，因此无法通过建立更复杂的模型来改进。那些拥有众多参数的复杂黑箱模型最大的问题就是试图通过自变量解释这部分误差，也就是过度拟合。随机误差的显著特点就是在不同的样本上是无法重复的，于是判断是否存在过度拟合的一个准则就是预留一部分样本作为测试集，然后检验训练出来的模型在测试集上的表现。这个我们随后会讲到。这里要澄清一点，过度拟合不只发生在这些黑箱模型上，其发生的根源在于参数个数太多（常超过观测个数），理论上说任何模型都可能过度拟合，只是因为黑箱模型的参数尤其多，其高灵活性和复杂度放大了过度拟合的问题。有些黑箱模型在训练的过程中会使用“袋外数据”（又称为Out of Bag [OOB]）来尽量避免过度拟合的影响。</p>
<p>如果建模的目的也包含推断，那么这些“黑箱”模型就不合适，这就需要在模型可以解释的范围内使用尽量灵活的模型，比如Lasso回归，多元自适应回归样条等。有人可能不同意Lasso回归是灵活的。从其本质还是传统回归的角度看，它确实没有那么灵活，受到很多模型假设的限制。但由于Lasso的罚函数能同时起到变量选择的作用，这个变量的选择的过程可以不依赖于p值之类的参数（这些参数基于数据分布假设因此具有局限性），而可以通过优化模型预测值和真实值的差距来进行变量选择，从这个角度上看，该模型是灵活的。根据笔者的应用经验，Lasso作为收缩（或变量选择）方法在实际应用中的效果非常好。对于一些市场营销或者社会心理学相关的抽样调查数据分析，分层贝叶斯是一种灵活有效的方法。</p>
<p>模型选择向来是非常困难的，这种困难不是数据分析行业特有的，很多专业领域都有类似的情况，比如医生判断病人所患的疾病，并在众多治疗方案中选择最合适的，这不是答案一目了然的选择题，决策的过程需要很多权衡和妥协。模型选择也类似，在选择过程中需要考虑具体的情况：项目目的，客户要求的精确度（这点很重要），计算量等等。这个选择的过程很难白纸黑字的像食谱一样写下来，这里我们只是尽己所能的介绍模型选择过程中需要考虑的点，以及评估不同模型的辅助性技术。具体的应用和“数据科学思维”还需要大家在从业过程中通过实践思考不断学习打磨。</p>
<p>若应变量包含可观的测量误差，那么这部分误差将反映在随机误差（<span class="math">\(Var(\mathbf{\epsilon})\)</span>）中。这部分误差使得均方根误差和<span class="math">\(R^2\)</span>相应的有下限和上限值。因此，随机误差项不仅仅代表结果中模型无法解释的波动，还含有测量误差。《应用预测模型（Applied Predictive Modeling）》<span class="citation">(Kjell Johnston 2013)</span>中第20.2小节用一个例子展示了因变量的测量误差对模型表现（RMSE和<span class="math">\(R^2\)</span>）的影响。</p>
<p>自变量误差</p>
</div>
<div id="section-5.3" class="section level2">
<h2><span class="header-section-number">5.3</span> 数据划分和再抽样</h2>
<p>模型训练和选择过程都离不开数据的划分和再抽样。数据划分是将一部分数据预留出来用于模型测试，只用另外的部分数据用于模型的训练。再抽样过程牵扯到重复的从训练集中抽取样本并且在不同的样本上拟合模型，以此来得到关于拟合模型的信息。假设我们想知道某线性模型拟合度<span class="math">\(R^2\)</span>的稳定性（也可以用其它模型拟合度量），可以重复的抽取不同的样本，然后拟合相同的线性模型，检查这些模型对应<span class="math">\(R^2\)</span>的变化。由于牵扯到使用随机样本重复拟合模型，这个过程有一定的计算量，最近五年里，数据处理工具和技术获得了飞速的发展。除非你需要处理PB级别的数据，或者每天要处理千亿级的事件，现阶段大多数技术已经能轻松满足你的需求了。划分和再抽样的一般过程如下：</p>
<ol style="list-style-type: decimal">
<li>将样本划分成训练集和测试集</li>
<li>使用训练集拟合模型</li>
<li>将拟合的模型应用于测试集评估模型表现</li>
</ol>
<p>关于数据划分，我们会介绍3种划分数据的方法：（1）按照结果变量划分数据；（2）按照预测变量划分数据；（3）按照时间序列划分数据。之后我们会介绍两种主要的再抽样方法： bootstrap和交互校验。我们会在接下来的模型选择的小节介绍用测试集评估模型表现。</p>
<div id="section-5.3.1" class="section level3">
<h3><span class="header-section-number">5.3.1</span> 划分训练集和测试集</h3>
<p>关于数据划分大家可能主要会问这三个问题：（1）为什么要划分训练集和测试集？（2）多少比例的数据用于训练集？（3）具体如何划分？我们现在就对此逐一回答。</p>
<p>刚接触数据科学的人常常会问<strong>为什么我们要预留一部分数据作为测试集而不是使用全部的数据用于训练</strong>。印象中传统商业智能声称的数据分析通常只是数据描述。通过从数据库中查询相关测量来回答简单的问题，如：2015年某产品每月销售量是多少？我们网站在过去一个月每天的访问量是多少？两种包装设计的同类产品在某大零售店上个月的销量差距多大？像这样的问题确实不用对数据进行划分，相反我们需要用尽可能完整的数据，然后对感兴趣的部分求和或者平均。假设数据观测准确，我们不需要怀疑问题的答案，因为这些问题本质上就是对数据进行某种描述总结，没有牵扯到任何分析推断。</p>
<p>数据科学家需要解决的不会是这样的问题，常是预测问题，或者同时还需要从预测模型中得到相应能够指导决策的推断。在这些情况下，分析的重心在于找到自变量<span class="math">\(\mathbf{X}\)</span>和应变量<span class="math">\(\mathbf{y}\)</span>之间的系统关系。这时我们就必须非常小心，因为我们在用一个样本得到一般化的结论，进而对将来可能出现的观测进行预测，这远远超越了描述统计的界限。根据彭加莱的理论，在预测未来的过程中，预测的越远的未来要求模型越精确，因为你的错误率会迅速上升。每向前预测一步，噪声会随着以一种非线性的方式迅速增加，因此我很难相信对5年以后某事件的定量预测。我们能够处理定性的事物，能够讨论系统的某些特点，但能够计算的东西是很局限的。在《黑天鹅》那本书中，作者以数学家Michael Berry的弹子球计算为例说明了这种放大效应。该实验是预测弹子球在球桌上的运动轨迹。如果弹子球的基本参数已知，你能够计算出桌面阻力，测量撞击量，那么就可以预测第1次撞击的结果。要预测第2次撞击就更为复杂一些，你需要小心确定球的初始状态，但不是不可能。如果要计算第9次撞击的结果你需要考虑某个站在桌子旁边的人的体重和产生的引力。要计算第56次撞击结果你需要考虑宇宙中的每一个基本粒子。注意这还只是单独的弹子球而没有牵扯到有着自由意志的人，以及不同人之间相互的影响。对现实世界的复杂局面，人的预测能力有着本质上的局限性。因此在实际预测分析当中，你需要很小心的界定这个可预测的边界，好比在弹子球实验中，你能预测第1次撞击的结果或者咬咬牙，再多杀一大片脑细胞做第2次撞击预测，但不要试图再进一步，承认自己的局限需要知识和勇气。回到实际分析中，如何找到预测的边界？（注：随着你经验的增长，你会遇到很多你无法预测（有时是分析）的情况。）目前我知道的方法就是在仔细确保当前情况基本符合假设的情况下，严格划分训练集和测试集，尽可能对模型的预测情况进行评估，检测预测模型的精确度和稳定性。划分背后隐含的假设是：</p>
<ol style="list-style-type: decimal">
<li>我们用于分析的数据展现的过程能够反应真实世界中事情的发展过程</li>
<li>我们想要对其建模的真实世界中事情的发展过程随着时间变化是相对稳定的。如，用上个月的数据建立的表现良好的模型，在接下来的一个月的观测上依旧能够有类似的良好表现</li>
</ol>
<p>换句话说，我们想要知道如果我们用模型来对新样本进行预测时会发生什么。我们的预测和真实将观测到的值有多接近？预测值偏离真实值的误差大致是多少？模型的误差是不是单向的，即预测是不是总大于真实值？这些都是很自然的问题，但它们的答案并非那么容易获得。最简单的理解模型在将来数据集上表现的方法就是试图模拟这件事。虽然严格说来，在将来事件发生之前，我们不可能得到相应的数据，但是我们能够预留一部分当前的数据并将它们视为将来的观测。例如，如果我们要预测2016年哪些农民还会某品牌的种子，可以用之前到2015年的历史数据建立预测模型，然后预测2016年的购买情况。这是一个相当好的模拟，由于我们其实已经知道2016年实际购买情况，可以将预测和真实情况进行对比。</p>
<p>在商业促销活动和信用风险的案例中，我们得到的数据通常和某个时间点相连（或者时间区间：一周，一个月，一个促销活动期间）。通常称这样的数据有代表性（用某时间点或者时间段的数据代表普遍情况）。在这样的情况下我们通常将数据集随机分成不同部分，然后用一部分（训练集）建立模型，另外一部分（测试集）来评估模型表现，可能的话对模型做出调整。</p>
<p>如果这两条假设大致正确，那么当前数据就能够合理反映未来的情况。因此在这种情况下，预留一部分当前数据来估计模型在将来的表现是合理的。明确了预测模型的一些假设前提，以及划分训练集和测试集的必要性之后，下一个问题是<strong>我们该将多少比例的数据用于训练集</strong>。</p>
<p>一般这需要视具体情况而定。通常需要考虑的两个因素是：（1）样本量；（2）计算速度。当样本量较大时，在考虑计算速度的条件下，我一般会尝试60%，70％和80%这三个比例，看哪个效果更好。如果样本量很小，那么测试集其评估模型效果的能力将非常有限，并且在原本样本量就不大的情况下再分出一部分数据会极大影响模型拟合。这种情况下，使用再抽样技术更加有效。常用的再抽样方法有交互校验和Bootstrap。</p>
<p>我们可以用createResample函数生成简单bootstrap样本，createFolds函数可以生成平衡的交互校验样本集。</p>
<p><strong>具体如何划分?</strong></p>
<p>划分训练集和测试集时需要小心避免两个数据集有系统差别。例如，我们不能简单的把前半部分数据当作训练集，后半部分当作测试集。因为数据有可能是以某种方式排列的，如，按收入从大到小，按访问次数多少排列等等。有一种避免数据集间随机差别的方法是用简单的随机抽样，如对每个样本我们都抛下硬币，人头面就归于训练集，菊花面就归于测试集。有时还有一些其它因素需要考虑，但本质都是随机抽样。要想真正理解划分数据背后的逻辑需要实践。下面我们介绍经常使用的几种划分方法。</p>
<ul>
<li>按照结果变量划分数据</li>
</ul>
<p>若结果变量<span class="math">\(\mathbf{y}\)</span>为分类变量，那么我们的到的测试集和训练集中结果变量各类的分布比例应该类似。可以使用<code>caret</code>包中的<code>createDataPartition()</code>函数平衡划分样本集。回到我们之前使用的服装消费者数据集，假设我们想要建立关于消费者类别（<code>segment</code>）的判别模型，这时结果变量为<code>segment</code>，我们用80%的样本训练模型，20%的样本做为测试集，且训练集和测试集中各类别的比例要尽可能相近。我们可以用如下R代码实现：</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 载入数据</span>
sim.dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;</span>)
<span class="co"># 需要caret包</span>
<span class="kw">library</span>(caret)
<span class="co"># 设置随机种子这样能得到相同的抽样结果</span>
<span class="kw">set.seed</span>(<span class="dv">3456</span>)
trainIndex &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(sim.dat$segment, <span class="dt">p =</span> .<span class="dv">8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)
<span class="kw">head</span>(trainIndex)</code></pre>
<pre><code>##      Resample1
## [1,]         1
## [2,]         2
## [3,]         3
## [4,]         4
## [5,]         6
## [6,]         7</code></pre>
<p><code>list = FALSE</code>选项使得返回的值是数据框。该函数还有一个选项<code>times</code>，用于设置划分的次数，你可以一次返回多次划分的结果，函数会返回一个（或多个）整数向量（指针向量），指明归于训练集的行（你可以设置<code>times＝2</code>再运行一下上面的代码看看输出有什么不同）。下面我们通过返回的指针向量（<code>trainIndex</code>）得到训练集和测试集：</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 得到训练集</span>
datTrain &lt;-<span class="st"> </span>sim.dat[ trainIndex,]
<span class="co"># 得到测试集</span>
datTest &lt;-<span class="st"> </span>sim.dat[-trainIndex,]</code></pre>
<p>按照设置，训练集中该有800个样本，测试集中有200个样本。我来看看两个集合中消费者类别的比例分布是否相似：</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plyr)
<span class="kw">ddply</span>(datTrain,<span class="st">&quot;segment&quot;</span>,summarise,<span class="dt">count=</span><span class="kw">length</span>(segment),
     <span class="dt">percentage=</span><span class="kw">round</span>( <span class="kw">length</span>(segment)/<span class="kw">nrow</span>(datTrain),<span class="dv">2</span>))</code></pre>
<pre><code>##       segment count percentage
## 1 Conspicuous   160       0.20
## 2       Price   200       0.25
## 3     Quality   160       0.20
## 4       Style   280       0.35</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(datTest,<span class="st">&quot;segment&quot;</span>,summarise,<span class="dt">count=</span><span class="kw">length</span>(segment),
      <span class="dt">percentage=</span><span class="kw">round</span>(<span class="kw">length</span>(segment)/<span class="kw">nrow</span>(datTest),<span class="dv">2</span>))</code></pre>
<pre><code>##       segment count percentage
## 1 Conspicuous    40       0.20
## 2       Price    50       0.25
## 3     Quality    40       0.20
## 4       Style    70       0.35</code></pre>
<p>很明显两个集合中消费者类别比例分布是一样的（实际应用中两个集合分布不一定严格相似，但应该非常接近）。</p>
<ul>
<li>按照自变量划分</li>
</ul>
<p>还可以使用最大差异度法<span class="citation">(Willett 2004)</span>划分数据（<code>maxDissim()</code>函数）。假设样本集A中含有m个样本，样本集B含有n个样本，n&gt;m，且我们要从B中选出一些样本加到A中，该子集中的样本要尽量和A中的不同。要实现这一点，对B中的一个样本，计算A中样本和该样本的差异度（距离，这里会算出m个值，因为A中有m个样本）。然后将和A中样本最不相同的B的样本抽取出来加入A，重复这个过程，直到A的样本量达到要求。关于这么权衡这m个差异度找到和A“最不相似”的样本，有不同的方法，比如以最小的值为准，将所有距离求和等等。这里没有什么黄金法则，建议大家尝试几种方法，查看比较得到的训练/测试样本自变量分布，选取其中一种。用这种方式可以得到自变量分布相似的不同样本集。R中有不同的计算样本间差异度（基于自变量观测）的函数。<code>caret</code>包中调用的是<code>proxy</code>包中的函数。关于不同的差异度测量，见相关包的帮助文档。我们可以通过选项 <code>obj</code>设置和样本集A“最不相似”的样本的方式，其中<code>minDiss</code>表示以最小差异度为准，<code>sumDiss</code>表示使用差异度之和。</p>
<p>我们用服装数据的一个子集为例展示按照自变量抽样。这里选取年龄和收入这两个变量。</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 最大差异度抽样用到proxy包</span>
<span class="kw">library</span>(proxy)
<span class="co"># 用lattice包绘制散点图</span>
<span class="kw">library</span>(lattice)
<span class="co"># 选取年龄和收入这两个变量</span>
testing&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span> ))</code></pre>
<p>我们先随机选取5个样本做为初始集（<code>start</code>），剩下的样本组成集合<code>samplePool</code>：</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">5</span>)
<span class="co"># 随机选取5个样本</span>
startSet &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">dim</span>(testing)[<span class="dv">1</span>], <span class="dv">5</span>)
start &lt;-<span class="st"> </span>testing[startSet,]
<span class="co"># 剩下的样本存在对象samplePool中</span>
samplePool &lt;-<span class="st"> </span>testing[-startSet,]</code></pre>
<p>通过<code>maxDissim()</code>函数从<code>samplePool</code>中抽取5个样本，这5个样本尽量和<code>start</code>中已有的样本不同。：</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 通过最大化差异得到的样本存在数据框new内</span>
<span class="co"># obj = minDiss 表示总体差异度以最小差异度为准</span>
newSamp &lt;-<span class="st"> </span><span class="kw">maxDissim</span>(start, samplePool,<span class="dt">obj =</span> minDiss, <span class="dt">n =</span> <span class="dv">5</span>)
new&lt;-samplePool[newSamp,]</code></pre>
<p>我们再从<code>samplePool</code>中不用最大差异法，而是随机抽取5个样本，将这5个样本存在数据框<code>new2</code>中：</p>
<pre class="sourceCode r"><code class="sourceCode r">newSet &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">dim</span>(samplePool)[<span class="dv">1</span>], <span class="dv">5</span>)
new2&lt;-testing[newSet,]</code></pre>
<p>绘制散点图比较两种不同方法（<code>new</code>：用最大化差异法抽取的样本；<code>new2</code>：随机抽取的样本）抽取的样本和初始样本（<code>start</code>）有什么不同：</p>
<pre class="sourceCode r"><code class="sourceCode r">start$group&lt;-<span class="kw">rep</span>(<span class="st">&quot;start&quot;</span>,<span class="kw">nrow</span>(start))
new$group&lt;-<span class="kw">rep</span>(<span class="st">&quot;new&quot;</span>,<span class="kw">nrow</span>(new))
new2$group&lt;-<span class="kw">rep</span>(<span class="st">&quot;new2&quot;</span>,<span class="kw">nrow</span>(new2))
<span class="kw">xyplot</span>(age~income,<span class="dt">data=</span><span class="kw">rbind</span>(start,new,new2),<span class="dt">grid =</span> <span class="ot">TRUE</span>,
       <span class="dt">group =</span> group, <span class="dt">auto.key =</span> <span class="ot">TRUE</span>
)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:maxdis"></span>
<img src="DS_R_files/figure-html/maxdis-1.png" alt="按自变量最大化差异抽样" width="80%" />
<p class="caption">
Figure 5.1: 按自变量最大化差异抽样
</p>
</div>
<p>由图<a href="section-5.html#fig:maxdis">5.1</a>可见，通过最大化差异抽取的样本（<code>new</code>）和初始样本点（<code>start</code>）分布在图的不同位置。而随机抽取的新样本（<code>new2</code>）和原始样本更加接近。我们为什么希望每次抽取的样本和之前的不一样呢？因为我们希望最后得到的训练集和测试集覆盖的自变量观测区间相似。如果抽取的样本点都来自一个区域的话（比如全部都是年龄30以下，收入10万以下），如果讲这个样本用于训练的模型很可能不具有预测这个区域外样本的能力。反之要是用这个样本做为测试集，则无法检测模型在这个区域外样本上的表现。</p>
<ul>
<li>按时间序列划分</li>
</ul>
<p>对于时间序列数据，用简单随机抽样通常不是最好的方式。有一种按时间序列划分训练集和测试集的方法，关于该方法的讨论见<span class="citation">(Hyndman and Athanasopoulos 2013)</span>。可以使用<code>caret</code>实现该划分。其中有3个需要设置的参数：</p>
<ul>
<li>initialWindow: the initial number of consecutive values in each training set sample</li>
<li>horizon: The number of consecutive values in test set sample</li>
<li>fixedWindow: A logical: if FALSE, the training set always start at the first sample and the training set size will vary over data splits. As an example, suppose we have a time series with 20 data points. We can fix initialWindow = 5 and look at different settings of the other two arguments. In the plot below, rows in each panel correspond to different data splits (i.e. resamples) and the columns correspond to different data points. Also, red indicates samples that are in included in the training set and the blue indicates samples in the test set.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">timeSlices &lt;-<span class="st"> </span><span class="kw">createTimeSlices</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(economics), 
                   <span class="dt">initialWindow =</span> <span class="dv">36</span>, <span class="dt">horizon =</span> <span class="dv">12</span>, <span class="dt">fixedWindow =</span> <span class="ot">TRUE</span>)
&gt;<span class="st"> </span><span class="kw">str</span>(timeSlices,<span class="dt">max.level =</span> <span class="dv">1</span>)
## List of 2
## $ train:List of 431
##   .. [list output truncated]
## $ test :List of 431
##   .. [list output truncated]
trainSlices &lt;-<span class="st"> </span>timeSlices[[<span class="dv">1</span>]]
testSlices &lt;-<span class="st"> </span>timeSlices[[<span class="dv">2</span>]]

plsFitTime &lt;-<span class="st"> </span><span class="kw">train</span>(unemploy ~<span class="st"> </span>pce +<span class="st"> </span>pop +<span class="st"> </span>psavert,
                    <span class="dt">data =</span> economics[trainSlices[[<span class="dv">1</span>]],],
                    <span class="dt">method =</span> <span class="st">&quot;pls&quot;</span>,
                    <span class="dt">preProc =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</code></pre>
</div>
<div id="section-5.3.2" class="section level3">
<h3><span class="header-section-number">5.3.2</span> 拟合模型</h3>
</div>
<div id="section-5.3.3" class="section level3">
<h3><span class="header-section-number">5.3.3</span> 评估模型表现</h3>
<p>模型选择的首要任务是决定一个模型表现的度量，即通过什么标准来决定两个模型谁更好。模型表现的度量方法有好几种，要想更加全面的了解模型的表现，有时需要结合多种度量方式。 为了了解模型是否适用于分析的目的，对模型的一些可视化方法，特别是残差图，将是至关重要的。 这些技术都将在本章进行讨论。</p>
<div id="section-5.3.3.1" class="section level4">
<h4><span class="header-section-number">5.3.3.1</span> 回归模型表现度量</h4>
<ul>
<li><strong><span class="math">\(C_{p}\)</span>，<span class="math">\(AIC\)</span>，<span class="math">\(BIC\)</span>， <span class="math">\(RMSE\)</span>和调整后的<span class="math">\(R^2\)</span></strong></li>
</ul>
<p>当因变量是数值时，可以使用均方误差平方根（Root mean squared error, RMSE）为指标衡量模型的表现。 这个度量是模型残差的函数，其中残差即为观测值减去模型的预测值。 均方误差（Mean squared error, MSE）的计算方法是将残差平方然后取平均， 而RMSE则是取MSE的平方根，从而它与原始数据的单位相同。 得到的RMSE取值通常解释为（平均意义上）残差离0的远近，或者解释为观测值和模型预测值之间平均的距离。 另一个常用的度量是R-Squared，通常写作<span class="math">\(R^2\)</span>。这个值被解释成模型能够解释多大比例的应变量总变异。我们对服装消费者数据中的收入（<code>income</code>）建立线性模型，将问卷调查回复作为自变量（<code>Q1-Q10</code>），结果如下所示，其中R-squared＝0.75表示模型可以解释因变量总变异的四分之三。 计算这个值的方法有很多种（Kvalseth 1985）， 其中最简单的一个是先计算观测值和预测值的相关系数（通常用 表示），然后再将其平方。尽管这是一个易于解释的统计量，但实际工作者必须记住， 是一种相关性而不是准确性的度量。</p>
<pre class="sourceCode r"><code class="sourceCode r">fit&lt;-<span class="kw">lm</span>(income~Q1+Q2+Q3+Q4+Q5+Q6+Q7+Q8+Q9+Q10,<span class="dt">data=</span>sim.dat)
<span class="kw">summary</span>(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = income ~ Q1 + Q2 + Q3 + Q4 + Q5 + Q6 + Q7 + Q8 + 
##     Q9 + Q10, data = sim.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -118725   -7466    -218    7372  127717 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    29685      18676   1.589  0.11235    
## Q1             -6649       1672  -3.978 7.58e-05 ***
## Q2              9632       2383   4.042 5.80e-05 ***
## Q3              2434       2205   1.104  0.27006    
## Q4             -2083       1870  -1.114  0.26572    
## Q5              5541       2904   1.908  0.05675 .  
## Q6             20222       2269   8.913  &lt; 2e-16 ***
## Q7             -2277       2354  -0.967  0.33367    
## Q8              1444       1965   0.735  0.46263    
## Q9              7535       2426   3.106  0.00196 ** 
## Q10             1744       1903   0.917  0.35959    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 24940 on 805 degrees of freedom
##   (184 observations deleted due to missingness)
## Multiple R-squared:  0.7527, Adjusted R-squared:  0.7496 
## F-statistic:   245 on 10 and 805 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>我们用stepAIC进行变量选择。</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">stepAIC</span>(fit)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fit2&lt;-<span class="kw">lm</span>(<span class="dt">formula =</span> income ~<span class="st"> </span>Q1 +<span class="st"> </span>Q2 +<span class="st"> </span>Q4 +<span class="st"> </span>Q5 +<span class="st"> </span>Q6 +<span class="st"> </span>Q9, <span class="dt">data =</span> sim.dat)
<span class="kw">summary</span>(fit2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = income ~ Q1 + Q2 + Q4 + Q5 + Q6 + Q9, data = sim.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -118207   -7492    -276    7092  127546 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    32346      14100   2.294 0.022046 *  
## Q1             -6144       1637  -3.752 0.000188 ***
## Q2              9876       2177   4.537 6.58e-06 ***
## Q4             -2157       1279  -1.687 0.092068 .  
## Q5              4147       2563   1.618 0.106104    
## Q6             22718       1672  13.587  &lt; 2e-16 ***
## Q9              6906       2383   2.898 0.003860 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 24930 on 809 degrees of freedom
##   (184 observations deleted due to missingness)
## Multiple R-squared:  0.7517, Adjusted R-squared:  0.7498 
## F-statistic: 408.1 on 6 and 809 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="section-5.3.3.2" class="section level4">
<h4><span class="header-section-number">5.3.3.2</span> 分类模型表现度量</h4>
</div>
</div>
<div id="section-5.3.4" class="section level3">
<h3><span class="header-section-number">5.3.4</span> 失衡数据</h3>
<p>判别分析中可能遇到一个最大问题就是数据失衡。比如贷款客户风险分析就是如此，真正违约不还贷款的客户可能只有千分之一，这意味只要闭着眼将所有的客户都判定为无风险就能的到99.9%的准确率。在这样的情况下，数据中关于低频率事件的信息很少，因此模型很难准确预测这些事件，而这些低频率事件通常有事我们关心的（如违约，疾病爆发）。对于统计学习模型来说，最理想当然是平衡的数据，但 很遗憾，现实生活很少满足理论假设。下面我们就介绍几种能够在某种程度上缓解类失衡的方法。这里要指出一点，你只能得到数据包含的的东西。记得之前讲到两部分误差，系统误差和随机误差。你能够该井的只是系统误差，你无法超于数据中关于小频率事件信息的极限。下面要讲的方法只是在原基础上对模型进行一些修正。这里我只介绍二分类的问题，因为绝大多数都是二分类。</p>
<ul>
<li>尝试尽可能多的模型</li>
</ul>
<p>当考虑该用什么模型解决一个具体的问题时，应该考虑多个可能的模型。从最简单的模型开始直到你能达到的难度上限。真正尝试拟合模型时，根据个人喜好，你可以从最简单的模型开始，每拟合一次模型，对数据中变量关系的理解会有所加深，慢慢过渡到更加复杂的模型。或者从最复杂的模型开始，但要做好简化模型的准备，使得模型具有更强的解释性。实际应用中，你不知道什么模型对当前问题最有效，所以比较不同的模型对于一个合格的数据科学家来说是必须的。当然，这有一个隐藏的前提条件是你能够快速有效的拟合不同模型。如果你需要让计算机跑1个晚上的程序来拟合一个模型，尝试这样的模型不是一个好主意。</p>
<ul>
<li>检查模型的稳定性</li>
</ul>
<p>提高模型稳定性有各种可能的方法，收集更多的观测，除去冗余变量，如之前提到的近0方差变量和高度相关变量。检查模型拟合的稳定程度最常用的方法是再抽样。通过抽取不同的样本拟合相同的模型，然后查看拟合参数的变化范围。要是需要检查模型在某假设条件不满足的情况下的表现，可以通过模拟数据进行考察。</p>
<p>有目标的估计因果效应，而不是将其当作庞大回归模型的副产物</p>
<p>不要想当然的假设回归系数能够解释成因果关系。</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-6.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/index.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>


</body>

</html>
