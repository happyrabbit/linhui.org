<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is my first book on data science">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my first book on data science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is my first book on data science" />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-10-19">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-4.html">
<link rel="next" href="section-6.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 数据操作</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 数据读写</a><ul>
<li class="chapter" data-level="6.1.1" data-path="section-6.html"><a href="section-6.html#tibble"><i class="fa fa-check"></i><b>6.1.1</b> 取代传统数据框的<code>tibble</code>对象</a></li>
<li class="chapter" data-level="6.1.2" data-path="section-6.html"><a href="section-6.html#readr"><i class="fa fa-check"></i><b>6.1.2</b> 高效数据读写：<code>readr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 数据整合</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#baseapply"><i class="fa fa-check"></i><b>6.2.1</b> base包：apply()</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#plyrddply"><i class="fa fa-check"></i><b>6.2.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#dplyr"><i class="fa fa-check"></i><b>6.2.3</b> dplyr包</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据整形</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#reshape2"><i class="fa fa-check"></i><b>6.3.1</b> <code>reshape2</code>包</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#tidyr"><i class="fa fa-check"></i><b>6.3.2</b> <code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>6.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 基础建模技术</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="7.3.1" data-path="section-7.html"><a href="section-7.html#section-7.3.1"><i class="fa fa-check"></i><b>7.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="7.3.2" data-path="section-7.html"><a href="section-7.html#section-7.3.2"><i class="fa fa-check"></i><b>7.3.2</b> 重抽样</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#-2"><i class="fa fa-check"></i><b>7.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 模型评估度量</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 回归模型评估度量</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 分类模型评估度量</a><ul>
<li class="chapter" data-level="8.2.1" data-path="section-8.html"><a href="section-8.html#kappa"><i class="fa fa-check"></i><b>8.2.1</b> Kappa统计量</a></li>
<li class="chapter" data-level="8.2.2" data-path="section-8.html"><a href="section-8.html#roc"><i class="fa fa-check"></i><b>8.2.2</b> ROC曲线</a></li>
<li class="chapter" data-level="8.2.3" data-path="section-8.html"><a href="section-8.html#section-8.2.3"><i class="fa fa-check"></i><b>8.2.3</b> 提升图</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#-3"><i class="fa fa-check"></i><b>8.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 特征工程</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 特征构建</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 特征提取</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 初步探索数据</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 主成分分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 探索性因子分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 高维标度化</a></li>
<li class="chapter" data-level="9.2.5" data-path="section-9.html"><a href="section-9.html#section-9.2.5"><i class="fa fa-check"></i><b>9.2.5</b> 知识扩展</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 特征选择</a><ul>
<li class="chapter" data-level="9.3.1" data-path="section-9.html"><a href="section-9.html#section-9.3.1"><i class="fa fa-check"></i><b>9.3.1</b> 过滤法</a></li>
<li class="chapter" data-level="9.3.2" data-path="section-9.html"><a href="section-9.html#section-9.3.2"><i class="fa fa-check"></i><b>9.3.2</b> 绕封法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="10.1.2" data-path="section-10.html"><a href="section-10.html#section-10.1.2"><i class="fa fa-check"></i><b>10.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="10.1.3" data-path="section-10.html"><a href="section-10.html#section-10.1.3"><i class="fa fa-check"></i><b>10.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 收缩方法</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 岭回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.2.2</b> Lasso</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 弹性网络</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.3</b> 知识扩展：Lasso的变量选择功能</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> 主成分和偏最小二乘回归</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="glmnet.html"><a href="glmnet.html"><i class="fa fa-check"></i><b>11</b> 广义线性模型压缩方法及<code>glmnet</code>包</a><ul>
<li class="chapter" data-level="11.1" data-path="glmnet.html"><a href="glmnet.html#glmnet"><i class="fa fa-check"></i><b>11.1</b> 初识<code>glmnet</code></a></li>
<li class="chapter" data-level="11.2" data-path="glmnet.html"><a href="glmnet.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 收缩线性回归</a></li>
<li class="chapter" data-level="11.3" data-path="glmnet.html"><a href="glmnet.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 逻辑回归</a><ul>
<li class="chapter" data-level="11.3.1" data-path="glmnet.html"><a href="glmnet.html#section-11.3.1"><i class="fa fa-check"></i><b>11.3.1</b> 普通逻辑回归</a></li>
<li class="chapter" data-level="11.3.2" data-path="glmnet.html"><a href="glmnet.html#section-11.3.2"><i class="fa fa-check"></i><b>11.3.2</b> 收缩逻辑回归</a></li>
<li class="chapter" data-level="11.3.3" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>11.3.3</b> 知识扩展：群组lasso逻辑回归</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#section-12.1"><i class="fa fa-check"></i><b>12.1</b> 聚类分析</a></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#section-12.2"><i class="fa fa-check"></i><b>12.2</b> 判别分析</a><ul>
<li class="chapter" data-level="12.2.1" data-path="section-12.html"><a href="section-12.html#section-12.2.1"><i class="fa fa-check"></i><b>12.2.1</b> 线性判别分析</a></li>
<li class="chapter" data-level="12.2.2" data-path="section-12.html"><a href="section-12.html#section-12.2.2"><i class="fa fa-check"></i><b>12.2.2</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="12.2.3" data-path="section-12.html"><a href="section-12.html#section-12.2.3"><i class="fa fa-check"></i><b>12.2.3</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="section-12.html"><a href="section-12.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 树模型</a><ul>
<li class="chapter" data-level="13.1" data-path="section-13.html"><a href="section-13.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 分裂准则</a></li>
<li class="chapter" data-level="13.2" data-path="section-13.html"><a href="section-13.html#section-13.2"><i class="fa fa-check"></i><b>13.2</b> 树模型的参数</a></li>
<li class="chapter" data-level="13.3" data-path="section-13.html"><a href="section-13.html#section-13.3"><i class="fa fa-check"></i><b>13.3</b> 装袋树</a></li>
<li class="chapter" data-level="13.4" data-path="section-13.html"><a href="section-13.html#section-13.4"><i class="fa fa-check"></i><b>13.4</b> 随机森林</a></li>
<li class="chapter" data-level="13.5" data-path="section-13.html"><a href="section-13.html#section-13.5"><i class="fa fa-check"></i><b>13.5</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-14.html"><a href="section-14.html"><i class="fa fa-check"></i><b>14</b> 深度学习</a><ul>
<li class="chapter" data-level="14.1" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>14.1</b> 介绍</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-5" class="section level1">
<h1><span class="header-section-number">第5章</span> 数据预处理</h1>
<div id="section-5.1" class="section level2">
<h2><span class="header-section-number">5.1</span> 介绍</h2>
<p>许多数据分析相关书籍着重介绍模型，算法和统计推断。但在实际应用中，刚到手的原始数据通常都不能直接用于建模。数据预处理是将原始数据转化成能够用于建模的一致数据的过程。建模失败的原因有多种，其中之一就是在建模前没有对数据进行恰当的预处理。数据预处理会极大的影响建模结果，如缺失值填补和对离群点的处理显然会影响统计分析的结果。因此这是整个分析流程中非常关键的一个环节，这一步没有到位，之后的分析就如同在沙地上建房，及其不稳固。</p>
<p>在实际分析项目中，根据数据清理的不同阶段，有下面几类数据：</p>
<ol style="list-style-type: decimal">
<li>原始数据</li>
<li>技术上正确的数据</li>
<li>可以用于模型的数据</li>
<li>整合后的数据</li>
<li>设置了固定格式的数据</li>
</ol>
<p>原始数据是刚开始得到的第一手数据，可以是从数据库读取出的销售数据，市场调查的同事给你的调查问卷回复，研发部门收集的实验数据等等。这些数据集可能很粗糙，不一定能直接读入R。 比如多行表格标题，或者格式不符合要求：</p>
<ul>
<li>用50%表示百分比而不是0.5，这样R读入时会将其当作字符型；</li>
<li>销售额的缺失值用“-”表示，而不是空格，这样R会将销售额当成字符型；</li>
<li>数据是在幻灯片文档中，或者电子表格不是“.csv”而是“.xlsx”格式；<br />
…</li>
</ul>
<p>总而言之，这样的数据有时不能直接读入R，需要进行一些清理；有些格式的数据需要安装特定的包读取。当对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据。这样的数据载入R后有合理的列标签，变量格式等等。但这不意味着这时的数据是完全无误的，如年龄变量可能是负数，折扣百分比可能大于1，没到法定年龄的某人可能有驾照号码，或者数据缺失。取决于你的具体情况，数据可能存在各种问题。你在建模之前需要对这样的数据进行进一步清理。除了数据本身是否合理的角度对数据进行清理以外，取决于你要使用的模型，还需要从技术层面对数据进行预处理，使之尽可能不要太过偏离模型假设。比如有偏数据，变量量级不同，离群值，变量间的共线性，需要将分类变量转化为数值变量等等。对技术上正确的数据进行进一步清理后就得到可以用于建模的数据。</p>
<p>有时我们需要对数据进行整合。比如你可能需要展示某个产品在不同价格下的年销售量，这时就需要将每天的销售量相加得到相应的年销售量；在聚类分析中，当你得到各个分类后，通常需要对不同类进行描述，这时也需要整合各个类的描述统计量（比如平均年龄，平均收入，年龄标准差等等）。数据整合通常是为了给人展示，或者进一步用于可视化。</p>
<p>对整合好的数据，根据不同客户的要求我们需要更改数据格式。比如简洁明了的行列标签，单元格颜色，对一些需要强调的数据高亮等等。</p>
<p>这里我们建议大家分别储存每一步得到的数据，以及各个处理过程使用的R代码，使得这个过程尽可能可重复。如果需要检查更改某个环节，也相对容易。在本章的剩余部分我们针对<strong>建模前的数据预处理以及数据整合</strong>。本章我们将介绍一系列的数据清理技术，并用R进行实践。除了技术以外，我们还会讲到如何针对不同的情况选择合适的数据预处理方式。</p>
<p>前面有提到，数据预处理一般指数据的清理、变换或者缺失值填补。不同的模型对于预测变量的类型有不同的敏感度，此外变量以什么形式进入模型也很重要，如5分量表的调查问卷回复是当作因子变量还是数值变量。</p>
<p>本章将介绍无监督数据处理，有监督的方法会在其它章节中讨论。例如，偏最小二乘回归（PLS）模型本质上是主成分分析（PCA）的有监督版本。我们还将描述不考虑因变量时移除自变量的方法。</p>
<p>先载入本章需要的R包（我将在相应代码注释中解释每个包的用途）：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 先安装这些包才能用library()函数载入</span>
<span class="co"># caret: 提供获取、使用、评估成百上千个机器学习模型及其拟合效果的系统交互界面</span>
<span class="co"># 为机器学习提供了结构化的方法并且对一系列机器学习过程进行评估</span>
<span class="kw">library</span>(caret)
<span class="co"># e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别</span>
<span class="kw">library</span>(e1071)
<span class="co"># gridExtra: 绘图辅助功能，讲不同的图形组合在一起成为图表</span>
<span class="kw">library</span>(gridExtra) 
<span class="co"># lattice: 建立在核心绘图能力上的格子框架图形</span>
<span class="kw">library</span>(lattice)
<span class="co"># imputeMissings: 填补缺失值</span>
<span class="kw">library</span>(imputeMissings)
<span class="co"># RANN: 应用k邻近算法</span>
<span class="kw">library</span>(RANN)
<span class="co"># corrplot: 相关矩阵的高级可视化</span>
<span class="kw">library</span>(corrplot)
<span class="co"># nnet: 拟合单个潜层级的神经网络模型</span>
<span class="kw">library</span>(nnet)
<span class="co"># car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数</span>
<span class="kw">library</span>(car)
<span class="co"># gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵</span>
<span class="kw">library</span>(gpairs)
<span class="co"># reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()</span>
<span class="kw">library</span>(reshape2)
<span class="co"># psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；</span>
<span class="co"># 我们会使用包中的describe()函数</span>
<span class="kw">library</span>(psych)
<span class="co"># plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总</span>
<span class="kw">library</span>(plyr)
<span class="co"># tidyr: 清理揉合数据的包，主要函数是spread()和gather()</span>
<span class="kw">library</span>(tidyr)</code></pre></div>
</div>
<div id="section-5.2" class="section level2">
<h2><span class="header-section-number">5.2</span> 数据清理</h2>
<p>当你得到上述技术上正确的数据后，第一步就是检查数据，看看都有哪些变量，这些变量分布如何，是不是存在错误的观测。我们先读取并且检查服装消费者数据：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim.dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)
<span class="kw">summary</span>(sim.dat)</code></pre></div>
<pre><code>##       age            gender        income       house    
##  Min.   : 16.00   Female:554   Min.   : 41776   No :432  
##  1st Qu.: 25.00   Male  :446   1st Qu.: 85832   Yes:568  
##  Median : 36.00                Median : 93869            
##  Mean   : 38.84                Mean   :113543            
##  3rd Qu.: 53.00                3rd Qu.:124572            
##  Max.   :300.00                Max.   :319704            
##                                NA&#39;s   :184               
##    store_exp         online_exp       store_trans     online_trans  
##  Min.   : -500.0   Min.   :  68.82   Min.   : 1.00   Min.   : 1.00  
##  1st Qu.:  205.0   1st Qu.: 420.34   1st Qu.: 3.00   1st Qu.: 6.00  
##  Median :  329.0   Median :1941.86   Median : 4.00   Median :14.00  
##  Mean   : 1356.8   Mean   :2120.18   Mean   : 5.35   Mean   :13.55  
##  3rd Qu.:  597.3   3rd Qu.:2440.78   3rd Qu.: 7.00   3rd Qu.:20.00  
##  Max.   :50000.0   Max.   :9479.44   Max.   :20.00   Max.   :36.00  
##                                                                     
##        Q1              Q2              Q3              Q4       
##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.000  
##  Median :3.000   Median :1.000   Median :1.000   Median :3.000  
##  Mean   :3.101   Mean   :1.823   Mean   :1.992   Mean   :2.763  
##  3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:4.000  
##  Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  
##                                                                 
##        Q5              Q6              Q7              Q8       
##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:1.750   1st Qu.:1.000   1st Qu.:2.500   1st Qu.:1.000  
##  Median :4.000   Median :2.000   Median :4.000   Median :2.000  
##  Mean   :2.945   Mean   :2.448   Mean   :3.434   Mean   :2.396  
##  3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:3.000  
##  Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  
##                                                                 
##        Q9             Q10              segment   
##  Min.   :1.000   Min.   :1.00   Conspicuous:200  
##  1st Qu.:2.000   1st Qu.:1.00   Price      :250  
##  Median :4.000   Median :2.00   Quality    :200  
##  Mean   :3.085   Mean   :2.32   Style      :350  
##  3rd Qu.:4.000   3rd Qu.:3.00                    
##  Max.   :5.000   Max.   :5.00                    
## </code></pre>
<p>发现什么问题没有？问卷调查回复Q1-Q10貌似合理，最小值都是1，最大值是5，因为问卷分值表是1-5。在实体店交易次数（<code>store_trans</code>）和在线交易次数（<code>store_trans</code>）看上去也合理。收入（income）有缺失值，处理缺失值的问题我们在下一小节会介绍。在线花销（<code>online_exp</code>）分布看上去没什么问题。实体店花销（<code>store_exp</code>）存在离群值，最大值有50000人民币，有个别受访者有着浓浓的土豪味。还有呢？大家可能已经发现其中有负值（最小值是－500），花销不可能是负数，这里你就要怀疑存在输入错误。类似的，<code>age</code>也存在不大可能的观测值，最大年龄是300，如果不是真的碰到青春期的千年老妖的话，这个年龄值应该是错误的。那怎么处理这些错误的值呢？取决于你的实际情况，如果你的样本量很大，不在乎这几个样本，可以删除这些不合理的值。在这里我们一共就1000个观测，而且问卷调查的数据在现实中通常都不容易获得，需要花费人力财力，故若因为其中某一个变量的值错误就将整个样本删去在此情况下有些可惜，所以我们可以将这些值设置成缺失状态，在下一步介绍缺失值处理的时候进行填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将错误的年龄观测设置为缺失值</span>
sim.dat$age[<span class="kw">which</span>(sim.dat$age&gt;<span class="dv">100</span>)]&lt;-<span class="ot">NA</span>
<span class="co"># 将错误的实体店购买观测设置为缺失值</span>
sim.dat$store_exp[<span class="kw">which</span>(sim.dat$store_exp&lt;<span class="dv">0</span>)]&lt;-<span class="ot">NA</span>
<span class="co"># 通过summary()函数检查清理情况</span>
<span class="kw">summary</span>(<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>)))</code></pre></div>
<pre><code>##       age            income      
##  Min.   :16.00   Min.   : 41776  
##  1st Qu.:25.00   1st Qu.: 85832  
##  Median :36.00   Median : 93869  
##  Mean   :38.58   Mean   :113543  
##  3rd Qu.:53.00   3rd Qu.:124572  
##  Max.   :69.00   Max.   :319704  
##  NA&#39;s   :1       NA&#39;s   :184</code></pre>
<p>现在我们接着处理数据中的缺失值。</p>
</div>
<div id="section-5.3" class="section level2">
<h2><span class="header-section-number">5.3</span> 缺失值填补</h2>
<p>缺失值填补是个大话题，单这一个就可以写本书。这里不会详细给大家介绍这个子领域，而是展示一些常用的缺失值处理方法，并且根据个人的工作经验对这些方法进行一些说明。对想进一步学习的读者，可以参考本小节中提到的相关参考资料。缺失值填补是对缺失的数据观测进行估计的过程。De Waal, Pannekoek和Scholtus的书<span class="citation">(Ton de Waal <a href="#ref-impute1">2011</a>)</span>中第7章对现存的一些缺失值填补方法做了简洁的概述。具体填补方法的选择取决于你的实际应用情况：关于缺失数据你有哪些辅助信息（比如如果客户管理系统将没有购买的客户对应的购买量设置为缺失的话，那你就该用0填补），变量之间是不是有些相关性限制（比如关于是否有驾照信息的缺失就可能受到年龄的限制，如果某人年龄低于16周岁，那就不可能有驾照信息）。因为情况各不相同，所以没有某个方法永远比其它方法好。</p>
<p>决定处理缺失值的方法之前要先了解缺失的原因等关于缺失的辅助信息。缺失是随机发生的么？如果这样的话，可以用中位数/众数填补，也可以使用均值填补。或者缺失其实是有潜在发生机制的？比如年龄大的人在问卷调查中更不愿意透露年龄，这样关于年龄的缺失就不是随机发生的，如果用均值或者中位数填补可能产生很大偏差。这时需要利用年龄和其它自变量的关系对缺失的值进行估计。比如可以基于那些没有缺失值的数据，用是否有子女，收入，问卷调查的回复这些信息来对年龄建模，然后用拟合的模型来进行预测（如用树模型）。</p>
<p>此外，建模的目的对于选择缺失值填补方法也很重要。若建模目的是对传统统计模型结果进行解释和推断，那么仔细研究缺失机制，尽可能用非缺失信息建模来估计缺失值就显得尤为重要。相反，如果建模的目的是预测，大部分情况下不会很严格的研究缺失机制（缺失机制很明显的时候除外），在缺失机制不太清楚的情况下，可以当成随机缺失进行填补（使用均值，中位数或者用K-近邻）。由于统计推断对缺失值更加敏感，所以抽样调查统计学对各种缺失值填补方法进行了深入的研究，这些研究着重于有效的统计推断。而在预测模型中的缺失值填补的问题和抽样调查中的有所不同，因为预测模型的主要目的是预测而非推断。因此关于预测模型中的缺失值填补方面的研究文献没有传统抽样调查统计那么多。想深入学习这方面知识的读者可以参考Saar-Tsechansky 和 Provost对判别模型中不同缺失值方法的比较<span class="citation">(Saar-Tsechansky M 2007b)</span>。还有之前提到的De Waal, Pannekoek和Scholtus的书<span class="citation">(Ton de Waal <a href="#ref-impute1">2011</a>)</span>。</p>
<div id="section-5.3.1" class="section level3">
<h3><span class="header-section-number">5.3.1</span> 中位数或众数填补</h3>
<p>在假设随机缺失的情况下，一个常用的填补方法是可以用含有缺失观测变量的中位数（连续变量）或者众数（分类变量）填补缺失值。 <code>imputeMissings</code>包中的函数<code>impute()</code>可以实现这类填补。我们用该函数对<code>sim.dat</code>数据框填补缺失值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将填补后的数据存在另外一个数据框中</span>
demo_imp&lt;-<span class="kw">impute</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;median/mode&quot;</span>)
<span class="co"># 只检查前5列，因为后面没有缺失值</span>
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<pre><code>##       age           gender        income       house       store_exp      
##  Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
##  1st Qu.:25.00   Male  :446   1st Qu.: 87896   Yes:568   1st Qu.:  205.1  
##  Median :36.00                Median : 93869             Median :  329.8  
##  Mean   :38.58                Mean   :109923             Mean   : 1357.7  
##  3rd Qu.:53.00                3rd Qu.:119456             3rd Qu.:  597.3  
##  Max.   :69.00                Max.   :319704             Max.   :50000.0</code></pre>
<p>从上面输出可以看到，填补后的数据框<code>demo_imp</code>没有缺失值。这个方法简单迅速，在工作中经常使用。但其有一个缺点，单独对每个变量进行缺失值填补而没有考虑到变量之间的关系，因而有的时候不太准确，如果缺失的比例较大，且你的建模目的是统计推断，建议进一步研究变量之间的关系，发觉缺失机制，通过对缺失变量建模来进行填补。上面的例子中缺失变量都是数值变量，<strong>如果缺失变量是分类／因子变量的话，<code>impute()</code>函数会用众数进行填补</strong>。</p>
<p>你也可以用上面讲到的<code>preProcess()</code>函数进行中位数填补，但<strong>该函数只针对数值变量，不能对分类变量进行众数填补</strong>。由于这里含有缺失值的都是数值变量，可以使用<code>preProcess()</code>函数。得到的结果和之前<code>impute()</code>函数相同。<code>preProcess()</code>函数的功能很强大，你可以将其想象成连接各种数据预处理方法的接口，我们之后会介绍该函数其它数据预处理功能。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;medianImpute&quot;</span>)
demo_imp2&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp2[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<pre><code>##       age           gender        income       house       store_exp      
##  Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
##  1st Qu.:25.00   Male  :446   1st Qu.: 87896   Yes:568   1st Qu.:  205.1  
##  Median :36.00                Median : 93869             Median :  329.8  
##  Mean   :38.58                Mean   :109923             Mean   : 1357.7  
##  3rd Qu.:53.00                3rd Qu.:119456             3rd Qu.:  597.3  
##  Max.   :69.00                Max.   :319704             Max.   :50000.0</code></pre>
</div>
<div id="k-" class="section level3">
<h3><span class="header-section-number">5.3.2</span> K-近邻填补</h3>
<p>直观的讲，K-邻近方法（也称为KNN）就是“物以类聚”这一思想的统计学表达。如果某人留着海藻般的长发，喜欢安妮宝贝的“现世安稳，岁月静好”，一会明亮一会忧伤，问题是你要知道这个人喜欢什么样的鞋子怎么办？去看看其他那些留着同样长发喜欢同样句子又明亮又忧伤的人都穿什么鞋子，然后你很可能得出结论：此人喜欢棉布鞋。</p>
<p>技术上讲，K-近邻方法建立在距离的定义之上（通常时欧几里德距离），其基本思路是对于含有缺失值的样本，寻找该离样本最近的K个样本（邻居），然后用这些邻居的观测均值对该样本的缺失值进行填补。由于这里找邻居根据的是样本点之间的距离，各个变量的标度需要统一，不然尺度大的变量在决定距离上会占主导作用。</p>
<p>我们使用<code>preProcess()</code>实现KNN填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
<span class="co"># 用predict()函数进行KNN填补</span>
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">Error in `[.data.frame`(old, , non_missing_cols, drop = FALSE) : 
  undefined columns selected</code></pre></div>
<p>程序报错说“undefined columns selected（选择了无法定义的列）”。这是因为<code>sim.dat</code>中有函数无法处理的非数值型变量，在上面代码的第一行使用<code>preProcess()</code>时，函数会自动忽略非数值型变量，所以你运行第一行代码没有问题。但是在第二行代码，通过<code>predict()</code>函数对数据框进行KNN填补时，数据框有非数值变量就会导致填补无法进行。我们移除这些变量，再进行填补就没有问题了。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 找到因子变量</span>
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(sim.dat,class)==<span class="st">&quot;factor&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat[,-idx])
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">3</span>])</code></pre></div>
<pre><code>##       age                 income           store_exp       
##  Min.   :-1.5910972   Min.   :-1.43989   Min.   :-0.43345  
##  1st Qu.:-0.9568733   1st Qu.:-0.53732   1st Qu.:-0.41574  
##  Median :-0.1817107   Median :-0.37606   Median :-0.37105  
##  Mean   : 0.0000156   Mean   : 0.02389   Mean   :-0.00042  
##  3rd Qu.: 1.0162678   3rd Qu.: 0.21540   3rd Qu.:-0.27437  
##  Max.   : 2.1437770   Max.   : 4.13627   Max.   :17.52734</code></pre>
<p>当前的例子中非数值型的变量只有因子，你在自己应用该方法时要注意是否还有字符型（<code>character</code>）变量。 <code>lapply(data,class)</code>命令可以返回一个数据框各列对应类别的列表，你只要将<code>data</code>换成你处理的数据框名即可。这里我们的数据框是<code>sim.dat</code>，于是你可以这样获得数据框各列的类别：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里只显示前3个元素</span>
<span class="kw">lapply</span>(sim.dat,class)[<span class="dv">1</span>:<span class="dv">3</span>]</code></pre></div>
<pre><code>## $age
## [1] &quot;integer&quot;
## 
## $gender
## [1] &quot;factor&quot;
## 
## $income
## [1] &quot;numeric&quot;</code></pre>
<p>将KNN填补的结果和之前中位数填补结果进行比较大家发现什么了？结果好像完全不一样。KNN返回的数据框整个尺度都变了。这是因为当你告诉<code>preProcess()</code>函数进行KNN填补时（选项<code>method=&quot;knnImpute&quot;</code>），函数会自动对数据进行标准化（下一小节将提到的中心化和标量化）。另外一种方法是使用下一小节中介绍的袋状树填补。关于KNN填补还有一点需要注意，算法无法对整行缺失的观测进行填补。这个并不难从直观上理解，既然改算法是通过邻近点的取值平均来填补，如果某一样本所有值都缺失，那怎么定义该样本的邻近点呢？下面我们在原数据框上添加一个所有观测都缺失的样本，将这个新的数据框储存在<code>temp</code>对象中，然后对temp进行KNN填补，看看会发生什么：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp&lt;-<span class="kw">rbind</span>(sim.dat,<span class="kw">rep</span>(<span class="ot">NA</span>,<span class="kw">ncol</span>(sim.dat)))
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(temp,class)==<span class="st">&quot;factor&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp&lt;-<span class="kw">predict</span>(imp,temp[,-idx])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">Error in FUN(newX[, i], ...) : 
  cannot impute when all predictors are missing in the new data point</code></pre></div>
<p>运行结果中有错误警告“cannot impute when all predictors are missing in the new data point（当样本对应的所有观测都缺失时无法填补）”。我们在拿到数据的时可以查找并删除这些完全缺失的样本。我们可以通过下面代码找到这样的行：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idx&lt;-<span class="kw">apply</span>(temp,<span class="dv">1</span>,function(x) <span class="kw">sum</span>(<span class="kw">is.na</span>(x)) )
<span class="kw">as.vector</span>(<span class="kw">which</span>(idx==<span class="kw">ncol</span>(temp)))</code></pre></div>
<pre><code>## [1] 1001</code></pre>
<p>结果显示第1001行所有的观测都缺失。你可以进一步删除所有观测都缺失的行。</p>
</div>
<div id="section-5.3.3" class="section level3">
<h3><span class="header-section-number">5.3.3</span> 袋状树填补</h3>
<p>另外一种填补方法是装袋树（Bagging，bootstrap aggregation 的缩写），最初由 Leo Breiman 提出，它是最早发展起来的集成方法之一<span class="citation">(L 1966a)</span>。对于数据中需要填补的变量，我们使用剩下的变量训练装袋树，然后再用训练出的树来对缺失值进行预测。虽然理论上说该方法更加强大，但计算量比KNN大了许多。在实际应用中，你一定要根据自己的具体情况选择填补的方式。因为你可以不断的探索使用理论上更加精确的填补方式，但也要考虑在这上面花的时间成本是不是值得，如果一个中位数，或者均值填补就可以满足建模需要，即使用袋状树填补可以提高些许精度，但是提升很可能非常小，没有太大的实际意义，尤其在样本量很大的时候。袋状树本身就是一个模型，可以用于回归和判别，我们之后在介绍树相关的方法时会进一步介绍。下面我们用<code>preProcess()</code>对数据框<code>sim.dat</code>进行袋状树填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;bagImpute&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">      age           gender        income       house       store_exp      
 Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
 1st Qu.:25.00   Male  :446   1st Qu.: 86762   Yes:568   1st Qu.:  205.1  
 Median :36.00                Median : 94739             Median :  329.0  
 Mean   :38.58                Mean   :114629             Mean   : 1357.6  
 3rd Qu.:53.00                3rd Qu.:123726             3rd Qu.:  597.3  
 Max.   :69.00                Max.   :319704             Max.   :50000.0  </code></pre></div>
</div>
</div>
<div id="section-5.4" class="section level2">
<h2><span class="header-section-number">5.4</span> 中心化和标量化</h2>
<p>这是最基本的数据变换。中心化是通过将变量的每个观测减去该变量均值，这样中心化后的变量观测均值为0。标量化是将变量观测除以变量标准差，标量化后的变量标准差为1。对于一些要对变量进行线性组合的模型，中心化和标量化保证了变量的线性组合是基于组合后的新变量能够解释的原始变量中的方差。统计学上的方差，从直观的角度讲就是<strong>信息</strong>。试想若上面的消费者数据中，所有人的在线交易次数都是相同的，那么在线交易次数这个变量方差就是0，从应用的角度这个变量没有给我们提供可以区分这些消费者的信息。用到基于方差的变量线性组合的模型有主成分分析（PCA）<span class="citation">(Jolliffe <a href="#ref-pca1">2002</a>)</span>，偏最小二乘分析（PLS）<span class="citation">(Geladi P <a href="#ref-PLS1">1986</a>)</span>，探索性因子分析（EFA）<span class="citation">(Mulaik <a href="#ref-EFA1">2009</a>)</span>等等。这两个变换可以很容易自己编写程序实施，我们以服装装消费者数据（<code>sim.dat</code>）中的收入（income）变量为例：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">income&lt;-sim.dat$income
<span class="co"># 变量income的均值，na.rm=T告诉R忽略缺失值</span>
mux&lt;-<span class="kw">mean</span>(income,<span class="dt">na.rm=</span>T)
<span class="co"># 变量income的标准差，na.rm=T告诉R忽略缺失值</span>
sdx&lt;-<span class="kw">sd</span>(income,<span class="dt">na.rm=</span>T)
<span class="co"># 中心化</span>
tr1&lt;-income-mux
<span class="co"># 标量化</span>
tr2&lt;-tr1/sdx</code></pre></div>
<p>上面代码中，<code>tr1</code>是<code>income</code>中心化后的结果。<code>tr2</code>是对中心化后的结果<code>tr1</code>进一步标量化的结果。下面是关于这三步分别得到结果的总结：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">data.frame</span>(<span class="kw">cbind</span>(income,tr1,tr2)))</code></pre></div>
<pre><code>##      income            tr1              tr2         
##  Min.   : 41776   Min.   :-71767   Min.   :-1.4399  
##  1st Qu.: 85832   1st Qu.:-27711   1st Qu.:-0.5560  
##  Median : 93869   Median :-19674   Median :-0.3947  
##  Mean   :113543   Mean   :     0   Mean   : 0.0000  
##  3rd Qu.:124572   3rd Qu.: 11029   3rd Qu.: 0.2213  
##  Max.   :319704   Max.   :206161   Max.   : 4.1363  
##  NA&#39;s   :184      NA&#39;s   :184      NA&#39;s   :184</code></pre>
<p>可以看到，中心化后的<code>tr1</code>均值为0，但取值跨度依旧很大。接着标量化后的<code>tr2</code>就是一个均值为0，标准差为1的向量。</p>
<p>你也可以直接用<code>caret</code>包中的函数preProcess()对多个变量同时进行中心化和标量化，这里我选取其中2个变量进行展示：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>))
<span class="co"># method选项用于设置变换的方式，你可以同时进行一系列变换。</span>
<span class="co"># center：中心化</span>
<span class="co"># scale：标量化</span>
trans&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))
<span class="co"># preProcess函数的给出的还不是变换后的结果</span>
<span class="co"># 你需要通过predict函数对你想要变换的数据应用preProcess的结果才能够得到变换后的数据框</span>
transformed&lt;-<span class="kw">predict</span>(trans,sdat)</code></pre></div>
<p>变换后这两个变量就分布在相似的尺度上：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(transformed)</code></pre></div>
<pre><code>##       age              income       
##  Min.   :-1.5911   Min.   :-1.4399  
##  1st Qu.:-0.9569   1st Qu.:-0.5560  
##  Median :-0.1817   Median :-0.3947  
##  Mean   : 0.0000   Mean   : 0.0000  
##  3rd Qu.: 1.0163   3rd Qu.: 0.2213  
##  Max.   : 2.1438   Max.   : 4.1363  
##  NA&#39;s   :1         NA&#39;s   :184</code></pre>
<p>有时只要标量化数据而不一定要中心化。例如，如果模型中有针对参数估计绝对值的罚函数和且通过调优参数来进行变量选择（如LASSO）的话，变量大体在一个量级范围内使得能确保对参数“公平”的变量选择。之后在对于收缩方法（shrinkage method）的介绍能够帮助你更清楚的理解这一点。当然，如果你要通过参数估计衡量各个自变量和应变量之间关系强度的话，必须要对变量观测标量化。我是收缩方法的重度使用者，在工作中，我针对自己的分析项目设计了下面这种变换方式，该方式对我处理的问题非常有效，称其为<strong>分位数变换</strong>吧：</p>
<p><span class="math display">\[\label{eq:quantile1} x_{ij}^{*}=\frac{x_{ij}-quantile(x_{.j},0.01)}{quantile(x_{.j}-0.99)-quantile(x_{.j},0.01)}\]</span></p>
<p>这里<span class="math inline">\(x_{ij}\)</span>代表第i个样本的第j个变量观测，<span class="math inline">\(quantile(x_{.j},0.01)\)</span>指的是第j个变量所有样本观测组成的向量的1%分位数，类似的<span class="math inline">\(quantile(x_{.j},0.99)\)</span>是99%分位数，的这里之所以使用99%和1%分位数，而非最大值和最小值是为了减弱离群点的影响。编写函数进行分位数变换 <a href="#eq:quantile1"></a> 非常容易：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qscale&lt;-function(dat){
  for (i in <span class="dv">1</span>:<span class="kw">ncol</span>(dat)){
    up&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.99</span>)
    low&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.01</span>)
    diff&lt;-up-low
    dat[,i]&lt;-(dat[,i]-low)/diff
  }
  <span class="kw">return</span>(dat)
}</code></pre></div>
<p>这里我们对中位数填补后的数据集<code>demo_imp2中的变量</code>收入（<code>income</code>），实体店消费（<code>store_exp</code>）和在线消费（<code>online_exp</code>）进行上面的分位数变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp3&lt;-<span class="kw">qscale</span>(<span class="kw">subset</span>(demo_imp2,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>)))
<span class="kw">summary</span>(demo_imp3)</code></pre></div>
<pre><code>##      income           store_exp           online_exp       
##  Min.   :-0.05776   Min.   :-0.003407   Min.   :-0.006023  
##  1st Qu.: 0.15736   1st Qu.: 0.003984   1st Qu.: 0.042719  
##  Median : 0.18521   Median : 0.022704   Median : 0.253691  
##  Mean   : 0.26009   Mean   : 0.176965   Mean   : 0.278417  
##  3rd Qu.: 0.30456   3rd Qu.: 0.062849   3rd Qu.: 0.322871  
##  Max.   : 1.23857   Max.   : 7.476996   Max.   : 1.298845</code></pre>
<p>变换后的变量取值基本分布在0-1的范围之内。</p>
</div>
<div id="section-5.5" class="section level2">
<h2><span class="header-section-number">5.5</span> 有偏分布</h2>
<p>如果模型要求变量服从一定的对称分布（如正态分布）时，则需要进行数据变换去除分布的偏度。偏度是3阶标准化中心矩，是用来衡量分布不对称程度的，该统计量的数学定义如下：</p>
<p><span class="math display">\[偏度=\frac{\sum(x_{i}+\bar{x})^{3}}{(n-1)v^{3/2}}\]</span> <span class="math display">\[v=\frac{\sum(x_{i}=\bar{x})^{2}}{(n-1)}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 需要使用e1071包中的偏度计算函数skewness()</span>
<span class="kw">set.seed</span>(<span class="dv">1000</span>)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="co"># 抽取1000个自由度为2的开方分布，右偏分布</span>
x1&lt;-<span class="kw">rchisq</span>(<span class="dv">1000</span>,<span class="dv">2</span>, <span class="dt">ncp =</span> <span class="dv">0</span>)
<span class="co"># 通过x1得到对应的左偏分布变量x2</span>
x2&lt;-<span class="kw">max</span>(x1)-x1
<span class="kw">plot</span>(<span class="kw">density</span>(x2),<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>,<span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;左偏，偏度＝&quot;</span>,<span class="kw">round</span>(<span class="kw">skewness</span>(x2),<span class="dv">2</span>)), <span class="dt">xlab=</span><span class="st">&quot;X2&quot;</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(x1),<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>,<span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;右偏，偏度＝&quot;</span>,<span class="kw">round</span>(<span class="kw">skewness</span>(x1),<span class="dv">2</span>)), <span class="dt">xlab=</span><span class="st">&quot;X1&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:skew"></span>
<img src="DS_R_files/figure-html/skew-1.png" alt="有偏分布展示" width="80%" />
<p class="caption">
Figure 5.1: 有偏分布展示
</p>
</div>
<p>分布是否有偏可以很容易从图上看到。图<a href="section-5.html#fig:skew">5.1</a>显示了两种类型的不对称分布。分布对称时偏度=0，分布左偏时偏度&lt;0，分布右偏时偏度&gt;0，且偏离程度越大，偏度统计量的绝对值越大。有很多变换有助于去除偏度，如log变换，平方根或者取倒数。但是仅仅靠观察图形无法知道哪种变换方法最好。大家有没有注意到，常用的一些变换都和指数函数有关，如 <span class="math inline">\(log(x)\)</span>（这个是对数函数，但也是指数函数的近亲嘛：））、<span class="math inline">\(x^2\)</span> 和 <span class="math inline">\(\frac{1}{x}\)</span>。于是Box和Cox（1964）<span class="citation">(Box G <a href="#ref-BOXCOX1">1964</a>)</span>提出了含有一个参数<span class="math inline">\(\lambda\)</span>的指数变换族：</p>
<p><span class="math display">\[x^{*}=\begin{cases}
\begin{array}{c}
\frac{x^{\lambda}-1}{\lambda}\\
log(x)
\end{array} &amp;amp; \begin{array}{c}
if\ \lambda\neq0\\
if\ \lambda=0
\end{array}\end{cases}\]</span></p>
<p>很容易看出这个变换族群包含了<span class="math inline">\(log(x)\)</span>变换（<span class="math inline">\(\lambda\)</span>=0），<span class="math inline">\(x^2\)</span>变换（<span class="math inline">\(\lambda\)</span>=2），<span class="math inline">\(sqrt(x)\)</span>变换（<span class="math inline">\(\lambda\)</span>=0.5）以及<span class="math inline">\(frac{1}{x}\)</span>变换（<span class="math inline">\(\lambda\)</span>=-1）等常用的变换。Box-Cox覆盖的面更加广，变换指数可能是任意实数。<code>caret</code>包中有两个函数可以进行该变换，一个是<code>BoxCoxTrans()</code>。另外一个是我们之前用到的<code>preProcess()</code>，这里推荐大家使用后者，因为我们可以通过更改其中<code>method</code>选项对数据进行不同的变换，可以把该函数看作是不同预处理方法的接口，熟练使用后大家会发现其功能强大且及其方便。这里给大家插播一则广告，关于<code>psych</code>包中的<code>describe()</code>函数。我很喜欢用这个函数来在处理数据的不同阶段检查各个变量的情况，偏度，峰度，是不是可能有离群值，取值范围，均值等等，这个函数比<code>summary()</code>好用多了。当然这因人而异，有的人喜欢通过散点图矩阵来看各个变量的分布情况，个人还是喜欢看变量分布的各个统计量。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describe</span>(sim.dat)</code></pre></div>
<pre><code>##              vars    n      mean       sd   median   trimmed      mad
## age             1  999     38.58    14.19    36.00     37.67    16.31
## gender*         2 1000      1.45     0.50     1.00      1.43     0.00
## income          3  816 113543.07 49842.29 93868.68 104841.94 28989.47
## house*          4 1000      1.57     0.50     2.00      1.58     0.00
## store_exp       5  999   1358.71  2775.17   329.80    845.14   197.47
## online_exp      6 1000   2120.18  1731.22  1941.86   1874.51  1015.21
## store_trans     7 1000      5.35     3.70     4.00      4.89     2.97
## online_trans    8 1000     13.55     7.96    14.00     13.42    10.38
## Q1              9 1000      3.10     1.45     3.00      3.13     1.48
## Q2             10 1000      1.82     1.17     1.00      1.65     0.00
## Q3             11 1000      1.99     1.40     1.00      1.75     0.00
## Q4             12 1000      2.76     1.16     3.00      2.83     1.48
## Q5             13 1000      2.94     1.28     4.00      3.05     0.00
## Q6             14 1000      2.45     1.44     2.00      2.43     1.48
## Q7             15 1000      3.43     1.46     4.00      3.54     0.00
## Q8             16 1000      2.40     1.15     2.00      2.36     1.48
## Q9             17 1000      3.08     1.12     4.00      3.23     0.00
## Q10            18 1000      2.32     1.14     2.00      2.27     1.48
## segment*       19 1000      2.70     1.15     3.00      2.75     1.48
##                   min       max     range  skew kurtosis      se
## age             16.00     69.00     53.00  0.47    -1.18    0.45
## gender*          1.00      2.00      1.00  0.22    -1.95    0.02
## income       41775.64 319704.34 277928.70  1.69     2.57 1744.83
## house*           1.00      2.00      1.00 -0.27    -1.93    0.02
## store_exp      155.81  50000.00  49844.19  8.08   115.04   87.80
## online_exp      68.82   9479.44   9410.63  1.18     1.31   54.75
## store_trans      1.00     20.00     19.00  1.11     0.69    0.12
## online_trans     1.00     36.00     35.00  0.03    -0.98    0.25
## Q1               1.00      5.00      4.00 -0.12    -1.36    0.05
## Q2               1.00      5.00      4.00  1.13    -0.32    0.04
## Q3               1.00      5.00      4.00  1.06    -0.40    0.04
## Q4               1.00      5.00      4.00 -0.18    -1.46    0.04
## Q5               1.00      5.00      4.00 -0.60    -1.40    0.04
## Q6               1.00      5.00      4.00  0.11    -1.89    0.05
## Q7               1.00      5.00      4.00 -0.90    -0.79    0.05
## Q8               1.00      5.00      4.00  0.21    -1.33    0.04
## Q9               1.00      5.00      4.00 -0.68    -1.10    0.04
## Q10              1.00      5.00      4.00  0.39    -1.23    0.04
## segment*         1.00      4.00      3.00 -0.20    -1.41    0.04</code></pre>
<p>大家可以很清楚的看到哪些变量有偏（<code>skew</code>），通过比较均值（<code>mean</code>）和修剪后的均值（<code>trimmed</code>），大概知道哪些变量可能存在离群值。修剪后的均值是去除最大和最小的一部分观测点后得出的均值。这两个值差距很大说明对应变量存在离群点，这里很明显在线消费（<code>store_exp</code>）存在离群点。</p>
<p>下面我们以数据集<code>sim_dat</code>中的变量<code>store_trans</code>和<code>online_trans</code>为例展示Box-Cox变换函数的使用方法：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取需要的两列，存在dat_bc中</span>
dat_bc&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span>))
(trans&lt;-<span class="kw">preProcess</span>(dat_bc,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;BoxCox&quot;</span>)))</code></pre></div>
<pre><code>## Created from 1000 samples and 2 variables
## 
## Pre-processing:
##   - Box-Cox transformation (2)
##   - ignored (0)
## 
## Lambda estimates for Box-Cox transformation:
## 0.1, 0.7</code></pre>
<p>上面的输出的第一行显示了样本量是1000，有2个变量。输出的最后一行表明每个变量对应的参数<span class="math inline">\(\lambda\)</span>估计值（0.1和0.7）。和之前一样，我们接着用<code>predict()</code>函数对数据框应用估计的变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,dat_bc)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(dat_bc$store_trans,<span class="dt">main=</span><span class="st">&quot;原始商店消费次数&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;store_trans&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)
<span class="kw">hist</span>(transformed$store_trans,<span class="dt">main=</span><span class="st">&quot;变换后商店消费次数&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;store_trans&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bc"></span>
<img src="DS_R_files/figure-html/bc-1.png" alt="Box-Cox变换展示" width="80%" />
<p class="caption">
Figure 5.2: Box-Cox变换展示
</p>
</div>
<p>从图<a href="section-5.html#fig:bc">5.2</a>可以看到，变换前商店消费量分布明显右偏，变换后情况显著改善，基本对称。<code>BoxCoxTrans()</code> 也可以进行Box-Cox变换，使用方法类似。但要注意的是<code>BoxCoxTrans()</code>只能作用于单个数值变量，不能像之前那样对一个数据框中的列一次性进行变换。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(trans&lt;-<span class="kw">BoxCoxTrans</span>(dat_bc$store_trans))</code></pre></div>
<pre><code>## Box-Cox Transformation
## 
## 1000 data points used to estimate Lambda
## 
## Input data summary:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.00    3.00    4.00    5.35    7.00   20.00 
## 
## Largest/Smallest: 20 
## Sample Skewness: 1.11 
## 
## Estimated Lambda: 0.1 
## With fudge factor, Lambda = 0 will be used for transformations</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,dat_bc$store_trans)
<span class="kw">skewness</span>(transformed)</code></pre></div>
<pre><code>## [1] -0.2154708</code></pre>
<p>参数<span class="math inline">\(\lambda\)</span>的估计和之前相同（0.1），原始观测的偏度为1.1，变换后偏度为－0.2，虽然不严格为0，但和之前比较有极大改善，可以用来计算变量间线性相关性，用于回归等。</p>
</div>
<div id="section-5.6" class="section level2">
<h2><span class="header-section-number">5.6</span> 处理离群点</h2>
<p>有时判断离群点并不是那么容易，因为没有一个非黑即白的标准。箱线图和直方图等一些基本的可视化可以用来初步检查是否有离群点。举个例子，我们可以对服装消费者数据中的数值型非问卷调查变量进行可视化：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取数值型非问卷调查变量</span>
sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>,<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span> ))
<span class="co"># 用car包中的函数scatterplotMatrix()绘制散点图矩阵</span>
<span class="kw">par</span>(<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">scatterplotMatrix</span>(sdat,<span class="dt">diagonal=</span><span class="st">&quot;boxplot&quot;</span>,<span class="dt">smoother=</span><span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:scm"></span>
<img src="DS_R_files/figure-html/scm-1.png" alt="数值型非问卷调查变量散点图矩阵" width="80%" />
<p class="caption">
Figure 5.3: 数值型非问卷调查变量散点图矩阵
</p>
</div>
<p>从图<a href="section-5.html#fig:scm">5.3</a>，商店消费量（<code>store_exp</code>）明显有离群点（记得之前的土豪么）。你也可以从中看到一些变量两两之间的关系。年龄和在线交易次数负相关，但和实体店交易次数正相关，貌似年纪大的人更倾向于实体店购买。当然，还有消费量和收入正相关。这样的散点图简单但是有效，可以在建模之前告诉你很多关于数据的信息。</p>
<p>除了可视化这样直观的方式外，在一定的假设条件下，有一些统计学的定义离群值的方法。如常用Z分值来判断可能的离群点。对于某观测变量<span class="math inline">\(\mathbf{Y}\)</span>的Z分值定义为：</p>
<p><span class="math display">\[Z_{i}=\frac{Y_{i}-\bar{Y}}{s}\]</span></p>
<p>其中<span class="math inline">\(\bar{Y}\)</span>和<span class="math inline">\(s\)</span>分别为观测列的均值和标准差。直观的理解Z分值就对观测离均值的距离的度量（多少个标准差单位）。这种方法可能具有误导性，尤其是在样本量小的时候。Iglewicz和Hoaglin提出使用修正后的Z分值来判断离群点<span class="citation">(Iglewicz and Hoaglin <a href="#ref-mad1">1993</a>)</span>：</p>
<p><span class="math display">\[M_{i}=\frac{0.6745(Y_{i}-\bar{Y})}{MAD}\]</span></p>
<p>其中MAD是一系列<span class="math inline">\(|Y_{i}-\bar{Y}|\)</span>的中位数，称为绝对离差中位数。他们建议将上面修正后的Z分值大于3.5的点标记为可能的离群点。我们来检查下商店消费量观测对应的Z分值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 计算商店消费量的绝对离差中位数，这里用na.omit()告诉R忽略缺失值</span>
ymad&lt;-<span class="kw">mad</span>(<span class="kw">na.omit</span>(sdat$income))
<span class="co"># 计算Z分值</span>
zs&lt;-(sdat$income-<span class="kw">mean</span>(<span class="kw">na.omit</span>(sdat$income)))/ymad
<span class="co"># 看看有多少个离群点</span>
<span class="kw">sum</span>(<span class="kw">na.omit</span>(zs&gt;<span class="fl">3.5</span>))</code></pre></div>
<pre><code>## [1] 59</code></pre>
<p>用该标准，商店消费量对应的离群点有59个。关于离群点还有其它不同的检测。更多关于不同检测方法可以参考<span class="citation">(Iglewicz and Hoaglin <a href="#ref-mad1">1993</a>)</span>。</p>
<p>很重要的一点是离群点的影响取决于你使用的模型。有的模型对离群值很敏感，如线性回归，逻辑回归。有的对离群点具有抗性，如基于树的模型，支持向量机。此外离群点和错误的观测不一样，它是真实的观测，其中包含信息，所以不能随意的删除。如果你使用的模型对离群点非常敏感，可以使用空间表示变换<span class="citation">(Serneels S <a href="#ref-ssp">2006</a>)</span>。该变换将自变量取值映射到高维的球面上。变换公式如下：</p>
<p><span class="math display">\[x_{ij}^{*}=\frac{x_{ij}}{\sqrt{\sum_{j=1}^{p}x_{ij}^{2}}}\]</span></p>
<p>其中<span class="math inline">\(x_{ij}\)</span>表示第i个样本对应第j个变量的观测。由公式可见，每个样本都除以了它们的平方模。公式的分母其实可以看作是该样本到p维空间0点的欧几里德距离，有三点需要特别注意：</p>
<ol style="list-style-type: decimal">
<li>在该变换前需要对自变量标准化</li>
<li>与中心化和标准化不同，这个变换操作的对象是所有自变量</li>
<li>如果需要移除变量（之后会提到移除高度相关变量），这一步必须要在空间表示变换之前，否者会导致一系列问题</li>
</ol>
<p>作为例子，我们用<code>caret</code>包中的<code>spatialSign()</code>函数对收入和年龄两个变量进行空间表示变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 用KNN填补缺失值</span>
sdat&lt;-sim.dat[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)]
imp&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;knnImpute&quot;</span>),<span class="dt">k=</span><span class="dv">5</span>)
sdat&lt;-<span class="kw">predict</span>(imp,sdat)
transformed &lt;-<span class="st"> </span><span class="kw">spatialSign</span>(sdat)
transformed &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(transformed)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(income ~<span class="st"> </span>age,<span class="dt">data =</span> sdat,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">main=</span><span class="st">&quot;变换前&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)
<span class="kw">plot</span>(income ~<span class="st"> </span>age,<span class="dt">data =</span> transformed,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">main=</span><span class="st">&quot;变换后&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:sst"></span>
<img src="DS_R_files/figure-html/sst-1.png" alt="空间表示变换图" width="80%" />
<p class="caption">
Figure 5.4: 空间表示变换图
</p>
</div>
<p>细心的读者可能已经发现，上面的代码中貌似并没有对数据进行标准化。如果你还记得，在介绍KNN填补的时候讲过，<code>preProcess()</code>在进行KNN的同时默认会对数据框进行标准化，所以上面代码没有特地标准化数据。</p>
</div>
<div id="section-5.7" class="section level2">
<h2><span class="header-section-number">5.7</span> 共线性</h2>
<p>共线性可能是大多数地球人都听过的一个词了，即使在传统企业市场部的营销人员都知道这个词，这也可能是他们唯一可以拿出来显摆的技术词汇。关于变量间的相关性，有个非常好用的包<code>corrplot</code>，其中同名函数<code>corrplot()</code>能够对变量相关矩阵进行可视化。函数中有一个选项可以设置变量的排序方式，使得相关性高的变量排列在一起。和之前一样，我们选取其中数值类的非问卷调查变量为例子，展示如何使用该函数探索变量之间共线性：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取数值型非问卷调查变量</span>
sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>,<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span> ))
<span class="co"># 用装袋树填补，换着用，帮大家练练手：）</span>
imp&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="st">&quot;bagImpute&quot;</span>)
sdat&lt;-<span class="kw">predict</span>(imp,sdat)
<span class="co"># 得到相关矩阵</span>
correlation&lt;-<span class="kw">cor</span>(sdat)
<span class="co"># 对相关矩阵作图</span>
<span class="kw">par</span>(<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">corrplot.mixed</span>(correlation,<span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>,<span class="dt">tl.pos=</span><span class="st">&quot;lt&quot;</span>,<span class="dt">upper=</span><span class="st">&quot;ellipse&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:corp"></span>
<img src="DS_R_files/figure-html/corp-1.png" alt="相关矩阵可视化" width="80%" />
<p class="caption">
Figure 5.5: 相关矩阵可视化
</p>
</div>
<p>这里我们使用的是<code>corrplot.mixed()</code>函数对相关矩阵可视化（图<a href="section-5.html#fig:corp">5.5</a>）。其中相关性越接近0颜色越浅且形状越接近圆，相关性不等于0的用椭圆表示（因为我们设置了选项upper=“ellipse”），相关性越大椭圆越窄，蓝色代表正相关，红色代表负相关，椭圆的方向也随着相关性正负变化。 相关系数在矩阵的下三角显示。可以看到，我们之前在散点图矩阵（图<a href="section-5.html#fig:scm">5.3</a>）中看到的变量相关性在这里很明显的展现出来，年龄和在线购物次数负相关，消费量和收入正相关。且有些线性相关性非常强（<code>online_trans</code>和<code>age</code>的相关系数是－0.85）。这会导致什么问题呢？这其实很容易理解，两个变量高度相关意味着它们含有重复的信息，我们其实不需要讲两个变量同时留在模型中。你可能会问，那重复未必有害处不是么？变量高度相关会倒是参数估计极为不稳定。举个例子，我们可以对收入进行简单的线性回归：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfit1&lt;-<span class="kw">lm</span>(income~age+online_trans+store_exp+store_trans,<span class="dt">data=</span>sdat)
<span class="kw">summary</span>(cfit1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = income ~ age + online_trans + store_exp + store_trans, 
##     data = sdat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -183840  -14126    -914   10944  156106 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  67790.0372  8640.8338   7.845 1.11e-14 ***
## age            221.5832   135.9644   1.630    0.103    
## online_trans  -270.9619   249.5672  -1.086    0.278    
## store_exp        5.7269     0.4356  13.147  &lt; 2e-16 ***
## store_trans   6399.5252   357.8722  17.882  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31650 on 995 degrees of freedom
## Multiple R-squared:  0.5763, Adjusted R-squared:  0.5746 
## F-statistic: 338.3 on 4 and 995 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>大家可以看到，年龄和在线购买的方差都比较大。因为这两个变量高度相关，模型也拿不准到底该如和分配这两个变量的系数。下面我们将年龄（age）删除，再进行一次回归：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfit2&lt;-<span class="kw">lm</span>(income~online_trans+store_exp+store_trans,<span class="dt">data=</span>sdat)
<span class="kw">summary</span>(cfit2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = income ~ online_trans + store_exp + store_trans, 
##     data = sdat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -182372  -14498   -1179   11127  156121 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  80861.0786  3217.6962  25.130  &lt; 2e-16 ***
## online_trans  -606.4452   141.2126  -4.295 1.92e-05 ***
## store_exp        5.6427     0.4329  13.035  &lt; 2e-16 ***
## store_trans   6425.0185   357.8273  17.956  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31670 on 996 degrees of freedom
## Multiple R-squared:  0.5752, Adjusted R-squared:  0.5739 
## F-statistic: 449.5 on 3 and 996 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>比较<code>cfit1</code>和<code>cfit2</code>中<code>online_trans</code>对应的系数估计之间巨大的变化，就可以很容易看出高度共线的变量同时出现在回归模型中对参数估计可能带来的影响了。于此同时<code>store_exp</code>和<code>store_trans</code>的参数估计在两个结果中差异不大。所以我们在进行回归之前需要移除一些高度相关的变量，使得模型中变量相关性在一定范围之内。我个人比较喜欢用《应用预测模型》<span class="citation">(Max Kuhn <a href="#ref-APM">2013</a>)</span>书中3.5小节中展示的算法，其核心思想是在删除尽可能少的变量的情况下将变量两两相关性控制在人为设定的一个阈值内：</p>
<blockquote>
<p>算法：处理高度相关变量</p>
<ol style="list-style-type: decimal">
<li>计算自变量的相关系数矩阵</li>
<li>找出相关系数绝对值最大的那对自变量（记为自变量A和B）</li>
<li>计算A和其他自变量相关系数的均值。对B也做同样的计算</li>
<li>如果A的平均相关系数更大，则将A移除；如若不然，移除B</li>
<li>重复步骤2到4，直至所有相关系数的绝对值都低于设定的阈值</li>
</ol>
</blockquote>
<p><code>caret</code>中的<code>findCorrelation()</code>函数能够实施上面的算法：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(highCorr&lt;-<span class="kw">findCorrelation</span>(<span class="kw">cor</span>(sdat),<span class="dt">cutoff=</span>.<span class="dv">75</span>))</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>结果返回的是需要删除的列号，这里算法告诉我们若要使得变量相关性在0.75内，需要删除第1列。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将高相关的变量删除</span>
sdat&lt;-sdat[-highCorr]
<span class="co"># 查看新的相关矩阵</span>
<span class="kw">cor</span>(sdat)</code></pre></div>
<pre><code>##                  income  store_exp online_exp store_trans online_trans
## income        1.0000000  0.6004006  0.5198623   0.7069595   -0.3572884
## store_exp     0.6004006  1.0000000  0.5349527   0.5399121   -0.1367411
## online_exp    0.5198623  0.5349527  1.0000000   0.4420638    0.2256370
## store_trans   0.7069595  0.5399121  0.4420638   1.0000000   -0.4367544
## online_trans -0.3572884 -0.1367411  0.2256370  -0.4367544    1.0000000</code></pre>
<p>移除变量后相关矩阵中元素的绝对值都低于0.75。这里需要提醒大家一点，关于这个相关性阈值的选取强烈建议大家将这个阈值成一个调优参数，试验不同的值，看哪个对应的模型精度最高。建议在0.6-0.8范围内寻找最优的阈值。关于共线性的处理还有一些其它方法，如主成分分析和因子分析，这些方法我们将在特征工程那一章进行讲解。</p>
</div>
<div id="section-5.8" class="section level2">
<h2><span class="header-section-number">5.8</span> 稀疏变量</h2>
<p>除了高度相关的变量以外，我们还需要移除那些观测非常稀疏的变量。一个极端的例子是某变量观测只有一个取值，我们可以将其称为0方差变量。有的可能只有若干取值，我们称其为近0方差变量。这里所讲的处理稀疏变量的方法无法解决大规模基因表达研究中的问题，在基因表达研究中的一个常见问题是观测少，同时变量数目远远超过观测，几乎所有变量都很稀疏，这种情况下需要很多新的高维模型，这是当前非常活跃的一个研究领域，但这不在本书讨论范围之内。这里讨论情况是由于各种原因，出现某些稀疏变量的情况。我们需要做的是识别这些变量然后将其删除。这些变量的存在对如线性回归和逻辑回归这样的模型拟合的表现和稳定性会有很大影响，但决策树模型没有影响。</p>
<p>通常识别这样的变量有两个法则：</p>
<ul>
<li>不同取值数目和样本量的比值</li>
<li>最常见的取值频数和第二常见的取值频数之间的比值</li>
</ul>
<p>我们可以设定上面的规则，然后用<code>caret</code>包中的<code>nearZeroVar()</code>函数过滤近0方差变量。为了展示该方法，我们在数据中加入一些这样的变量，然后应用该函数查找它们：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 先备份数据</span>
zero_demo&lt;-sim.dat
<span class="co"># 加上两个稀疏变量</span>
<span class="co"># zero1 的取值全是1</span>
<span class="co"># zero2 除了第一个元素是1以外其余全是0</span>
zero_demo$zero1&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,<span class="kw">nrow</span>(zero_demo))
zero_demo$zero2&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">nrow</span>(zero_demo)-<span class="dv">1</span>))</code></pre></div>
<p>上面代码中我们生成了两个新的变量（<code>zero1</code>和<code>zero2</code>），它们分别为0方差和近0方差变量，然后将这两个变量添加到数据框<code>zero_demo</code>上。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nearZeroVar</span>(zero_demo,<span class="dt">freqCut =</span> <span class="dv">95</span>/<span class="dv">5</span>, <span class="dt">uniqueCut =</span> <span class="dv">10</span>)</code></pre></div>
<p>我们将函数<code>nearZeroVar()</code>应用在含有稀疏变量的数据框上，和之前查找高共线性变量一样，函数返回的是稀疏变量对应的列号。这里返回的是我们生成的两个稀疏变量所在的列。你可以接下来删除这两列。注意这里的两个选项分别对应我们上面提到的两个定义稀疏变量的标准。<code>uniqueCut =</code>是不同取值数目和样本量的比值； <code>freqCut =</code>是最常见的取值频数和第二常见的取值频数之间的比值。你可以根据具体情况提高或者降低这些标准。一个很自然的问题是该怎么选？你要是在这个行业久了就会发现，即使是这样一个和数学相关的技术性行业，非黑即白的事情也是很少存在的。目前为止在我看来（我也还在这个领域不停的学习），所有关于标准，参数，模型选择的问题，最好的答案只有一个，看哪种选择能帮你达成建模目标。比如你的建模目标预测，那你就要看看不同选择下给出的预测精度哪个更高。这个标准甚至超过的p值， AIC等等一堆统计学的测量。我们在下一章讨论建模技术的时候会进一步展开。</p>
</div>
<div id="section-5.9" class="section level2">
<h2><span class="header-section-number">5.9</span> 编码名义变量</h2>
<p>名义变量，又称虚设变量，是一个指标性质的变量，通常取值0或1。有时你需要将分类变量转化成名义变量。比如一些问卷调查每个问题都有A,B,C,D,E五个选项，你得到数据后通常要将每个问题对应的分类变量转化成5个名义变量，然后将其中一个选项当作基准选项。我们在介绍逻辑回归及其衍生模型的那节中会展示一个这样的案例分析。我们还是用服装消费者的数据为例，假设我们要将性别（<code>gender</code>）和房产拥有情况（<code>house</code>）这两个变量转化为名义变量，R中有两个函数可以进行这项操作，<code>nnet</code>包中的｀class.ind()｀函数，但该函数有个局限是一次只能处理一个变量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumVar&lt;-<span class="kw">class.ind</span>(sim.dat$gender)
<span class="kw">head</span>(dumVar)</code></pre></div>
<pre><code>##      Female Male
## [1,]      1    0
## [2,]      1    0
## [3,]      0    1
## [4,]      0    1
## [5,]      0    1
## [6,]      0    1</code></pre>
<p>我们可以看到性别这个变量被重新编码为2个名义变量，你在建模时需要删除其中一个，因为它们之间有重复信息（正常情况下非男即女嘛）。这样在分类变量多的时候得写个循环来进行重新编码还是有些麻烦。另外一个更加方便的方法是<code>caret</code>包（功能强大的包，简直是居家旅行必备神器！）中的<code>dummyVars()</code> 函数：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~gender+house+income,
                  <span class="dt">data=</span>sim.dat,
                  <span class="co"># 用原变量名加上因子层级的名称作为新的名义变量名</span>
                  <span class="dt">levelsOnly=</span>F)
<span class="kw">head</span>(<span class="kw">predict</span>(dumMod,sim.dat))</code></pre></div>
<pre><code>##   gender.Female gender.Male house.No house.Yes   income
## 1             1           0        0         1 120963.4
## 2             1           0        0         1 122008.1
## 3             0           1        0         1 114202.3
## 4             0           1        0         1 113616.3
## 5             0           1        0         1 124252.6
## 6             0           1        0         1 107661.5</code></pre>
<p><code>dummyVars()</code>可以用类似模型公式的表达方式对任何变量同时进行转化。而且公式右边不一定要是分类变量，你发现我将收入（<code>income</code>）这个变量也加上去了，对于数值型变量，函数会保持原变量，这样的好处在于你不需要特地选定其中的因子变量，转换后再添加到原数据框上，还要删除原变量，省去了很多麻烦。不仅仅如此，该函数还可以添加交互效应，比如：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~gender+house+income+income:gender,
                  <span class="dt">data=</span>sim.dat,
                  <span class="dt">levelsOnly=</span>F)
<span class="kw">head</span>(<span class="kw">predict</span>(dumMod,sim.dat))</code></pre></div>
<pre><code>##   gender.Female gender.Male house.No house.Yes   income
## 1             1           0        0         1 120963.4
## 2             1           0        0         1 122008.1
## 3             0           1        0         1 114202.3
## 4             0           1        0         1 113616.3
## 5             0           1        0         1 124252.6
## 6             0           1        0         1 107661.5
##   gender.Female:income gender.Male:income
## 1             120963.4                0.0
## 2             122008.1                0.0
## 3                  0.0           114202.3
## 4                  0.0           113616.3
## 5                  0.0           124252.6
## 6                  0.0           107661.5</code></pre>
<p>这里，如果你觉得男性中收入水平对行为的影响和女性收入水平对行为的影响不一样，女性高收入的人在服装购买上大花销更大，而男性收入高低对服装花销影响不大，这就要检测收入和性别的交互效应，可以在公式中加入<code>income:gender</code>得到交互效应编码。是不是很方便？</p>
<p>到目前为止，我们讲了几种常用的数据预处理方式，这些处理的目的是为了得到我们在本章开始所讲的可以用于模型的数据。本章的最后一部分想讲讲一些数据整合的方法。数据整合可能用在任何一个阶段，可能数据行列安排的方式不符合建模要求，或者之后的数据展示需要对比不同的群体，这些都涉及到数据整合。下面我介绍一些自己工作中常用到的数据整合方法。</p>
</div>
<div id="section-5.10" class="section level2">
<h2><span class="header-section-number">5.10</span> 本章总结</h2>
<p>本章介绍了常用的建模前的数据预处理方法。需要补充一点，这里我没有讲到是连续变量的离散化，也称为区间化自变量。比如将年龄转变为由&lt;25，25-40，40-60和&gt;60组成的分类变量。个人不赞成分析师自行将连续变量离散化，如果客户或相关领域专家给出明确的理由，在该领域这么划分是通常惯例，或者只有划分成某种区间模型结果才能够解释，那么你可以根据对方的观点划分。而从分析的角度，手动区间化连续型数据是不推荐的。连续变量的效能通常比区间变量高。你需要权衡将连续变量离散化对可解释性的提升和对模型精确度的损害。注意这里指的是人为主观的将一些连续变量转变为分类变量而非模型检测出的截断点。有一些模型，如分类/回归树和多元自适性回归样条，它们在建模过程中能够估计合适的截断点。这些模型使用了所有自变量的信息，对不同变量进行评估，使用可靠的统计方法，并且是基于某个准则（我们在下一章会讲到）来得到合适的区间划分。这样的划分是可以的，但这属于建模，而非数据预处理。</p>
<p>下面总结一下通常情况下得到技术上正确的数据（对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据）后需要经历的数据预处理流程：</p>
<ol style="list-style-type: decimal">
<li>检查数据：变量分布，是不是存在错误的观测</li>
<li>缺失值填补：了解缺失原因，选择填补方式</li>
<li>数据变换：取决于需要建立的模型，对不符合正态分布假设，变量尺度差异大，有离群值的数据进行变换</li>
<li>检查共线性：找到高度线性相关的变量，决定删除变量，还是使用PCA，CFA这类非监督方法得到不相关的变量线性组合</li>
<li>稀疏变量：查找并且删除稀疏变量</li>
<li>编码名义变量：对于不能作用于分类变量的模型，将分类变量转化成0/1名义变量</li>
</ol>
<p>我们将在下一章介绍一些数据整合和整形的方法，以及R中能够进行高效数据操作的包。得到可以用于模型的数据后，接下来就该进入建模阶段了。</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-impute1">
<p>Ton de Waal, Sander Scholtus, Jeroen Pannekoek. 2011. <em>Handbook of Statistical Data Editing and Imputation</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-pca1">
<p>Jolliffe, I.T. 2002. <em>Principla Component Analysis</em>. 2nd ed. New York: Springer.</p>
</div>
<div id="ref-PLS1">
<p>Geladi P, Kowalski B. 1986. “Partial Least-Squares Regression: A Tutorial.” <em>Analytica Chimica Acta</em>, no. 185: 1–17.</p>
</div>
<div id="ref-EFA1">
<p>Mulaik, S.A. 2009. <em>Foundations of Factor Analysis</em>. 2ND ed. Boca Raton: Chapman&amp;Hall/CRC.</p>
</div>
<div id="ref-BOXCOX1">
<p>Box G, Cox D. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> Series B (Methodological): 211–52.</p>
</div>
<div id="ref-mad1">
<p>Iglewicz, Boris, and David Hoaglin. 1993. “How to Detect and Handle Outliers.” <em>The ASQC Basic References in Quality Control: Statistical Techniques</em> 16.</p>
</div>
<div id="ref-ssp">
<p>Serneels S, Espen PV, Nolf ED. 2006. “Spatial Sign Pre-Processing: A Simple Way to Impart Moderate Robustness to Multivariate Estimators.” <em>Journal of Chemical Information and Modeling</em> 46 (3): 1402–9.</p>
</div>
<div id="ref-APM">
<p>Max Kuhn, Kjell Johnston. 2013. <em>Applied Predictive Modeling</em>. Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-6.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-yuchuli.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
