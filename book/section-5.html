<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.0.72 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-06-10">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-4.html">
<link rel="next" href="section-6.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="5.10.1" data-path="section-5.html"><a href="section-5.html#baseapply"><i class="fa fa-check"></i><b>5.10.1</b> base包：apply()</a></li>
<li class="chapter" data-level="5.10.2" data-path="section-5.html"><a href="section-5.html#plyrddply"><i class="fa fa-check"></i><b>5.10.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="5.10.3" data-path="section-5.html"><a href="section-5.html#dplyr"><i class="fa fa-check"></i><b>5.10.3</b> dplyr包</a></li>
<li class="chapter" data-level="5.10.4" data-path="section-5.html"><a href="section-5.html#reshape2"><i class="fa fa-check"></i><b>5.10.4</b> 数据整形：<code>reshape2</code>包</a></li>
<li class="chapter" data-level="5.10.5" data-path="section-5.html"><a href="section-5.html#tidyr"><i class="fa fa-check"></i><b>5.10.5</b> 数据整形：<code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="section-5.html"><a href="section-5.html#section-5.11"><i class="fa fa-check"></i><b>5.11</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 建模技术简介</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#section-6.2.1"><i class="fa fa-check"></i><b>6.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#section-6.2.2"><i class="fa fa-check"></i><b>6.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#section-6.2.3"><i class="fa fa-check"></i><b>6.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#section-6.3.1"><i class="fa fa-check"></i><b>6.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#section-6.3.2"><i class="fa fa-check"></i><b>6.3.2</b> 重抽样</a></li>
<li class="chapter" data-level="6.3.3" data-path="section-6.html"><a href="section-6.html#section-6.3.3"><i class="fa fa-check"></i><b>6.3.3</b> 评估模型表现</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 特征工程</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 特征构建</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 特征提取</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 主成分分析</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 因子分析</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 高维标度化</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 变量选择</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="8.1.1" data-path="section-8.html"><a href="section-8.html#section-8.1.1"><i class="fa fa-check"></i><b>8.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="8.1.2" data-path="section-8.html"><a href="section-8.html#section-8.1.2"><i class="fa fa-check"></i><b>8.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="8.1.3" data-path="section-8.html"><a href="section-8.html#section-8.1.3"><i class="fa fa-check"></i><b>8.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 收缩方法</a></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> 分层线性回归</a></li>
<li class="chapter" data-level="8.4" data-path="section-8.html"><a href="section-8.html#section-8.4"><i class="fa fa-check"></i><b>8.4</b> 贝叶斯线性回归</a></li>
<li class="chapter" data-level="8.5" data-path="section-8.html"><a href="section-8.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> 贝叶斯分层线性回归</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 树模型</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 基本树模型</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 装袋树</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 随机森林</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#section-9.4"><i class="fa fa-check"></i><b>9.4</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 聚类分析</a></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 判别分析</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#section-10.2.2"><i class="fa fa-check"></i><b>10.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-10.html"><a href="section-10.html#section-10.2.4"><i class="fa fa-check"></i><b>10.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 关联法则分析</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 关联法则简介</a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 案例：商业购物篮分析</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 关联法则可视化</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 数据可视化和结果展示</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#r-markdown"><i class="fa fa-check"></i><b>12.1</b> R Markdown</a><ul>
<li class="chapter" data-level="12.1.1" data-path="section-12.html"><a href="section-12.html#r-markdown"><i class="fa fa-check"></i><b>12.1.1</b> 什么是R Markdown?</a></li>
<li class="chapter" data-level="12.1.2" data-path="section-12.html"><a href="section-12.html#how-to-start"><i class="fa fa-check"></i><b>12.1.2</b> How to Start?</a></li>
<li class="chapter" data-level="12.1.3" data-path="section-12.html"><a href="section-12.html#interactive-r-markdown-document"><i class="fa fa-check"></i><b>12.1.3</b> Interactive R Markdown Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 数据科学的科学</a></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-5" class="section level1">
<h1><span class="header-section-number">第5章</span> 数据预处理</h1>
<div id="section-5.1" class="section level2">
<h2><span class="header-section-number">5.1</span> 介绍</h2>
<p>许多数据分析相关书籍着重介绍模型，算法和统计推断。但在实际应用中，刚到手的原始数据通常都不能直接用于建模。数据预处理是将原始数据转化成能够用于建模的一致数据的过程。建模失败的原因有多种，其中之一就是在建模前没有对数据进行恰当的预处理。数据预处理会极大的影响建模结果，如缺失值填补和对离群点的处理显然会影响统计分析的结果。因此这是整个分析流程中非常关键的一个环节，这一步没有到位，之后的分析就如同在沙地上建房，及其不稳固。</p>
<p>在实际分析项目中，根据数据清理的不同阶段，有下面几类数据：</p>
<ol style="list-style-type: decimal">
<li>原始数据</li>
<li>技术上正确的数据</li>
<li>可以用于模型的数据</li>
<li>整合后的数据</li>
<li>设置了固定格式的数据</li>
</ol>
<p>原始数据是刚开始得到的第一手数据，可以是从数据库读取出的销售数据，市场调查的同事给你的调查问卷回复，研发部门收集的实验数据等等。这些数据集可能很粗糙，不一定能直接读入R。 比如多行表格标题，或者格式不符合要求：</p>
<ul>
<li>用50%表示百分比而不是0.5，这样R读入时会将其当作字符型；</li>
<li>销售额的缺失值用“-”表示，而不是空格，这样R会将销售额当成字符型；</li>
<li>数据是在幻灯片文档中，或者电子表格不是“.csv”而是“.xlsx”格式；<br />
…</li>
</ul>
<p>总而言之，这样的数据有时不能直接读入R，需要进行一些清理；有些格式的数据需要安装特定的包读取。当对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据。这样的数据载入R后有合理的列标签，变量格式等等。但这不意味着这时的数据是完全无误的，如年龄变量可能是负数，折扣百分比可能大于1，没到法定年龄的某人可能有驾照号码，或者数据缺失。取决于你的具体情况，数据可能存在各种问题。你在建模之前需要对这样的数据进行进一步清理。除了数据本身是否合理的角度对数据进行清理以外，取决于你要使用的模型，还需要从技术层面对数据进行预处理，使之尽可能不要太过偏离模型假设。比如有偏数据，变量量级不同，离群值，变量间的共线性，需要将分类变量转化为数值变量等等。对技术上正确的数据进行进一步清理后就得到可以用于建模的数据。</p>
<p>有时我们需要对数据进行整合。比如你可能需要展示某个产品在不同价格下的年销售量，这时就需要将每天的销售量相加得到相应的年销售量；在聚类分析中，当你得到各个分类后，通常需要对不同类进行描述，这时也需要整合各个类的描述统计量（比如平均年龄，平均收入，年龄标准差等等）。数据整合通常是为了给人展示，或者进一步用于可视化。</p>
<p>对整合好的数据，根据不同客户的要求我们需要更改数据格式。比如简洁明了的行列标签，单元格颜色，对一些需要强调的数据高亮等等。</p>
<p>这里我们建议大家分别储存每一步得到的数据，以及各个处理过程使用的R代码，使得这个过程尽可能可重复。如果需要检查更改某个环节，也相对容易。在本章的剩余部分我们针对<strong>建模前的数据预处理以及数据整合</strong>。本章我们将介绍一系列的数据清理技术，并用R进行实践。除了技术以外，我们还会讲到如何针对不同的情况选择合适的数据预处理方式。</p>
<p>前面有提到，数据预处理一般指数据的清理、变换或者缺失值填补。不同的模型对于预测变量的类型有不同的敏感度，此外变量以什么形式进入模型也很重要，如5分量表的调查问卷回复是当作因子变量还是数值变量。</p>
<p>本章将介绍无监督数据处理，有监督的方法会在其它章节中讨论。例如，偏最小二乘回归（PLS）模型本质上是主成分分析（PCA）的有监督版本。我们还将描述不考虑因变量时移除自变量的方法。</p>
<p>先载入本章需要的R包（我将在相应代码注释中解释每个包的用途）：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 先安装这些包才能用library()函数载入</span>
<span class="co"># caret: 提供获取、使用、评估成百上千个机器学习模型及其拟合效果的系统交互界面</span>
<span class="co"># 为机器学习提供了结构化的方法并且对一系列机器学习过程进行评估</span>
<span class="kw">library</span>(caret)
<span class="co"># e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别</span>
<span class="kw">library</span>(e1071)
<span class="co"># gridExtra: 绘图辅助功能，讲不同的图形组合在一起成为图表</span>
<span class="kw">library</span>(gridExtra) 
<span class="co"># lattice: 建立在核心绘图能力上的格子框架图形</span>
<span class="kw">library</span>(lattice)
<span class="co"># imputeMissings: 填补缺失值</span>
<span class="kw">library</span>(imputeMissings)
<span class="co"># RANN: 应用k邻近算法</span>
<span class="kw">library</span>(RANN)
<span class="co"># corrplot: 相关矩阵的高级可视化</span>
<span class="kw">library</span>(corrplot)
<span class="co"># nnet: 拟合单个潜层级的神经网络模型</span>
<span class="kw">library</span>(nnet)
<span class="co"># car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数</span>
<span class="kw">library</span>(car)
<span class="co"># gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵</span>
<span class="kw">library</span>(gpairs)
<span class="co"># reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()</span>
<span class="kw">library</span>(reshape2)
<span class="co"># psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；</span>
<span class="co"># 我们会使用包中的describe()函数</span>
<span class="kw">library</span>(psych)
<span class="co"># plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总</span>
<span class="kw">library</span>(plyr)
<span class="co"># tidyr: 清理揉合数据的包，主要函数是spread()和gather()</span>
<span class="kw">library</span>(tidyr)</code></pre></div>
</div>
<div id="section-5.2" class="section level2">
<h2><span class="header-section-number">5.2</span> 数据清理</h2>
<p>当你得到上述技术上正确的数据后，第一步就是检查数据，看看都有哪些变量，这些变量分布如何，是不是存在错误的观测。我们先读取并且检查服装消费者数据：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim.dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;</span>)
<span class="kw">summary</span>(sim.dat)</code></pre></div>
<pre><code>##       age            gender        income       house    
##  Min.   : 16.00   Female:554   Min.   : 41776   No :432  
##  1st Qu.: 25.00   Male  :446   1st Qu.: 85832   Yes:568  
##  Median : 36.00                Median : 93869            
##  Mean   : 38.84                Mean   :113543            
##  3rd Qu.: 53.00                3rd Qu.:124572            
##  Max.   :300.00                Max.   :319704            
##                                NA&#39;s   :184               
##    store_exp         online_exp       store_trans     online_trans  
##  Min.   : -500.0   Min.   :  68.82   Min.   : 1.00   Min.   : 1.00  
##  1st Qu.:  205.0   1st Qu.: 420.34   1st Qu.: 3.00   1st Qu.: 6.00  
##  Median :  329.0   Median :1941.86   Median : 4.00   Median :14.00  
##  Mean   : 1356.8   Mean   :2120.18   Mean   : 5.35   Mean   :13.55  
##  3rd Qu.:  597.3   3rd Qu.:2440.78   3rd Qu.: 7.00   3rd Qu.:20.00  
##  Max.   :50000.0   Max.   :9479.44   Max.   :20.00   Max.   :36.00  
##                                                                     
##        Q1              Q2              Q3              Q4       
##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.000  
##  Median :3.000   Median :1.000   Median :1.000   Median :3.000  
##  Mean   :3.101   Mean   :1.823   Mean   :1.992   Mean   :2.763  
##  3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:4.000  
##  Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  
##                                                                 
##        Q5              Q6              Q7              Q8       
##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
##  1st Qu.:1.750   1st Qu.:1.000   1st Qu.:2.500   1st Qu.:1.000  
##  Median :4.000   Median :2.000   Median :4.000   Median :2.000  
##  Mean   :2.945   Mean   :2.448   Mean   :3.434   Mean   :2.396  
##  3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:3.000  
##  Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.000  
##                                                                 
##        Q9             Q10              segment   
##  Min.   :1.000   Min.   :1.00   Conspicuous:200  
##  1st Qu.:2.000   1st Qu.:1.00   Price      :250  
##  Median :4.000   Median :2.00   Quality    :200  
##  Mean   :3.085   Mean   :2.32   Style      :350  
##  3rd Qu.:4.000   3rd Qu.:3.00                    
##  Max.   :5.000   Max.   :5.00                    
## </code></pre>
<p>发现什么问题没有？问卷调查回复Q1-Q10貌似合理，最小值都是1，最大值是5，因为问卷分值表是1-5。在实体店交易次数（<code>store_trans</code>）和在线交易次数（<code>store_trans</code>）看上去也合理。收入（income）有缺失值，处理缺失值的问题我们在下一小节会介绍。在线花销（<code>online_exp</code>）分布看上去没什么问题。实体店花销（<code>store_exp</code>）存在离群值，最大值有50000人民币，有个别受访者有着浓浓的土豪味。还有呢？大家可能已经发现其中有负值（最小值是－500），花销不可能是负数，这里你就要怀疑存在输入错误。类似的，<code>age</code>也存在不大可能的观测值，最大年龄是300，如果不是真的碰到青春期的千年老妖的话，这个年龄值应该是错误的。那怎么处理这些错误的值呢？取决于你的实际情况，如果你的样本量很大，不在乎这几个样本，可以删除这些不合理的值。在这里我们一共就1000个观测，而且问卷调查的数据在现实中通常都不容易获得，需要花费人力财力，故若因为其中某一个变量的值错误就将整个样本删去在此情况下有些可惜，所以我们可以将这些值设置成缺失状态，在下一步介绍缺失值处理的时候进行填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将错误的年龄观测设置为缺失值</span>
sim.dat$age[<span class="kw">which</span>(sim.dat$age&gt;<span class="dv">100</span>)]&lt;-<span class="ot">NA</span>
<span class="co"># 将错误的实体店购买观测设置为缺失值</span>
sim.dat$store_exp[<span class="kw">which</span>(sim.dat$store_exp&lt;<span class="dv">0</span>)]&lt;-<span class="ot">NA</span>
<span class="co"># 通过summary()函数检查清理情况</span>
<span class="kw">summary</span>(<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>)))</code></pre></div>
<pre><code>##       age            income      
##  Min.   :16.00   Min.   : 41776  
##  1st Qu.:25.00   1st Qu.: 85832  
##  Median :36.00   Median : 93869  
##  Mean   :38.58   Mean   :113543  
##  3rd Qu.:53.00   3rd Qu.:124572  
##  Max.   :69.00   Max.   :319704  
##  NA&#39;s   :1       NA&#39;s   :184</code></pre>
<p>现在我们接着处理数据中的缺失值。</p>
</div>
<div id="section-5.3" class="section level2">
<h2><span class="header-section-number">5.3</span> 缺失值填补</h2>
<p>缺失值填补是个大话题，单这一个就可以写本书。这里不会详细给大家介绍这个子领域，而是展示一些常用的缺失值处理方法，并且根据个人的工作经验对这些方法进行一些说明。对想进一步学习的读者，可以参考本小节中提到的相关参考资料。缺失值填补是对缺失的数据观测进行估计的过程。De Waal, Pannekoek和Scholtus的书<span class="citation">(Ton de Waal <a href="#ref-impute1">2011</a>)</span>中第7章对现存的一些缺失值填补方法做了简洁的概述。具体填补方法的选择取决于你的实际应用情况：关于缺失数据你有哪些辅助信息（比如如果客户管理系统将没有购买的客户对应的购买量设置为缺失的话，那你就该用0填补），变量之间是不是有些相关性限制（比如关于是否有驾照信息的缺失就可能受到年龄的限制，如果某人年龄低于16周岁，那就不可能有驾照信息）。因为情况各不相同，所以没有某个方法永远比其它方法好。</p>
<p>决定处理缺失值的方法之前要先了解缺失的原因等关于缺失的辅助信息。缺失是随机发生的么？如果这样的话，可以用中位数/众数填补，也可以使用均值填补。或者缺失其实是有潜在发生机制的？比如年龄大的人在问卷调查中更不愿意透露年龄，这样关于年龄的缺失就不是随机发生的，如果用均值或者中位数填补可能产生很大偏差。这时需要利用年龄和其它自变量的关系对缺失的值进行估计。比如可以基于那些没有缺失值的数据，用是否有子女，收入，问卷调查的回复这些信息来对年龄建模，然后用拟合的模型来进行预测（如用树模型）。</p>
<p>此外，建模的目的对于选择缺失值填补方法也很重要。若建模目的是对传统统计模型结果进行解释和推断，那么仔细研究缺失机制，尽可能用非缺失信息建模来估计缺失值就显得尤为重要。相反，如果建模的目的是预测，大部分情况下不会很严格的研究缺失机制（缺失机制很明显的时候除外），在缺失机制不太清楚的情况下，可以当成随机缺失进行填补（使用均值，中位数或者用K-近邻）。由于统计推断对缺失值更加敏感，所以抽样调查统计学对各种缺失值填补方法进行了深入的研究，这些研究着重于有效的统计推断。而在预测模型中的缺失值填补的问题和抽样调查中的有所不同，因为预测模型的主要目的是预测而非推断。因此关于预测模型中的缺失值填补方面的研究文献没有传统抽样调查统计那么多。想深入学习这方面知识的读者可以参考Saar-Tsechansky 和 Provost对判别模型中不同缺失值方法的比较<span class="citation">(Saar-Tsechansky M 2007b)</span>。还有之前提到的De Waal, Pannekoek和Scholtus的书<span class="citation">(Ton de Waal <a href="#ref-impute1">2011</a>)</span>。</p>
<div id="section-5.3.1" class="section level3">
<h3><span class="header-section-number">5.3.1</span> 中位数或众数填补</h3>
<p>在假设随机缺失的情况下，一个常用的填补方法是可以用含有缺失观测变量的中位数（连续变量）或者众数（分类变量）填补缺失值。 <code>imputeMissings</code>包中的函数<code>impute()</code>可以实现这类填补。我们用该函数对<code>sim.dat</code>数据框填补缺失值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将填补后的数据存在另外一个数据框中</span>
demo_imp&lt;-<span class="kw">impute</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;median/mode&quot;</span>)
<span class="co"># 只检查前5列，因为后面没有缺失值</span>
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<pre><code>##       age           gender        income       house       store_exp      
##  Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
##  1st Qu.:25.00   Male  :446   1st Qu.: 87896   Yes:568   1st Qu.:  205.1  
##  Median :36.00                Median : 93869             Median :  329.8  
##  Mean   :38.58                Mean   :109923             Mean   : 1357.7  
##  3rd Qu.:53.00                3rd Qu.:119456             3rd Qu.:  597.3  
##  Max.   :69.00                Max.   :319704             Max.   :50000.0</code></pre>
<p>从上面输出可以看到，填补后的数据框<code>demo_imp</code>没有缺失值。这个方法简单迅速，在工作中经常使用。但其有一个缺点，单独对每个变量进行缺失值填补而没有考虑到变量之间的关系，因而有的时候不太准确，如果缺失的比例较大，且你的建模目的是统计推断，建议进一步研究变量之间的关系，发觉缺失机制，通过对缺失变量建模来进行填补。上面的例子中缺失变量都是数值变量，<strong>如果缺失变量是分类／因子变量的话，<code>impute()</code>函数会用众数进行填补</strong>。</p>
<p>你也可以用上面讲到的<code>preProcess()</code>函数进行中位数填补，但<strong>该函数只针对数值变量，不能对分类变量进行众数填补</strong>。由于这里含有缺失值的都是数值变量，可以使用<code>preProcess()</code>函数。得到的结果和之前<code>impute()</code>函数相同。<code>preProcess()</code>函数的功能很强大，你可以将其想象成连接各种数据预处理方法的接口，我们之后会介绍该函数其它数据预处理功能。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;medianImpute&quot;</span>)
demo_imp2&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp2[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<pre><code>##       age           gender        income       house       store_exp      
##  Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
##  1st Qu.:25.00   Male  :446   1st Qu.: 87896   Yes:568   1st Qu.:  205.1  
##  Median :36.00                Median : 93869             Median :  329.8  
##  Mean   :38.58                Mean   :109923             Mean   : 1357.7  
##  3rd Qu.:53.00                3rd Qu.:119456             3rd Qu.:  597.3  
##  Max.   :69.00                Max.   :319704             Max.   :50000.0</code></pre>
</div>
<div id="k-" class="section level3">
<h3><span class="header-section-number">5.3.2</span> K-近邻填补</h3>
<p>直观的讲，K-邻近方法（也称为KNN）就是“物以类聚”这一思想的统计学表达。如果某人留着海藻般的长发，喜欢安妮宝贝的“现世安稳，岁月静好”，一会明亮一会忧伤，问题是你要知道这个人喜欢什么样的鞋子怎么办？去看看其他那些留着同样长发喜欢同样句子又明亮又忧伤的人都穿什么鞋子，然后你很可能得出结论：此人喜欢棉布鞋。</p>
<p>技术上讲，K-近邻方法建立在距离的定义之上（通常时欧几里德距离），其基本思路是对于含有缺失值的样本，寻找该离样本最近的K个样本（邻居），然后用这些邻居的观测均值对该样本的缺失值进行填补。由于这里找邻居根据的是样本点之间的距离，各个变量的标度需要统一，不然尺度大的变量在决定距离上会占主导作用。</p>
<p>我们使用<code>preProcess()</code>实现KNN填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
<span class="co"># 用predict()函数进行KNN填补</span>
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">Error in `[.data.frame`(old, , non_missing_cols, drop = FALSE) : 
  undefined columns selected</code></pre></div>
<p>程序报错说“undefined columns selected（选择了无法定义的列）”。这是因为<code>sim.dat</code>中有函数无法处理的非数值型变量，在上面代码的第一行使用<code>preProcess()</code>时，函数会自动忽略非数值型变量，所以你运行第一行代码没有问题。但是在第二行代码，通过<code>predict()</code>函数对数据框进行KNN填补时，数据框有非数值变量就会导致填补无法进行。我们移除这些变量，再进行填补就没有问题了。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 找到因子变量</span>
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(sim.dat,class)==<span class="st">&quot;factor&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat[,-idx])
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">3</span>])</code></pre></div>
<pre><code>##       age                 income           store_exp       
##  Min.   :-1.5910972   Min.   :-1.43989   Min.   :-0.43345  
##  1st Qu.:-0.9568733   1st Qu.:-0.53732   1st Qu.:-0.41574  
##  Median :-0.1817107   Median :-0.37606   Median :-0.37105  
##  Mean   : 0.0000156   Mean   : 0.02389   Mean   :-0.00042  
##  3rd Qu.: 1.0162678   3rd Qu.: 0.21540   3rd Qu.:-0.27437  
##  Max.   : 2.1437770   Max.   : 4.13627   Max.   :17.52734</code></pre>
<p>当前的例子中非数值型的变量只有因子，你在自己应用该方法时要注意是否还有字符型（<code>character</code>）变量。 <code>lapply(data,class)</code>命令可以返回一个数据框各列对应类别的列表，你只要将<code>data</code>换成你处理的数据框名即可。这里我们的数据框是<code>sim.dat</code>，于是你可以这样获得数据框各列的类别：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里只显示前3个元素</span>
<span class="kw">lapply</span>(sim.dat,class)[<span class="dv">1</span>:<span class="dv">3</span>]</code></pre></div>
<pre><code>## $age
## [1] &quot;integer&quot;
## 
## $gender
## [1] &quot;factor&quot;
## 
## $income
## [1] &quot;numeric&quot;</code></pre>
<p>将KNN填补的结果和之前中位数填补结果进行比较大家发现什么了？结果好像完全不一样。KNN返回的数据框整个尺度都变了。这是因为当你告诉<code>preProcess()</code>函数进行KNN填补时（选项<code>method=&quot;knnImpute&quot;</code>），函数会自动对数据进行标准化（下一小节将提到的中心化和标量化）。另外一种方法是使用下一小节中介绍的袋状树填补。关于KNN填补还有一点需要注意，算法无法对整行缺失的观测进行填补。这个并不难从直观上理解，既然改算法是通过邻近点的取值平均来填补，如果某一样本所有值都缺失，那怎么定义该样本的邻近点呢？下面我们在原数据框上添加一个所有观测都缺失的样本，将这个新的数据框储存在<code>temp</code>对象中，然后对temp进行KNN填补，看看会发生什么：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp&lt;-<span class="kw">rbind</span>(sim.dat,<span class="kw">rep</span>(<span class="ot">NA</span>,<span class="kw">ncol</span>(sim.dat)))
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(temp,class)==<span class="st">&quot;factor&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp&lt;-<span class="kw">predict</span>(imp,temp[,-idx])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">Error in FUN(newX[, i], ...) : 
  cannot impute when all predictors are missing in the new data point</code></pre></div>
<p>运行结果中有错误警告“cannot impute when all predictors are missing in the new data point（当样本对应的所有观测都缺失时无法填补）”。我们在拿到数据的时可以查找并删除这些完全缺失的样本。我们可以通过下面代码找到这样的行：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idx&lt;-<span class="kw">apply</span>(temp,<span class="dv">1</span>,function(x) <span class="kw">sum</span>(<span class="kw">is.na</span>(x)) )
<span class="kw">as.vector</span>(<span class="kw">which</span>(idx==<span class="kw">ncol</span>(temp)))</code></pre></div>
<pre><code>## [1] 1001</code></pre>
<p>结果显示第1001行所有的观测都缺失。你可以进一步删除所有观测都缺失的行。</p>
</div>
<div id="section-5.3.3" class="section level3">
<h3><span class="header-section-number">5.3.3</span> 袋状树填补</h3>
<p>另外一种填补方法是装袋树（Bagging，bootstrap aggregation 的缩写），最初由 Leo Breiman 提出，它是最早发展起来的集成方法之一<span class="citation">(L 1966a)</span>。对于数据中需要填补的变量，我们使用剩下的变量训练装袋树，然后再用训练出的树来对缺失值进行预测。虽然理论上说该方法更加强大，但计算量比KNN大了许多。在实际应用中，你一定要根据自己的具体情况选择填补的方式。因为你可以不断的探索使用理论上更加精确的填补方式，但也要考虑在这上面花的时间成本是不是值得，如果一个中位数，或者均值填补就可以满足建模需要，即使用袋状树填补可以提高些许精度，但是提升很可能非常小，没有太大的实际意义，尤其在样本量很大的时候。袋状树本身就是一个模型，可以用于回归和判别，我们之后在介绍树相关的方法时会进一步介绍。下面我们用<code>preProcess()</code>对数据框<code>sim.dat</code>进行袋状树填补。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;bagImpute&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span>:<span class="dv">5</span>])</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">      age           gender        income       house       store_exp      
 Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
 1st Qu.:25.00   Male  :446   1st Qu.: 86762   Yes:568   1st Qu.:  205.1  
 Median :36.00                Median : 94739             Median :  329.0  
 Mean   :38.58                Mean   :114629             Mean   : 1357.6  
 3rd Qu.:53.00                3rd Qu.:123726             3rd Qu.:  597.3  
 Max.   :69.00                Max.   :319704             Max.   :50000.0  </code></pre></div>
</div>
</div>
<div id="section-5.4" class="section level2">
<h2><span class="header-section-number">5.4</span> 中心化和标量化</h2>
<p>这是最基本的数据变换。中心化是通过将变量的每个观测减去该变量均值，这样中心化后的变量观测均值为0。标量化是将变量观测除以变量标准差，标量化后的变量标准差为1。对于一些要对变量进行线性组合的模型，中心化和标量化保证了变量的线性组合是基于组合后的新变量能够解释的原始变量中的方差。统计学上的方差，从直观的角度讲就是<strong>信息</strong>。试想若上面的消费者数据中，所有人的在线交易次数都是相同的，那么在线交易次数这个变量方差就是0，从应用的角度这个变量没有给我们提供可以区分这些消费者的信息。用到基于方差的变量线性组合的模型有主成分分析（PCA）<span class="citation">(Jolliffe <a href="#ref-pca1">2002</a>)</span>，偏最小二乘分析（PLS）<span class="citation">(Geladi P <a href="#ref-PLS1">1986</a>)</span>，探索性因子分析（EFA）<span class="citation">(Mulaik <a href="#ref-EFA1">2009</a>)</span>等等。这两个变换可以很容易自己编写程序实施，我们以服装装消费者数据（<code>sim.dat</code>）中的收入（income）变量为例：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">income&lt;-sim.dat$income
<span class="co"># 变量income的均值，na.rm=T告诉R忽略缺失值</span>
mux&lt;-<span class="kw">mean</span>(income,<span class="dt">na.rm=</span>T)
<span class="co"># 变量income的标准差，na.rm=T告诉R忽略缺失值</span>
sdx&lt;-<span class="kw">sd</span>(income,<span class="dt">na.rm=</span>T)
<span class="co"># 中心化</span>
tr1&lt;-income-mux
<span class="co"># 标量化</span>
tr2&lt;-tr1/sdx</code></pre></div>
<p>上面代码中，<code>tr1</code>是<code>income</code>中心化后的结果。<code>tr2</code>是对中心化后的结果<code>tr1</code>进一步标量化的结果。下面是关于这三步分别得到结果的总结：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">data.frame</span>(<span class="kw">cbind</span>(income,tr1,tr2)))</code></pre></div>
<pre><code>##      income            tr1              tr2         
##  Min.   : 41776   Min.   :-71767   Min.   :-1.4399  
##  1st Qu.: 85832   1st Qu.:-27711   1st Qu.:-0.5560  
##  Median : 93869   Median :-19674   Median :-0.3947  
##  Mean   :113543   Mean   :     0   Mean   : 0.0000  
##  3rd Qu.:124572   3rd Qu.: 11029   3rd Qu.: 0.2213  
##  Max.   :319704   Max.   :206161   Max.   : 4.1363  
##  NA&#39;s   :184      NA&#39;s   :184      NA&#39;s   :184</code></pre>
<p>可以看到，中心化后的<code>tr1</code>均值为0，但取值跨度依旧很大。接着标量化后的<code>tr2</code>就是一个均值为0，标准差为1的向量。</p>
<p>你也可以直接用<code>caret</code>包中的函数preProcess()对多个变量同时进行中心化和标量化，这里我选取其中2个变量进行展示：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>))
<span class="co"># method选项用于设置变换的方式，你可以同时进行一系列变换。</span>
<span class="co"># center：中心化</span>
<span class="co"># scale：标量化</span>
trans&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))
<span class="co"># preProcess函数的给出的还不是变换后的结果</span>
<span class="co"># 你需要通过predict函数对你想要变换的数据应用preProcess的结果才能够得到变换后的数据框</span>
transformed&lt;-<span class="kw">predict</span>(trans,sdat)</code></pre></div>
<p>变换后这两个变量就分布在相似的尺度上：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(transformed)</code></pre></div>
<pre><code>##       age              income       
##  Min.   :-1.5911   Min.   :-1.4399  
##  1st Qu.:-0.9569   1st Qu.:-0.5560  
##  Median :-0.1817   Median :-0.3947  
##  Mean   : 0.0000   Mean   : 0.0000  
##  3rd Qu.: 1.0163   3rd Qu.: 0.2213  
##  Max.   : 2.1438   Max.   : 4.1363  
##  NA&#39;s   :1         NA&#39;s   :184</code></pre>
<p>有时只要标量化数据而不一定要中心化。例如，如果模型中有针对参数估计绝对值的罚函数和且通过调优参数来进行变量选择（如LASSO）的话，变量大体在一个量级范围内使得能确保对参数“公平”的变量选择。之后在对于收缩方法（shrinkage method）的介绍能够帮助你更清楚的理解这一点。当然，如果你要通过参数估计衡量各个自变量和应变量之间关系强度的话，必须要对变量观测标量化。我是收缩方法的重度使用者，在工作中，我针对自己的分析项目设计了下面这种变换方式，该方式对我处理的问题非常有效，称其为<strong>分位数变换</strong>吧：</p>
<p><span class="math display">\[\label{eq:quantile1} x_{ij}^{*}=\frac{x_{ij}-quantile(x_{.j},0.01)}{quantile(x_{.j}-0.99)-quantile(x_{.j},0.01)}\]</span></p>
<p>这里<span class="math inline">\(x_{ij}\)</span>代表第i个样本的第j个变量观测，<span class="math inline">\(quantile(x_{.j},0.01)\)</span>指的是第j个变量所有样本观测组成的向量的1%分位数，类似的<span class="math inline">\(quantile(x_{.j},0.99)\)</span>是99%分位数，的这里之所以使用99%和1%分位数，而非最大值和最小值是为了减弱离群点的影响。编写函数进行分位数变换 <a href="#eq:quantile1"></a> 非常容易：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qscale&lt;-function(dat){
  for (i in <span class="dv">1</span>:<span class="kw">ncol</span>(dat)){
    up&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.99</span>)
    low&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.01</span>)
    diff&lt;-up-low
    dat[,i]&lt;-(dat[,i]-low)/diff
  }
  <span class="kw">return</span>(dat)
}</code></pre></div>
<p>这里我们对中位数填补后的数据集<code>demo_imp2中的变量</code>收入（<code>income</code>），实体店消费（<code>store_exp</code>）和在线消费（<code>online_exp</code>）进行上面的分位数变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp3&lt;-<span class="kw">qscale</span>(<span class="kw">subset</span>(demo_imp2,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>)))
<span class="kw">summary</span>(demo_imp3)</code></pre></div>
<pre><code>##      income           store_exp           online_exp       
##  Min.   :-0.05776   Min.   :-0.003407   Min.   :-0.006023  
##  1st Qu.: 0.15736   1st Qu.: 0.003984   1st Qu.: 0.042719  
##  Median : 0.18521   Median : 0.022704   Median : 0.253691  
##  Mean   : 0.26009   Mean   : 0.176965   Mean   : 0.278417  
##  3rd Qu.: 0.30456   3rd Qu.: 0.062849   3rd Qu.: 0.322871  
##  Max.   : 1.23857   Max.   : 7.476996   Max.   : 1.298845</code></pre>
<p>变换后的变量取值基本分布在0-1的范围之内。</p>
</div>
<div id="section-5.5" class="section level2">
<h2><span class="header-section-number">5.5</span> 有偏分布</h2>
<p>如果模型要求变量服从一定的对称分布（如正态分布）时，则需要进行数据变换去除分布的偏度。偏度是3阶标准化中心矩，是用来衡量分布不对称程度的，该统计量的数学定义如下：</p>
<p><span class="math display">\[偏度=\frac{\sum(x_{i}+\bar{x})^{3}}{(n-1)v^{3/2}}\]</span> <span class="math display">\[v=\frac{\sum(x_{i}=\bar{x})^{2}}{(n-1)}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 需要使用e1071包中的偏度计算函数skewness()</span>
<span class="kw">set.seed</span>(<span class="dv">1000</span>)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="co"># 抽取1000个自由度为2的开方分布，右偏分布</span>
x1&lt;-<span class="kw">rchisq</span>(<span class="dv">1000</span>,<span class="dv">2</span>, <span class="dt">ncp =</span> <span class="dv">0</span>)
<span class="co"># 通过x1得到对应的左偏分布变量x2</span>
x2&lt;-<span class="kw">max</span>(x1)-x1
<span class="kw">plot</span>(<span class="kw">density</span>(x2),<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>,<span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;左偏，偏度＝&quot;</span>,<span class="kw">round</span>(<span class="kw">skewness</span>(x2),<span class="dv">2</span>)), <span class="dt">xlab=</span><span class="st">&quot;X2&quot;</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(x1),<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>,<span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;右偏，偏度＝&quot;</span>,<span class="kw">round</span>(<span class="kw">skewness</span>(x1),<span class="dv">2</span>)), <span class="dt">xlab=</span><span class="st">&quot;X1&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:skew"></span>
<img src="DS_R_files/figure-html/skew-1.png" alt="有偏分布展示" width="80%" />
<p class="caption">
Figure 5.1: 有偏分布展示
</p>
</div>
<p>分布是否有偏可以很容易从图上看到。图<a href="section-5.html#fig:skew">5.1</a>显示了两种类型的不对称分布。分布对称时偏度=0，分布左偏时偏度&lt;0，分布右偏时偏度&gt;0，且偏离程度越大，偏度统计量的绝对值越大。有很多变换有助于去除偏度，如log变换，平方根或者取倒数。但是仅仅靠观察图形无法知道哪种变换方法最好。大家有没有注意到，常用的一些变换都和指数函数有关，如 <span class="math inline">\(log(x)\)</span>（这个是对数函数，但也是指数函数的近亲嘛：））、<span class="math inline">\(x^2\)</span> 和 <span class="math inline">\(\frac{1}{x}\)</span>。于是Box和Cox（1964）<span class="citation">(Box G <a href="#ref-BOXCOX1">1964</a>)</span>提出了含有一个参数<span class="math inline">\(\lambda\)</span>的指数变换族：</p>
<p><span class="math display">\[x^{*}=\begin{cases}
\begin{array}{c}
\frac{x^{\lambda}-1}{\lambda}\\
log(x)
\end{array} &amp;amp; \begin{array}{c}
if\ \lambda\neq0\\
if\ \lambda=0
\end{array}\end{cases}\]</span></p>
<p>很容易看出这个变换族群包含了<span class="math inline">\(log(x)\)</span>变换（<span class="math inline">\(\lambda\)</span>=0），<span class="math inline">\(x^2\)</span>变换（<span class="math inline">\(\lambda\)</span>=2），<span class="math inline">\(sqrt(x)\)</span>变换（<span class="math inline">\(\lambda\)</span>=0.5）以及<span class="math inline">\(frac{1}{x}\)</span>变换（<span class="math inline">\(\lambda\)</span>=-1）等常用的变换。Box-Cox覆盖的面更加广，变换指数可能是任意实数。<code>caret</code>包中有两个函数可以进行该变换，一个是<code>BoxCoxTrans()</code>。另外一个是我们之前用到的<code>preProcess()</code>，这里推荐大家使用后者，因为我们可以通过更改其中<code>method</code>选项对数据进行不同的变换，可以把该函数看作是不同预处理方法的接口，熟练使用后大家会发现其功能强大且及其方便。这里给大家插播一则广告，关于<code>psych</code>包中的<code>describe()</code>函数。我很喜欢用这个函数来在处理数据的不同阶段检查各个变量的情况，偏度，峰度，是不是可能有离群值，取值范围，均值等等，这个函数比<code>summary()</code>好用多了。当然这因人而异，有的人喜欢通过散点图矩阵来看各个变量的分布情况，个人还是喜欢看变量分布的各个统计量。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describe</span>(sim.dat)</code></pre></div>
<pre><code>##              vars    n      mean       sd   median   trimmed      mad
## age             1  999     38.58    14.19    36.00     37.67    16.31
## gender*         2 1000      1.45     0.50     1.00      1.43     0.00
## income          3  816 113543.07 49842.29 93868.68 104841.94 28989.47
## house*          4 1000      1.57     0.50     2.00      1.58     0.00
## store_exp       5  999   1358.71  2775.17   329.80    845.14   197.47
## online_exp      6 1000   2120.18  1731.22  1941.86   1874.51  1015.21
## store_trans     7 1000      5.35     3.70     4.00      4.89     2.97
## online_trans    8 1000     13.55     7.96    14.00     13.42    10.38
## Q1              9 1000      3.10     1.45     3.00      3.13     1.48
## Q2             10 1000      1.82     1.17     1.00      1.65     0.00
## Q3             11 1000      1.99     1.40     1.00      1.75     0.00
## Q4             12 1000      2.76     1.16     3.00      2.83     1.48
## Q5             13 1000      2.94     1.28     4.00      3.05     0.00
## Q6             14 1000      2.45     1.44     2.00      2.43     1.48
## Q7             15 1000      3.43     1.46     4.00      3.54     0.00
## Q8             16 1000      2.40     1.15     2.00      2.36     1.48
## Q9             17 1000      3.08     1.12     4.00      3.23     0.00
## Q10            18 1000      2.32     1.14     2.00      2.27     1.48
## segment*       19 1000      2.70     1.15     3.00      2.75     1.48
##                   min       max     range  skew kurtosis      se
## age             16.00     69.00     53.00  0.47    -1.18    0.45
## gender*          1.00      2.00      1.00  0.22    -1.95    0.02
## income       41775.64 319704.34 277928.70  1.69     2.57 1744.83
## house*           1.00      2.00      1.00 -0.27    -1.93    0.02
## store_exp      155.81  50000.00  49844.19  8.08   115.04   87.80
## online_exp      68.82   9479.44   9410.63  1.18     1.31   54.75
## store_trans      1.00     20.00     19.00  1.11     0.69    0.12
## online_trans     1.00     36.00     35.00  0.03    -0.98    0.25
## Q1               1.00      5.00      4.00 -0.12    -1.36    0.05
## Q2               1.00      5.00      4.00  1.13    -0.32    0.04
## Q3               1.00      5.00      4.00  1.06    -0.40    0.04
## Q4               1.00      5.00      4.00 -0.18    -1.46    0.04
## Q5               1.00      5.00      4.00 -0.60    -1.40    0.04
## Q6               1.00      5.00      4.00  0.11    -1.89    0.05
## Q7               1.00      5.00      4.00 -0.90    -0.79    0.05
## Q8               1.00      5.00      4.00  0.21    -1.33    0.04
## Q9               1.00      5.00      4.00 -0.68    -1.10    0.04
## Q10              1.00      5.00      4.00  0.39    -1.23    0.04
## segment*         1.00      4.00      3.00 -0.20    -1.41    0.04</code></pre>
<p>大家可以很清楚的看到哪些变量有偏（<code>skew</code>），通过比较均值（<code>mean</code>）和修剪后的均值（<code>trimmed</code>），大概知道哪些变量可能存在离群值。修剪后的均值是去除最大和最小的一部分观测点后得出的均值。这两个值差距很大说明对应变量存在离群点，这里很明显在线消费（<code>store_exp</code>）存在离群点。</p>
<p>下面我们以数据集<code>sim_dat</code>中的变量<code>store_trans</code>和<code>online_trans</code>为例展示Box-Cox变换函数的使用方法：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取需要的两列，存在dat_bc中</span>
dat_bc&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span>))
(trans&lt;-<span class="kw">preProcess</span>(dat_bc,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;BoxCox&quot;</span>)))</code></pre></div>
<pre><code>## Created from 1000 samples and 2 variables
## 
## Pre-processing:
##   - Box-Cox transformation (2)
##   - ignored (0)
## 
## Lambda estimates for Box-Cox transformation:
## 0.1, 0.7</code></pre>
<p>上面的输出的第一行显示了样本量是1000，有2个变量。输出的最后一行表明每个变量对应的参数<span class="math inline">\(\lambda\)</span>估计值（0.1和0.7）。和之前一样，我们接着用<code>predict()</code>函数对数据框应用估计的变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,dat_bc)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(dat_bc$store_trans,<span class="dt">main=</span><span class="st">&quot;原始商店消费次数&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;store_trans&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)
<span class="kw">hist</span>(transformed$store_trans,<span class="dt">main=</span><span class="st">&quot;变换后商店消费次数&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;store_trans&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bc"></span>
<img src="DS_R_files/figure-html/bc-1.png" alt="Box-Cox变换展示" width="80%" />
<p class="caption">
Figure 5.2: Box-Cox变换展示
</p>
</div>
<p>从图<a href="section-5.html#fig:bc">5.2</a>可以看到，变换前商店消费量分布明显右偏，变换后情况显著改善，基本对称。<code>BoxCoxTrans()</code> 也可以进行Box-Cox变换，使用方法类似。但要注意的是<code>BoxCoxTrans()</code>只能作用于单个数值变量，不能像之前那样对一个数据框中的列一次性进行变换。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(trans&lt;-<span class="kw">BoxCoxTrans</span>(dat_bc$store_trans))</code></pre></div>
<pre><code>## Box-Cox Transformation
## 
## 1000 data points used to estimate Lambda
## 
## Input data summary:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    1.00    3.00    4.00    5.35    7.00   20.00 
## 
## Largest/Smallest: 20 
## Sample Skewness: 1.11 
## 
## Estimated Lambda: 0.1 
## With fudge factor, Lambda = 0 will be used for transformations</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,dat_bc$store_trans)
<span class="kw">skewness</span>(transformed)</code></pre></div>
<pre><code>## [1] -0.2154708</code></pre>
<p>参数<span class="math inline">\(\lambda\)</span>的估计和之前相同（0.1），原始观测的偏度为1.1，变换后偏度为－0.2，虽然不严格为0，但和之前比较有极大改善，可以用来计算变量间线性相关性，用于回归等。</p>
</div>
<div id="section-5.6" class="section level2">
<h2><span class="header-section-number">5.6</span> 处理离群点</h2>
<p>有时判断离群点并不是那么容易，因为没有一个非黑即白的标准。箱线图和直方图等一些基本的可视化可以用来初步检查是否有离群点。举个例子，我们可以对服装消费者数据中的数值型非问卷调查变量进行可视化：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取数值型非问卷调查变量</span>
sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>,<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span> ))
<span class="co"># 用car包中的函数scatterplotMatrix()绘制散点图矩阵</span>
<span class="kw">par</span>(<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">scatterplotMatrix</span>(sdat,<span class="dt">diagonal=</span><span class="st">&quot;boxplot&quot;</span>,<span class="dt">smoother=</span><span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:scm"></span>
<img src="DS_R_files/figure-html/scm-1.png" alt="数值型非问卷调查变量散点图矩阵" width="80%" />
<p class="caption">
Figure 5.3: 数值型非问卷调查变量散点图矩阵
</p>
</div>
<p>从图<a href="section-5.html#fig:scm">5.3</a>，商店消费量（<code>store_exp</code>）明显有离群点（记得之前的土豪么）。你也可以从中看到一些变量两两之间的关系。年龄和在线交易次数负相关，但和实体店交易次数正相关，貌似年纪大的人更倾向于实体店购买。当然，还有消费量和收入正相关。这样的散点图简单但是有效，可以在建模之前告诉你很多关于数据的信息。</p>
<p>除了可视化这样直观的方式外，在一定的假设条件下，有一些统计学的定义离群值的方法。如常用Z分值来判断可能的离群点。对于某观测变量<span class="math inline">\(\mathbf{Y}\)</span>的Z分值定义为：</p>
<p><span class="math display">\[Z_{i}=\frac{Y_{i}-\bar{Y}}{s}\]</span></p>
<p>其中<span class="math inline">\(\bar{Y}\)</span>和<span class="math inline">\(s\)</span>分别为观测列的均值和标准差。直观的理解Z分值就对观测离均值的距离的度量（多少个标准差单位）。这种方法可能具有误导性，尤其是在样本量小的时候。Iglewicz和Hoaglin提出使用修正后的Z分值来判断离群点<span class="citation">(Iglewicz and Hoaglin <a href="#ref-mad1">1993</a>)</span>：</p>
<p><span class="math display">\[M_{i}=\frac{0.6745(Y_{i}-\bar{Y})}{MAD}\]</span></p>
<p>其中MAD是一系列<span class="math inline">\(|Y_{i}-\bar{Y}|\)</span>的中位数，称为绝对离差中位数。他们建议将上面修正后的Z分值大于3.5的点标记为可能的离群点。我们来检查下商店消费量观测对应的Z分值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 计算商店消费量的绝对离差中位数，这里用na.omit()告诉R忽略缺失值</span>
ymad&lt;-<span class="kw">mad</span>(<span class="kw">na.omit</span>(sdat$income))
<span class="co"># 计算Z分值</span>
zs&lt;-(sdat$income-<span class="kw">mean</span>(<span class="kw">na.omit</span>(sdat$income)))/ymad
<span class="co"># 看看有多少个离群点</span>
<span class="kw">sum</span>(<span class="kw">na.omit</span>(zs&gt;<span class="fl">3.5</span>))</code></pre></div>
<pre><code>## [1] 59</code></pre>
<p>用该标准，商店消费量对应的离群点有59个。关于离群点还有其它不同的检测。更多关于不同检测方法可以参考<span class="citation">(Iglewicz and Hoaglin <a href="#ref-mad1">1993</a>)</span>。</p>
<p>很重要的一点是离群点的影响取决于你使用的模型。有的模型对离群值很敏感，如线性回归，逻辑回归。有的对离群点具有抗性，如基于树的模型，支持向量机。此外离群点和错误的观测不一样，它是真实的观测，其中包含信息，所以不能随意的删除。如果你使用的模型对离群点非常敏感，可以使用空间表示变换<span class="citation">(Serneels S <a href="#ref-ssp">2006</a>)</span>。该变换将自变量取值映射到高维的球面上。变换公式如下：</p>
<p><span class="math display">\[x_{ij}^{*}=\frac{x_{ij}}{\sqrt{\sum_{j=1}^{p}x_{ij}^{2}}}\]</span></p>
<p>其中<span class="math inline">\(x_{ij}\)</span>表示第i个样本对应第j个变量的观测。由公式可见，每个样本都除以了它们的平方模。公式的分母其实可以看作是该样本到p维空间0点的欧几里德距离，有三点需要特别注意：</p>
<ol style="list-style-type: decimal">
<li>在该变换前需要对自变量标准化</li>
<li>与中心化和标准化不同，这个变换操作的对象是所有自变量</li>
<li>如果需要移除变量（之后会提到移除高度相关变量），这一步必须要在空间表示变换之前，否者会导致一系列问题</li>
</ol>
<p>作为例子，我们用<code>caret</code>包中的<code>spatialSign()</code>函数对收入和年龄两个变量进行空间表示变换：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 用KNN填补缺失值</span>
sdat&lt;-sim.dat[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)]
imp&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;knnImpute&quot;</span>),<span class="dt">k=</span><span class="dv">5</span>)
sdat&lt;-<span class="kw">predict</span>(imp,sdat)
transformed &lt;-<span class="st"> </span><span class="kw">spatialSign</span>(sdat)
transformed &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(transformed)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(income ~<span class="st"> </span>age,<span class="dt">data =</span> sdat,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">main=</span><span class="st">&quot;变换前&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)
<span class="kw">plot</span>(income ~<span class="st"> </span>age,<span class="dt">data =</span> transformed,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">main=</span><span class="st">&quot;变换后&quot;</span>,<span class="dt">family =</span><span class="st">&quot;Songti SC&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:sst"></span>
<img src="DS_R_files/figure-html/sst-1.png" alt="空间表示变换图" width="80%" />
<p class="caption">
Figure 5.4: 空间表示变换图
</p>
</div>
<p>细心的读者可能已经发现，上面的代码中貌似并没有对数据进行标准化。如果你还记得，在介绍KNN填补的时候讲过，<code>preProcess()</code>在进行KNN的同时默认会对数据框进行标准化，所以上面代码没有特地标准化数据。</p>
</div>
<div id="section-5.7" class="section level2">
<h2><span class="header-section-number">5.7</span> 共线性</h2>
<p>共线性可能是大多数地球人都听过的一个词了，即使在传统企业市场部的营销人员都知道这个词，这也可能是他们唯一可以拿出来显摆的技术词汇。关于变量间的相关性，有个非常好用的包<code>corrplot</code>，其中同名函数<code>corrplot()</code>能够对变量相关矩阵进行可视化。函数中有一个选项可以设置变量的排序方式，使得相关性高的变量排列在一起。和之前一样，我们选取其中数值类的非问卷调查变量为例子，展示如何使用该函数探索变量之间共线性：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取数值型非问卷调查变量</span>
sdat&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>,<span class="st">&quot;store_trans&quot;</span>,<span class="st">&quot;online_trans&quot;</span> ))
<span class="co"># 用装袋树填补，换着用，帮大家练练手：）</span>
imp&lt;-<span class="kw">preProcess</span>(sdat,<span class="dt">method=</span><span class="st">&quot;bagImpute&quot;</span>)
sdat&lt;-<span class="kw">predict</span>(imp,sdat)
<span class="co"># 得到相关矩阵</span>
correlation&lt;-<span class="kw">cor</span>(sdat)
<span class="co"># 对相关矩阵作图</span>
<span class="kw">par</span>(<span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">corrplot.mixed</span>(correlation,<span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>,<span class="dt">tl.pos=</span><span class="st">&quot;lt&quot;</span>,<span class="dt">upper=</span><span class="st">&quot;ellipse&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:corp"></span>
<img src="DS_R_files/figure-html/corp-1.png" alt="相关矩阵可视化" width="80%" />
<p class="caption">
Figure 5.5: 相关矩阵可视化
</p>
</div>
<p>这里我们使用的是<code>corrplot.mixed()</code>函数对相关矩阵可视化（图<a href="section-5.html#fig:corp">5.5</a>）。其中相关性越接近0颜色越浅且形状越接近圆，相关性不等于0的用椭圆表示（因为我们设置了选项upper=“ellipse”），相关性越大椭圆越窄，蓝色代表正相关，红色代表负相关，椭圆的方向也随着相关性正负变化。 相关系数在矩阵的下三角显示。可以看到，我们之前在散点图矩阵（图<a href="section-5.html#fig:scm">5.3</a>）中看到的变量相关性在这里很明显的展现出来，年龄和在线购物次数负相关，消费量和收入正相关。且有些线性相关性非常强（<code>online_trans</code>和<code>age</code>的相关系数是－0.85）。这会导致什么问题呢？这其实很容易理解，两个变量高度相关意味着它们含有重复的信息，我们其实不需要讲两个变量同时留在模型中。你可能会问，那重复未必有害处不是么？变量高度相关会倒是参数估计极为不稳定。举个例子，我们可以对收入进行简单的线性回归：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfit1&lt;-<span class="kw">lm</span>(income~age+online_trans+store_exp+store_trans,<span class="dt">data=</span>sdat)
<span class="kw">summary</span>(cfit1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = income ~ age + online_trans + store_exp + store_trans, 
##     data = sdat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -183840  -14126    -914   10944  156106 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  67790.0372  8640.8338   7.845 1.11e-14 ***
## age            221.5832   135.9644   1.630    0.103    
## online_trans  -270.9619   249.5672  -1.086    0.278    
## store_exp        5.7269     0.4356  13.147  &lt; 2e-16 ***
## store_trans   6399.5252   357.8722  17.882  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31650 on 995 degrees of freedom
## Multiple R-squared:  0.5763, Adjusted R-squared:  0.5746 
## F-statistic: 338.3 on 4 and 995 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>大家可以看到，年龄和在线购买的方差都比较大。因为这两个变量高度相关，模型也拿不准到底该如和分配这两个变量的系数。下面我们将年龄（age）删除，再进行一次回归：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cfit2&lt;-<span class="kw">lm</span>(income~online_trans+store_exp+store_trans,<span class="dt">data=</span>sdat)
<span class="kw">summary</span>(cfit2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = income ~ online_trans + store_exp + store_trans, 
##     data = sdat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -182372  -14498   -1179   11127  156121 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  80861.0786  3217.6962  25.130  &lt; 2e-16 ***
## online_trans  -606.4452   141.2126  -4.295 1.92e-05 ***
## store_exp        5.6427     0.4329  13.035  &lt; 2e-16 ***
## store_trans   6425.0185   357.8273  17.956  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31670 on 996 degrees of freedom
## Multiple R-squared:  0.5752, Adjusted R-squared:  0.5739 
## F-statistic: 449.5 on 3 and 996 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>比较<code>cfit1</code>和<code>cfit2</code>中<code>online_trans</code>对应的系数估计之间巨大的变化，就可以很容易看出高度共线的变量同时出现在回归模型中对参数估计可能带来的影响了。于此同时<code>store_exp</code>和<code>store_trans</code>的参数估计在两个结果中差异不大。所以我们在进行回归之前需要移除一些高度相关的变量，使得模型中变量相关性在一定范围之内。我个人比较喜欢用《应用预测模型》<span class="citation">(Kjell Johnston <a href="#ref-APM">2013</a>)</span>书中3.5小节中展示的算法，其核心思想是在删除尽可能少的变量的情况下将变量两两相关性控制在人为设定的一个阈值内：</p>
<blockquote>
<p>算法：处理高度相关变量</p>
<ol style="list-style-type: decimal">
<li>计算自变量的相关系数矩阵</li>
<li>找出相关系数绝对值最大的那对自变量（记为自变量A和B）</li>
<li>计算A和其他自变量相关系数的均值。对B也做同样的计算</li>
<li>如果A的平均相关系数更大，则将A移除；如若不然，移除B</li>
<li>重复步骤2到4，直至所有相关系数的绝对值都低于设定的阈值</li>
</ol>
</blockquote>
<p><code>caret</code>中的<code>findCorrelation()</code>函数能够实施上面的算法：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(highCorr&lt;-<span class="kw">findCorrelation</span>(<span class="kw">cor</span>(sdat),<span class="dt">cutoff=</span>.<span class="dv">75</span>))</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>结果返回的是需要删除的列号，这里算法告诉我们若要使得变量相关性在0.75内，需要删除第1列。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 将高相关的变量删除</span>
sdat&lt;-sdat[-highCorr]
<span class="co"># 查看新的相关矩阵</span>
<span class="kw">cor</span>(sdat)</code></pre></div>
<pre><code>##                  income  store_exp online_exp store_trans online_trans
## income        1.0000000  0.6004006  0.5198623   0.7069595   -0.3572884
## store_exp     0.6004006  1.0000000  0.5349527   0.5399121   -0.1367411
## online_exp    0.5198623  0.5349527  1.0000000   0.4420638    0.2256370
## store_trans   0.7069595  0.5399121  0.4420638   1.0000000   -0.4367544
## online_trans -0.3572884 -0.1367411  0.2256370  -0.4367544    1.0000000</code></pre>
<p>移除变量后相关矩阵中元素的绝对值都低于0.75。这里需要提醒大家一点，关于这个相关性阈值的选取强烈建议大家将这个阈值成一个调优参数，试验不同的值，看哪个对应的模型精度最高。建议在0.6-0.8范围内寻找最优的阈值。关于共线性的处理还有一些其它方法，如主成分分析和因子分析，这些方法我们将在特征工程那一章进行讲解。</p>
</div>
<div id="section-5.8" class="section level2">
<h2><span class="header-section-number">5.8</span> 稀疏变量</h2>
<p>除了高度相关的变量以外，我们还需要移除那些观测非常稀疏的变量。一个极端的例子是某变量观测只有一个取值，我们可以将其称为0方差变量。有的可能只有若干取值，我们称其为近0方差变量。这里所讲的处理稀疏变量的方法无法解决大规模基因表达研究中的问题，在基因表达研究中的一个常见问题是观测少，同时变量数目远远超过观测，几乎所有变量都很稀疏，这种情况下需要很多新的高维模型，这是当前非常活跃的一个研究领域，但这不在本书讨论范围之内。这里讨论情况是由于各种原因，出现某些稀疏变量的情况。我们需要做的是识别这些变量然后将其删除。这些变量的存在对如线性回归和逻辑回归这样的模型拟合的表现和稳定性会有很大影响，但决策树模型没有影响。</p>
<p>通常识别这样的变量有两个法则：</p>
<ul>
<li>不同取值数目和样本量的比值</li>
<li>最常见的取值频数和第二常见的取值频数之间的比值</li>
</ul>
<p>我们可以设定上面的规则，然后用<code>caret</code>包中的<code>nearZeroVar()</code>函数过滤近0方差变量。为了展示该方法，我们在数据中加入一些这样的变量，然后应用该函数查找它们：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 先备份数据</span>
zero_demo&lt;-sim.dat
<span class="co"># 加上两个稀疏变量</span>
<span class="co"># zero1 的取值全是1</span>
<span class="co"># zero2 除了第一个元素是1以外其余全是0</span>
zero_demo$zero1&lt;-<span class="kw">rep</span>(<span class="dv">1</span>,<span class="kw">nrow</span>(zero_demo))
zero_demo$zero2&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">nrow</span>(zero_demo)-<span class="dv">1</span>))</code></pre></div>
<p>上面代码中我们生成了两个新的变量（<code>zero1</code>和<code>zero2</code>），它们分别为0方差和近0方差变量，然后将这两个变量添加到数据框<code>zero_demo</code>上。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nearZeroVar</span>(zero_demo,<span class="dt">freqCut =</span> <span class="dv">95</span>/<span class="dv">5</span>, <span class="dt">uniqueCut =</span> <span class="dv">10</span>)</code></pre></div>
<p>我们将函数<code>nearZeroVar()</code>应用在含有稀疏变量的数据框上，和之前查找高共线性变量一样，函数返回的是稀疏变量对应的列号。这里返回的是我们生成的两个稀疏变量所在的列。你可以接下来删除这两列。注意这里的两个选项分别对应我们上面提到的两个定义稀疏变量的标准。<code>uniqueCut =</code>是不同取值数目和样本量的比值； <code>freqCut =</code>是最常见的取值频数和第二常见的取值频数之间的比值。你可以根据具体情况提高或者降低这些标准。一个很自然的问题是该怎么选？你要是在这个行业久了就会发现，即使是这样一个和数学相关的技术性行业，非黑即白的事情也是很少存在的。目前为止在我看来（我也还在这个领域不停的学习），所有关于标准，参数，模型选择的问题，最好的答案只有一个，看哪种选择能帮你达成建模目标。比如你的建模目标预测，那你就要看看不同选择下给出的预测精度哪个更高。这个标准甚至超过的p值， AIC等等一堆统计学的测量。我们在下一章讨论建模技术的时候会进一步展开。</p>
</div>
<div id="section-5.9" class="section level2">
<h2><span class="header-section-number">5.9</span> 编码名义变量</h2>
<p>名义变量，又称虚设变量，是一个指标性质的变量，通常取值0或1。有时你需要将分类变量转化成名义变量。比如一些问卷调查每个问题都有A,B,C,D,E五个选项，你得到数据后通常要将每个问题对应的分类变量转化成5个名义变量，然后将其中一个选项当作基准选项。我们在介绍逻辑回归及其衍生模型的那节中会展示一个这样的案例分析。我们还是用服装消费者的数据为例，假设我们要将性别（<code>gender</code>）和房产拥有情况（<code>house</code>）这两个变量转化为名义变量，R中有两个函数可以进行这项操作，<code>nnet</code>包中的｀class.ind()｀函数，但该函数有个局限是一次只能处理一个变量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumVar&lt;-<span class="kw">class.ind</span>(sim.dat$gender)
<span class="kw">head</span>(dumVar)</code></pre></div>
<pre><code>##      Female Male
## [1,]      1    0
## [2,]      1    0
## [3,]      0    1
## [4,]      0    1
## [5,]      0    1
## [6,]      0    1</code></pre>
<p>我们可以看到性别这个变量被重新编码为2个名义变量，你在建模时需要删除其中一个，因为它们之间有重复信息（正常情况下非男即女嘛）。这样在分类变量多的时候得写个循环来进行重新编码还是有些麻烦。另外一个更加方便的方法是<code>caret</code>包（功能强大的包，简直是居家旅行必备神器！）中的<code>dummyVars()</code> 函数：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~gender+house+income,
                  <span class="dt">data=</span>sim.dat,
                  <span class="co"># 用原变量名加上因子层级的名称作为新的名义变量名</span>
                  <span class="dt">levelsOnly=</span>F)
<span class="kw">head</span>(<span class="kw">predict</span>(dumMod,sim.dat))</code></pre></div>
<pre><code>##   gender.Female gender.Male house.No house.Yes   income
## 1             1           0        0         1 120963.4
## 2             1           0        0         1 122008.1
## 3             0           1        0         1 114202.3
## 4             0           1        0         1 113616.3
## 5             0           1        0         1 124252.6
## 6             0           1        0         1 107661.5</code></pre>
<p>看到没有，<code>dummyVars()</code>可以用类似模型公式的表达方式对任何变量同时进行转化。而且公式右边不一定要是分类变量，你发现我将收入（<code>income</code>）这个变量也加上去了，对于数值型变量，函数会保持原变量，这样的好处在于你不需要特地选定其中的因子变量，转换后再添加到原数据框上，还要删除原变量，省去了很多麻烦。不仅仅如此，该函数还可以添加交互效应，比如：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~gender+house+income+income:gender,
                  <span class="dt">data=</span>sim.dat,
                  <span class="dt">levelsOnly=</span>F)
<span class="kw">head</span>(<span class="kw">predict</span>(dumMod,sim.dat))</code></pre></div>
<pre><code>##   gender.Female gender.Male house.No house.Yes   income
## 1             1           0        0         1 120963.4
## 2             1           0        0         1 122008.1
## 3             0           1        0         1 114202.3
## 4             0           1        0         1 113616.3
## 5             0           1        0         1 124252.6
## 6             0           1        0         1 107661.5
##   gender.Female:income gender.Male:income
## 1             120963.4                0.0
## 2             122008.1                0.0
## 3                  0.0           114202.3
## 4                  0.0           113616.3
## 5                  0.0           124252.6
## 6                  0.0           107661.5</code></pre>
<p>这里，如果你觉得男性中收入水平对行为的影响和女性收入水平对行为的影响不一样，女性高收入的人在服装购买上大花销更大，而男性收入高低对服装花销影响不大，这就要检测收入和性别的交互效应，可以在公式中加入<code>income:gender</code>得到交互效应编码。是不是很方便？</p>
<p>到目前为止，我们讲了几种常用的数据预处理方式，这些处理的目的是为了得到我们在本章开始所讲的可以用于模型的数据。本章的最后一部分想讲讲一些数据整合的方法。数据整合可能用在任何一个阶段，可能数据行列安排的方式不符合建模要求，或者之后的数据展示需要对比不同的群体，这些都涉及到数据整合。下面我介绍一些自己工作中常用到的数据整合方法。</p>
</div>
<div id="section-5.10" class="section level2">
<h2><span class="header-section-number">5.10</span> 数据整合和整形</h2>
<p>这一小节将介绍一些经常用到的有效数据整合方法，和R中可以实现这些整合的函数。在进行分析之前用描述统计量（均值，标准差等等）和数据可视化总结探索数据集很重要，在分析之后对结果进行总结也很重要，此外我们还经常需要对数据的格式和排列方式进行变换，使得数据结构符合模型的要求。</p>
<p>这一节我们主要介绍常用的数据整合和整形的方式，以及如何用R实现这些操作。我们会跳过一些基础的变量水平的描述，比如对于离散变量，我们通常会用频数表格稍微在需要时查看变量各个层级观测的频数（<code>table()</code>），或者两个变量的交叉表格。还可以通过对离散变量绘制条形图。对于连续变量，我们时不时需要查看某个变量的均值（<code>mean()</code>），标准差（<code>sd()</code>）,分位数（<code>quantile()</code>）之类的。此外还有一些像<code>summary()</code>，<code>str()</code>和<code>describe()</code>（这个函数是’psych’包里的，之前有用过）这样的函数能给出关于一个数据框的总结。以上提到的这些都是一些最基础的探索各个阶段数据（包括模型结果）的方法。但仅仅这些是不够的，这些方法的灵活性不高，输出的信息是固定的。我们可能不想要<code>summary()</code>函数输出的全部信息，而有些我们想要的信息它却没有。比如如果我们想要知道每个类别的客户收入，在线花销等的均值；或者我们想要在每个类别中找到收入最高的人，然后将他们提取出来集合在一起；又或者我们希望有一个新的变量指示购买的渠道（是在线还是实体店），并且将这个变量用于建模，这时就需要对数据进行整形，将在线购买的记录和实体店购买的记录逐行排列而非现在的逐列。这些操作如果仅仅使用初级函数会非常繁琐，且运算效率也不高。R中有一些其它包可以非常高效简洁的完成这些看似复杂的任务。初次接触这些函数的小伙伴会觉得它们不太好使，那是自然，功能强的东西选项自然多些，灵活性越强的工具，你学习掌握的时间自然长些，但这就是一个<strong>熟能生巧</strong>的事情，又一次，老古人的话放在那里闪闪发光。</p>
<div id="baseapply" class="section level3">
<h3><span class="header-section-number">5.10.1</span> base包：apply()</h3>
<p>R基础包中有几个强大的函数，<code>apply()</code>、<code>lapply()</code>和<code>sapply()</code>等。它们做的事情类似，只是对应的对象，或返回对象的格式不同。这些函数对于R的初学者来说可能有些难，但一旦熟悉以后会发现它们非常有效。它们是干什么的？简单来说就是依次对某一对象的某一部分重复应用一个指定的函数。它们的不同在于，<code>apply()</code>将你指定的函数作用于<strong>数据框</strong>对象的行或列，返回一个<strong>向量</strong>。‘lapply()’ 将指定的函数作用于<strong>列表</strong>或者<strong>数据框</strong>对象，返回一个长度相同的<strong>列表</strong>。<code>sapply()</code>更加便捷，且算是对<code>lapply()</code>进行了包装，若<code>sapply()</code>中参数<code>simplify=FALSE</code>，那么其返回的值和<code>lapply()</code>是一样的。若<code>simplify=TRUE</code>，则<code>sapply()</code>的返回值不是一个列表，而是一个矩阵。因为在平常工作中通常处理的都是数据框，所以这里主要介绍函数<code>apply()</code>的用法。大家可能会觉得很抽象，觉得抽象很正常，因为这几兄弟确实不太接地气，我现在用这些函数几乎每次都得去查帮助文档。回到我们的服装消费者数据。如果我想知道样本中所有数值变量的均值和标准差该怎么办？这在建模前检查数据和建模后展示数据时都经常用到。</p>
<p>记得我们之前通过<code>preProcess()</code>函数对数据进行KNN填补时，需要提取数据框中所有的数值变量用到的是<code>lapply()</code>函数。这里不能用<code>apply()</code>函数是因为<code>apply()</code>函数自动将对象转化成矩阵，这样就会丢失每列的类别信息，而<code>lapply()</code>不会对对象进行转化（这样细微的差别需要常用R渐渐熟悉了才会慢慢了解，我也是写书的时候发现这个，方才请教了一位R高人才明白个中缘由：））。我们再次用该函数选取其中数值型的变量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdat&lt;-sim.dat[,!<span class="kw">lapply</span>(sim.dat,class)==<span class="st">&quot;factor&quot;</span>]</code></pre></div>
<p>现在的数据框<code>sdat</code>中只包括数值型的变量。这样我们就可以用<code>apply()</code>函数对每列求均值和标准差了：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apply</span>(sdat, <span class="dt">MARGIN=</span><span class="dv">2</span>,function(x) <span class="kw">mean</span>(<span class="kw">na.omit</span>(x)))</code></pre></div>
<pre><code>##          age       income    store_exp   online_exp  store_trans 
##     38.57858 113543.06522   1358.70923   2120.18119      5.35000 
## online_trans           Q1           Q2           Q3           Q4 
##     13.54600      3.10100      1.82300      1.99200      2.76300 
##           Q5           Q6           Q7           Q8           Q9 
##      2.94500      2.44800      3.43400      2.39600      3.08500 
##          Q10 
##      2.32000</code></pre>
<p>这里我们定义了一个函数<code>function(x) mean(na.omit(x))</code>，这个函数很简单，就是对任何向量求均值同时忽略其中的缺失值。<code>MARGIN=2</code>告诉函数逐列应用定义的函数。如果要计算行均值，只要简单的将margin参数设置为1即可。结果可见，平均说来在线购买次数和消费量都要高于实体店购买。对于10个问卷调查，第二个问题（<code>Q2</code>）平均得分最低。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apply</span>(sdat, <span class="dt">MARGIN=</span><span class="dv">2</span>,function(x) <span class="kw">sd</span>(<span class="kw">na.omit</span>(x)))</code></pre></div>
<pre><code>##          age       income    store_exp   online_exp  store_trans 
##    14.190572 49842.287197  2775.166414  1731.224308     3.695559 
## online_trans           Q1           Q2           Q3           Q4 
##     7.956959     1.450139     1.168348     1.402106     1.155061 
##           Q5           Q6           Q7           Q8           Q9 
##     1.284377     1.438529     1.455941     1.154347     1.118493 
##          Q10 
##     1.136174</code></pre>
<p>让我们再来看看标准差，代码和计算均值几乎是一样的，只是将均值函数<code>mean()</code>换成标准差函数<code>sd()</code>。虽然在线花费的均值高过实体店花费，但是实体店花费的标准差比在线花费高很多，认真看过本章开头的读者应该知道，这是由于个把土豪在实体店买了上万的衣服。还有问卷调查的第二个问题，虽然之前看到的均值很小，但是标准差也很小，这说明了什么？说明总体对该问题的评分都偏低，如果用于客户分组的话该问题可能不具有太高的区分度。关于这点，我们可以在客户分组那个章节以该数据集为例进行核实。虽然这都是一些简单的统计量，但能够使你在建模前了解更多的关于数据的信息，这对于模型选择和结果解释都有无形的帮助。</p>
</div>
<div id="plyrddply" class="section level3">
<h3><span class="header-section-number">5.10.2</span> plyr包：ddply()函数</h3>
<p>之前讲过一个居家旅行必备神器是<code>caret</code>包，希望大家还记得，这个包实在是太强大了，我们之后会反复用到里面的各个函数，但这里不会详细介绍这个包的所有功能，因为具体介绍R中函数的用法不是本书主要目的，而且关于各种包网上有很多文档材料，如果你真的知道你要对数据做什么，找到相应的R包并在网上查看相应帮助资料学会如何使用并不困难（对于有一定经验的R用来说），但很多时候，我们的问题在于即使不知道该如何解决实际问题，本书的重点是给大家展示数据科学家是如何通过这些技术手段解决问题的，R是一个功能强大的工具，但是手段不是目的。回归主题，现在要再讲第二个必备神器，<code>plyr</code>包。同样我不会详细介绍这个包的用法，而是展示如何用这个包中的ddply()函数帮助我们进行数据分析。还是服装消费者的数据（我知道这很没有创意，但太有创意了老换数据集对你们理解模型方法没有什么好处：）），之前我们都没有用到数据框中的最后一列指明消费者类别的变量<code>segment</code>。已经忘记了消费者类别定义的小伙伴们请回到生成数据的那小节，复习下。有客户分组项目经验的人都知道，在通过聚类（在聚类的章节会说到）得到分组以后，下一件事情就是看看每组客户都是些什么样的人，也就是建立各组客户档案。下面我们就来看看各组客户的人口统计学和消费行为档案吧：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(sim.dat,<span class="st">&quot;segment&quot;</span>,summarize, <span class="dt">Age=</span><span class="kw">round</span>(<span class="kw">mean</span>(<span class="kw">na.omit</span>(age)),<span class="dv">0</span>),
      <span class="dt">FemalePct=</span><span class="kw">round</span>(<span class="kw">mean</span>(gender==<span class="st">&quot;Female&quot;</span>),<span class="dv">2</span>),
      <span class="dt">HouseYes=</span><span class="kw">round</span>(<span class="kw">mean</span>(house==<span class="st">&quot;Yes&quot;</span>),<span class="dv">2</span>),
      <span class="dt">store_exp=</span><span class="kw">round</span>(<span class="kw">mean</span>(<span class="kw">na.omit</span>(store_exp),<span class="dt">trim=</span><span class="fl">0.1</span>),<span class="dv">0</span>),
      <span class="dt">online_exp=</span><span class="kw">round</span>(<span class="kw">mean</span>(online_exp),<span class="dv">0</span>),
      <span class="dt">store_trans=</span><span class="kw">round</span>(<span class="kw">mean</span>(store_trans),<span class="dv">1</span>),
      <span class="dt">online_trans=</span><span class="kw">round</span>(<span class="kw">mean</span>(online_trans),<span class="dv">1</span>))</code></pre></div>
<pre><code>##       segment Age FemalePct HouseYes store_exp online_exp store_trans
## 1 Conspicuous  40      0.32     0.86      4990       4898        10.9
## 2       Price  60      0.45     0.94       501        205         6.1
## 3     Quality  35      0.47     0.34       301       2013         2.9
## 4       Style  24      0.81     0.27       200       1962         3.0
##   online_trans
## 1         11.1
## 2          3.0
## 3         16.0
## 4         21.1</code></pre>
<p>这结果信息量太大了，不过并不奇怪。在实际应用中，真实客户分组是未知的并且分析的目标就是找到这样的组。也就是说在实际客户分组的项目中，这是我们希望的到的分析上的最终结果。在对这个结果进行解读之前，我们先看看上面<code>ddply()</code>代码。函数的第一个参数是数据集（<code>sim.dat</code>），其次是告诉函数要按照哪个分类变量进行总结，这里我们只想对不同类别的消费者进行总结，但也可以是多个变量，如你可以将该参数设置成<code>ddply(sim.dat, c(“segment”,”house”), …)</code>，结果读者试着自行脑补下：）。接下来<code>summarize</code>是说我们希望对数据框分组做总结，你可以设置其它功能比如<code>transform</code>（在组内进行数据变换）和<code>subset</code>（在组内进行数据选择）。接下来分别是：</p>
<ul>
<li><p>Age：计算每组的年龄均值</p></li>
<li><p>FemalePct：计算每组女性的比例</p></li>
<li><p>HouseYes：计算每组内有房的人的比例</p></li>
<li><p>store_exp：计算每组实体店消费均值，这里我们用修剪后的（<code>trim=0.1</code>）均值，因为通过之前的数据探索我们知道这个变量观测有些土豪离群点。</p></li>
<li><p>online_exp：计算每组在线消费均值</p></li>
<li><p>store_trans：计算每组实体店消费次数均值</p></li>
<li><p>online_trans：计算每组在线消费次数均值</p></li>
</ul>
<p>了解这些以后，我们看看消费者群体之间有何不同。</p>
<ul>
<li><p>炫耀性消费（Conspicuous）人群年龄平均40岁左右，基本中年土豪，女性大概占了1/3另外2/3是男性（基本是大叔控的目标），土豪在哪里都买的多，在线消费量和实体店消费量都远大于其他人，在线和实体店消费的量和次数都差不多，反正有钱不在乎在哪买，看到好的就买，有钱任性嘛！基本有房（0.86），剩下14%没房的如果不是由于观点坚决不买房的话，那或许是在北上广这样的地方高不成低不就，买房不够消费有余，这也提醒我们如果这些样本是来自不同城市的话，我们可能还需要收集消费者所在城市的信息，城市的生活水平很大程度上影响了消费行为。</p></li>
<li><p>对价格敏感的人（Price）年龄大（60），基本有房（0.94）这和他们的年龄有关，房奴是后来时代发展的产物。这类人在线消费比其他人都少，还是倾向于在实体店消费（平均在线交易次数是3，而实体店消费次数是6），这也是唯一一类在线消费低于实体店消费的。</p></li>
<li><p>注重服装质量的人（Quality）平均年龄居中，可能和炫耀性消费人群没有显著差别，男女比例基本一半一半。明显偏爱在线消费，消费量和土豪比差远了，但位居其次，估计是中产。有房的人不是很多（0.34），这代人很不幸已经进入房奴的时代。</p></li>
<li><p>风格类（Style），这些无疑是年轻人了，平均年龄只有24，大学生或者刚工作不久的白领，绝大多数是女性（0.81），有房的不多（0.27）或者可以说能完全靠啃老的不多：），也是典型的在线一族，在线购买的次数比Quality和Conspicuous的人多但是消费额却没有他们大。</p></li>
</ul>
<p>这里就提醒我们需要计算平均每次购买的花销，这样可以了解各个群体大概都买什么价位的东西。大家看到没有，分析是一个迭代学习的过程，我们在探索数据的过程中可能会发现一些问题，促使我们去检查某部分数据或者计算一些新的变量，使用新的可视化来探索数据。我们接着用<code>ddply()</code>补充计算这两个统计量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(sim.dat,<span class="st">&quot;segment&quot;</span>,summarize,<span class="dt">avg_online=</span><span class="kw">round</span>(<span class="kw">sum</span>(online_exp)/<span class="kw">sum</span>(online_trans),<span class="dv">2</span>),
      <span class="dt">avg_store=</span><span class="kw">round</span>(<span class="kw">sum</span>(store_exp)/<span class="kw">sum</span>(store_trans),<span class="dv">2</span>))</code></pre></div>
<pre><code>##       segment avg_online avg_store
## 1 Conspicuous     442.27    479.25
## 2       Price      69.28     81.30
## 3     Quality     126.05    105.12
## 4       Style      92.83    121.07</code></pre>
<p>结果显示价格敏感的人群果然买的价位最低，其次是风格类人群，这些人不一定是对价格敏感，但或许钱包不允许他们买太贵的。注重质量的买的东西价格比风格类的高些，但远不及土豪组，物美价廉的东西毕竟少，这些人可能更看重性价比，不会炫耀性消费但也不会买低质廉价的东西。我们在之后客户分组的时候还会进行类似的总结，那时我们会加上关于问卷调查的回复。大家看到了么，短短的几行代码就可以得到这么有信息量的总结。你可能会说这样的总结通过excel的数据透视表（pivot table）也能完成，但是用R代码要快得多，而且这只是其中一部分功能，如果之前说的，你可以设置其它功能比如<code>transform</code>（在组内进行数据变换）和<code>subset</code>（在组内进行数据选择），并且计算的东西也是可以自己定义。</p>
<p>为了方便，我们按照消费者类别比例随机抽取11个样本，选择3个变量（<code>age</code>，<code>store_exp</code>和<code>segment</code>）用于展示（数据框：<code>examp</code>）。这里用于分层抽样的函数在之后介绍建模辅助技术时会讲到，所以这里不做介绍。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">set.seed</span>(<span class="dv">2016</span>)
trainIndex&lt;-<span class="kw">createDataPartition</span>(sim.dat$segment,<span class="dt">p=</span><span class="fl">0.01</span>,<span class="dt">list=</span>F,<span class="dt">times=</span><span class="dv">1</span>)
examp&lt;-sim.dat[trainIndex,<span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;segment&quot;</span>)]</code></pre></div>
<p><code>examp</code>数据集只有11行3列。我们先看看<code>transform</code>设置的作用：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(examp,<span class="st">&quot;segment&quot;</span>,transform,<span class="dt">store_pct=</span><span class="kw">round</span>(store_exp/<span class="kw">sum</span>(store_exp),<span class="dv">2</span>))</code></pre></div>
<pre><code>##    age store_exp     segment store_pct
## 1   42 6319.0718 Conspicuous      0.55
## 2   42 5106.4816 Conspicuous      0.45
## 3   55  595.2520       Price      0.42
## 4   64  399.3550       Price      0.28
## 5   64  426.6653       Price      0.30
## 6   39  362.4795     Quality      0.58
## 7   35  260.5065     Quality      0.42
## 8   23  205.6099       Style      0.25
## 9   24  212.3040       Style      0.26
## 10  24  202.1017       Style      0.25
## 11  28  200.1906       Style      0.24</code></pre>
<p>可以看到，设置<code>transform</code>使得函数对数据集按照指定分类变量（<code>segment</code>）在组内进行数据变换，并将变换后得到的新变量添加到原数据集后。再来看看<code>subset</code>设置：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(examp,<span class="st">&quot;segment&quot;</span>,subset,store_exp&gt;<span class="kw">median</span>(store_exp))</code></pre></div>
<pre><code>##   age store_exp     segment
## 1  42 6319.0718 Conspicuous
## 2  55  595.2520       Price
## 3  39  362.4795     Quality
## 4  23  205.6099       Style
## 5  24  212.3040       Style</code></pre>
<p>上面代码可以获取每个消费者类别（<code>segment</code>）中实体店消费（<code>store_exp</code>）大于该类别中位数的样本。</p>
</div>
<div id="dplyr" class="section level3">
<h3><span class="header-section-number">5.10.3</span> dplyr包</h3>
<p><code>dplyr</code>包是<code>plyr</code>包中的<code>ddply()</code>等函数的强化版，专门处理数据框（dataframe）对象，大幅提高了速度, 并且提供了更稳健的与其它数据库对象间的接口。由于分析中绝大多数是处理数据框，这个包尤其好用。这里我对这个包进行比较详细的介绍。接下来会按顺序介绍该包的几块重要功能：</p>
<ol style="list-style-type: decimal">
<li>数据框显示</li>
<li>数据截选（按行／列）</li>
<li>数据总结</li>
<li>生成新变量</li>
<li>合并数据集</li>
</ol>
<div id="section-5.10.3.1" class="section level4">
<h4><span class="header-section-number">5.10.3.1</span> 数据框显示</h4>
<ul>
<li><code>tbl_df()</code>函数: 能将数据转化成<code>tbl</code>类，这样查看起来更加方便，输出会调整适应当前窗口</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里不展示输出</span>
dplyr::<span class="kw">tbl_df</span>(sim.dat)</code></pre></div>
<ul>
<li><code>glimpse()</code>函数：类似之前的<code>tbl_df()</code>函数，只是转了方向。变量由列变成行。输出结果同样可以自动调整以适应窗口。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里不展示输出</span>
dplyr::<span class="kw">glimpse</span>(sim.dat)</code></pre></div>
</div>
<div id="section-5.10.3.2" class="section level4">
<h4><span class="header-section-number">5.10.3.2</span> 数据截选（按行／列）</h4>
<p>先介绍按行截选。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 提取出满足条件的行：收入大于30万的样本</span>
<span class="kw">library</span>(magrittr)
<span class="kw">library</span>(dplyr)
dplyr::<span class="kw">filter</span>(sim.dat, income &gt;<span class="dv">300000</span>) %&gt;%
dplyr::<span class="kw">tbl_df</span>()</code></pre></div>
<pre><code>## Source: local data frame [4 x 19]
## 
##     age gender   income  house store_exp online_exp store_trans
##   (int) (fctr)    (dbl) (fctr)     (dbl)      (dbl)       (int)
## 1    40   Male 301398.0    Yes  4840.461   3618.212          10
## 2    33   Male 319704.3    Yes  5998.305   4395.923           9
## 3    41   Male 317476.2    Yes  3029.844   4179.671          11
## 4    37 Female 315697.2    Yes  6548.970   4284.065          13
## Variables not shown: online_trans (int), Q1 (int), Q2 (int), Q3 (int), Q4
##   (int), Q5 (int), Q6 (int), Q7 (int), Q8 (int), Q9 (int), Q10 (int),
##   segment (fctr)</code></pre>
<p>这里用到了一个可能大家之间没有见过的操作符号<code>%&gt;%</code>，这是管道操作，其意思是将<code>%&gt;%</code>左边的对象传递给右边的函数，作为第一个选项的设置（或剩下唯一一个选项的设置）。比如：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x %&gt;%<span class="st"> </span><span class="kw">f</span>(y) 等同于 <span class="kw">f</span>(x, y)
y %&gt;%<span class="st"> </span><span class="kw">f</span>(x, ., z) 等同于 <span class="kw">f</span>(x, y, z )</code></pre></div>
<p>管道操作来自于<code>magrittr</code>包，它能够极大简化代码，增加代码可读性。尤其对于<code>dplyr</code>包中的函数操作。大家看下面这段代码，能够知道都干了什么么？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ave_exp &lt;-<span class="st"> </span><span class="kw">filter</span>( 
  <span class="kw">summarise</span>(
    <span class="kw">group_by</span>( 
      <span class="kw">filter</span>(
        sim.dat, 
        !<span class="kw">is.na</span>(income)
      ), 
      segment
    ), 
    <span class="dt">ave_online_exp =</span> <span class="kw">mean</span>(online_exp), 
    <span class="dt">n =</span> <span class="kw">n</span>()
  ), 
  n &gt;<span class="st"> </span><span class="dv">200</span>
) </code></pre></div>
<p>再看看用管道操作符进行相同操作的代码：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">avg_exp &lt;-<span class="st"> </span>sim.dat %&gt;%<span class="st"> </span>
<span class="st"> </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(income)) %&gt;%<span class="st"> </span>
<span class="st"> </span><span class="kw">group_by</span>(segment) %&gt;%<span class="st"> </span>
<span class="st"> </span><span class="kw">summarise</span>( 
   <span class="dt">ave_online_exp =</span> <span class="kw">mean</span>(online_exp), 
   <span class="dt">n =</span> <span class="kw">n</span>() ) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(n &gt;<span class="st"> </span><span class="dv">200</span>)</code></pre></div>
<p>用<code>%&gt;%</code>的代码是不是简洁清晰的多？我们从上掉下依次读下代码都干了什么：</p>
<ol style="list-style-type: decimal">
<li>选出数据框<code>sim.dat</code>中收入未缺失的观测</li>
<li>按照<code>segment</code>变量对观测分组</li>
<li>对每组数据求在线消费额的平均值，并赋予新的变量<code>ave_online_exp</code></li>
<li>对每组计算观测个数，赋值为<code>n</code></li>
<li>选出结果中观测个数大于200的行</li>
</ol>
<p>上面代码中用到的一些没有讲到的函数马上就会介绍。 <code>distinct()</code>函数可以删除数据框中重复的行。可以说是<code>unique()</code>函数在数据框上的扩展。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 删除重复的行
## 这里没有重复的行
dplyr::<span class="kw">distinct</span>(sim.dat)</code></pre></div>
<p><code>sample_frac()</code>函数可以随机选取一定比例的行。<code>sample_n()</code>函数可以随机选取一定数目的行。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dplyr::<span class="kw">sample_frac</span>(sim.dat, <span class="fl">0.5</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) 
dplyr::<span class="kw">sample_n</span>(sim.dat, <span class="dv">10</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) </code></pre></div>
<p><code>slice()</code>可以选取指定位置的行。和<code>sim.dat[10:15,]</code>类似。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取sim.dat的10到15行</span>
dplyr::<span class="kw">slice</span>(sim.dat, <span class="dv">10</span>:<span class="dv">15</span>) </code></pre></div>
<p><code>top_n()</code>可以选取某变量取值最高的若干观测。如果有指定组的话，可以对每组选择相应变量取值最高的观测。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 选取收入最高的两个观测</span>
dplyr::<span class="kw">top_n</span>(sim.dat,<span class="dv">2</span>,income)</code></pre></div>
<p>对列变量的选择使用的是<code>select()</code>函数。下面我展示一些代码，并在相应的注释中指出该代码的功能。大家自己运行下看看结果。更多信息，键入<code>?select</code>查阅该函数的帮助文档。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 通过列名选取变量</span>
<span class="co"># 选取 sim.dat数据框中的income，age和store_exp列</span>
dplyr::<span class="kw">select</span>(sim.dat,income,age,store_exp)
<span class="co"># 选取列名中含有某字符串（_）的列</span>
<span class="co"># 该命令将选取store_exp，online_exp，store_trans和online_trans</span>
dplyr::<span class="kw">select</span>(sim.dat, <span class="kw">contains</span>(<span class="st">&quot;_&quot;</span>))
<span class="co"># 选取以某字符串（e）结尾的列</span>
<span class="co"># 结果选取了age，income和house</span>
<span class="co"># 类似的starts_with指以某字符串开始的列</span>
dplyr::<span class="kw">select</span>(sim.dat, <span class="kw">ends_with</span>(<span class="st">&quot;e&quot;</span>))
<span class="co"># 选取列Q1，Q2，Q3，Q4和Q5</span>
<span class="kw">select</span>(sim.dat, <span class="kw">num_range</span>(<span class="st">&quot;Q&quot;</span>, <span class="dv">1</span>:<span class="dv">5</span>)) 
<span class="co"># 选取列名在某字符串中的列</span>
dplyr::<span class="kw">select</span>(sim.dat, <span class="kw">one_of</span>(<span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;income&quot;</span>)))
<span class="co"># 选取两个列名之间的列，包含头尾两列</span>
dplyr::<span class="kw">select</span>(sim.dat, age:online_exp)
<span class="co"># 选出出了某列（age）以外的其它列</span>
dplyr::<span class="kw">select</span>(sim.dat, -age)</code></pre></div>
</div>
<div id="section-5.10.3.3" class="section level4">
<h4><span class="header-section-number">5.10.3.3</span> 数据总结</h4>
<p>这里的操作类似于<code>apply()</code>和<code>ddply()</code>， 可以对数据框的每一列进行某个函数操作；或者按照某个分类变量将观测分组，然后对每组观测按列进行函数操作。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 对列online_trans取均值，返回的是一个单一值</span>
dplyr::<span class="kw">summarise</span>(sim.dat, <span class="dt">avg_online =</span> <span class="kw">mean</span>(online_trans)) </code></pre></div>
<pre><code>##   avg_online
## 1     13.546</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 对数据框中的每一列应用函数anyNA()</span>
<span class="co"># 这里可以指定一个函数向量，如c(&quot;anyNA&quot;,&quot;is.factor&quot;)</span>
dplyr::<span class="kw">summarise_each</span>(sim.dat, <span class="kw">funs_</span>(<span class="kw">c</span>(<span class="st">&quot;anyNA&quot;</span>)))</code></pre></div>
<pre><code>##     age gender income house store_exp online_exp store_trans online_trans
## 1 FALSE  FALSE   TRUE FALSE     FALSE      FALSE       FALSE        FALSE
##      Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10 segment
## 1 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE   FALSE</code></pre>
<p>若要根据某分类变量对观测进行分组总结，可以使用<code>group_by()</code>函数。比如：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 对每个消费者类别对应变量应用anyNA()函数</span>
sim.dat %&gt;%<span class="st"> </span><span class="kw">group_by</span>(segment) %&gt;%<span class="st"> </span><span class="kw">summarise_each</span>(<span class="kw">funs_</span>(<span class="kw">c</span>(<span class="st">&quot;anyNA&quot;</span>)))</code></pre></div>
<pre><code>## Source: local data frame [4 x 19]
## 
##       segment   age gender income house store_exp online_exp store_trans
##        (fctr) (lgl)  (lgl)  (lgl) (lgl)     (lgl)      (lgl)       (lgl)
## 1 Conspicuous FALSE  FALSE   TRUE FALSE     FALSE      FALSE       FALSE
## 2       Price FALSE  FALSE   TRUE FALSE     FALSE      FALSE       FALSE
## 3     Quality FALSE  FALSE   TRUE FALSE     FALSE      FALSE       FALSE
## 4       Style FALSE  FALSE   TRUE FALSE     FALSE      FALSE       FALSE
## Variables not shown: online_trans (lgl), Q1 (lgl), Q2 (lgl), Q3 (lgl), Q4
##   (lgl), Q5 (lgl), Q6 (lgl), Q7 (lgl), Q8 (lgl), Q9 (lgl), Q10 (lgl)</code></pre>
<p>你在数据总结操作中赋予各种总结函数，如<code>mean()</code>，<code>sd()</code>等。但注意这里的总结函数是作用于向量，返回单一值。比如函数<code>is.na()</code>，作用于向量，但返回的也是向量，就不可以在此使用。</p>
</div>
<div id="section-5.10.3.4" class="section level4">
<h4><span class="header-section-number">5.10.3.4</span> 生成新变量</h4>
<p><code>dplyr</code>包中的<code>mutate()</code>函数可以进行列计算，然后将结果添加到原数据集上。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dplyr::<span class="kw">mutate</span>(sim.dat, <span class="dt">total_exp =</span> store_exp +<span class="st"> </span>online_exp)</code></pre></div>
<p>对每列应用窗口函数，它们作用于一个向量然后返回一个向量。回顾刚才介绍<code>dplyr</code>的总结功能时讲到总结函数作用于一个向量返回一个数值。注意理解这两者的不同。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里的min_rank等价于rank(ties.method = &quot;min&quot;)</span>
<span class="co"># mutate_each()对每列应用指定的窗口函数</span>
dplyr::<span class="kw">mutate_each</span>(sim.dat, <span class="kw">funs</span>(min_rank)) </code></pre></div>
<p><code>transmute()</code>函数和<code>mutate()</code>类似，区别在于它只返回新生成的列，删除原始列。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dplyr::<span class="kw">transmute</span>(sim.dat, <span class="dt">total_exp =</span> store_exp +<span class="st"> </span>online_exp) </code></pre></div>
<p>这里没有显示代码的结果，大家需要自己操作看看结果，这样对理解学习这些函数很有帮助。关于R中的窗口函数，大家可以自己查找相关资料。熟悉这些常见的函数及其功能，可以提高用R做数据变换的效率（不用总查帮助）。这个过程没有什么技巧可言，纯粹是熟能生巧。</p>
</div>
<div id="section-5.10.3.5" class="section level4">
<h4><span class="header-section-number">5.10.3.5</span> 合并数据集</h4>
<p>这里先随机抽取两个小数据集来展示数据集合并。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">data.frame</span>(<span class="kw">cbind</span>(<span class="dt">ID=</span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;B&quot;</span>,<span class="st">&quot;C&quot;</span>),<span class="dt">x1=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)))
y&lt;-<span class="kw">data.frame</span>(<span class="kw">cbind</span>(<span class="dt">ID=</span><span class="kw">c</span>(<span class="st">&quot;B&quot;</span>,<span class="st">&quot;C&quot;</span>,<span class="st">&quot;D&quot;</span>),<span class="dt">y1=</span><span class="kw">c</span>(T,T,F)))
x</code></pre></div>
<pre><code>##   ID x1
## 1  A  1
## 2  B  2
## 3  C  3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y</code></pre></div>
<pre><code>##   ID    y1
## 1  B  TRUE
## 2  C  TRUE
## 3  D FALSE</code></pre>
<p>这里数据框<code>x</code>和<code>y</code>都非常简单，由一个<code>ID</code>变量和各自的观测变量组成。下面我们来介绍各种合并操作。</p>
<ul>
<li><code>left_join()</code>从<code>y</code>到<code>x</code>合并数据。结果保留了数据框<code>x</code>的3行。类似大家可以自行尝试<code>right_join()</code>。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">left_join</span>(x,y,<span class="dt">by=</span><span class="st">&quot;ID&quot;</span>)</code></pre></div>
<pre><code>##   ID x1   y1
## 1  A  1 &lt;NA&gt;
## 2  B  2 TRUE
## 3  C  3 TRUE</code></pre>
<ul>
<li><code>inner_join()</code>返回的是<code>y</code>和<code>x</code>中都可以匹配的观测。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inner_join</span>(x,y,<span class="dt">by=</span><span class="st">&quot;ID&quot;</span>)</code></pre></div>
<pre><code>##   ID x1   y1
## 1  B  2 TRUE
## 2  C  3 TRUE</code></pre>
<ul>
<li><code>full_join()</code>返回的是<code>y</code>或者<code>x</code>中含有的观测。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">full_join</span>(x,y,<span class="dt">by=</span><span class="st">&quot;ID&quot;</span>)</code></pre></div>
<pre><code>##   ID   x1    y1
## 1  A    1  &lt;NA&gt;
## 2  B    2  TRUE
## 3  C    3  TRUE
## 4  D &lt;NA&gt; FALSE</code></pre>
<ul>
<li><code>semi_join()</code>对<code>x</code>中的观测进行筛选，找到那些同时在<code>y</code>中<strong>可以匹配</strong>的观测，但并没有将<code>y</code>的变量<code>y1</code>合并进来。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">semi_join</span>(x,y,<span class="dt">by=</span><span class="st">&quot;ID&quot;</span>)</code></pre></div>
<pre><code>##   ID x1
## 1  B  2
## 2  C  3</code></pre>
<ul>
<li><code>anti_join()</code>同样对<code>x</code>中的观测进行筛选，找到那些在<code>y</code>中<strong>无法匹配</strong>的观测。</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anti_join</span>(x,y,<span class="dt">by=</span><span class="st">&quot;ID&quot;</span>)</code></pre></div>
<pre><code>##   ID x1
## 1  A  1</code></pre>
<p>此外，<code>dplyr</code>包中还有各种针对数据框的交（<code>intersect()</code>）、并（<code>union()</code>）和补（<code>setdiff()</code>）运算，以及将一个数据框按照行或者列添加到另一个数据框上的操作（<code>bind_rows()</code>，<code>bind_cols()</code>）。这里就不一一介绍，大家自己用一个简单的数据框尝试下。</p>
</div>
</div>
<div id="reshape2" class="section level3">
<h3><span class="header-section-number">5.10.4</span> 数据整形：<code>reshape2</code>包</h3>
<p>终于到本章末尾了。之前提到过，如果我们希望有一个新的变量指示购买的渠道（是在线还是实体店），并且将这个变量用于建模，这时就需要对数据进行整形（也称作数据整理，或者揉数据），将在线购买的记录和实体店购买的记录逐行排列而非现在的逐列。我们可以用<code>reshape2</code>包中的相关函数实现这些操作。可能有的读者知道有个包叫做<code>reshape</code>，这是初版，后面的<code>reshape2</code>是重写升级版。这个数据整形的过程确实和揉面团有些类似，先将数据通过<code>melt()</code>函数将数据揉开，然后再通过<code>dcast()</code>函数将数据重塑成想要的形状，为了更清晰的展示函数对数据结构的影响，我们选取其中小部分列，和前5行：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(sdat&lt;-sim.dat[<span class="dv">1</span>:<span class="dv">5</span>,<span class="dv">1</span>:<span class="dv">6</span>])</code></pre></div>
<pre><code>##   age gender   income house store_exp online_exp
## 1  57 Female 120963.4   Yes  529.1344   303.5125
## 2  63 Female 122008.1   Yes  478.0058   109.5297
## 3  59   Male 114202.3   Yes  490.8107   279.2496
## 4  60   Male 113616.3   Yes  347.8090   141.6698
## 5  51   Male 124252.6   Yes  379.6259   112.2372</code></pre>
<p>我们截取的子数据框一共5行，6列。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(mdat &lt;-<span class="st"> </span><span class="kw">melt</span>(sdat, <span class="dt">measure.vars=</span><span class="kw">c</span>(<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>)))</code></pre></div>
<pre><code>##    age gender   income house   variable    value
## 1   57 Female 120963.4   Yes  store_exp 529.1344
## 2   63 Female 122008.1   Yes  store_exp 478.0058
## 3   59   Male 114202.3   Yes  store_exp 490.8107
## 4   60   Male 113616.3   Yes  store_exp 347.8090
## 5   51   Male 124252.6   Yes  store_exp 379.6259
## 6   57 Female 120963.4   Yes online_exp 303.5125
## 7   63 Female 122008.1   Yes online_exp 109.5297
## 8   59   Male 114202.3   Yes online_exp 279.2496
## 9   60   Male 113616.3   Yes online_exp 141.6698
## 10  51   Male 124252.6   Yes online_exp 112.2372</code></pre>
<p>我们将变量<code>store_exp</code>和<code>online_exp</code>揉合在一起，结果产生了新的两列，一列是变量<code>variable</code>，指代是哪个揉合变量，另外一列是取值<code>value</code>，即变量对应的值。我们也称这样逐行排列的方式称为长数据格式。由于这里我们并没有指定除了要揉合的变量外的id变量，于是函数默认将所有剩下的变量都当作id变量。对于这些变量保留原来对应的观测，只是对<code>store_exp</code>和<code>online_exp</code>分别重复一次。所以得到的结果有10行。如果我们要对消费量（value）建立线性模型，并且考虑购买渠道的效应的话就可以利用揉合后的数据：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里为了展示回归需要更多的数据，所以用原数据框的所有行</span>
mdat&lt;-<span class="kw">melt</span>(sim.dat[,<span class="dv">1</span>:<span class="dv">6</span>], <span class="dt">measure.vars=</span><span class="kw">c</span>(<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>))
fit&lt;-<span class="kw">lm</span>(value~gender+house+income+variable+age,<span class="dt">data=</span>mdat)
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = value ~ gender + house + income + variable + age, 
##     data = mdat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -4208   -821   -275    533  44353 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        -9.132e+02  1.560e+02  -5.855 5.76e-09 ***
## genderMale          3.572e+02  1.028e+02   3.475 0.000524 ***
## houseYes           -5.687e+01  1.138e+02  -0.500 0.617275    
## income              2.834e-02  1.079e-03  26.268  &lt; 2e-16 ***
## variableonline_exp  8.296e+02  9.772e+01   8.489  &lt; 2e-16 ***
## age                -2.793e+01  3.356e+00  -8.321  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1974 on 1626 degrees of freedom
##   (368 observations deleted due to missingness)
## Multiple R-squared:  0.348,  Adjusted R-squared:  0.346 
## F-statistic: 173.5 on 5 and 1626 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>这里<code>lm()</code>函数自动将实体店消费<code>store_exp</code>设置成基准水平，只看对应的系数估计表明，在其它条件不变的情况下，在线购买的人比商店购买的人平均消费高出830元，而且购买渠道的效应非常显著。看到这样的结果，分析师需要考虑建议商家提高网上商城的购物体验，采取一些手段改变那些实体店为主的消费者改变消费习惯。当然，当靠一个线性回归系数就作出这样的建议有些仓促，还需要对模型的可靠性进行进一步检查。下一章就会讲到模型选择和评估。</p>
<p>如果我们将<code>house</code>和<code>gender</code>指定为id变量，结果为：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里用所用的数据</span>
<span class="co"># 缺失值填补</span>
demo_imp&lt;-<span class="kw">impute</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;median/mode&quot;</span>)
mdat &lt;-<span class="st"> </span><span class="kw">melt</span>(demo_imp, <span class="dt">measure.vars=</span><span class="kw">c</span>(<span class="st">&quot;store_exp&quot;</span>,<span class="st">&quot;online_exp&quot;</span>),<span class="dt">id.vars=</span><span class="kw">c</span>(<span class="st">&quot;house&quot;</span>,<span class="st">&quot;gender&quot;</span>))
<span class="kw">head</span>(mdat)</code></pre></div>
<pre><code>##   house gender  variable    value
## 1   Yes Female store_exp 529.1344
## 2   Yes Female store_exp 478.0058
## 3   Yes   Male store_exp 490.8107
## 4   Yes   Male store_exp 347.8090
## 5   Yes   Male store_exp 379.6259
## 6   Yes   Male store_exp 338.3154</code></pre>
<p><code>melt()</code>函数不仅能揉合数据框，还能揉合列表，矩阵，表格等。感兴趣的小伙伴可以自己在网上找相关的介绍，很容易找到案例代码，自己一步一步跟着运行一遍就很清楚了。这里揉合数据是为了建模需要，有的时候是为了进一步重塑数据结构。好比把一个积木房子拆开重新盖一个新的造型。这就要用到该包的第二个重要函数<code>dcast()</code>（这是升级版中的函数，初级版本的<code>reshape</code>包对应的是<code>cast()</code>函数）。比如，如果想知道对于有房和没有房的男性和女性，在线消费和实体店消费的总额分别是多少：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dcast</span>(mdat, house+gender~<span class="st"> </span>variable, sum)</code></pre></div>
<pre><code>##   house gender store_exp online_exp
## 1    No Female  171102.2   583492.4
## 2    No   Male  133130.8   332499.9
## 3   Yes Female  355320.2   500856.9
## 4   Yes   Male  697297.3   703332.0</code></pre>
<p>上面代码中<code>~</code>左边是你用来划分数据框的id变量，这里是<code>house</code>和<code>gender</code>，右边是你计算根据的变量（也必须是分类变量），真正用于计算的数值是你之前揉合过程中生成的<code>value</code>那列值。这两个函数确实不太好理解，大家需要对一个数据框自己实际操作才能真正理解。</p>
</div>
<div id="tidyr" class="section level3">
<h3><span class="header-section-number">5.10.5</span> 数据整形：<code>tidyr</code>包</h3>
<p>R中还有一个能够用于数据整形的包<code>tidyr</code>。下面我们截取一个小数据框(<code>sdat</code>)展示包中一些主要函数的功能。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sdat&lt;-sim.dat[<span class="dv">1</span>:<span class="dv">5</span>,]%&gt;%
<span class="st">  </span>dplyr::<span class="kw">select</span>(age,gender,store_exp,store_trans)
sdat %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<pre><code>## Source: local data frame [5 x 4]
## 
##     age gender store_exp store_trans
##   (int) (fctr)     (dbl)       (int)
## 1    57 Female  529.1344           2
## 2    63 Female  478.0058           4
## 3    59   Male  490.8107           7
## 4    60   Male  347.8090          10
## 5    51   Male  379.6259           4</code></pre>
<p>首先是<code>gather()</code>函数。它的作用类似于<code>reshape2</code>中的<code>melt()</code>。下面这条命令的结果和<code>melt(sdat, measure.vars=c(&quot;store_exp&quot;,&quot;store_trans&quot;))</code>是一样的。其中<code>variable</code>和<code>value</code>是自定义的揉合生成的两列新变量的名字。<code>variable</code>列对应原数据中参与揉合的变量名，<code>value</code>列是参与揉合的变量的取值。<code>store_exp,store_trans</code>告诉R对那些变量进行揉合。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">msdat&lt;-tidyr::<span class="kw">gather</span>(sdat,<span class="st">&quot;variable&quot;</span>,<span class="st">&quot;value&quot;</span>,store_exp,store_trans)
msdat %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<pre><code>## Source: local data frame [10 x 4]
## 
##      age gender    variable    value
##    (int) (fctr)       (chr)    (dbl)
## 1     57 Female   store_exp 529.1344
## 2     63 Female   store_exp 478.0058
## 3     59   Male   store_exp 490.8107
## 4     60   Male   store_exp 347.8090
## 5     51   Male   store_exp 379.6259
## 6     57 Female store_trans   2.0000
## 7     63 Female store_trans   4.0000
## 8     59   Male store_trans   7.0000
## 9     60   Male store_trans  10.0000
## 10    51   Male store_trans   4.0000</code></pre>
<p>如果用我们之前讲到的管道操作，上面代码可以等价的写成：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里不显示输出结果</span>
sdat%&gt;%<span class="kw">gather</span>(<span class="st">&quot;variable&quot;</span>,<span class="st">&quot;value&quot;</span>,store_exp,store_trans)</code></pre></div>
<p>和<code>gather()</code>相反的是<code>spread()</code>，前者将不同的列堆叠起来，后者将同一列分开。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">msdat %&gt;%<span class="st"> </span><span class="kw">spread</span>(variable,value)</code></pre></div>
<pre><code>##   age gender store_exp store_trans
## 1  51   Male  379.6259           4
## 2  57 Female  529.1344           2
## 3  59   Male  490.8107           7
## 4  60   Male  347.8090          10
## 5  63 Female  478.0058           4</code></pre>
<p><code>tidyr</code>包中还有另外两个互补的函数，<code>separate()</code>和<code>unite()</code>。<code>separate()</code>函数可以将不同列分开成为多列。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sepdat&lt;-<span class="st"> </span>msdat %&gt;%<span class="st"> </span><span class="kw">separate</span>(variable,<span class="kw">c</span>(<span class="st">&quot;Source&quot;</span>,<span class="st">&quot;Type&quot;</span>))
sepdat %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>()</code></pre></div>
<pre><code>## Source: local data frame [10 x 5]
## 
##      age gender Source  Type    value
##    (int) (fctr)  (chr) (chr)    (dbl)
## 1     57 Female  store   exp 529.1344
## 2     63 Female  store   exp 478.0058
## 3     59   Male  store   exp 490.8107
## 4     60   Male  store   exp 347.8090
## 5     51   Male  store   exp 379.6259
## 6     57 Female  store trans   2.0000
## 7     63 Female  store trans   4.0000
## 8     59   Male  store trans   7.0000
## 9     60   Male  store trans  10.0000
## 10    51   Male  store trans   4.0000</code></pre>
<p>可以看到，原来的变量<code>variable</code>被分成了两部分：<code>Source</code>和<code>Type</code>。你可以通过设置<code>sep=</code>来自定义用于划分字符的正则表达，默认是所有非字母和数字的字符。比如这里的“_”。</p>
<p>与<code>separate()</code>相反的函数是<code>unite()</code>， 它能将不同的列合并在一起。类似于<code>paste()</code>函数的数据框版本。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sepdat %&gt;%<span class="st"> </span><span class="kw">unite</span>(<span class="st">&quot;variable&quot;</span>,Source,Type,<span class="dt">sep=</span><span class="st">&quot;_&quot;</span>)</code></pre></div>
<pre><code>##    age gender    variable    value
## 1   57 Female   store_exp 529.1344
## 2   63 Female   store_exp 478.0058
## 3   59   Male   store_exp 490.8107
## 4   60   Male   store_exp 347.8090
## 5   51   Male   store_exp 379.6259
## 6   57 Female store_trans   2.0000
## 7   63 Female store_trans   4.0000
## 8   59   Male store_trans   7.0000
## 9   60   Male store_trans  10.0000
## 10  51   Male store_trans   4.0000</code></pre>
<p>上面的代码将原先分开的两列又合并回去了，并赋予的和之前一样的列名<code>&quot;variable&quot;</code>。</p>
<p>整形这部分可能是数据处理变换中最复杂的，这种复杂和证明数学定理不同，主要是需要时间熟悉。更像一门手艺，所以大家要发扬手艺人精神，多使用这些函数，把数据当面团一样揉来揉去的，也挺好玩的，不是么？觉得R太难有些犹豫需不需要学习的小伙伴们，<strong>磨刀不误砍柴工</strong>，再一次中国的老古话放在那里闪闪发光的有木有？</p>
</div>
</div>
<div id="section-5.11" class="section level2">
<h2><span class="header-section-number">5.11</span> 本章总结</h2>
<p>本章介绍了常用的建模前的数据预处理以及数据整合方法。需要补充一点，这里我没有讲到是连续变量的离散化，也称为区间化自变量。比如将年龄转变为由&lt;25，25-40，40-60和&gt;60组成的分类变量。个人不赞成分析师自行将连续变量离散化，如果客户或相关领域专家给出明确的理由，在该领域这么划分是通常惯例，或者只有划分成某种区间模型结果才能够解释，那么你可以根据对方的观点划分。而从分析的角度，手动区间化连续型数据是不推荐的。连续变量的效能通常比区间变量高。你需要权衡将连续变量离散化对可解释性的提升和对模型精确度的损害。注意这里指的是人为主观的将一些连续变量转变为分类变量而非模型检测出的截断点。有一些模型，如分类/回归树和多元自适性回归样条，它们在建模过程中能够估计合适的截断点。这些模型使用了所有自变量的信息，对不同变量进行评估，使用可靠的统计方法，并且是基于某个准则（我们在下一章会讲到）来得到合适的区间划分。这样的划分是可以的，但这属于建模，而非数据预处理。</p>
<p>下面总结一下通常情况下得到技术上正确的数据（对数据进行必要的清理，格式变换后，可以顺利用R读入成数据框时，就是技术上正确的数据）后需要经历的数据预处理流程：</p>
<ol style="list-style-type: decimal">
<li>检查数据：变量分布，是不是存在错误的观测</li>
<li>缺失值填补：了解缺失原因，选择填补方式</li>
<li>数据变换：取决于需要建立的模型，对不符合正态分布假设，变量尺度差异大，有离群值的数据进行变换</li>
<li>检查共线性：找到高度线性相关的变量，决定删除变量，还是使用PCA，CFA这类非监督方法得到不相关的变量线性组合</li>
<li>稀疏变量：查找并且删除稀疏变量</li>
<li>编码名义变量：对于不能作用于分类变量的模型，将分类变量转化成0/1名义变量</li>
</ol>
<p>最后我们介绍了一些数据整合和整形的方法，整合方法类似于excel中的透视表格，R中有一些功能强大的函数能够有效的进行各种数据整合。我们介绍了<code>base</code>包中的<code>apply()</code>函数，还有更加高级灵活的<code>plyr</code>包中<code>ddply()</code>函数的各种用法。由于实际工作中大部分时间是处理数据框，所以这里我们介绍了<code>plyr</code>包的一个专门针对数据框的强化包<code>dplyr</code>。该包对于数据的整合非常高效。对于数据的整形（长型数据和宽型数据的转换），我们举例说明了由于模型需要将数据从宽型转化成长型的情况，并且用<code>reshape2</code>包实现了该过程。此外我们还介绍了另外一个数据整形的包<code>tidyr</code>。这两个包相较于数据整合的那几个包而言更难理解，大家需要多花些时间熟悉其中的操作。得到可以用于模型的数据后，接下来就该进入建模阶段了。</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-impute1">
<p>Ton de Waal, Sander Scholtus, Jeroen Pannekoek. 2011. <em>Handbook of Statistical Data Editing and Imputation</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-pca1">
<p>Jolliffe, I.T. 2002. <em>Principla Component Analysis</em>. 2nd ed. New York: Springer.</p>
</div>
<div id="ref-PLS1">
<p>Geladi P, Kowalski B. 1986. “Partial Least-Squares Regression: A Tutorial.” <em>Analytica Chimica Acta</em>, no. 185: 1–17.</p>
</div>
<div id="ref-EFA1">
<p>Mulaik, S.A. 2009. <em>Foundations of Factor Analysis</em>. 2ND ed. Boca Raton: Chapman&amp;Hall/CRC.</p>
</div>
<div id="ref-BOXCOX1">
<p>Box G, Cox D. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> Series B (Methodological): 211–52.</p>
</div>
<div id="ref-mad1">
<p>Iglewicz, Boris, and David Hoaglin. 1993. “How to Detect and Handle Outliers.” <em>The ASQC Basic References in Quality Control: Statistical Techniques</em> 16.</p>
</div>
<div id="ref-ssp">
<p>Serneels S, Espen PV, Nolf ED. 2006. “Spatial Sign Pre-Processing: A Simple Way to Impart Moderate Robustness to Multivariate Estimators.” <em>Journal of Chemical Information and Modeling</em> 46 (3): 1402–9.</p>
</div>
<div id="ref-APM">
<p>Kjell Johnston, Max Kuhn &amp;. 2013. <em>Applied Predictive Modeling</em>. Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-6.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-yuchuli.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
