<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is my first book on data science">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my first book on data science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is my first book on data science" />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-10-06">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-10.html">
<link rel="next" href="section-12.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 数据整合</a><ul>
<li class="chapter" data-level="6.1.1" data-path="section-6.html"><a href="section-6.html#baseapply"><i class="fa fa-check"></i><b>6.1.1</b> base包：apply()</a></li>
<li class="chapter" data-level="6.1.2" data-path="section-6.html"><a href="section-6.html#plyrddply"><i class="fa fa-check"></i><b>6.1.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="6.1.3" data-path="section-6.html"><a href="section-6.html#dplyr"><i class="fa fa-check"></i><b>6.1.3</b> dplyr包</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 数据整形</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#reshape2"><i class="fa fa-check"></i><b>6.2.1</b> <code>reshape2</code>包</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#tidyr"><i class="fa fa-check"></i><b>6.2.2</b> <code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>6.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 基础建模技术</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="7.3.1" data-path="section-7.html"><a href="section-7.html#section-7.3.1"><i class="fa fa-check"></i><b>7.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="7.3.2" data-path="section-7.html"><a href="section-7.html#section-7.3.2"><i class="fa fa-check"></i><b>7.3.2</b> 重抽样</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#-2"><i class="fa fa-check"></i><b>7.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 模型评估度量</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 回归模型评估度量</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 分类模型评估度量</a><ul>
<li class="chapter" data-level="8.2.1" data-path="section-8.html"><a href="section-8.html#kappa"><i class="fa fa-check"></i><b>8.2.1</b> Kappa统计量</a></li>
<li class="chapter" data-level="8.2.2" data-path="section-8.html"><a href="section-8.html#roc"><i class="fa fa-check"></i><b>8.2.2</b> ROC曲线</a></li>
<li class="chapter" data-level="8.2.3" data-path="section-8.html"><a href="section-8.html#section-8.2.3"><i class="fa fa-check"></i><b>8.2.3</b> 提升图</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#-3"><i class="fa fa-check"></i><b>8.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 特征工程</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 特征构建</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 特征提取</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 初步探索数据</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 主成分分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 探索性因子分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 高维标度化</a></li>
<li class="chapter" data-level="9.2.5" data-path="section-9.html"><a href="section-9.html#section-9.2.5"><i class="fa fa-check"></i><b>9.2.5</b> 知识扩展</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 特征选择</a><ul>
<li class="chapter" data-level="9.3.1" data-path="section-9.html"><a href="section-9.html#section-9.3.1"><i class="fa fa-check"></i><b>9.3.1</b> 过滤法</a></li>
<li class="chapter" data-level="9.3.2" data-path="section-9.html"><a href="section-9.html#section-9.3.2"><i class="fa fa-check"></i><b>9.3.2</b> 绕封法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="10.1.2" data-path="section-10.html"><a href="section-10.html#section-10.1.2"><i class="fa fa-check"></i><b>10.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="10.1.3" data-path="section-10.html"><a href="section-10.html#section-10.1.3"><i class="fa fa-check"></i><b>10.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 收缩方法</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 岭回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.2.2</b> Lasso</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 弹性网络</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#lasso"><i class="fa fa-check"></i><b>10.3</b> 知识扩展：Lasso的变量选择功能</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> 主成分和偏最小二乘回归</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="glmnet.html"><a href="glmnet.html"><i class="fa fa-check"></i><b>11</b> 广义线性模型压缩方法及<code>glmnet</code>包</a><ul>
<li class="chapter" data-level="11.1" data-path="glmnet.html"><a href="glmnet.html#glmnet"><i class="fa fa-check"></i><b>11.1</b> 初识<code>glmnet</code></a></li>
<li class="chapter" data-level="11.2" data-path="glmnet.html"><a href="glmnet.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 线性回归</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#section-12.1"><i class="fa fa-check"></i><b>12.1</b> 聚类分析</a></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#section-12.2"><i class="fa fa-check"></i><b>12.2</b> 判别分析</a><ul>
<li class="chapter" data-level="12.2.1" data-path="section-12.html"><a href="section-12.html#section-12.2.1"><i class="fa fa-check"></i><b>12.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="12.2.2" data-path="section-12.html"><a href="section-12.html#section-12.2.2"><i class="fa fa-check"></i><b>12.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="12.2.3" data-path="section-12.html"><a href="section-12.html#section-12.2.3"><i class="fa fa-check"></i><b>12.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="12.2.4" data-path="section-12.html"><a href="section-12.html#section-12.2.4"><i class="fa fa-check"></i><b>12.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="section-12.html"><a href="section-12.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 树模型</a><ul>
<li class="chapter" data-level="13.1" data-path="section-13.html"><a href="section-13.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 分裂准则</a></li>
<li class="chapter" data-level="13.2" data-path="section-13.html"><a href="section-13.html#section-13.2"><i class="fa fa-check"></i><b>13.2</b> 树模型的参数</a></li>
<li class="chapter" data-level="13.3" data-path="section-13.html"><a href="section-13.html#section-13.3"><i class="fa fa-check"></i><b>13.3</b> 装袋树</a></li>
<li class="chapter" data-level="13.4" data-path="section-13.html"><a href="section-13.html#section-13.4"><i class="fa fa-check"></i><b>13.4</b> 随机森林</a></li>
<li class="chapter" data-level="13.5" data-path="section-13.html"><a href="section-13.html#section-13.5"><i class="fa fa-check"></i><b>13.5</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-14.html"><a href="section-14.html"><i class="fa fa-check"></i><b>14</b> 深度学习</a><ul>
<li class="chapter" data-level="14.1" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>14.1</b> 介绍</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glmnet" class="section level1">
<h1><span class="header-section-number">第11章</span> 广义线性模型压缩方法及<code>glmnet</code>包</h1>
<p>之前只是对线性回归使用罚函数。不难理解，这样的罚函数可以用于很多其它回回归函数的优化上，比如逻辑回归，泊松回归等。<code>glmnet</code>包能够通过<strong>罚极大似然函数</strong>拟合广义线性回归，也就是在似然函数上加上罚函数，和之间在RSS上加罚函数类似。之前的线性回归的情况是广义线性回归的一个特例。和之前一样，罚函数的选择可以是一阶范数和二阶范数的一个组合。<code>glmnet</code>包可以对一系列调优参数值同时计算参数估计。除了线性回归外，该包可以拟合的广义线性模型还有：逻辑回归、多项式回归，泊松回归，cox回归。<code>glmnet</code>包的作者是Jerome Friedman、Trevor Hastie、Rob Tibshirani和Noah Simon，当前的R包由Trevor Hastie维护。该包还有一个matlab版本。</p>
<p>广义线性模型压缩方法可以表达成优化下面方程：</p>
<p><span class="math display">\[\underset{\beta_{0},\mathbf{\beta}}{min}\frac{1}{N}\Sigma_{i=1}^{N}w_{i}l(y_{i},\beta_{0}+\mathbf{\beta^{T}x_{i}})+\lambda[(1-\alpha)\parallel\mathbf{\beta}\parallel_{2}^{2}/2+\alpha\parallel\mathbf{\beta}\parallel_{1}]\]</span></p>
<p>其中需要对一定范围内的<span class="math inline">\(\lambda\)</span>值进行调优。其中：</p>
<p><span class="math display">\[l(y_{i},\beta_{0}+\mathbf{\beta^{T}x_{i}})=-log[\mathcal{L}(y_{i},\beta_{0}+\mathbf{\beta^{T}x_{i}})]\]</span></p>
<p>也就是似然函数<span class="math inline">\(\mathcal{L}(y_{i},\beta_{0}+\mathbf{\beta^{T}x_{i}})\)</span>取对数后再加负号，最大化似然函数即等价于最小化<span class="math inline">\(l(y_{i},\beta_{0}+\mathbf{\beta^{T}x_{i}})\)</span>。参数<span class="math inline">\(\alpha\)</span>控制了弹性网络罚函数，即在岭回归（<span class="math inline">\(\alpha=0\)</span>）和lasso（<span class="math inline">\(\alpha=1\)</span>）之间权衡。<span class="math inline">\(\lambda\)</span>控制了罚函数的总体权重，其值越大，罚函数相对于似然函数的权重越高。</p>
<p>之前我们已经讲过，岭回归的罚函数能够将参数估计向0收缩，但是不能收缩为0。而lasso的罚函数能够将参数严格收缩为0，因而具有变量选择功能。弹性网络的罚函数结合了这两者。这里的<span class="math inline">\(\alpha\)</span>也是需要估计的参数。<code>glmnet</code>包使用的是循环坐标下降法（cyclical coordinate descent），这是一种非梯度优化算法。算法每次针对一个参数优化目标方程，固定所有其它参数，然后转向另外一个参数，如此循环直到收敛。</p>
<div id="glmnet" class="section level2">
<h2><span class="header-section-number">11.1</span> 初识<code>glmnet</code></h2>
<p>在介绍具体不同的广义线性模型压缩方法之前，先让大家熟悉一下这个R包的基本使用方式。我会简单的介绍下其中的主要函数，功能，和输出。这样大家对这个包能做什么有个大致的概念。后面的小节会分别介绍不同模型。</p>
<p>默认设置下的模型是高斯线性回归或者最小二乘模型，也就是之前几个小节介绍的模型，只是参数化的方式略有不同，但都是RSS加上一个罚函数。所以我们还是从之前服装消费者数据集中的自变量和应变量开始：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(glmnet)
dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)
<span class="co"># 对数据进行一些清理，删除错误的样本观测，消费金额不能为负数</span>
dat&lt;-<span class="kw">subset</span>(dat,store_exp&gt;<span class="dv">0</span> &amp;<span class="st"> </span>online_exp&gt;<span class="dv">0</span>)
<span class="co"># 将10个问卷调查变量当作自变量</span>
trainx&lt;-dat[,<span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>,<span class="kw">names</span>(dat))]
<span class="co"># 将实体店消费量和在线消费之和当作应变量</span>
<span class="co"># 得到总消费量=实体店消费+在线消费</span>
trainy&lt;-dat$store_exp+dat$online_exp</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glmfit=<span class="kw">glmnet</span>(<span class="kw">as.matrix</span>(trainx),trainy)</code></pre></div>
<p>这里函数<code>glmnet()</code>返回的对象<code>glmfit</code>中含有所有之后可能进一步会用到的模型拟合信息。大家并不需要手动的检查<code>glmfit</code>中都有那些信息，然后提取相应的部分，而是可以通过<code>plot()</code>、<code>coef()</code>、<code>predict()</code>这类耳熟能详的函数来得到相应的信息。比如我们可以用如下方式绘制lasso的参数选择路径图：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(glmfit,<span class="dt">label=</span>T)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-189-1.png" width="672" /></p>
<p>图中每种颜色的线代表对应一个自变量，展示的是随着lasso罚函数（也就是一阶范数，有时也称为<span class="math inline">\(l_{1}-norm\)</span>）对应调优参数<span class="math inline">\(\lambda\)</span>变化，各个变量对应的参数估计路径（注：当<span class="math inline">\(\alpha=1\)</span>时，优化方程里就只有lasso罚函数）。图中有上下两个x轴标度，下x轴是<span class="math inline">\(\lambda\)</span>变化对应最优解的一阶范数值（也就是<span class="math inline">\(\parallel\mathbf{\beta}\parallel_{1}\)</span>），上x轴是相应<span class="math inline">\(\lambda\)</span>值对应的非0参数估计个数，也就是lasso模型的自由度。我们可以查看路径的具体每一步信息：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(glmfit)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode html"><code class="sourceCode html">Call:  glmnet(x = as.matrix(trainx), y = trainy) 

      Df   %Dev   Lambda
 [1,]  0 0.0000 3042.000
 [2,]  2 0.1038 2771.000
 [3,]  2 0.1919 2525.000
 [4,]  2 0.2650 2301.000
 [5,]  3 0.3264 2096.000
 [6,]  3 0.3894 1910.000
 [7,]  3 0.4417 1741.000
 [8,]  3 0.4852 1586.000
 [9,]  3 0.5212 1445.000
[10,]  3 0.5512 1317.000
[11,]  3 0.5760 1200.000
[12,]  3 0.5967 1093.000
[13,]  3 0.6138  996.000
[14,]  3 0.6280  907.500
...</code></pre></div>
<p>这里第一列<code>Df</code>表示非零估计的参数个数，<code>%Dev</code>解释的方差百分比，以及<code>Lambda</code>调优参数<span class="math inline">\(\lambda\)</span>的取值。虽然在默认设置下，glmnet会尝试100个不同的<span class="math inline">\(\lambda\)</span>取值，但如果随着<span class="math inline">\(\lambda\)</span>的减小，<code>%Dev</code>百分比只发生微小变化的时候，算法也会提前停止，上面的例子算法就只计算了68个不同的调优参数取值。我们也可以通过指定一个<span class="math inline">\(\lambda\)</span>的取值来得到对应的参数估计，其中<code>s=</code>用来指定调优参数值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(glmfit,<span class="dt">s=</span><span class="dv">1200</span>)</code></pre></div>
<pre><code>## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept) 2255.2221
## Q1          -390.9214
## Q2           653.6437
## Q3           624.4068
## Q4             .     
## Q5             .     
## Q6             .     
## Q7             .     
## Q8             .     
## Q9             .     
## Q10            .</code></pre>
<p>在<span class="math inline">\(\lambda=1200\)</span>时，只有3个变量（<code>Q1</code>、<code>Q2</code>和<code>Q3</code>）的参数估计非0。你也可以用新数据对一个或多个<span class="math inline">\(\lambda\)</span>值进行预测。我们随机抽取3个观测作为新数据，然后用<code>predict()</code>函数得到针对多个<span class="math inline">\(\lambda\)</span>值的预测：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newdat=<span class="kw">matrix</span>(<span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">9</span>,<span class="dv">30</span>,<span class="dt">replace =</span> T),<span class="dt">nrow=</span><span class="dv">3</span>)
<span class="kw">predict</span>(glmfit,newdat,<span class="dt">s=</span><span class="kw">c</span>(<span class="dv">1741</span>,<span class="dv">2000</span>))</code></pre></div>
<pre><code>##             1        2
## [1,] 3337.144 3394.986
## [2,] 6559.382 6186.969
## [3,] 6831.266 6765.357</code></pre>
<p>结果中每列分别对应一个<span class="math inline">\(\lambda\)</span>取值的预测。这里需要通过交互校验进行参数（<span class="math inline">\(\lambda\)</span>）调优。<code>glmnet</code>包中的<code>cv.glmnet()</code>可以实现这一目标。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvfit=<span class="kw">cv.glmnet</span>(<span class="kw">as.matrix</span>(trainx),trainy)</code></pre></div>
<p><code>cv.glmnet()</code>会返回一个列表，其中包括交互校验过程的结果，我们将该结果存在<code>cvfit</code>这个对象里。 我们可以对交互校验结果可视化：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(cvfit)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-193-1.png" width="672" /></p>
<p>红色的点是不同<span class="math inline">\(\lambda\)</span>取值对应的交互校验均方误差，灰色的线是相应置信区间。两条虚线表示选中的两个调优参数。左边的那个调优参数值对应的是最小的交互校验均方误差，右边的那个调优参数值是离最小均方误差一个标准差的调优参数值。我们可以通过下面代码查看根据两种不同规则选中的调优参数值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 最小均方误差对应的参数值</span>
cvfit$lambda.min</code></pre></div>
<pre><code>## [1] 7.893144</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 一个标准差原则下对应的参数值</span>
cvfit$lambda.1se</code></pre></div>
<pre><code>## [1] 1199.688</code></pre>
<p>我们也可以按如下方式查看不同调优参数值对应的回归参数（注意这里不是调优参数估计）估计：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 一个标准差原则下对应的回归参数估计</span>
<span class="kw">coef</span>(cvfit,<span class="dt">s=</span><span class="st">&quot;lambda.1se&quot;</span>)</code></pre></div>
<pre><code>## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept) 2255.3136
## Q1          -391.0562
## Q2           653.7079
## Q3           624.5119
## Q4             .     
## Q5             .     
## Q6             .     
## Q7             .     
## Q8             .     
## Q9             .     
## Q10            .</code></pre>
</div>
<div id="section-11.2" class="section level2">
<h2><span class="header-section-number">11.2</span> 线性回归</h2>
<p>普通线性回归是广义线性回归框架下的一种特殊情况。这里将要介绍的是之前章节中线性回归的收缩方法的另外一种实现方式。之后我们会介绍广义框架下更多模型的收缩方法：逻辑回归，多项回归和泊松回归。</p>
<p>线性回归有两种，一种是我们已经介绍过的属于高斯（<code>gaussian</code>）家族的模型，其中应变量是一个向量。另外一种是多元高斯（<code>multivariate gaussian</code>），也就是多元响应变量的情况，这时应变量是一个矩阵，参数也是矩阵。我们着重介绍用<code>glmnet</code>包实现普通高斯收缩回归。</p>
<p>假定自变量观测<span class="math inline">\(\mathbf{x_{i}}\in \mathbb{R}^{p}\)</span>，应变量<span class="math inline">\(y_{i} \in \mathbb{R},\ i=1,\dots,n\)</span>。这里的收缩线性回归目标是找到能够优化下面方程的参数估计，这和前一章参数化的方式略有不同，但本质是相同的：</p>
<p><span class="math display">\[\underset{(\beta_{0},\mathbf{\beta})\in \mathbb{R}^{p+1}}{min}\frac{1}{2n}\Sigma_{i=1}^{n}(y_{i}-\beta_{0}-\mathbf{x_{i}^{T} \beta)}^2+\lambda [(1-\alpha)]\Vert\beta\Vert_2^2/2+\alpha\Vert\beta\Vert_1\]</span> 其中<span class="math inline">\(\lambda&gt;0\)</span>是总体的复杂度参数，<span class="math inline">\(0\leq\alpha\leq1\)</span>是权衡lasso（<span class="math inline">\(\alpha=1\)</span>）和ridge（<span class="math inline">\(\alpha=0\)</span>）罚函数的参数。<code>glmnet</code>提供了定义各种参数设置的选项。下面是一些通常需要用到的参数设置：</p>
<ul>
<li><p><code>alpha</code>：上面优化函数中的<span class="math inline">\(\alpha\)</span>，默认设置是<span class="math inline">\(\alpha=1\)</span>，也就是lasso回归，你可以将其设置为0进行岭回归。<span class="math inline">\(\alpha\in[0,1]\)</span>。</p></li>
<li><p><code>weights</code>： 每个观测的权重，默认设置下每个观测的权重都是1，权重总和就是参数个数n。你也可以自定义每个观测的权重，但是<code>glmnet</code>包会自动将你设置的权重标准化，使得权重之和总是n。</p></li>
<li><p><code>nlambda</code>：调优参数<span class="math inline">\(\lambda\)</span>的取值个数，默认设置是100。函数会自行生成一个含有<code>nlambda</code>个<span class="math inline">\(\lambda\)</span>取值的向量进行调优。这些值的选取基于两个量：<code>lambda.max</code>和<code>lambda.min.ratio</code>。前者是最大的lambda值，在<span class="math inline">\(\alpha\)</span>不为0的情况下，一阶范数罚<span class="math inline">\(\Vert\beta\Vert_1\)</span>使得存在一个<span class="math inline">\(\lambda\)</span>取值时所有的参数估计都收缩为0，也就是模型中只有截距项。这个取值就是<code>lambda.max</code>。当<span class="math inline">\(\alpha＝0\)</span>的时候，<code>lambda.max</code>将是无穷大，因此在这种情况下，函数会自动选择一个很小的<span class="math inline">\(\alpha\)</span>值用来计算<code>lambda.max</code>。具体背后的数学原理，可以参考上一章的“知识扩展：Lasso的变量选择功能”小节。<code>lambda.min.ratio</code>是向量中最小的<span class="math inline">\(\lambda\)</span>取值与最大<span class="math inline">\(\lambda\)</span>取值的比例。如果<code>lambda.min.ratio＝0</code>，表明调优参数<span class="math inline">\(\lambda\)</span>的取值向量分布从0到<code>lambda.max</code>。</p></li>
<li><p><code>lambda</code>：如果不用设定<code>nlambda</code>的方式，你也可以通过设定<code>lambda</code>这个参数自己定义调优参数值向量。</p></li>
<li><p><code>standardize</code>：用来告诉函数是否标准化自变量的逻辑值。默认设置为<code>standardize=TRUE</code>。</p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-10.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-12.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/11-glmnet.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
