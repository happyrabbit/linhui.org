<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.0.72 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-06-08">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-9.html">
<link rel="next" href="section-11.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="5.10.1" data-path="section-5.html"><a href="section-5.html#baseapply"><i class="fa fa-check"></i><b>5.10.1</b> base包：apply()</a></li>
<li class="chapter" data-level="5.10.2" data-path="section-5.html"><a href="section-5.html#plyrddply"><i class="fa fa-check"></i><b>5.10.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="5.10.3" data-path="section-5.html"><a href="section-5.html#dplyr"><i class="fa fa-check"></i><b>5.10.3</b> dplyr包</a></li>
<li class="chapter" data-level="5.10.4" data-path="section-5.html"><a href="section-5.html#section-5.10.4"><i class="fa fa-check"></i><b>5.10.4</b> 数据整形</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="section-5.html"><a href="section-5.html#section-5.11"><i class="fa fa-check"></i><b>5.11</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 建模技术简介</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#section-6.2.1"><i class="fa fa-check"></i><b>6.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#section-6.2.2"><i class="fa fa-check"></i><b>6.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#section-6.2.3"><i class="fa fa-check"></i><b>6.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#section-6.3.1"><i class="fa fa-check"></i><b>6.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#section-6.3.2"><i class="fa fa-check"></i><b>6.3.2</b> 重抽样</a></li>
<li class="chapter" data-level="6.3.3" data-path="section-6.html"><a href="section-6.html#section-6.3.3"><i class="fa fa-check"></i><b>6.3.3</b> 评估模型表现</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 特征工程</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 特征构建</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 特征提取</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 主成分分析</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 因子分析</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 高维标度化</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 变量选择</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="8.1.1" data-path="section-8.html"><a href="section-8.html#section-8.1.1"><i class="fa fa-check"></i><b>8.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="8.1.2" data-path="section-8.html"><a href="section-8.html#section-8.1.2"><i class="fa fa-check"></i><b>8.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="8.1.3" data-path="section-8.html"><a href="section-8.html#section-8.1.3"><i class="fa fa-check"></i><b>8.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 收缩方法</a></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> 分层线性回归</a></li>
<li class="chapter" data-level="8.4" data-path="section-8.html"><a href="section-8.html#section-8.4"><i class="fa fa-check"></i><b>8.4</b> 贝叶斯线性回归</a></li>
<li class="chapter" data-level="8.5" data-path="section-8.html"><a href="section-8.html#section-8.5"><i class="fa fa-check"></i><b>8.5</b> 贝叶斯分层线性回归</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 树模型</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 基本树模型</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 装袋树</a></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 随机森林</a></li>
<li class="chapter" data-level="9.4" data-path="section-9.html"><a href="section-9.html#section-9.4"><i class="fa fa-check"></i><b>9.4</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 聚类分析</a></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 判别分析</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-10.html"><a href="section-10.html#section-10.2.1"><i class="fa fa-check"></i><b>10.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-10.html"><a href="section-10.html#section-10.2.2"><i class="fa fa-check"></i><b>10.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-10.html"><a href="section-10.html#section-10.2.3"><i class="fa fa-check"></i><b>10.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-10.html"><a href="section-10.html#section-10.2.4"><i class="fa fa-check"></i><b>10.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 关联法则分析</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 关联法则简介</a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 案例：商业购物篮分析</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 关联法则可视化</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 数据可视化和结果展示</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#r-markdown"><i class="fa fa-check"></i><b>12.1</b> R Markdown</a><ul>
<li class="chapter" data-level="12.1.1" data-path="section-12.html"><a href="section-12.html#r-markdown"><i class="fa fa-check"></i><b>12.1.1</b> 什么是R Markdown?</a></li>
<li class="chapter" data-level="12.1.2" data-path="section-12.html"><a href="section-12.html#how-to-start"><i class="fa fa-check"></i><b>12.1.2</b> How to Start?</a></li>
<li class="chapter" data-level="12.1.3" data-path="section-12.html"><a href="section-12.html#interactive-r-markdown-document"><i class="fa fa-check"></i><b>12.1.3</b> Interactive R Markdown Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 数据科学的科学</a></li>
<li class="chapter" data-level="14" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-10" class="section level1">
<h1><span class="header-section-number">第10章</span> 聚类判别分析</h1>
<div id="section-10.1" class="section level2">
<h2><span class="header-section-number">10.1</span> 聚类分析</h2>
<p>聚类是无监督学习，主要着眼于梳理数据结构。林林总总的聚类方法的目的都是将数据划分成不同的部分（类），使得同一类的观测尽可能相似，不同类的样本尽可能相异。 What makes clustering different from supervised learning is that there is no number or name that tells you what group each point belongs to, what the groups represent, or even how many groups there should be. If supervised learning is picking out planets from among the stars in the night sky, then clustering is inventing constellations. Clustering tries to separate out data into natural “clumps,” so that a human analyst can more easily interpret it and explain it to others.</p>
<p>Clustering always relies on a definition of closeness or similarity, called a distance metric. The distance metric can be any measurable quantity, such as difference in IQ, number of shared genetic base pairs, or miles-as-the-crow-flies. Clustering questions all try to break data into more nearly uniform groups.</p>
<p>Which shoppers have similar tastes in produce? Which viewers like the same kind of movies? Which printer models fail the same way? During which days of the week does this electrical substation have similar electrical power demands? What is a natural way to break these documents into five topic groups?</p>
</div>
<div id="section-10.2" class="section level2">
<h2><span class="header-section-number">10.2</span> 判别分析</h2>
<div id="section-10.2.1" class="section level3">
<h3><span class="header-section-number">10.2.1</span> 逻辑回归</h3>
<div id="section-10.2.1.1" class="section level4">
<h4><span class="header-section-number">10.2.1.1</span> 普通逻辑回归</h4>
</div>
<div id="lasso" class="section level4">
<h4><span class="header-section-number">10.2.1.2</span> LASSO逻辑回归</h4>
</div>
<div id="lasso" class="section level4">
<h4><span class="header-section-number">10.2.1.3</span> 分组LASSO逻辑回归</h4>
</div>
<div id="section-10.2.1.4" class="section level4">
<h4><span class="header-section-number">10.2.1.4</span> 疾病预测案例</h4>
<p>Risk scoring systems for predicting disease are widely used in medicine. Such scoring systems are usually derived from multivariate logistic regression models with disease as the response variable. Typical approaches in the literature select potential explanatory variables (risk factors) based on variable significance , with risk scores of selected variables assigned based on estimated regression coefficients . However, when the number of potential explanatory variables is large, such approaches may fail to produce a risk scoring system with the greatest power for predicting disease.</p>
<p>This paper is motivated by the need to develop a risk scoring system for porcine reproductive and respiratory syndrome (PRRS) based on survey data. PRRS, caused by the PRRS virus, is a major disease, production and financial problem for swine producers in nearly every country. PRRS costs the United States swine industry around $560 million annually . PRRS outbreaks in China caused pork prices to increase by 85 percent in 2006 . For breeding herds, costs of clinical outbreaks of PRRS result from lost production due to abortion, mummies, stillborns, pre-wean mortality and sow deaths and increased costs for treatment and control. Performance of observational studies to better understand the relative importance of risk factors for PRRS outbreaks have been limited by the availability of good data on a large set of farms over a relatively long period of time.</p>
<p>In human medicine, large datasets of information on risk factors, prevalence, incidence and clinical outcomes of disease are common. In veterinary medicine, until recently, there have been no parallel efforts to create epidemiological databases on a similar scale. The American Association of Swine Veterinarians (AASV) Production Animal Disease Risk Assessment Program (PADRAP) is a program through which a set of web-based risk assessment surveys are delivered(please visit: <a href="http://vdpambi.vdl.iastate.edu/padrap/default.aspx" class="uri">http://vdpambi.vdl.iastate.edu/padrap/default.aspx</a>). It is used by veterinarians who are members of the AASV. Each of the surveys consists of a set of questions about potential risk factors for clinical outbreaks of PRRS in swine. Each question may have up to 6 possible responses. Members of the AASV use PADRAP to help producers systematically assess biosecurity factors that may be associated with clinical outcomes. As assessments are performed by veterinarians they are added to the database of completed assessments.</p>
<p>Version 2 of the PRRS Risk Assessment for the Breeding Herd survey was introduced in 2005. The survey instrument was developed using expert opinion with the aid of the PRRS Risk Assessment Working Group composed of 21 veterinarians and researchers with expertise in PRRS. Initial estimates of the risk scores associated with each response were based on the consensus of expert opinion and equal weight is assigned to each question.</p>
<p>The aim of this study is to use the survey data that has been collected to develop a risk scoring system with 127 survey questions (categorical explanatory variables) that outperforms the current risk scoring system based on expert opinion when multivariate logistic regression is used in similar studies with variables selected by significance.  Quasi-complete-separation may result when there are a large number of explanatory variables which makes estimation of the coefficients unstable. To stabilize the estimation of parameter coefficients, one popular approach is the lasso algorithm with <span class="math inline">\(l_{1}\)</span>-norm penalty proposed by Tibshirani . Since the lasso algorithm can estimate some variable coefficients to be 0, it can also be used as a variable selection tool. For models with categorical survey questions (explanatory variables), however, original lasso algorithm only selects individual dummy variables instead of sets of the dummy variables grouped by question in the survey. Another disadvantage of applying lasso to grouped variables is that the estimates are affected by the way dummy variables are encoded. Thus the group lasso  method has been proposed to enable variable selection in linear regression models on groups of variables, instead of on single variables. For logistic regression models, the group lasso algorithm was first studied by<br />
Kim et al. . They proposed a gradient descent algorithm to solve the corresponding constrained problem, which does, however, depend on unknown constants. Meier et al.  proposed a new algorithm that could work directly on the penalized problem and its convergence property does not depend on unknown constants. The algorithm is especially suitable for high-dimensional problems. It can also be applied to solve the corresponding convex optimization problem in generalized linear models. The logistic group lasso involves selection of a penalty (tuning) parameter <span class="math inline">\(\lambda\)</span> which can be determined by cross-validation. The group lasso estimator proposed by Meier et al.  for logistic regression has been shown to be statistically consistent, even with large number of categorical predictors.</p>
<p>In this paper, we propose to use the logistic group lasso algorithm to construct risk scoring systems for predicting clinical PRRS outbreaks in swine herds. The paper is organized as follows. In Section 2, we introduce the group lasso method for logistic regression to construct risk scoring system for clinical PRRS outbreaks. The penalty parameter <span class="math inline">\(\lambda\)</span> for group lasso is selected through leave-one-out cross validation, using the criterion of the area under the receiver operating characteristic curve (AUC). Section 3 presents a simulation study to evaluate the performance of each method. In Section 4, we discuss the application to the PRRS survey data from 896 swine breeding herd sites in the United States and Canada. We show our scoring system for PRRS is superior to both the current scoring system based on expert opinion and that developed by using logistic regression with model selection based on variable significance. Finally results and conclusions presented in Section 5 and 6.</p>
</div>
<div id="models-for-risk-scoring-systems" class="section level4">
<h4><span class="header-section-number">10.2.1.5</span> Models for risk scoring systems</h4>
<p>Consider risk scoring system construction using a samples of <span class="math inline">\(n\)</span> observations, with information collected for <span class="math inline">\(G\)</span> categorical predictors and one binary response variable for each observation. Let <span class="math inline">\(\bx_{i,g}\)</span> be the vector of dummy variables associated with the <span class="math inline">\(g\)</span>th categorical predictor for the <span class="math inline">\(i\)</span>th observation, and let <span class="math inline">\(y_i\)</span> (= 1, diseased; or 0, not diseased) be the binary response for the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(i=1,\cdots,n\)</span>, <span class="math inline">\(g=1,\cdots,G\)</span>. Denote the degrees of freedom of the <span class="math inline">\(g\)</span>th predictor by <span class="math inline">\(df_g\)</span>, which is also the length of vector <span class="math inline">\(\bx_{i,g}\)</span>, <span class="math inline">\(i=1,\cdots,n\)</span>.</p>
</div>
<div id="multivariate-logistic-regression-model" class="section level4">
<h4><span class="header-section-number">10.2.1.6</span> Multivariate logistic regression model</h4>
<p>Multivariate logistic regression has been used to construct risk scoring systems for predicting disease . Denote the probability of disease for <span class="math inline">\(i\)</span>th subject by <span class="math inline">\(\theta_i\)</span>, the model can be formulated as</p>
\begin{equation}
y_{i}\sim Bounoulli(\theta_{i}),
\end{equation}
with
\begin{equation}
\log\left(\frac{\theta_{i}}{1-\theta_{i}}\right)=\eta_{\bbeta}(x_{i})=\beta_{0}+\sum_{g=1}^{G}\bx_{i,g}^{T}\bbeta_{g},
\end{equation}
<p>where <span class="math inline">\(\beta_{0}\)</span> is the intercept and <span class="math inline">\(\bbeta_{g}\)</span> is the parameter vector corresponding to the <span class="math inline">\(g\)</span>th predictor.</p>
Construction of risk scoring systems using logistic regression usually consists of two steps: selection among the <span class="math inline">\(G\)</span> risk factors, and estimation of the selected factor parameters. For model selection, significance has been used as a criterion for inclusion and exclusion of risk factors . Some researchers use univariate logistic regression to screen factors by significance before putting them into a multivariate logistic regression model , whereas others  don’t. Traditional estimation of logistic parameters <span class="math inline">\(\bbeta=(\beta_{0}^{T},\bbeta_{1}^{T},\bbeta_{2}^{T},...,\bbeta_{G}^{T})^{T}\)</span> is done through maximizing the log-likelihood
\begin{eqnarray*}
l(\bbeta)&amp;=&amp;log[\prod_{i=1}^{n}\theta_{i}^{y_{i}}(1-\theta_{i})^{1-y_{i}}]\\
&amp;=&amp;\sum_{i=1}^{n}\{y_{i}log(\theta_{i})+(1-y_{i})log(1-\theta_{i})\}\\
&amp;=&amp;\sum_{i=1}^{n}\{\ y_{i}\eta_{\bbeta}(\bx_{i})-log[1+exp(\eta_{\bbeta}(\bx_{i}))]\ \}.
\end{eqnarray*}
<p>For logistic regression analysis with a large number of explanatory variables, complete- or quasi-complete-separation may result which makes the maximum likelihood estimation unstable.</p>
</div>
<div id="group-lasso-for-logistic-regression" class="section level4">
<h4><span class="header-section-number">10.2.1.7</span> Group lasso for logistic regression}</h4>
<p>In this paper, we propose to perform model selection and parameter estimation for risk scoring system construction by using the group lasso algorithm of Meier et al. . Instead of minimizing the negative log-likelihood <span class="math inline">\(-l(\bbeta)\)</span> in the maximum likelihood method, the logistic group lasso estimates are calculated by minimizing the covex function</p>
\begin{equation}
S_{\lambda}(\beta)=-l(\bbeta)+\lambda\sum_{g=1}^{G}s(df_{g})\parallel\bbeta_{g}\parallel_{2},
\end{equation}
<p>where <span class="math inline">\(\lambda\)</span> is a tuning parameter for the penalty and <span class="math inline">\(s(\cdot)\)</span> is a function to rescale the penalty. In lasso algorithms, choice of <span class="math inline">\(\lambda\)</span> is usually determined by cross-validation using data. For <span class="math inline">\(s(\cdot)\)</span>, we use the square root function <span class="math inline">\(s(df_g)=df_g^{0.5}\)</span> as suggested in Meier et al. .</p>
<p>%### Choosing <span class="math inline">\(\lambda\)</span> through leave-one-out cross validation}</p>
<p>Here we consider selection of the tuning parameter <span class="math inline">\(\lambda\)</span> from a multiplicative grid of 148 values <span class="math inline">\(\{0.96\lambda_{max},0.96^{2}\lambda_{max},0.96^{3}\lambda_{max},...,0.96^{148}\lambda_{max}\}\)</span>, as in Meier et al. . Here <span class="math inline">\(\lambda_{max}\)</span> is defined as</p>
\begin{equation}
\lambda_{max}=\underset{g\in\{1,...,G\}}{max}\left\{\frac{1}{s(df_{g})}\parallel \bx_{g}^{T}(\by-\bar{\by})\parallel_{2}\right\},
\end{equation}
<p>such that when <span class="math inline">\(\lambda=\lambda_{max}\)</span>, only the intercept is in the model. When <span class="math inline">\(\lambda\)</span> goes to <span class="math inline">\(0\)</span>, the model is equivalent to regular logistic regression.</p>
<p>The optimal value of <span class="math inline">\(\lambda\)</span> is determined through leave-one-out cross validation, which is a special case of K-fold cross-validation with K being equal to <span class="math inline">\(n\)</span>, the number of observations in the sample. In each fold, leave-one-out cross validation uses a single observation from the original sample as the validation data, and the remaining observations as the training data. This step is repeated until each observation in the sample is used once as the validation data. Predicted probabilities of disease are calculated from cross-validation and are compared to true observed disease status to assess the predictive power of model.</p>
<p>In this paper, we assess the predictive power of each model through ROC analysis. ROC curve is a graph of pairs of the true positive rate (sensitivity) and false positive rate (1-specificity) that result as the cutoff value for the predicted probability of disease is varied. %The cutoff value varied in order from minimum to maximum of the resulted score. Theoretically, cutoff values can be any values on the real line. The practical cutoff values are determined from resulting scores based on our data. The value of AUC is used as the criterion to evaluate the predictive power of the logistic model. AUC as well as the confidence interval are estimated through the approach proposed by DeLong et al. . The AUC can be interpreted as the probability that a random diseased individual has larger predicted probability of disease than a random non-diseased individual  and it has been used to assess predictive power of risk scoring systems . We calculate the AUCs for cross-validations of all <span class="math inline">\(\lambda\)</span>s, and the value of <span class="math inline">\(\lambda\)</span> with the largest AUC is chosen as the <span class="math inline">\(\lambda\)</span> used in constructing the final scoring system.</p>
<p>Besides AUC, two other goodness-of-fit criteria for: the log-likelihood score used in Meier et al. , and the maximum correlation coefficient in Yeo and Burge  were also considered. The log-likelihood is taken as the average over all cross-validation sets. The maximum correlation coefficient is defined as</p>
\begin{equation}
\rho_{max}=max\{\rho_{\tau}|\tau\in(0,1)\},
\end{equation}
<p>where <span class="math inline">\(\tau\in(0,1)\)</span> is a threshold to classify the predicted probability into a binary disease status and <span class="math inline">\(\rho_\tau\)</span> is the Pearson correlation coefficient between the true binary disease status and the predictive disease status with threshold <span class="math inline">\(\tau\)</span>.</p>
\section{Simulation Study}
<p>A simulation study to %use simulation to demonstrate group lasso logistic regression and compare it to ordinary forward stepwise logistic regression is performed.</p>
\section{Application to PRRS Data}
<p>In this section, we apply the proposed method to construct a scoring system for PRRS survey data of swine breeding herd sites in the United States and Canada.</p>
</div>
<div id="data-description" class="section level4">
<h4><span class="header-section-number">10.2.1.8</span> Data Description</h4>
<p>Surveys in the database completed between March 2005 and March 2009 are candidates for inclusion in the analysis. To avoid multiple surveys from a single swine breeding herd site, the study dataset is limited to responses obtained from the most recently completed survey for each site. Surveys meeting these criteria are extracted from the database, and identity information is removed. Incomplete surveys are excluded.</p>
<p>%The outcome of interest is whether a breeding herd site reported %a clinical PRRS outbreak in the 3 years prior to when the assessment %was completed. The outcome of interest is whether a site is positive or not. Positive sites are sites with clinical PRRS outbreak in the 3 years prior to when the assessment was completed, negative sites otherwise. The information to determine the outcome was obtained from the survey. A clinical PRRS outbreak is described in the survey as an increase in one or more reproductive performance measures that exceeds normal variation with diagnostic confirmation of PRRS virus involvement.</p>
<p>Of the 896 sites in the United States and Canada included in the study, 499 (56%) became positive during the past 3 years. 127 survey questions are considered potential explanatory variables in the analysis. The survey questions are first converted to dummy indicator variables. All of the responses for each survey question are defined as a group of variables.</p>
</div>
<div id="application-of-logistic-group-lasso" class="section level4">
<h4><span class="header-section-number">10.2.1.9</span> Application of logistic group lasso</h4>
<p>First, leave-one-out cross validation is used to choose tuning parameter <span class="math inline">\(\lambda\)</span>, as described in Section 2.3. % In each fold of cross-validation, one of the 896 farms is excluded and the other 895 farms are used as a training data set on which the % group lasso logistic regression is applied. The resulting model is used to calculate a predicted probability for PRRS outbreak for the excluded farm. This procedure is repeated for all 896 farms.</p>
<p>For each <span class="math inline">\(\lambda\)</span> in the grid <span class="math inline">\(\{0.96\lambda_{max},0.96^{2}\lambda_{max},0.96^{3}\lambda_{max},...,0.96^{148}\lambda_{max}\}\)</span>, the values of three evaluation criteria are calculated based on cross validation. The penalty parameter for final risk scoring system is selected to be the one that optimizes AUC.</p>
<p>%### Comparison with other risk scoring systems}</p>
<p>The logistic group lasso based scoring system is compared with two other systems:</p>
\begin{enumerate}

\item The current risk scoring system used in versions 2 of the PRRS risk assessment for the breeding herd that is based on expert opinion,
\item A risk scoring system based on multivariate logistic regression model  selected by variable significance.

\end{enumerate}
<p>We construct the significance based logistic model by following the method used by Van Zee et al. . Specifically, we use forward stepwise variable selection to construct the logistic regression model with 0.05 significant level. Leave-one-out cross validation is applied to the model construction by variable significance, in the same manner as described for logistic group lasso.</p>
<p>ROC curves are plotted for the three risk scoring systems. A point estimate as well as the 95% confidence interval for the AUC are provided. The estimated AUCs are compared by using the nonparametric approach of DeLong et al.  and p-values are calculated.</p>
<p>R package {}``grplasso’’  is used to perform group lasso logistic regression. Significance-based logistic model selection is performed using the LOGISTIC procedure in SAS. All other algorithms and calculations are programmed in R language.</p>
</div>
<div id="determination-of-penalty-parameter-lambda" class="section level4">
<h4><span class="header-section-number">10.2.1.10</span> Determination of penalty parameter <span class="math inline">\(\lambda\)</span></h4>
<p>The AUC, maximum correlation coefficient and log-likelihood are calculated based on leave-one-out cross validation and are plotted against the penalty parameter <span class="math inline">\(\lambda\)</span> in Figure . The trends for all three criteria are similar with a sharp increase for small values of <span class="math inline">\(\lambda\)</span> and gradual decrease after reaching the maximum. The optimal values of <span class="math inline">\(\lambda\)</span> selected to maximize the three criteria are 11.72, 4.22 and 11.72 for AUC, maximum correlation coefficient and log-likelihood respectively.</p>
\begin{figure}
\resizebox*{15cm}{!}{\includegraphics{ThreeCri}}%
\caption{Three criteria for choice of penalty parameter $\lambda$}
\label{Flo:penalty}
\end{figure}
</div>
<div id="logistic-group-lasso-based-prrs-risk-scoring-system" class="section level4">
<h4><span class="header-section-number">10.2.1.11</span> Logistic group lasso based PRRS risk scoring system</h4>
<p>The penalty parameter maximizing AUC (i.e. <span class="math inline">\(\lambda=11.72\)</span>) from the leave-one-out cross validation is used for the group lasso estimation of the logistic regression parameters. Figure~ show the distributions of the predicted probabilities based on cross validation for both negative and positive farms. It can be observed that the predicted probability for positive farms is larger than that of negative farms in stochastic order. The actual risk score can take the value of the predicted probability, the linear predictor in the logistic regression model, or any strictly increasing function of the predicted probability. This is because the ROC curve for a predictor is invariate to such transformation.</p>
\begin{figure}
\resizebox*{15cm}{!}{\includegraphics{histograms}}%
\caption{Distributions of estimated probabilities for both negative and positive groups}
\label{histogram}
\end{figure}
In the resulting scoring system, 74 out of 127 survey questions are estimated with 0 coefficients and are excluded from the system. PADRAP questions target internal risks (bio-management of virus already present) and external risks (bio-exclusion of virus not present). A summary of the number of questions included in the final risk scoring system in each category of risk factors in the PRRS Risk Assessment for the Breeding Herd is shown in Table 1.
\begin{table}
\caption{Summary of number of questions in the final risk scoring system by category of risk factors }
\begin{center} \begin{tabular}{lrrrr} \hline Category of risk factors &amp; \multicolumn{2}{r}{Questions} &amp; \multicolumn{2}{r}{Dummy Variables}  \\ \hline INTERNAL RISKS &amp; Included &amp; Total &amp; Included &amp; Total \\ Circulation Risk &amp; &amp; &amp; &amp; \\ Characteristics of the herd &amp; 3 &amp; 4 &amp; 9 &amp; 11 \\ Characteristics of the site &amp; 0 &amp; 2 &amp; 0 &amp; 5 \\ Management practices &amp; 0 &amp; 2 &amp; 0 &amp; 9 \\--------- &amp;-------&amp;------&amp;------&amp;------\\
\textbf{\textit{Total}} &amp; \textbf{\textit{3}}  &amp; \textbf{\textit{8}} &amp; \textbf{\textit{9}} &amp; \textbf{\textit{25}}\\ &amp; &amp; &amp; &amp;

\\ EXTERNAL RISKS &amp; &amp; &amp; &amp; \\ Pig Related &amp; &amp; &amp; &amp; \\ Entry of replacement animals into the breeding herd &amp; 4 &amp; 12 &amp; 18 &amp; 40 \\ Entry of semen into the breeding herd &amp; 13 &amp; 31 &amp; 47 &amp; 104 \\ &amp; &amp; &amp; &amp; \\ Non-Pig Related &amp; &amp; &amp; &amp; \\ Transportation of live animals &amp; 13 &amp; 29 &amp; 38 &amp; 71 \\ Transportation of feed &amp; 1 &amp; 1 &amp; 2 &amp; 2 \\ Employee and service vehicles &amp; 1 &amp; 2 &amp; 3 &amp; 6 \\ Disposal of dead animals and waste management &amp; 2 &amp; 8 &amp; 3 &amp; 10 \\ Employees and visitors &amp; 5 &amp; 9 &amp; 15 &amp; 19 \\ Entry of supplies &amp; 1 &amp; 1 &amp; 3 &amp; 3 \\ Facilities &amp; 0 &amp; 4 &amp; 0 &amp; 11 \\ Biovectors &amp; 1 &amp; 1 &amp; 2 &amp; 1 \\ Density of pig farms in the area &amp; 3 &amp; 3 &amp; 10 &amp; 10 \\ Neighboring pig farms &amp; 3 &amp; 13 &amp; 12 &amp; 28 \\ Distance to pork industry infrastructure &amp; 2 &amp; 4 &amp; 5 &amp; 11 \\ Topography and forestation of surrounding area &amp; 1 &amp; 1 &amp; 3 &amp; 3 \\ --------- &amp;-------&amp;------&amp;------&amp;------\\
\textbf{\textit{Total}} &amp; \textbf{\textit{50}}  &amp; \textbf{\textit{119}} &amp; \textbf{\textit{161}} &amp;\textbf{\textit{319}}\\\hline \end{tabular} \end{center} 
\end{table}
<p>Three out of eight questions regarding internal risk factors remain in the scoring system, and they are all factors concerning characteristics of the herd. Fifty questions remain in external risk factor section out of the total 119 questions. %Sixty nine questions are excluded out of the external risk factors section and fifty remain. In the external risks section, all of the 14 categories have at least one question remaining in the final scoring system, except all 4 questions concerning facilities are excluded. Several categories have a large number of questions removed. In particular, 8 of 12 (66.7%) questions concerning entry of animals into the breeding herd, 18 of 31 (58.1%) questions concerning entry of semen into the breeding herd, 16 of 29 (55.2%) questions concerning transportation of live animals, and 10 of 13 (76.9%) questions concerning neighboring pig farms are excluded.</p>
</div>
<div id="comparison-among-risk-scoring-systems" class="section level4">
<h4><span class="header-section-number">10.2.1.12</span> Comparison among risk scoring systems</h4>
<p>The ROC curves for the three risk scoring systems are plotted in Figure . The ROC curves for the two scoring systems based on logistic regression analyses of the data are constructed using the results of leave-one-out cross validation. The ROC curve of logistic group lasso apparently dominates the other two scoring systems.</p>
\begin{figure}
\includegraphics{roc_plot_diff_model}
\caption{ROC curves for three risk scoring systems}
\label{ROC}
\end{figure}
<p>Point and 95% interval estimates of AUC are reported in Table 2. The risk scoring system based on the has the largest AUC = 0.848. This AUC estimate is significantly higher than those based on either expert opinion (AUC = 0.696, p-value <span class="math inline">\(&lt;\)</span> 0.001) or logistic regression model selected by variable significance (AUC = 0.807, p-value <span class="math inline">\(&lt;\)</span> 0.001).</p>
\begin{table}
\caption{AUC estimations for three risk scoring systems}
\begin{center} \begin{tabular}{lcc} \hline Model Names &amp; AUC &amp; 95\% CI \\ \hline Group Lasso &amp; 0.848 &amp; (0.822, 0.873) \\ Significance Based Method &amp; 0.807 &amp; (0.773, 0.841) \\ Expert Opinion &amp; 0.696 &amp; (0.661, 0.731) \\ \hline \end{tabular} \end{center}
\end{table}
<p>Results for the simulation study are shown in Table 3. The mean AUC is increasing with the value of <span class="math inline">\(\gamma\)</span> for both methods. The Wilcoxon signed-rank test result in the last column of Table 3 shows that AUC’s from group lasso are significant larger than those from logistic regression, especially for <span class="math inline">\(\gamma \geq 0.25\)</span>.</p>
<p></p>
\begin{table}
\caption{Simulation study result with various values of coefficient $\gamma$ with  mean and standard deviation for both method, mean difference and p value from Wilcox signed rank test }
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline 
Coefficient $\gamma$  &amp; Group Lasso (mean$\pm$sd ) &amp; Logistic Regression (mean$\pm$sd )  &amp; Difference  &amp; p value \tabularnewline
\hline 
0.1  &amp; $0.57\pm0.03$ &amp; $0.54\pm0.06$ &amp; $0.03$ &amp; $0.040$\tabularnewline
\hline 
0.25 &amp; $0.71\pm0.02$ &amp; $0.64\pm0.04$ &amp; $0.07$ &amp; $&lt;0.001$\tabularnewline
\hline 
0.5  &amp; $0.91\pm0.03$ &amp; $0.78\pm0.03$ &amp; $0.13$ &amp; $&lt;0.001$\tabularnewline
\hline 
1 &amp; $0.92\pm0.01$ &amp; $0.82\pm0.02$ &amp; $0.1$0 &amp; $&lt;0.001$\tabularnewline
\hline 
2 &amp; $0.95\pm0.01$ &amp; $0.84\pm0.02$ &amp; $0.11$ &amp; $&lt;0.001$\tabularnewline
\hline 
\end{tabular}
 \end{center}
\end{table}
</div>
<div id="discussion" class="section level4">
<h4><span class="header-section-number">10.2.1.13</span> Discussion</h4>
<p>The risk scoring system for disease developed using the logistic group lasso algorithm significantly improves upon the current risk scoring system based on expert opinion for predicting whether a swine breeding site experienced a PRRS outbreak. %We introduce the logistic group lasso algorithm to develop risk scoring systems for diseases. Choice of penalty parameter <span class="math inline">\(\lambda\)</span> is determined by leave-one-out cross validation with criterion %of AUC. %We apply our method to construct a new risk scoring system for PRRS outbreak in swine farms. Our scoring system significantly improves the current risk scoring system based on expert %opinion with respect to informing us about the contribution of certain category to the probability of outbreak. The simuation study explores the performance of the scoring systems with different settings of coefficients. The logistic group lasso based scoring system is superior to the scoring system constructed through logistic regression selected by variable significance.</p>
<p>One advantage of group lasso is that it can be used as variable selection tool by setting 0 coefficients to parameters. It not only helps to find important explanatory factors in predicting the response variables but also identifies questions that could be removed from the survey without affecting the survey’s ability for classifying herds according to whether they report clinical PRRS outbreaks in the previous 3 years.</p>
<p>Seventy-four of the 127 questions analyzed are excluded from the final risk scoring system based on logistic group lasso. The analysis and results demonstrate how a program like PADRAP, that is supported by a professional association and used by a community of veterinarians, can generate valuable data that contributes to our understanding of the relative importance of risk factors and areas of risk factors for clinical outcomes. The results may also be used to decrease the reliance upon expert opinion to identify questions that should remain in the survey and those that may be eliminated to iteratively increase the value of the program and the data.</p>
<p>关于100多种判别分析的选择。</p>
</div>
</div>
<div id="section-10.2.2" class="section level3">
<h3><span class="header-section-number">10.2.2</span> 线性判别分析</h3>
</div>
<div id="section-10.2.3" class="section level3">
<h3><span class="header-section-number">10.2.3</span> 最小二乘判别分析</h3>
</div>
<div id="section-10.2.4" class="section level3">
<h3><span class="header-section-number">10.2.4</span> 朴素贝叶斯</h3>
<p>朴素贝叶斯（Naive Bayes）是基于概率的判别法。</p>
</div>
</div>
<div id="section-10.3" class="section level2">
<h2><span class="header-section-number">10.3</span> 案例：客户分组</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-9.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-11.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-juleipanbie.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
