<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.0.72 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-07-13">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-9.html">
<link rel="next" href="section-11.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#readr"><i class="fa fa-check"></i><b>6.1</b> 高效数据读写：<code>readr</code>包</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 数据整合</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#baseapply"><i class="fa fa-check"></i><b>6.2.1</b> base包：apply()</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#plyrddply"><i class="fa fa-check"></i><b>6.2.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#dplyr"><i class="fa fa-check"></i><b>6.2.3</b> dplyr包</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据整形</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#reshape2"><i class="fa fa-check"></i><b>6.3.1</b> <code>reshape2</code>包</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#tidyr"><i class="fa fa-check"></i><b>6.3.2</b> <code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>6.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 基础建模技术</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="7.3.1" data-path="section-7.html"><a href="section-7.html#section-7.3.1"><i class="fa fa-check"></i><b>7.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="7.3.2" data-path="section-7.html"><a href="section-7.html#section-7.3.2"><i class="fa fa-check"></i><b>7.3.2</b> 重抽样</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#-2"><i class="fa fa-check"></i><b>7.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 模型评估度量</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 回归模型评估度量</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 分类模型评估度量</a><ul>
<li class="chapter" data-level="8.2.1" data-path="section-8.html"><a href="section-8.html#kappa"><i class="fa fa-check"></i><b>8.2.1</b> Kappa统计量</a></li>
<li class="chapter" data-level="8.2.2" data-path="section-8.html"><a href="section-8.html#roc"><i class="fa fa-check"></i><b>8.2.2</b> ROC曲线</a></li>
<li class="chapter" data-level="8.2.3" data-path="section-8.html"><a href="section-8.html#section-8.2.3"><i class="fa fa-check"></i><b>8.2.3</b> 提升图</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#-3"><i class="fa fa-check"></i><b>8.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 特征工程</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 特征构建</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 特征提取</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 初步探索数据</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 主成分分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 探索性因子分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 高维标度化</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 变量选择</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="10.1.2" data-path="section-10.html"><a href="section-10.html#section-10.1.2"><i class="fa fa-check"></i><b>10.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="10.1.3" data-path="section-10.html"><a href="section-10.html#section-10.1.3"><i class="fa fa-check"></i><b>10.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 收缩方法</a></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 分层线性回归</a></li>
<li class="chapter" data-level="10.4" data-path="section-10.html"><a href="section-10.html#section-10.4"><i class="fa fa-check"></i><b>10.4</b> 贝叶斯线性回归</a></li>
<li class="chapter" data-level="10.5" data-path="section-10.html"><a href="section-10.html#section-10.5"><i class="fa fa-check"></i><b>10.5</b> 贝叶斯分层线性回归</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 树模型</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 基本树模型</a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 装袋树</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 随机森林</a></li>
<li class="chapter" data-level="11.4" data-path="section-11.html"><a href="section-11.html#section-11.4"><i class="fa fa-check"></i><b>11.4</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#section-12.1"><i class="fa fa-check"></i><b>12.1</b> 聚类分析</a></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#section-12.2"><i class="fa fa-check"></i><b>12.2</b> 判别分析</a><ul>
<li class="chapter" data-level="12.2.1" data-path="section-12.html"><a href="section-12.html#section-12.2.1"><i class="fa fa-check"></i><b>12.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="12.2.2" data-path="section-12.html"><a href="section-12.html#section-12.2.2"><i class="fa fa-check"></i><b>12.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="12.2.3" data-path="section-12.html"><a href="section-12.html#section-12.2.3"><i class="fa fa-check"></i><b>12.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="12.2.4" data-path="section-12.html"><a href="section-12.html#section-12.2.4"><i class="fa fa-check"></i><b>12.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="section-12.html"><a href="section-12.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 关联法则分析</a><ul>
<li class="chapter" data-level="13.1" data-path="section-13.html"><a href="section-13.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 关联法则简介</a></li>
<li class="chapter" data-level="13.2" data-path="section-13.html"><a href="section-13.html#section-13.2"><i class="fa fa-check"></i><b>13.2</b> 案例：商业购物篮分析</a></li>
<li class="chapter" data-level="13.3" data-path="section-13.html"><a href="section-13.html#section-13.3"><i class="fa fa-check"></i><b>13.3</b> 关联法则可视化</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-14.html"><a href="section-14.html"><i class="fa fa-check"></i><b>14</b> 数据可视化和结果展示</a><ul>
<li class="chapter" data-level="14.1" data-path="section-14.html"><a href="section-14.html#r-markdown"><i class="fa fa-check"></i><b>14.1</b> R Markdown</a><ul>
<li class="chapter" data-level="14.1.1" data-path="section-14.html"><a href="section-14.html#r-markdown"><i class="fa fa-check"></i><b>14.1.1</b> 什么是R Markdown?</a></li>
<li class="chapter" data-level="14.1.2" data-path="section-14.html"><a href="section-14.html#how-to-start"><i class="fa fa-check"></i><b>14.1.2</b> How to Start?</a></li>
<li class="chapter" data-level="14.1.3" data-path="section-14.html"><a href="section-14.html#interactive-r-markdown-document"><i class="fa fa-check"></i><b>14.1.3</b> Interactive R Markdown Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="section-15.html"><a href="section-15.html"><i class="fa fa-check"></i><b>15</b> 数据科学的科学</a></li>
<li class="chapter" data-level="16" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>16</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-10" class="section level1">
<h1><span class="header-section-number">第10章</span> 线性回归极其衍生</h1>
<p>本章主要讲线性回归和它的衍生，顺序由易到难。先介绍普通线性回归（也称为最小二乘回归），这是非常简单的（可能是最简单的）有监督方法，相对于其它方法，普通线性回归可谓历史悠久，声名远扬。很多非理工科专业的小伙伴也都听过或者用过该模型。虽然和很多我们将要介绍的更新的模型比起来，普通线性回归太过低端，但它依旧是有用并且被广泛使用，此外，很多新模型其实是普通线性模型的衍生。因此理解普通线性模型对理解后面更加复杂的模型非常重要。之后我们会讲到两个收缩方法：岭回归和Lasso回归。和普通最小二乘估计相比，收缩方法可以将参数估计向0“收缩”，当观测量少时（相对于变量个数而言），这种方法有助于减少估计方差，稳定参数估计。接下来我们会介绍分层线性回归，和贝叶斯框架下的分层线性回归。R有强大的拟合线性模型的功能。我们先回顾一些基本知识，展示如何用R展示拟合相应模型，但是本章不会介绍所有实践中需要知道的知识。我们鼓励想进一步了解模型的读者参考我们在介绍该部分时列出的参考资料。本章中我们还是使用服装消费者数据解释线性模型。我们需要回答类似这样的问题：“那些变量是总消费量（线上和实体店消费额之和）的驱动因子？”这个问题的答案可以帮助公司知道需要将钱投到产品的哪个方面（如服装的设计，服装质量等）。</p>
<p>这里特别要注意的一点是，驱动因子不意味着原因。线性模型只假设变量之间存在<strong>关联性</strong>。如果某汽车客户问卷调查结果显示满意度和价格之间正相关，难道商家为了提高消费者满意度而刻意提高汽车价格？貌似不符合常识。更可能的情况是因为价格更高的汽车质量也更好，客户真正满意的是汽车的质量。因果关系在分析实践中是个很大的坑，在解释结果的时候一定要小心再小心，一定要将问题放在相应的语境中。</p>
<div id="section-10.1" class="section level2">
<h2><span class="header-section-number">10.1</span> 普通线性回归</h2>
<p>虽然最小二乘线性回归看起来太过简单粗暴，但现在很多更复杂的模型其基本形式也是线性的。比如逻辑回归，就是对因变量的均值进行逻辑变换后再拟合线性模型。通常我们都将神经网络模型归于非线性模型，但神经网络中的每个潜变量都是某些预测变量的线性组合。日光之下，并无新事。在大量新技术不断涌入更新换代的今天，人的思维更加容易见树不见林。很多事物本质上是有相似性的，找到光怪陆离的表象下的实质是一种重要的能力。在学习了很多不同的方法之后应该退后一步，看看这些方法的演变联系，对背后的知识进行提取抽象，触及本质，时不时停下来问自己：这些模型背后的根本思想是什么？ 在R实现这些模型也类似，不同的模型在R中的表达方法都是模仿线性模型的拟合语句。因此，只要理解了如何使用R拟合，解释和诊断线性模型，你能够举一反三的应用其它更加复杂的模型。本节主要介绍用R中<code>lm()</code>拟合最小二乘线性模型，以及该函数中的不同选项。然后我们将会讲到线性模型的诊断方法，它们用于检测模型的假设是否成立，或者我们拟合的结果是否充分。</p>
<div id="section-10.1.1" class="section level3">
<h3><span class="header-section-number">10.1.1</span> 最小二乘线性模型</h3>
<p>在线性模型中，</p>
<p><span class="math display">\[f(\mathbf{X})=\mathbf{X}\mathbf{\beta}=\beta_{0}+\sum_{j=1}^{p}\mathbf{x_{.j}}\beta_{j}\]</span></p>
<p>其中<span class="math inline">\(\mathbf{\beta}\)</span>是长度为<span class="math inline">\(p+1\)</span>的参数向量。这里的数学公式表达和之前6.1中介绍的一致。最小二乘估计就是选择<span class="math inline">\(\mathbf{\beta^{T}}=(\beta_{0},\beta_{1},...,\beta_{p})\)</span>最小化下面残差平方和：</p>
<p><span class="math display">\[RSS(\beta)=\sum_{i=1}^{N}(y_{i}-f(\mathbf{x_{i.}}))^{2}=\sum_{i=1}^{N}(y_{i}-\beta_{0}-\sum_{j=1}^{p}x_{ij}\beta_{j})^{2}\]</span></p>
<p>我们还是从载入数据开始。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)</code></pre></div>
<p>在我们开始之前，还需要对数据进行一些清理，删除错误的样本观测，消费金额不能为负数。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat&lt;-<span class="kw">subset</span>(dat,store_exp&gt;<span class="dv">0</span> &amp;<span class="st"> </span>online_exp&gt;<span class="dv">0</span>)</code></pre></div>
<p>我们将10个问卷调查变量当作自变量。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modeldat&lt;-dat[,<span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>,<span class="kw">names</span>(dat))]</code></pre></div>
<p>将实体店消费量和在线消费之和当作应变量。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 得到总消费量=实体店消费+在线消费</span>
modeldat$total_exp&lt;-dat$store_exp+dat$online_exp</code></pre></div>
<p>我们先检查一下数据，看是不是有缺失值或者离群点：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里没有展示输出结果</span>
<span class="kw">summary</span>(modeldat)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(modeldat$total_exp,<span class="dt">main=</span><span class="st">&quot;&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;total_exp&quot;</span>)
<span class="kw">boxplot</span>(modeldat$total_exp)</code></pre></div>
<p><img src="DS_R_files/figure-html/checkplot-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>数据集<code>modeldat</code>中没有缺失值，但是明显有离群点，而且应变量<code>total_exp</code>分布明显偏离正态。我们删除离群点，然后对应变量进行对数变换。</p>
<p>我们用之前数据预处理章节介绍的Z分值的方法查找并删除离群点。这里不重复解释，不明白的读者可以返回复习相应的章节。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y&lt;-modeldat$total_exp
<span class="co"># 求Z分值</span>
zs&lt;-(y-<span class="kw">mean</span>(y))/<span class="kw">mad</span>(y)
<span class="co"># 找到Z分值大于3.5的离群点，删除这些观测</span>
modeldat&lt;-modeldat[-<span class="kw">which</span>(zs&gt;<span class="fl">3.5</span>),]</code></pre></div>
<p>这里我们先不对应变量进行对数变换，之后在回归函数的公式里对应变量进行变换。接下来检查变量的共线性：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(corrplot)
correlation&lt;-<span class="kw">cor</span>(modeldat[,<span class="kw">grep</span>(<span class="st">&quot;Q&quot;</span>,<span class="kw">names</span>(modeldat))])
<span class="kw">corrplot.mixed</span>(correlation,<span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>,<span class="dt">tl.pos=</span><span class="st">&quot;lt&quot;</span>,<span class="dt">upper=</span><span class="st">&quot;ellipse&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:corplotlm"></span>
<img src="DS_R_files/figure-html/corplotlm-1.png" alt="自变量相关矩阵图" width="80%" />
<p class="caption">
Figure 10.1: 自变量相关矩阵图
</p>
</div>
<p>由图<a href="section-10.html#fig:corplotlm">10.1</a> 可以看到，变量之间有很强的相关性。我们用之前在预处理章节中提到的删除高度相关变量的算法，设置阈值为0.75：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
highcor&lt;-<span class="kw">findCorrelation</span>(correlation,<span class="dt">cutoff=</span>.<span class="dv">75</span>)
modeldat&lt;-modeldat[,-highcor]</code></pre></div>
<p>现在我们可以拟合线性模型。标准的模型公式表达是在“~”号的左边指定因变量，右边指定自变量。“.”表示数据集<code>modeldat</code>中除了因变量之外的所有变量都被当作自变量。这里我们没有考虑交互效应，如果要添加<code>Q1</code>和<code>Q2</code>的交互效应，只要在“~”右边加上“Q1*Q2”即可。注意下面的代码中我们对原始变量进行了对数变换（<code>log(total_exp)</code>）。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmfit&lt;-<span class="kw">lm</span>(<span class="kw">log</span>(total_exp)~.,<span class="dt">data=</span>modeldat)
<span class="kw">summary</span>(lmfit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(total_exp) ~ ., data = modeldat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.17494 -0.13719  0.01284  0.14163  0.56227 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  8.098314   0.054286 149.177  &lt; 2e-16 ***
## Q1          -0.145340   0.008823 -16.474  &lt; 2e-16 ***
## Q2           0.102275   0.019492   5.247 1.98e-07 ***
## Q3           0.254450   0.018348  13.868  &lt; 2e-16 ***
## Q6          -0.227684   0.011520 -19.764  &lt; 2e-16 ***
## Q8          -0.090706   0.016497  -5.498 5.15e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2262 on 805 degrees of freedom
## Multiple R-squared:  0.8542, Adjusted R-squared:  0.8533 
## F-statistic: 943.4 on 5 and 805 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>从模型结果总结中我们可以看到各个自变量的参数估计（<code>Estimate</code>列）、标准差（<code>Std. Error</code>），t统计量（<code>t value</code>）和p值（<code>Pr(&gt;|t|)</code>）。在输出的底部包含了残差标准误，即RMSE（<code>Residual standard error</code>），<span class="math inline">\(R^2\)</span>（<code>Multiple R-squared</code>）和调整后的<span class="math inline">\(R^2\)</span>（<code>Adjusted R-squared</code>），模型的F统计量（<code>F-statistic</code>）以及相应F检验的显著性p值（<code>p-value</code>）。</p>
<ul>
<li><strong>关于p值的讨论</strong></li>
</ul>
<p>谈到p值，不能不提美国统计协会在2016年2月发表的关于P值的声明 “Position on p-values: context, process, and purpose” <span class="citation">(Ronald L. Wassersteina <a href="#ref-ASA_P">2016</a>)</span> ，统计之都有一篇对该声明的中文总结<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>。关于p值弊端的讨论在统计学领域已经不是新鲜事。其中一些抨击言辞比较激烈的是 Siegfried：</p>
<blockquote>
<p>这是科学中最肮脏的秘密：使用统计假设检验的“科学方法”建立在一个脆弱的基础之上。——ScienceNews（Siegfried, 2010）</p>
</blockquote>
<blockquote>
<p>假设检验中用到的统计方法……比Facebook隐私条款的缺陷还多。——ScienceNews（Siegfried, 2014）</p>
</blockquote>
<p>尽管争议已经持续了很久，但这是第一次统计协会对该话题给出郑重的声明，其主要目的不是解决该问题，而是对这些批评和讨论作一个回应，讨论发表一些关于p值的普遍共识，唤起大家对科学研究可重复性的重要性。声明中概括了关于p值的6个准则：</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>P值可以表达的是数据与一个给定模型不匹配的程度。</li>
<li>P值并不能衡量某条假设为真的概率，或是数据仅由随机因素产生的概率。</li>
<li>科学结论、商业决策或政策制定不应该仅依赖于P值是否超过一个给定的阈值。</li>
<li>合理的推断过程需要完整的报告和透明度。</li>
<li>P值或统计显著性并不衡量影响的大小或结果的重要性。</li>
<li>P值就其本身而言，并不是一个非常好的对模型或假设所含证据大小的衡量。</li>
</ol>
</blockquote>
<p>在文章末尾列举了一些其他替代手段，其中之一就是报告置信区间而非p值。 回到当前的例子，这里我们不去讨论参数估计的对应p值，而是使用各个参数估计的置信区间。在R中可以用下面代码得到置信区间：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(lmfit,<span class="dt">level=</span><span class="fl">0.9</span>)</code></pre></div>
<pre><code>##                     5 %        95 %
## (Intercept)  8.00891811  8.18771037
## Q1          -0.15986889 -0.13081186
## Q2           0.07017625  0.13437445
## Q3           0.22423576  0.28466333
## Q6          -0.24665434 -0.20871330
## Q8          -0.11787330 -0.06353905</code></pre>
<p>上面的输出就是参数的90%置信区间。其中<code>level=0.9</code>将置信度设置为0.9。</p>
<p>拟合线性模型是非常容易的，以致于很多分析师拟合了模型之后不考虑模型是否合理，直接撰写结果报告。其实我们可以很容易用R从不同方面检查模型的拟合情况和假设条件。下面的几个小节中我们将介绍一些常用的线性模型诊断方法。</p>
</div>
<div id="section-10.1.2" class="section level3">
<h3><span class="header-section-number">10.1.2</span> 回归诊断</h3>
<p>拟合线性模型是非常容易的，以致于很多分析师拟合了模型之后不考虑模型是否合理，直接撰写结果报告。其实我们可以很容易用R从不同方面检查模型的拟合情况和假设条件。下面的几个小节中我们将介绍一些常用的线性模型诊断方法。我们希望需要最小二乘估计（OLS）同时也是最优线性无偏估计（BLUE）。换句话说，我们希望得到的估计的期望即为真实值（无偏），且最小化残差方差（最优）。根据高斯-马尔可夫定理（Gauss-Markov theorem），OLS在下面条件满足时是BLUE:</p>
<ol style="list-style-type: decimal">
<li>自变量（<span class="math inline">\(\mathbf{x_{.j}}\)</span>）和随机误差（<span class="math inline">\(\mathbf{\epsilon}\)</span>）不相关，即：<span class="math inline">\(cov(\mathbf{x_{.j},\epsilon})=0\)</span> 对 <span class="math inline">\(\forall j=j\in1...p\)</span></li>
<li>随机误差均值为0：<span class="math inline">\(E(\mathbf{\epsilon|X})=0\)</span></li>
<li>随机误差方差一致且相互独立：<span class="math inline">\(Var(\mathbf{\epsilon})=\sigma^{2}I\)</span>，其中<span class="math inline">\(\sigma\)</span>是正实数，<span class="math inline">\(I\)</span>是<span class="math inline">\(n\times n\)</span>的单位矩阵</li>
</ol>
<p>下面介绍4种图形诊断。</p>
<ol style="list-style-type: decimal">
<li><p>残差图（Residuals vs Fitted）</p>
残差图分析法是一种直观、方便的分析方法。它以残差<span class="math inline">\(\epsilon_{i}\)</span>为纵坐标，以样本拟合值为横坐标画散点图（也可以绘制横坐标为任意自变量的残差散点图）。正常情况下残差分布应该是随机的。我们要检查残差图的如下几个方面：
<ul>
<li>残差是否在0附近分布</li>
<li>残差分布是否随机，如果呈现出某种特定分布模式（如：随横坐标的增大而增大或减小）的话，说明当前模型关系的假设不充分</li>
<li>残差是否存在异方差性，比如随着拟合值增大残差分布方差增加，这就说明残差分布有异方差性。如前所述，当存在异方差时，参数估计值虽然是无偏的，但不是最小方差线性无偏估计。由于参数的显著性检验是基于残差分布假设的，所以在该假设不成立的情况下该检验也将失效。如果你用该回归方程来预测新样本，效果很可能极不理想。</li>
</ul></li>
<li><p>Q-Q图（Norm Q-Q）</p>
<p>Q-Q图是一种正态分布检测。对于标准状态分布，Q-Q图上的点分布在Y=X直线上，点偏离直线越远说明样本偏离正态分布越远。</p></li>
<li><p>标准化残差方根散点图（Scale-Location）</p>
<p>和残差图类似，横坐标依旧是样本拟合值，纵坐标变为了标准化残差的绝对值开方。</p></li>
<li><p>Cook距离图（Cook’s distance）</p>
<p>该图用于判断观测值是否有异常点。一般认为 当D&lt;0.5时认为不是异常值点；当D&gt;0.5时认为是异常值点。</p></li>
</ol>
<p>对回归结果应用<code>plot()</code>函数可以得到不同的图形诊断。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lmfit,<span class="dt">which=</span><span class="dv">1</span>)
<span class="kw">plot</span>(lmfit,<span class="dt">which=</span><span class="dv">2</span>)
<span class="kw">plot</span>(lmfit,<span class="dt">which=</span><span class="dv">3</span>)
<span class="kw">plot</span>(lmfit,<span class="dt">which=</span><span class="dv">4</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:errorplot"></span>
<img src="DS_R_files/figure-html/errorplot-1.png" alt="一般线性回归残差图" width="80%" />
<p class="caption">
Figure 10.2: 一般线性回归残差图
</p>
</div>
<p>从回归的四个图形结果（图<a href="section-10.html#fig:errorplot">10.2</a>）来看：</p>
<ul>
<li>残差图：数据点都基本均匀地分布在直线y=0的两侧, 无明显趋势，满足线性假设。</li>
<li>标准Q-Q图：图上的点基本都在y=x直线附件，可认为残差近似服从正态分布；</li>
<li>标准化残差方根散点图：若满足不变方差假设，则在该图中水平线周围的点应随机分布，最高点为残差最大值点。该图显示基本符合方差齐性的要求。</li>
<li>Cook距离图：最大的Cook距离为0.05左右，可以认为没有异常值点。</li>
</ul>
</div>
<div id="section-10.1.3" class="section level3">
<h3><span class="header-section-number">10.1.3</span> 离群点，高杠杆点和强影响点</h3>
<p>关于一般线性回归，最好检查下是否有观测会强烈影响线性模型拟合结果。如果一个或者几个观测对模型结果有决定性的影响，那么用这些观测得到的模型是具有误导性的。这里我们介绍这三类观测点的检测：离群点，高杠杆点和强影响点。</p>
<ul>
<li>离群点</li>
</ul>
<p>刚才介绍的Cook距离图，以及之前讲到的Z分值都可以用来检测线性模型中的离群点。注意，Z分值仅仅是针对应变量观测而言，和使用的模型无关，即其并未考虑模型的拟合情况。下面我们用<code>car</code>包<span class="citation">(John Fox and Weisberg <a href="#ref-car">2011</a>)</span>中的<code>outlierTest()</code>函数对拟合模型对象检测是否存在离群点，和Z分值方法鉴别的离群点不同，这里的离群点指的是<strong>那些模型预测效果不佳的观测点</strong>，通常有很大的、或正或负的残差，正残差说明模型低估了响应值，负残差说明高佑了响应值。这里使用的是Bonferroni离群点检验，该检验也可作用于广义线性模型。对于一般线性模型使用的是t检验，对于广义线性模型使用的是正态检验。关于该检验相关知识见 <span class="citation">(Williams <a href="#ref-Williams1987">1987</a>; J. Fox <a href="#ref-fox2008">2008</a>; Cook and Weisberg <a href="#ref-cookd">1982</a>; S. Weisberg <a href="#ref-weisberg14">2014</a>)</span>。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
<span class="kw">outlierTest</span>(lmfit) <span class="co">#Bonferroni离群点检验</span></code></pre></div>
<pre><code>##      rstudent unadjusted p-value Bonferonni p
## 960 -5.295504          1.533e-07   0.00012432</code></pre>
<p><code>outlierTest()</code>函数是根据单个最大（或正或负）残差值的显著性来判断是否有离群点，若不显著，则说明数据集中没有离群点，若显著，则建议删除该离群点，然后再检验是否还有其他离群点存在。这里我们删除第960个被认为是离群点的观测。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">outlierTest</span>(lmfit)</code></pre></div>
<pre><code>##      rstudent unadjusted p-value Bonferonni p
## 960 -5.295504          1.533e-07   0.00012432</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 这里数据modeldat的行名是原数据集的行号，所以是字符类型</span>
<span class="co"># 找到相应的观测</span>
idex&lt;-<span class="kw">which</span>(<span class="kw">row.names</span>(modeldat)==<span class="st">&quot;960&quot;</span>)
<span class="co"># 删除离群观测</span>
modeldat=modeldat[-idex,]</code></pre></div>
<p>接下来我们再拟合一次模型然后检测看看是否还有离群点：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmfit&lt;-<span class="kw">lm</span>(<span class="kw">log</span>(total_exp)~.,<span class="dt">data=</span>modeldat)
<span class="kw">outlierTest</span>(lmfit)</code></pre></div>
<pre><code>## 
## No Studentized residuals with Bonferonni p &lt; 0.05
## Largest |rstudent|:
##      rstudent unadjusted p-value Bonferonni p
## 155 -3.818112         0.00014483      0.11731</code></pre>
<p>可以看到现在没有检测出显著离群点。</p>
<ul>
<li></li>
</ul>
<p>高杠杆值点是与其他预测变量有关的离群点，即它们是由许多异常的预测变量组合起来的，与响应变量值没有关系。 高杠杆值的观测点可通过帽子矩阵的值（hat statistic）判断。对于一个给定的数据集，帽子均值为<span class="math inline">\(p/n\)</span>，其中p是模型估计的参数数目（包含截距项），n是样本量。一般来说，若观测点的帽子值大于帽子均值的2或3倍，则可认定为高杠杆值点。</p>
<!--
hat.plot<-function(fit){  
  p<-length(coefficients(fit))  
  n<-length(fitted(fit))  
  plot(hatvalues(fit),main="Index Plot of Hat Values")  
  abline(h=c(2,3)*p/n,col="red",lty=2)  
  identify(1:n,hatvalues(fit),names(hatvalues(fit)))  
}  
hat.plot(model) 

此图中可以看到1号点是高杠杆值点。

强影响点

强影响点，即对模型参数估计值影响有些比例失衡的点。例如，当移除 模型的一个观测点时模型会发生巨大的改变，那么需要检测一下数据中是否存在强影响点。Cook距离，或称为D统计量。Cook’s D值大于4/(n-k-1)，则表明它是强影响点，其中n为样本量大小，k是预测变量数目（有助于鉴别强影响点，但并不提供关于这些点如何影响模型的信息）。
对回归的影响点。根据Cook距离，13号点可能是个强影响点。

帽子统计量、DFFITS准测、Cook统计量和COVRATIO准则在R软件可分别通过hatvalues(),dffits(),cooks.distance()和covration()函数计算。influence.measures()可对一次获得这四个统计量的结果。 影响分析综合分析

influencePlot(model) 
#car包中的influencePlot（）函数，可将离群点、
#杠杆点和强影响点的信息整合到一幅图形中
influence.measures(model)

纵坐标超过2或小于-2的州可被认为是离群点，水平轴超过0.2或0.3的州有高杠杆值（通常为预测值的组合）。圆圈大小与影响成比例，圆圈很大的点可能是对模型估计造成的不成比例影响的强影响点。influence.measures()的inf用×标注异常值。
-->
</div>
</div>
<div id="section-10.2" class="section level2">
<h2><span class="header-section-number">10.2</span> 收缩方法</h2>
</div>
<div id="section-10.3" class="section level2">
<h2><span class="header-section-number">10.3</span> 分层线性回归</h2>
<p>我们 已经讨论过简单线性模型，下面讨论该模型的扩展分层线性模型。什么时候需要使用分层模型呢？需要考虑分层结构的常见情况有两种。（1）当你的数据有嵌套结构，这是指一些观测可能属于更高一层级单位。比如在教育学分析当中通常需要研究学生的学习情况，同一所学校或者同一班级的学生相似度更高，这里我们就需要考虑学生学习情况的个体观测可能嵌套在班级，或者学校这个更高一层级单位中。市场营销中，地理位置通常是一个更高的层极单位。北上广的消费者和一些二三线城市的消费者可能不同，东南沿海和东北地区的消费者差异可能更大。这些情况中我们都需要考虑分层结构。（2）还有一种情况是针对纵向数据。比如对一些人年收入连续10年的观测，那么研究观测就该考虑个人的随机效应。类似的还有我们的航空公司满意度调查数据，每个受访者针对每项对3个航空公司进行评分，这里也需要考虑受访者的个体随机效应，可能的情况是有的人倾向于给高分，有的人倾向于给低分，这样的倾向和问卷问题以及哪家航空公司无关。</p>
</div>
<div id="section-10.4" class="section level2">
<h2><span class="header-section-number">10.4</span> 贝叶斯线性回归</h2>
</div>
<div id="section-10.5" class="section level2">
<h2><span class="header-section-number">10.5</span> 贝叶斯分层线性回归</h2>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-ASA_P">
<p>Ronald L. Wassersteina, Nicole A. Lazara. 2016. “Position on P-Values: Context, Process, and Purpose.”</p>
</div>
<div id="ref-car">
<p>Fox, John, and Sanford Weisberg. 2011. “An R Companion to Applied Regression.” <em>Sage</em>.</p>
</div>
<div id="ref-Williams1987">
<p>Williams, D. A. 1987. “Generalized Linear Model Diagnostics Using the Deviance and Single Case Deletions.” <em>Applied Statistics</em> 36: 181–191.</p>
</div>
<div id="ref-fox2008">
<p>Fox, J. 2008. “Applied Regression Analysis and Generalized Linear Models.” <em>Sage</em>.</p>
</div>
<div id="ref-cookd">
<p>Cook, R. D., and S Weisberg. 1982. <em>Residuals and Influence in Regression</em>. Chapman; Hall.</p>
</div>
<div id="ref-weisberg14">
<p>Weisberg, S. 2014. <em>Applied Linear Regression</em>. <em>Applied Linear Regression</em>. Fourth Edition. Wiley.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="http://cos.name/2016/03/asa-statement-on-p-value/" class="uri">http://cos.name/2016/03/asa-statement-on-p-value/</a><a href="section-10.html#fnref1">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-9.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-11.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-xianxinghuigui.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
