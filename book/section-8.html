<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>数据科学家：R语言</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is my first book on data science">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="数据科学家：R语言" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my first book on data science" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="数据科学家：R语言" />
  
  <meta name="twitter:description" content="This is my first book on data science" />
  

<meta name="author" content="林荟">

<meta name="date" content="2016-07-18">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-7.html">
<link rel="next" href="section-9.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据科学家：R语言</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 介绍</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学</a><ul>
<li class="chapter" data-level="2.1" data-path="section-2.html"><a href="section-2.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 什么是数据科学？</a></li>
<li class="chapter" data-level="2.2" data-path="section-2.html"><a href="section-2.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 什么是数据科学家？</a></li>
<li class="chapter" data-level="2.3" data-path="section-2.html"><a href="section-2.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 数据科学家需要的技能</a></li>
<li class="chapter" data-level="2.4" data-path="section-2.html"><a href="section-2.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 数据科学可以解决什么问题？</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-2.html"><a href="section-2.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 前提要求</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-2.html"><a href="section-2.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 问题种类</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-3.html"><a href="section-3.html"><i class="fa fa-check"></i><b>3</b> 数据集模拟和背景介绍</a><ul>
<li class="chapter" data-level="3.1" data-path="section-3.html"><a href="section-3.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 服装消费者数据</a></li>
<li class="chapter" data-level="3.2" data-path="section-3.html"><a href="section-3.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 航空公司满意度调查</a></li>
<li class="chapter" data-level="3.3" data-path="section-3.html"><a href="section-3.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 生猪疫情风险预测数据</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据分析一般流程</a><ul>
<li class="chapter" data-level="4.1" data-path="section-4.html"><a href="section-4.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 问题到数据</a></li>
<li class="chapter" data-level="4.2" data-path="section-4.html"><a href="section-4.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 数据到信息</a></li>
<li class="chapter" data-level="4.3" data-path="section-4.html"><a href="section-4.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信息到行动</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 数据预处理</a><ul>
<li class="chapter" data-level="5.1" data-path="section-5.html"><a href="section-5.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 介绍</a></li>
<li class="chapter" data-level="5.2" data-path="section-5.html"><a href="section-5.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 数据清理</a></li>
<li class="chapter" data-level="5.3" data-path="section-5.html"><a href="section-5.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 缺失值填补</a><ul>
<li class="chapter" data-level="5.3.1" data-path="section-5.html"><a href="section-5.html#section-5.3.1"><i class="fa fa-check"></i><b>5.3.1</b> 中位数或众数填补</a></li>
<li class="chapter" data-level="5.3.2" data-path="section-5.html"><a href="section-5.html#k-"><i class="fa fa-check"></i><b>5.3.2</b> K-近邻填补</a></li>
<li class="chapter" data-level="5.3.3" data-path="section-5.html"><a href="section-5.html#section-5.3.3"><i class="fa fa-check"></i><b>5.3.3</b> 袋状树填补</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="section-5.html"><a href="section-5.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 中心化和标量化</a></li>
<li class="chapter" data-level="5.5" data-path="section-5.html"><a href="section-5.html#section-5.5"><i class="fa fa-check"></i><b>5.5</b> 有偏分布</a></li>
<li class="chapter" data-level="5.6" data-path="section-5.html"><a href="section-5.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 处理离群点</a></li>
<li class="chapter" data-level="5.7" data-path="section-5.html"><a href="section-5.html#section-5.7"><i class="fa fa-check"></i><b>5.7</b> 共线性</a></li>
<li class="chapter" data-level="5.8" data-path="section-5.html"><a href="section-5.html#section-5.8"><i class="fa fa-check"></i><b>5.8</b> 稀疏变量</a></li>
<li class="chapter" data-level="5.9" data-path="section-5.html"><a href="section-5.html#section-5.9"><i class="fa fa-check"></i><b>5.9</b> 编码名义变量</a></li>
<li class="chapter" data-level="5.10" data-path="section-5.html"><a href="section-5.html#section-5.10"><i class="fa fa-check"></i><b>5.10</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 数据整合和整形</a><ul>
<li class="chapter" data-level="6.1" data-path="section-6.html"><a href="section-6.html#readr"><i class="fa fa-check"></i><b>6.1</b> 高效数据读写：<code>readr</code>包</a></li>
<li class="chapter" data-level="6.2" data-path="section-6.html"><a href="section-6.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 数据整合</a><ul>
<li class="chapter" data-level="6.2.1" data-path="section-6.html"><a href="section-6.html#baseapply"><i class="fa fa-check"></i><b>6.2.1</b> base包：apply()</a></li>
<li class="chapter" data-level="6.2.2" data-path="section-6.html"><a href="section-6.html#plyrddply"><i class="fa fa-check"></i><b>6.2.2</b> plyr包：ddply()函数</a></li>
<li class="chapter" data-level="6.2.3" data-path="section-6.html"><a href="section-6.html#dplyr"><i class="fa fa-check"></i><b>6.2.3</b> dplyr包</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="section-6.html"><a href="section-6.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 数据整形</a><ul>
<li class="chapter" data-level="6.3.1" data-path="section-6.html"><a href="section-6.html#reshape2"><i class="fa fa-check"></i><b>6.3.1</b> <code>reshape2</code>包</a></li>
<li class="chapter" data-level="6.3.2" data-path="section-6.html"><a href="section-6.html#tidyr"><i class="fa fa-check"></i><b>6.3.2</b> <code>tidyr</code>包</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="section-6.html"><a href="section-6.html#-1"><i class="fa fa-check"></i><b>6.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 基础建模技术</a><ul>
<li class="chapter" data-level="7.1" data-path="section-7.html"><a href="section-7.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 有监督和无监督</a></li>
<li class="chapter" data-level="7.2" data-path="section-7.html"><a href="section-7.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 误差及其来源</a><ul>
<li class="chapter" data-level="7.2.1" data-path="section-7.html"><a href="section-7.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 系统误差和随机误差</a></li>
<li class="chapter" data-level="7.2.2" data-path="section-7.html"><a href="section-7.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 应变量误差</a></li>
<li class="chapter" data-level="7.2.3" data-path="section-7.html"><a href="section-7.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 自变量误差</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="section-7.html"><a href="section-7.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 数据划分和再抽样</a><ul>
<li class="chapter" data-level="7.3.1" data-path="section-7.html"><a href="section-7.html#section-7.3.1"><i class="fa fa-check"></i><b>7.3.1</b> 划分训练集和测试集</a></li>
<li class="chapter" data-level="7.3.2" data-path="section-7.html"><a href="section-7.html#section-7.3.2"><i class="fa fa-check"></i><b>7.3.2</b> 重抽样</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="section-7.html"><a href="section-7.html#-2"><i class="fa fa-check"></i><b>7.4</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 模型评估度量</a><ul>
<li class="chapter" data-level="8.1" data-path="section-8.html"><a href="section-8.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 回归模型评估度量</a></li>
<li class="chapter" data-level="8.2" data-path="section-8.html"><a href="section-8.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 分类模型评估度量</a><ul>
<li class="chapter" data-level="8.2.1" data-path="section-8.html"><a href="section-8.html#kappa"><i class="fa fa-check"></i><b>8.2.1</b> Kappa统计量</a></li>
<li class="chapter" data-level="8.2.2" data-path="section-8.html"><a href="section-8.html#roc"><i class="fa fa-check"></i><b>8.2.2</b> ROC曲线</a></li>
<li class="chapter" data-level="8.2.3" data-path="section-8.html"><a href="section-8.html#section-8.2.3"><i class="fa fa-check"></i><b>8.2.3</b> 提升图</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="section-8.html"><a href="section-8.html#-3"><i class="fa fa-check"></i><b>8.3</b> 本章总结</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 特征工程</a><ul>
<li class="chapter" data-level="9.1" data-path="section-9.html"><a href="section-9.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 特征构建</a></li>
<li class="chapter" data-level="9.2" data-path="section-9.html"><a href="section-9.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 特征提取</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-9.html"><a href="section-9.html#section-9.2.1"><i class="fa fa-check"></i><b>9.2.1</b> 初步探索数据</a></li>
<li class="chapter" data-level="9.2.2" data-path="section-9.html"><a href="section-9.html#section-9.2.2"><i class="fa fa-check"></i><b>9.2.2</b> 主成分分析</a></li>
<li class="chapter" data-level="9.2.3" data-path="section-9.html"><a href="section-9.html#section-9.2.3"><i class="fa fa-check"></i><b>9.2.3</b> 探索性因子分析</a></li>
<li class="chapter" data-level="9.2.4" data-path="section-9.html"><a href="section-9.html#section-9.2.4"><i class="fa fa-check"></i><b>9.2.4</b> 理论背景</a></li>
<li class="chapter" data-level="9.2.5" data-path="section-9.html"><a href="section-9.html#section-9.2.5"><i class="fa fa-check"></i><b>9.2.5</b> 高维标度化</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="section-9.html"><a href="section-9.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 变量选择</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 线性回归极其衍生</a><ul>
<li class="chapter" data-level="10.1" data-path="section-10.html"><a href="section-10.html#section-10.1"><i class="fa fa-check"></i><b>10.1</b> 普通线性回归</a><ul>
<li class="chapter" data-level="10.1.1" data-path="section-10.html"><a href="section-10.html#section-10.1.1"><i class="fa fa-check"></i><b>10.1.1</b> 最小二乘线性模型</a></li>
<li class="chapter" data-level="10.1.2" data-path="section-10.html"><a href="section-10.html#section-10.1.2"><i class="fa fa-check"></i><b>10.1.2</b> 回归诊断</a></li>
<li class="chapter" data-level="10.1.3" data-path="section-10.html"><a href="section-10.html#section-10.1.3"><i class="fa fa-check"></i><b>10.1.3</b> 离群点，高杠杆点和强影响点</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="section-10.html"><a href="section-10.html#section-10.2"><i class="fa fa-check"></i><b>10.2</b> 收缩方法</a></li>
<li class="chapter" data-level="10.3" data-path="section-10.html"><a href="section-10.html#section-10.3"><i class="fa fa-check"></i><b>10.3</b> 分层线性回归</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 树模型</a><ul>
<li class="chapter" data-level="11.1" data-path="section-11.html"><a href="section-11.html#section-11.1"><i class="fa fa-check"></i><b>11.1</b> 基本树模型</a></li>
<li class="chapter" data-level="11.2" data-path="section-11.html"><a href="section-11.html#section-11.2"><i class="fa fa-check"></i><b>11.2</b> 装袋树</a></li>
<li class="chapter" data-level="11.3" data-path="section-11.html"><a href="section-11.html#section-11.3"><i class="fa fa-check"></i><b>11.3</b> 随机森林</a></li>
<li class="chapter" data-level="11.4" data-path="section-11.html"><a href="section-11.html#section-11.4"><i class="fa fa-check"></i><b>11.4</b> 其它树话题</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 聚类判别分析</a><ul>
<li class="chapter" data-level="12.1" data-path="section-12.html"><a href="section-12.html#section-12.1"><i class="fa fa-check"></i><b>12.1</b> 聚类分析</a></li>
<li class="chapter" data-level="12.2" data-path="section-12.html"><a href="section-12.html#section-12.2"><i class="fa fa-check"></i><b>12.2</b> 判别分析</a><ul>
<li class="chapter" data-level="12.2.1" data-path="section-12.html"><a href="section-12.html#section-12.2.1"><i class="fa fa-check"></i><b>12.2.1</b> 逻辑回归</a></li>
<li class="chapter" data-level="12.2.2" data-path="section-12.html"><a href="section-12.html#section-12.2.2"><i class="fa fa-check"></i><b>12.2.2</b> 线性判别分析</a></li>
<li class="chapter" data-level="12.2.3" data-path="section-12.html"><a href="section-12.html#section-12.2.3"><i class="fa fa-check"></i><b>12.2.3</b> 最小二乘判别分析</a></li>
<li class="chapter" data-level="12.2.4" data-path="section-12.html"><a href="section-12.html#section-12.2.4"><i class="fa fa-check"></i><b>12.2.4</b> 朴素贝叶斯</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="section-12.html"><a href="section-12.html#section-12.3"><i class="fa fa-check"></i><b>12.3</b> 案例：客户分组</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-13.html"><a href="section-13.html"><i class="fa fa-check"></i><b>13</b> 关联法则分析</a><ul>
<li class="chapter" data-level="13.1" data-path="section-13.html"><a href="section-13.html#section-13.1"><i class="fa fa-check"></i><b>13.1</b> 关联法则简介</a></li>
<li class="chapter" data-level="13.2" data-path="section-13.html"><a href="section-13.html#section-13.2"><i class="fa fa-check"></i><b>13.2</b> 案例：商业购物篮分析</a></li>
<li class="chapter" data-level="13.3" data-path="section-13.html"><a href="section-13.html#section-13.3"><i class="fa fa-check"></i><b>13.3</b> 关联法则可视化</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-14.html"><a href="section-14.html"><i class="fa fa-check"></i><b>14</b> 数据可视化和结果展示</a><ul>
<li class="chapter" data-level="14.1" data-path="section-14.html"><a href="section-14.html#r-markdown"><i class="fa fa-check"></i><b>14.1</b> R Markdown</a><ul>
<li class="chapter" data-level="14.1.1" data-path="section-14.html"><a href="section-14.html#r-markdown"><i class="fa fa-check"></i><b>14.1.1</b> 什么是R Markdown?</a></li>
<li class="chapter" data-level="14.1.2" data-path="section-14.html"><a href="section-14.html#how-to-start"><i class="fa fa-check"></i><b>14.1.2</b> How to Start?</a></li>
<li class="chapter" data-level="14.1.3" data-path="section-14.html"><a href="section-14.html#interactive-r-markdown-document"><i class="fa fa-check"></i><b>14.1.3</b> Interactive R Markdown Document</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="section-15.html"><a href="section-15.html"><i class="fa fa-check"></i><b>15</b> 数据科学的科学</a></li>
<li class="chapter" data-level="16" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>16</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据科学家：R语言</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-8" class="section level1">
<h1><span class="header-section-number">第8章</span> 模型评估度量</h1>
<p>当我们问哪个模型拟合效果好的时候我们到底在问什么？很多看似明确合理的问题一旦究其细节就会发现，其定义非常模糊以至于无法直接回答。这个问题的模糊之处在于没有指明用什么来衡量“拟合效果”？要比较模型首要任务是确定一个模型表现的度量，即通过什么标准来决定两个模型谁更好。模型表现的度量方法有好几种，要想更加全面的了解模型的表现，有时需要结合多种度量方式。这里我们只是单独介绍模型表现评估的度量，真正对度量的使用是建立在<strong>数据划分和再抽样</strong>的基础上的，也就是拟合模型和评估模型使用的数据集应该不同，否则得到的度量估计将过度乐观。</p>
<div id="section-8.1" class="section level2">
<h2><span class="header-section-number">8.1</span> 回归模型评估度量</h2>
<p>接下来我们会依次介绍下面几种回归模型的表现度量方式：RMSE、校正<span class="math inline">\(R^2\)</span>、<span class="math inline">\(C_{p}\)</span>、AIC和BIC。</p>
<p>当因变量是数值时，我们可以使用均方误差平方根（Root mean squared error, RMSE）为指标衡量模型的表现。 这个度量是模型残差的函数，其中残差即为观测值减去模型的预测值。 均方误差（Mean squared error, MSE）的计算方法是将残差平方然后取平均， 而RMSE则是取MSE的平方根，从而它与原始数据的单位相同。</p>
<p><span class="math display">\[MSE=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}\]</span> <span class="math display">\[RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}}\]</span></p>
<p>得到的RMSE取值通常解释为残差离0的平均距离，或者解释为观测值和模型预测值之间平均的距离。回到之前介绍误差来源时用过的例子，对服装消费者数据中的收入（<code>income</code>）建立一般线性模型，将消费记录变量作为自变量，结果如下所示：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 载入服装消费者数据</span>
sim.dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/SegData.csv&quot;</span>)
fit&lt;-<span class="kw">lm</span>(income~store_exp+online_exp+store_trans+online_trans,<span class="dt">data=</span>sim.dat)
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = income ~ store_exp + online_exp + store_trans + 
##     online_trans, data = sim.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -128768  -15804     441   13375  150945 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  85711.6796  3651.5991  23.472  &lt; 2e-16 ***
## store_exp        3.1977     0.4754   6.726 3.28e-11 ***
## online_exp       8.9949     0.8943  10.058  &lt; 2e-16 ***
## store_trans   4631.7507   436.4777  10.612  &lt; 2e-16 ***
## online_trans -1451.1618   178.8355  -8.115 1.80e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31530 on 811 degrees of freedom
##   (184 observations deleted due to missingness)
## Multiple R-squared:  0.6018, Adjusted R-squared:  0.5998 
## F-statistic: 306.4 on 4 and 811 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>拟合的线性模型<code>fit</code>的RMSE为3.15310^{4}（输出底部“Residual standard error:”后面的值）。</p>
<p>另一个常用的度量是R-Squared，通常写作<span class="math inline">\(R^2\)</span>。它实际上是观测值和预测值的相关系数的平方。大家可能对线性回归中的<span class="math inline">\(R^2\)</span>很熟悉，但它可以用于任何回归模型。通常解释成模型能够解释的应变量总变异的比例其中R-squared＝0.6 表示模型可以解释因变量总变异的四分之三。尽管这是一个易于解释的统计量，但要注意它是一种相关性而不是准确性的度量，它依赖于应变量方差。比如虽然<code>fit</code>的<span class="math inline">\(R^2\)</span>不低，但是RMSE为0.6，说明预测的收入和真实收入之间的平均差距为3.15310^{4}，这样的精确度并不高。在应变量的取值很大时，即使&gt;90%的<span class="math inline">\(R^2\)</span>也不一定代表足够的精确度，在对公司的销售总额进行建模就常是这样的情况。之前我们在展示自变量和应变量误差对模型表现影响的时候有用过<span class="math inline">\(R^2\)</span>，那时并没有考虑变量个数对<span class="math inline">\(R^2\)</span>的影响（因为变量个数和观测个数相比并不多）。但事实上<span class="math inline">\(R^2\)</span>会随着变量个数的增加而增大。校正<span class="math inline">\(R^2\)</span>就是针对该问题对原<span class="math inline">\(R^2\)</span>进行改进。原始<span class="math inline">\(R^2\)</span>的定义为：</p>
<p><span class="math display">\[R^{2}=1-\frac{RSS}{TSS}\]</span></p>
<p>其中<span class="math inline">\(RSS=\sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^{2}\)</span>，<span class="math inline">\(TSS=\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}\)</span>。</p>
<p>由于RSS总是随着变量个数的增加而降低，<span class="math inline">\(R^2\)</span>也就相应随着变量个数增加而增加。对于有<span class="math inline">\(p\)</span>个变量的最小二乘模型，校正<span class="math inline">\(R^2\)</span>定义为：</p>
<p><span class="math display">\[校正R^{2}=1-\frac{RSS/(n-p-1)}{TSS/(n-1)}\]</span></p>
<p>最大化<span class="math inline">\(校正R^{2}\)</span>等同于最小化<span class="math inline">\(RSS/(n-p-1)\)</span>。由于考虑了变量个数<span class="math inline">\(p\)</span>，<span class="math inline">\(RSS/(n-p-1)\)</span>随着变量个数的增加可能增加或者减少。<span class="math inline">\(校正R^{2}\)</span>的直观想法是当模型中已经包含所有有用的变量后继续加入噪音变量只能略微降低<span class="math inline">\(RSS\)</span>，由于变量个数增加，<span class="math inline">\(n-p-1\)</span>增加进而整体<span class="math inline">\(RSS/(n-p-1)\)</span>反而增加了，于是<span class="math inline">\(校正R^{2}\)</span>会降低。因此，从理论上讲对应最大<span class="math inline">\(校正R^{2}\)</span>的模型只包含有效变量而没有噪音变量。模型每加入一个噪音变量都会受到“惩罚”。</p>
<p>对于含有<span class="math inline">\(p\)</span>个变量的最小二乘拟合模型，<span class="math inline">\(C_{p}\)</span>的定义如下：</p>
<p><span class="math display">\[C_{p}=\frac{1}{n}(RSS+2p\hat{\sigma}^{2})\]</span></p>
<p>其中<span class="math inline">\(\hat{\sigma}^{2}\)</span>是对模型随机项<span class="math inline">\(\epsilon\)</span>的方差的估计。本质上<span class="math inline">\(C_{p}\)</span>统计量就是在训练集的<span class="math inline">\(RSS\)</span>上加上惩罚<span class="math inline">\(2p\hat{\sigma}^{2}\)</span>，对基于训练集过度乐观的误差估计做出调整。很明显，当变量个数增加时，惩罚也随之加重，这可以抵消变量个数增加导致的<span class="math inline">\(RSS\)</span>减小。用于模型选择时，我们选择对应<span class="math inline">\(C_{p}\)</span>更小的模型。</p>
<p>AIC可以用于评估很多模型，它是基于最大似然值的。在线性回归的例子里，最大似然估计和最小二乘估计是一样的： <span class="math display">\[AIC=n+nlog(2\pi)+nlog(RSS/n)+2(p+1)\]</span></p>
<p>BIC 也是基于最大似然值：</p>
<p><span class="math display">\[BIC=n+nlog(2\pi)+nlog(RSS/n)+log(n)(p+1)\]</span></p>
<p>R中的函数<code>AIC()</code>和<code>BIC()</code>就是按上面的公式分别计算AIC和BIC的。在很多教科书里通常会省略常数项<span class="math inline">\(n+nlog(2\pi)\)</span>，且用<span class="math inline">\(p\)</span>代替<span class="math inline">\(p+1\)</span>。但不同的公式效果相同，因为使用时只考虑相对大小。和AIC相比，BIC对参数个数进行了更加严厉的惩罚。所以通过BIC选出的模型通常参数个数比AIC少。</p>
<p>模型评估和变量选择要求选取一个相应的选择标准，关于变量选择，在特征工程的章节中会详细介绍。</p>
<!--注意，虽然这里以一般线性模型为例，本小节中介绍的模型表现度量不仅仅限于一般线性模型，而是所有应变量为连续性的模型。-->
</div>
<div id="section-8.2" class="section level2">
<h2><span class="header-section-number">8.2</span> 分类模型评估度量</h2>
<p>本小节关注判别模型（即，应变量为分类变量）的表现度量。之前对连续型变量适用的RMSE和<span class="math inline">\(R^2\)</span>不适用于分类模型。分类指对给定观测样本预测其所属类别，而且类别空间已知，所以是有监督学习。这个和聚类不同，聚类分析的目的是得到类别空间，是无监督学习，这在之后聚类和判别的部分还会更详细的介绍。通常遇到的问题是二分类，比如是否有某种疾病，垃圾邮件分类器等。也有多分类问题，比如服装消费数据中的消费者类别。这里我们用生猪疫情风险预测数据为例展示分类模型的评估度量。这里我们训练一个随机森林模型对农场疫情爆发概率进行评估，之后在树模型的章节中会对模型本身进行更详细的介绍。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(randomForest)
<span class="kw">library</span>(caret)
<span class="kw">library</span>(readr)
<span class="co"># 读取数据</span>
<span class="co"># 载入数据</span>
disease_dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;/Users/happyrabbit/Documents/GitHub/DataScientistR/Data/sim1_da1.csv&quot;</span>)
<span class="co"># 可以用glimpse()函数查看数据</span>
<span class="co"># glimpse(disease_dat)</span></code></pre></div>
<p>AirlineRating</p>
<p>划分训练集和测试集，在训练集（<code>xTrain</code>和<code>yTrain</code>）上得到模型，然后在测试集（<code>xTest</code>和<code>yTest</code>）上评估模型表现。70%的样本用于训练，剩下30%用于模型评估：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 划分训练集和测试集</span>
<span class="kw">set.seed</span>(<span class="dv">2016</span>)
trainIndex&lt;-<span class="kw">createDataPartition</span>(disease_dat$y,<span class="dt">p=</span><span class="fl">0.8</span>,<span class="dt">list=</span>F,<span class="dt">times=</span><span class="dv">1</span>)
xTrain&lt;-disease_dat[trainIndex,]%&gt;%<span class="kw">select</span>(-y)
xTest&lt;-disease_dat[-trainIndex,]%&gt;%<span class="kw">select</span>(-y)
<span class="co"># 需要将应变量转化成因子类型</span>
yTrain&lt;-disease_dat$y[trainIndex]%&gt;%<span class="kw">as.factor</span>()
yTest&lt;-disease_dat$y[-trainIndex]%&gt;%<span class="kw">as.factor</span>()</code></pre></div>
<p>训练随机森林模型：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_rf&lt;-<span class="kw">randomForest</span>(yTrain~.,<span class="dt">data=</span>xTrain,<span class="dt">mtry=</span><span class="kw">trunc</span>(<span class="kw">sqrt</span>(<span class="kw">ncol</span>(xTrain)-<span class="dv">1</span>)),<span class="dt">ntree=</span><span class="dv">1000</span>,<span class="dt">importance=</span>T)</code></pre></div>
<p>为了展示不同的模型评估法则，我们将训练得到的随机森林模型应用到测试集，得到两种预测：</p>
<ol style="list-style-type: decimal">
<li>每个类别的概率预测（结果为0到1之间的连续值，可以通过在代码中添加选项<code>prob</code>得到预测，结果存在<code>yhatprob</code>对象中）</li>
<li>离散类别预测（结果为0/1形式，存在<code>yhat</code>对象中）</li>
</ol>
<p>我们分别看看这两个预测结果：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yhatprob&lt;-<span class="kw">predict</span>(train_rf,xTest,<span class="st">&quot;prob&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">100</span>)
car::<span class="kw">some</span>(yhatprob)</code></pre></div>
<pre><code>##         0     1
## 45  0.592 0.408
## 158 0.455 0.545
## 255 0.575 0.425
## 291 0.513 0.487
## 314 0.620 0.380
## 392 0.538 0.462
## 402 0.472 0.528
## 443 0.542 0.458
## 462 0.620 0.380
## 626 0.586 0.414</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yhat&lt;-<span class="kw">predict</span>(train_rf,xTest)
car::<span class="kw">some</span>(yhat)</code></pre></div>
<pre><code>## 206 273 305 348 519 524 525 599 701 780 
##   1   0   0   0   0   0   0   0   1   0 
## Levels: 0 1</code></pre>
<p>现在我们就用上面的两种预测结果为例介绍不同的预测类评估方法。</p>
<div id="kappa" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Kappa统计量</h3>
<p><strong>混淆矩阵（Confusion Matrix）</strong>是对分类结果进行详细描述的一个表，是简单的观测类和预测类的交叉表。在此例中，观测类是<code>yTest</code>，预测类是<code>yhat</code>，相应的混淆矩阵为：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(yhat,yTest)</code></pre></div>
<pre><code>##     yTest
## yhat  0  1
##    0 68 56
##    1  3 33</code></pre>
<p>表格中左上角和右下角分别代表预测正确的样本数目，左下角和右上角代表错误预测的样本数目。更一般的二分类混淆矩阵如下：</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">观测发生</th>
<th align="left">观测不发生</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">预测发生</td>
<td align="left">TP</td>
<td align="left">FP</td>
</tr>
<tr class="even">
<td align="left">预测不发生</td>
<td align="left">FN</td>
<td align="left">TN</td>
</tr>
</tbody>
</table>
<p>其中TP代表真阳性，FP代表假阳性，TN代表真阴性，FN代表假阴性。表格左上到右下对角线上的元素表示正确预测的样本数目，另一个方向的对角线上的元素代表误判的样本数。评估类预测最简单的指标是<strong>总体精确率</strong>，即预测正确的总体样本比例:</p>
<p><span class="math display">\[总体精确率=\frac{TP+TN}{TP+TN+FP+FN}\]</span></p>
<p>对类别数目大于2的情况，可以类似计算总体精确率。该统计量很直观，但有一些缺点，首先总体精确率没有区分错误类型。实际应用中，不同错误对应的损失可能不同，这时就无法用总体精确率衡量模型。 比如过滤垃圾邮件，误删一封重要的邮件带来的损失要高于收到一封垃圾邮件的损失。Provost等人<span class="citation">(Provost F <a href="#ref-Provost1998">1998</a>)</span>深入讨论了用精确率来比较不同的分类器存在的问题。其次总体精确率没有考虑真实频率。比如在保险风险分析中，有风险的概率可能只有千分之一或者更小，模型只要将所有样本都清一色判定为无风险就能达到几乎完美的精确率。有时我们将不用模型也能得到的精确率称为<strong>无信息率</strong>。这里将所有样本判定为无风险得到的无信息率至少是99.9%。在这种情况下模型的精确率需要高于无信息率才算合理。</p>
<p>还有一种一致性检验方法叫做Kappa统计量，最早由Cohen等人在1960年提出用于考察两个不同的诊断方法在结果上是否具有一致性<span class="citation">(J <a href="#ref-Cohen1960">1960</a>)</span>。Kappa考虑到简单由偶然情况产生的准确性。具体公式如下：</p>
<p><span class="math display">\[Kappa=\frac{P_{0}+P_{e}}{1-P_{e}}\]</span></p>
<p>假设<span class="math inline">\(n=TP+TN+FP+FN\)</span>为总体样本数，其中<span class="math inline">\(P_{0}=\frac{TP+TN}{n}\)</span>为实际预测一致率，<span class="math inline">\(P_{e}=\frac{(TP+FP)(TP+FN)+(FN+TN)(FP+TN)}{n^{2}}\)</span>为由简单偶然情况产生的一致率。Kappa取值从-1到1，值越高一致性越强。</p>
<ul>
<li>Kappa = 1 时，表明完全一致。</li>
<li>Kappa = 0 时，则一致性与偶然预期的相同。</li>
<li>Kappa &lt; 0 时，一致性比偶然预期的还要弱，不过这种情况很少发生。</li>
</ul>
<p>一般说来，Kappa值在0.3到0.5之间代表合理的一致性。假定一个模型的精确度很高（90%），但偶然预期的精确度也很高（85%），Kappa统计量为<span class="math inline">\(\frac{1}{3}\)</span>，表明预测和观测适度一致。Kappa统计量也可以扩展至评估类别大于2的情形。<code>fmsb</code>包中的<code>Kappa.test()</code>函数能用于计算Cohen的Kappa统计量。该函数还能对Kappa统计量进行统计检验，并且给出置信区间。以上面观测类<code>yTest</code>和预测类<code>yhat</code>结果为例，可以通过如下代码计算Kappa统计量：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kt&lt;-fmsb::<span class="kw">Kappa.test</span>(<span class="kw">table</span>(yhat,yTest))
<span class="co"># 统计量估值在函数返回值的Result对象中</span>
kt$Result$estimate</code></pre></div>
<pre><code>## [1] 0.3054738</code></pre>
<p>上面函数返回结果中包含一个<code>Judgement</code>对象:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kt$Judgement</code></pre></div>
<pre><code>## [1] &quot;Fair agreement&quot;</code></pre>
<p>这是基于Landis和Koch提出的Kappa统计量的一般性解释方法<span class="citation">(Landis JR <a href="#ref-landis1977">1977</a>)</span>：</p>
<ul>
<li>Kappa&lt; 0：无一致性（No agreement）</li>
<li>Kappa在0-0.2之间：略微一致（Slignt agreement）</li>
<li>Kappa在0.2-0.4之间：轻度一致（Fair agreement）</li>
<li>Kappa在0.4-0.6之间：适度一致（Moderate agreement）</li>
<li>Kappa在0.6-0.8之间：强一致（Substantial agreement）</li>
<li>Kappa在0.8-1.0之间：几乎完全一致（Almost perfect agreement）</li>
</ul>
</div>
<div id="roc" class="section level3">
<h3><span class="header-section-number">8.2.2</span> ROC曲线</h3>
<p>相对与简单的类取值，类概率中含有更多的模型预测信息，比如之前得到的<code>yhatprob</code>就是连续的预测值。对于这样的预测结果，ROC曲线是一个通用评估方法。该方法确定一个有效的阈值，超过这个阈值的观测被标注为某类。比如所有<code>yhatprob</code>&gt;0.9的样本都判定为风格类。ROC曲线是基于灵敏度和特异度这两个统计量。考虑之前展示的二分类情况的混淆矩阵。模型的灵敏度为在所有真实观测到“发生”的样本中被准确预测为“发生”的比率：</p>
<p><span class="math display">\[灵敏度=\frac{正确预测为“发生”的样本数目}{观测到“发生”的样本数目}=\frac{TP}{TP+FN}\]</span></p>
<p>特异度指的是观测到“不发生”的样本中准确预测为“不发生”的比率：</p>
<p><span class="math display">\[特异度=\frac{正确预测为“不发生”的样本数目}{观测到“不发生”的样本数目}=\frac{TN}{TN+FP}\]</span></p>
<p>灵敏度也称为真阳性率，特异度也称为真阴性率。“1-特异度”为假阳性率。灵敏度和特异度对应的分母是固定的，当模型将更多样本判定为“发生”时，对应的灵敏度会增加，特异度会降低。根据不同错误类型导致的损失，通常需要建模者在灵敏度和特异度之间做出权衡。ROC曲线是权衡这二者的一个有效工具。ROC曲线是通过设定一系列预测结果阈值，得到相应的真阳性率（灵敏度）和假阳性率（1-特异度）绘制成的曲线。我们得到的关于农场疫情爆发预测概率结果<code>yhatprob</code>为例，展示如何用<code>rROC</code>包中的相应函数得到ROC曲线和相关统计量。<code>yhatprob</code>中的第2列代表将样本判定为疫情爆发的概率，其两列相加和为1。我们可以使用函数<code>roc()</code>得到相应的ROC对象<code>rocCurve</code>。然后将不同的函数应用在该对象上得到相应的图形结果或者统计量。下面的代码可以用来得到ROC曲线：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pROC)
rocCurve&lt;-<span class="kw">roc</span>(<span class="dt">response=</span>yTest,<span class="dt">predictor=</span>yhatprob[,<span class="dv">2</span>])
<span class="kw">plot</span>(rocCurve,<span class="dt">legacy.axes=</span>T)</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<pre><code>## 
## Call:
## roc.default(response = yTest, predictor = yhatprob[, 2])
## 
## Data: yhatprob[, 2] in 71 controls (yTest 0) &lt; 89 cases (yTest 1).
## Area under the curve: 0.8083</code></pre>
<p>其中<code>roc()</code>函数中的第一个参数<code>response</code>是真实观测值，<code>predictor</code>是连续预测结果，这里赋予的是判定为爆发的预测概率。ROC曲线的横坐标是1-特异度，纵坐标是灵敏度。一个完美的模型能完全区分两个类，灵敏度和特异度均为100%。从图形上看，ROC曲线为通过(0,0)和(1,1)的曲线。完美模型对应的曲线还通过(0,1)点，对应的曲线下面积为1。完全无效的模型对应的曲线趋近于45度对角线，曲线下面积为0.5。可以将不同模型结果对应的ROC曲线放在一张图中，直观对比模型效果。或者通过曲线下面积（AUC）量化比较模型，对应面积越大的模型越有效。DeLong等提出了基于U统计量的估计和比较AUC的方法<span class="citation">(E.R. DeLong <a href="#ref-delong1988">1988</a>)</span>，也可以通过bootstrap得到AUC的置信区间<span class="citation">(Hall P <a href="#ref-hall2004">2004</a>)</span>。</p>
<p>在R中，我们可以通过如下代码得到基于DeLong提出的非参方法得到的AUC的估计和置信区间：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 得到AUC的估计</span>
<span class="kw">auc</span>(rocCurve)</code></pre></div>
<pre><code>## Area under the curve: 0.8083</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># DeLong方法得到的AUC置信区间</span>
<span class="kw">ci.auc</span>(rocCurve)</code></pre></div>
<pre><code>## 95% CI: 0.7419-0.8746 (DeLong)</code></pre>
<p>ROC曲线和线下面积AUC是我最常用的评估分类模型的方式，由于它是灵敏度和特异度的函数，对类失衡有抗性<span class="citation">(Provost F <a href="#ref-Provost1998">1998</a>; T <a href="#ref-Fawcett2006">2006</a>)</span>。用AUC和其它单一度量类似，在用某个量总结曲线时会带来信息的损失，因为很可能没有某条曲线一致好于其它的曲线（曲线交叉）。如果我们对曲线特定的区域感兴趣，可以直接比较曲线。如果我们关心的是ROC曲线低的一端，可以使用ROC曲线下局部面积度量<span class="citation">(D <a href="#ref-McClish1989">1989</a>)</span>，该度量关注曲线特定部分。ROC曲线主要针对二分类定义，但之后不同人将其扩展到多分类的情况<span class="citation">(Hand D <a href="#ref-Hand2001">2001</a>; Lachiche N <a href="#ref-Lachiche2003">2003</a>; Li J <a href="#ref-Li2008">2008</a>)</span>。</p>
</div>
<div id="section-8.2.3" class="section level3">
<h3><span class="header-section-number">8.2.3</span> 提升图</h3>
<p>除了数值度量以外，还有一些对分类结果评估的可视化工具，如提升图。提升图以图形的形式表示模型预测比随机预测相比带来的改进，根据“提升”分数来选择模型，或者确定应该将数据中多大比例的样本视为目标群体可以从模型预测结果中获益。这样抽象的描述很难让大家理解提升图。因此我们将其放在应用的语境下。我们用猪场疫情数据为例。之前我们在训练集上训练随机森林模型，然后将模型应用在含有160个样本的测试集（<code>xTest</code>）上。我们对测试集样本的预测<code>yhatprob</code>来解释提升图。由于我们感兴趣的是疫情爆发的事件——<code>yhatprob</code>第二列（第一列是无疫情的概率）——我们将针对疫情爆发的连续概率预测存在一个新对象<code>modelscore</code>中。真实情况是有89个样本有疫情。如果我们将这160个样本按照模型预测分值<code>modelscore</code>从高到低排序，对于完美的模型，排序后的前89个样本应该正好就是那些疫情爆发的样本。当预测完全随机时，排序后前x％的样本中根据随机概率也该正好含有89个发生疫情的样本中的x％。提升图展示了通过模型预测排序筛选出的样本比随机样本对应目标类命中率的差别。</p>
<p>下面我们抽取了一些随机分值（<code>randomscore</code>），对其和模型预测结果（<code>modelscore</code>）绘制提升图，比较它们。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelscore&lt;-yhatprob[,<span class="dv">2</span>]
<span class="co"># 随机抽取一些分值</span>
randomscore&lt;-<span class="kw">rnorm</span>(<span class="kw">length</span>(yTest))
labs&lt;-<span class="kw">c</span>(<span class="dt">modelscore=</span><span class="st">&quot;Random Forest&quot;</span>,
        <span class="dt">randomscore=</span><span class="st">&quot;Random Number&quot;</span>)</code></pre></div>
<p>我们可以使用<code>caret</code>包中的<code>lift()</code>函数来绘制提升曲线。该函数用一个公式作为输入选项，公式左侧是真实类别，公式右侧是多个预测值。这里公式右侧是模型分值和随机分值：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">liftCurve&lt;-<span class="kw">lift</span>(yTest~modelscore+randomscore,<span class="dt">class=</span><span class="st">&quot;1&quot;</span>,<span class="dt">labels=</span>labs)</code></pre></div>
<p>为了绘制多条提升图，使用lattice包中的xyplot()函数：</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xyplot</span>(liftCurve,<span class="dt">auto.key=</span><span class="kw">list</span>(<span class="dt">columns=</span><span class="dv">2</span>,<span class="dt">lines=</span>T,<span class="dt">points=</span>F))</code></pre></div>
<p><img src="DS_R_files/figure-html/unnamed-chunk-92-1.png" width="672" /></p>
<p>提升图的横轴是累计样本百分比，纵轴是累计获取的目标类样本百分比。比如随机森林模型提升曲线上的点(6.25,11.24)表示：按照模型预测分值从高到低排序后的前6.25%的样本中含有160个疫情爆发样本中的0.1123596。和ROC曲线类似，我们可以通过比较不同模型的提升图来选择模型，曲线下面积也可作为模型效果的度量。此外我们也可能对曲线的某一部分特别感兴趣。比如在当前的例子中，如果判定一个农场在未来5年内可能爆发疫情，那么通常的措施是对该农场进行大规模的清洗消毒，这样的措施花费很高。假设我们只能对50%的农场进行清理，那么就该选择对应横坐标为50%，疫情爆发样本命中率最高的模型。在这个应用场景下，在支出预算一定时最大化效率。</p>
<!--

### 失衡数据

判别分析中可能遇到一个最大问题就是数据失衡。比如贷款客户风险分析就是如此，真正违约不还贷款的客户可能只有千分之一，这意味只要闭着眼将所有的客户都判定为无风险就能的到99.9%的准确率。在这样的情况下，数据中关于低频率事件的信息很少，因此模型很难准确预测这些事件，而这些低频率事件通常有事我们关心的（如违约，疾病爆发）。对于统计学习模型来说，最理想当然是平衡的数据，但 很遗憾，现实生活很少满足理论假设。下面我们就介绍几种能够在某种程度上缓解类失衡的方法。这里要指出一点，你只能得到数据包含的的东西。记得之前讲到两部分误差，系统误差和随机误差。你能够该井的只是系统误差，你无法超于数据中关于小频率事件信息的极限。下面要讲的方法只是在原基础上对模型进行一些修正。这里我只介绍二分类的问题，因为绝大多数都是二分类。
-->
</div>
</div>
<div id="-3" class="section level2">
<h2><span class="header-section-number">8.3</span> 本章总结</h2>
<p>本章探讨了模型评估的度量。在数据分析项目中，评估模型是非常重要的。掌握本章和上一章介绍的数据划分和再抽样技术就具备评估模型的技术能力了。这里关于分类模型评估有一个重要话题由于篇幅所限没有介绍，就是预测概率校准和处理类失衡的问题。对此话题感兴趣的读者可以参考Max Kuhn 和 Kjell Johnston的书《Applied Predictive Modeling》中的第11章<span class="citation">(Max Kuhn <a href="#ref-APM">2013</a>)</span>，这本书的中文版已于2016年5月由电子工业出版社出版。模型选择和评估要求分析师将模型放在具体项目语境下。这是体现科学和艺术结合的典型环节。我们在本书之后讲具体模型的时候会给出几个完整的案例分析，其中包括用之前讲到的这些建模技术进行模型选择。关于模型评估还要提两点：</p>
<ol style="list-style-type: decimal">
<li><p>尝试尽可能多的模型</p>
<p>当考虑该用什么模型解决某具体的问题时，应该考虑多个可能的模型。从最简单的模型开始直到你能达到的难度上限。真正尝试拟合模型时，根据个人喜好，你可以从最简单的模型开始，每拟合一次模型，对数据中变量关系的理解会有所加深，慢慢过渡到更加复杂的模型。或者从最复杂的模型开始，但要做好简化模型的准备，使得模型具有更强的解释性。实际应用中，你不知道什么模型对当前问题最有效，所以比较不同的模型对于一个合格的数据科学家来说是必须的。当然，这有一个隐藏的前提条件是你能够快速有效的拟合不同模型。如果你需要让计算机跑1个晚上的程序来拟合一个模型，尝试这样的模型不是一个好主意。</p></li>
<li><p>检查模型的稳定性</p>
<p>提高模型稳定性有各种可能的方法，收集更多的观测，除去冗余变量，如之前提到的近0方差变量和高度相关变量。检查模型拟合的稳定程度最常用的方法是再抽样。通过抽取不同的样本拟合相同的模型，然后查看拟合参数的变化范围。要是需要检查模型在某假设条件不满足的情况下的表现，可以通过模拟数据进行考察。</p></li>
</ol>
<p>最后我想用George Box的那句统计学界家喻户晓的名言结束这一章：</p>
<blockquote>
<p>所有模型都是错的，但其中有一些是有用的。(All models are wrong, but some are useful.)</p>
</blockquote>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-Provost1998">
<p>Provost F, Kohavi R, Fawcett T. 1998. “The Case Against Accuracy Esti- Mation for Comparing Induction Algorithms.” <em>Proceedings of the Fifteenth International Conference on Machine Learning</em>, 445–53.</p>
</div>
<div id="ref-Cohen1960">
<p>J, Cohen. 1960. “A Coefficient of Agreement for Nominal Data.” <em>Educational and Psychological Measurement</em> 20: 37–46.</p>
</div>
<div id="ref-landis1977">
<p>Landis JR, Koch GG. 1977. “The Measurement of Observer Agreement for Categorical Data.” <em>Biometrics</em> 33: 159–74.</p>
</div>
<div id="ref-delong1988">
<p>E.R. DeLong, D.L. Clarke-Pearson, D.M. DeLong. 1988. “Comparing the Areas Under Two or More Correlated Receiver Operating Characteristics Curves: A Nonparametric Approach.” <em>Biometrics</em> 44: 837–45.</p>
</div>
<div id="ref-hall2004">
<p>Hall P, Fan Y, Hyndman R. 2004. “Nonparametric Confidence Intervals for Receiver Operating Characteristic Curves.” <em>Biometrika</em> 91: 743–50.</p>
</div>
<div id="ref-Fawcett2006">
<p>T, Fawcett. 2006. “An Introduction to ROC Analysis.” <em>Pattern Recognition Letters</em> 27 (8): 861–74.</p>
</div>
<div id="ref-McClish1989">
<p>D, McClish. 1989. “Analyzing a Portion of the ROC Curve.” <em>Medical Decision Making</em> 9: 190–95.</p>
</div>
<div id="ref-Hand2001">
<p>Hand D, Till R. 2001. “A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems.” <em>Machine Learning</em> 45 (2): 171–86.</p>
</div>
<div id="ref-Lachiche2003">
<p>Lachiche N, Flach P. 2003. “Improving Accuracy and Cost of Two–Class and Multi–Class Probabilistic Classifiers Using ROC Curves.” <em>In ``Proceed- Ings of the Twentieth International Conference on Machine Learning</em> 20 (416–424).</p>
</div>
<div id="ref-Li2008">
<p>Li J, Fine JP. 2008. “ROC Analysis with Multiple Classes and Multiple Tests: Methodology and Its Application in Microarray Studies.” <em>Biostatistics</em> 9 (3): 566–76.</p>
</div>
<div id="ref-APM">
<p>Max Kuhn, Kjell Johnston. 2013. <em>Applied Predictive Modeling</em>. Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-9.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-moxingpinggu.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
