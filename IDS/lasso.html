<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.2 LASSO | Practitioner’s Guide to Data Science</title>
  <meta name="description" content="Introduction to Data Science" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="10.2 LASSO | Practitioner’s Guide to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.2 LASSO | Practitioner’s Guide to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li" />


<meta name="date" content="2023-02-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ridge-regression.html"/>
<link rel="next" href="elastic-net.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li><a href="index.html#preface" id="toc-preface">Preface</a>
<ul>
<li><a href="goal-of-the-book.html#goal-of-the-book" id="toc-goal-of-the-book">Goal of the Book</a></li>
<li><a href="what-this-book-covers.html#what-this-book-covers" id="toc-what-this-book-covers">What This Book Covers</a></li>
<li><a href="who-this-book-is-for.html#who-this-book-is-for" id="toc-who-this-book-is-for">Who This Book Is For</a></li>
<li><a href="how-to-use-this-book.html#how-to-use-this-book" id="toc-how-to-use-this-book">How to Use This Book</a>
<ul>
<li><a href="how-to-use-this-book.html#what-the-book-assumes" id="toc-what-the-book-assumes">What the Book Assumes</a></li>
<li><a href="how-to-use-this-book.html#how-to-run-r-and-python-code" id="toc-how-to-run-r-and-python-code">How to Run R and Python Code</a></li>
</ul></li>
<li><a href="complementary-reading.html#complementary-reading" id="toc-complementary-reading">Complementary Reading</a></li>
</ul></li>
<li><a href="about-the-authors.html#about-the-authors" id="toc-about-the-authors">About the Authors</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a>
<ul>
<li><a href="a-brief-history-of-data-science.html#a-brief-history-of-data-science" id="toc-a-brief-history-of-data-science"><span class="toc-section-number">1.1</span> A Brief History of Data Science</a></li>
<li><a href="data-science-role-and-skill-tracks.html#data-science-role-and-skill-tracks" id="toc-data-science-role-and-skill-tracks"><span class="toc-section-number">1.2</span> Data Science Role and Skill Tracks</a>
<ul>
<li><a href="data-science-role-and-skill-tracks.html#engineering" id="toc-engineering"><span class="toc-section-number">1.2.1</span> Engineering</a></li>
<li><a href="data-science-role-and-skill-tracks.html#analysis" id="toc-analysis"><span class="toc-section-number">1.2.2</span> Analysis</a></li>
<li><a href="data-science-role-and-skill-tracks.html#modelinginference" id="toc-modelinginference"><span class="toc-section-number">1.2.3</span> Modeling/Inference</a></li>
</ul></li>
<li><a href="what-kind-of-questions-can-data-science-solve.html#what-kind-of-questions-can-data-science-solve" id="toc-what-kind-of-questions-can-data-science-solve"><span class="toc-section-number">1.3</span> What Kind of Questions Can Data Science Solve?</a>
<ul>
<li><a href="what-kind-of-questions-can-data-science-solve.html#prerequisites" id="toc-prerequisites"><span class="toc-section-number">1.3.1</span> Prerequisites</a></li>
<li><a href="what-kind-of-questions-can-data-science-solve.html#problem-type" id="toc-problem-type"><span class="toc-section-number">1.3.2</span> Problem Type</a></li>
</ul></li>
<li><a href="structure-of-data-science-team.html#structure-of-data-science-team" id="toc-structure-of-data-science-team"><span class="toc-section-number">1.4</span> Structure of Data Science Team</a></li>
<li><a href="data-science-roles.html#data-science-roles" id="toc-data-science-roles"><span class="toc-section-number">1.5</span> Data Science Roles</a></li>
</ul></li>
<li><a href="SoftSkillsforDataScientists.html#SoftSkillsforDataScientists" id="toc-SoftSkillsforDataScientists"><span class="toc-section-number">2</span> Soft Skills for Data Scientists</a>
<ul>
<li><a href="comparison-between-statistician-and-data-scientist.html#comparison-between-statistician-and-data-scientist" id="toc-comparison-between-statistician-and-data-scientist"><span class="toc-section-number">2.1</span> Comparison between Statistician and Data Scientist</a></li>
<li><a href="beyond-data-and-analytics.html#beyond-data-and-analytics" id="toc-beyond-data-and-analytics"><span class="toc-section-number">2.2</span> Beyond Data and Analytics</a></li>
<li><a href="three-pillars-of-knowledge.html#three-pillars-of-knowledge" id="toc-three-pillars-of-knowledge"><span class="toc-section-number">2.3</span> Three Pillars of Knowledge</a></li>
<li><a href="data-science-project-cycle.html#data-science-project-cycle" id="toc-data-science-project-cycle"><span class="toc-section-number">2.4</span> Data Science Project Cycle</a>
<ul>
<li><a href="data-science-project-cycle.html#types-of-data-science-projects" id="toc-types-of-data-science-projects"><span class="toc-section-number">2.4.1</span> Types of Data Science Projects</a></li>
<li><a href="data-science-project-cycle.html#ProblemFormulationandProjectPlanningStage" id="toc-ProblemFormulationandProjectPlanningStage"><span class="toc-section-number">2.4.2</span> Problem Formulation and Project Planning Stage</a></li>
<li><a href="data-science-project-cycle.html#project-modeling-stage" id="toc-project-modeling-stage"><span class="toc-section-number">2.4.3</span> Project Modeling Stage</a></li>
<li><a href="data-science-project-cycle.html#ModelImplementationandPostProductionStage" id="toc-ModelImplementationandPostProductionStage"><span class="toc-section-number">2.4.4</span> Model Implementation and Post Production Stage</a></li>
<li><a href="data-science-project-cycle.html#ProjectCycleSummary" id="toc-ProjectCycleSummary"><span class="toc-section-number">2.4.5</span> Project Cycle Summary</a></li>
</ul></li>
<li><a href="common-mistakes-in-data-science.html#common-mistakes-in-data-science" id="toc-common-mistakes-in-data-science"><span class="toc-section-number">2.5</span> Common Mistakes in Data Science</a>
<ul>
<li><a href="common-mistakes-in-data-science.html#problem-formulation-stage" id="toc-problem-formulation-stage"><span class="toc-section-number">2.5.1</span> Problem Formulation Stage</a></li>
<li><a href="common-mistakes-in-data-science.html#project-planning-stage" id="toc-project-planning-stage"><span class="toc-section-number">2.5.2</span> Project Planning Stage</a></li>
<li><a href="common-mistakes-in-data-science.html#project-modeling-stage-1" id="toc-project-modeling-stage-1"><span class="toc-section-number">2.5.3</span> Project Modeling Stage</a></li>
<li><a href="common-mistakes-in-data-science.html#model-implementation-and-post-production-stage" id="toc-model-implementation-and-post-production-stage"><span class="toc-section-number">2.5.4</span> Model Implementation and Post Production Stage</a></li>
<li><a href="common-mistakes-in-data-science.html#summary-of-common-mistakes" id="toc-summary-of-common-mistakes"><span class="toc-section-number">2.5.5</span> Summary of Common Mistakes</a></li>
</ul></li>
</ul></li>
<li><a href="introduction-to-the-data.html#introduction-to-the-data" id="toc-introduction-to-the-data"><span class="toc-section-number">3</span> Introduction to The Data</a>
<ul>
<li><a href="customer-data-for-a-clothing-company.html#customer-data-for-a-clothing-company" id="toc-customer-data-for-a-clothing-company"><span class="toc-section-number">3.1</span> Customer Data for A Clothing Company</a></li>
<li><a href="swinediseasedata.html#swinediseasedata" id="toc-swinediseasedata"><span class="toc-section-number">3.2</span> Swine Disease Breakout Data</a></li>
<li><a href="mnist-dataset.html#mnist-dataset" id="toc-mnist-dataset"><span class="toc-section-number">3.3</span> MNIST Dataset</a></li>
<li><a href="imdb-dataset.html#imdb-dataset" id="toc-imdb-dataset"><span class="toc-section-number">3.4</span> IMDB Dataset</a></li>
</ul></li>
<li><a href="bigdatacloudplatform.html#bigdatacloudplatform" id="toc-bigdatacloudplatform"><span class="toc-section-number">4</span> Big Data Cloud Platform</a>
<ul>
<li><a href="power-of-cluster-of-computers.html#power-of-cluster-of-computers" id="toc-power-of-cluster-of-computers"><span class="toc-section-number">4.1</span> Power of Cluster of Computers</a></li>
<li><a href="evolution-of-cluster-computing.html#evolution-of-cluster-computing" id="toc-evolution-of-cluster-computing"><span class="toc-section-number">4.2</span> Evolution of Cluster Computing</a>
<ul>
<li><a href="evolution-of-cluster-computing.html#hadoop" id="toc-hadoop"><span class="toc-section-number">4.2.1</span> Hadoop</a></li>
<li><a href="evolution-of-cluster-computing.html#spark" id="toc-spark"><span class="toc-section-number">4.2.2</span> Spark</a></li>
</ul></li>
<li><a href="CloudEnvironment.html#CloudEnvironment" id="toc-CloudEnvironment"><span class="toc-section-number">4.3</span> Introduction of Cloud Environment</a>
<ul>
<li><a href="CloudEnvironment.html#open-account-and-create-a-cluster" id="toc-open-account-and-create-a-cluster"><span class="toc-section-number">4.3.1</span> Open Account and Create a Cluster</a></li>
<li><a href="CloudEnvironment.html#r-notebook" id="toc-r-notebook"><span class="toc-section-number">4.3.2</span> R Notebook</a></li>
<li><a href="CloudEnvironment.html#markdown-cells" id="toc-markdown-cells"><span class="toc-section-number">4.3.3</span> Markdown Cells</a></li>
</ul></li>
<li><a href="leveragesparkr.html#leveragesparkr" id="toc-leveragesparkr"><span class="toc-section-number">4.4</span> Leverage Spark Using R Notebook</a></li>
<li><a href="databases-and-sql.html#databases-and-sql" id="toc-databases-and-sql"><span class="toc-section-number">4.5</span> Databases and SQL</a>
<ul>
<li><a href="databases-and-sql.html#history" id="toc-history"><span class="toc-section-number">4.5.1</span> History</a></li>
<li><a href="databases-and-sql.html#database-table-and-view" id="toc-database-table-and-view"><span class="toc-section-number">4.5.2</span> Database, Table and View</a></li>
<li><a href="databases-and-sql.html#basic-sql-statement" id="toc-basic-sql-statement"><span class="toc-section-number">4.5.3</span> Basic SQL Statement</a></li>
<li><a href="databases-and-sql.html#advanced-topics-in-database" id="toc-advanced-topics-in-database"><span class="toc-section-number">4.5.4</span> Advanced Topics in Database</a></li>
</ul></li>
</ul></li>
<li><a href="datapreprocessing.html#datapreprocessing" id="toc-datapreprocessing"><span class="toc-section-number">5</span> Data Pre-processing</a>
<ul>
<li><a href="data-cleaning.html#data-cleaning" id="toc-data-cleaning"><span class="toc-section-number">5.1</span> Data Cleaning</a></li>
<li><a href="missing-values.html#missing-values" id="toc-missing-values"><span class="toc-section-number">5.2</span> Missing Values</a>
<ul>
<li><a href="missing-values.html#impute-missing-values-with-medianmode" id="toc-impute-missing-values-with-medianmode"><span class="toc-section-number">5.2.1</span> Impute missing values with median/mode</a></li>
<li><a href="missing-values.html#k-nearest-neighbors" id="toc-k-nearest-neighbors"><span class="toc-section-number">5.2.2</span> K-nearest neighbors</a></li>
<li><a href="missing-values.html#bagging-tree" id="toc-bagging-tree"><span class="toc-section-number">5.2.3</span> Bagging Tree</a></li>
</ul></li>
<li><a href="centering-and-scaling.html#centering-and-scaling" id="toc-centering-and-scaling"><span class="toc-section-number">5.3</span> Centering and Scaling</a></li>
<li><a href="resolve-skewness.html#resolve-skewness" id="toc-resolve-skewness"><span class="toc-section-number">5.4</span> Resolve Skewness</a></li>
<li><a href="outliers.html#outliers" id="toc-outliers"><span class="toc-section-number">5.5</span> Resolve Outliers</a></li>
<li><a href="collinearity.html#collinearity" id="toc-collinearity"><span class="toc-section-number">5.6</span> Collinearity</a></li>
<li><a href="sparse-variables.html#sparse-variables" id="toc-sparse-variables"><span class="toc-section-number">5.7</span> Sparse Variables</a></li>
<li><a href="re-encode-dummy-variables.html#re-encode-dummy-variables" id="toc-re-encode-dummy-variables"><span class="toc-section-number">5.8</span> Re-encode Dummy Variables</a></li>
</ul></li>
<li><a href="datawrangline.html#datawrangline" id="toc-datawrangline"><span class="toc-section-number">6</span> Data Wrangling</a>
<ul>
<li><a href="summarize-data.html#summarize-data" id="toc-summarize-data"><span class="toc-section-number">6.1</span> Summarize Data</a>
<ul>
<li><a href="summarize-data.html#dplyr-package" id="toc-dplyr-package"><span class="toc-section-number">6.1.1</span> <code>dplyr</code> package</a></li>
<li><a href="summarize-data.html#applyfamilyinbaser" id="toc-applyfamilyinbaser"><span class="toc-section-number">6.1.2</span> <code>apply()</code>, <code>lapply()</code> and <code>sapply()</code> in base R</a></li>
</ul></li>
<li><a href="tidy-and-reshape-data.html#tidy-and-reshape-data" id="toc-tidy-and-reshape-data"><span class="toc-section-number">6.2</span> Tidy and Reshape Data</a></li>
</ul></li>
<li><a href="modeltuningstrategy.html#modeltuningstrategy" id="toc-modeltuningstrategy"><span class="toc-section-number">7</span> Model Tuning Strategy</a>
<ul>
<li><a href="vbtradeoff.html#vbtradeoff" id="toc-vbtradeoff"><span class="toc-section-number">7.1</span> Variance-Bias Trade-Off</a></li>
<li><a href="datasplittingresampling.html#datasplittingresampling" id="toc-datasplittingresampling"><span class="toc-section-number">7.2</span> Data Splitting and Resampling</a>
<ul>
<li><a href="datasplittingresampling.html#datasplitting" id="toc-datasplitting"><span class="toc-section-number">7.2.1</span> Data Splitting</a></li>
<li><a href="datasplittingresampling.html#resampling" id="toc-resampling"><span class="toc-section-number">7.2.2</span> Resampling</a></li>
</ul></li>
</ul></li>
<li><a href="measuring-performance.html#measuring-performance" id="toc-measuring-performance"><span class="toc-section-number">8</span> Measuring Performance</a>
<ul>
<li><a href="regression-model-performance.html#regression-model-performance" id="toc-regression-model-performance"><span class="toc-section-number">8.1</span> Regression Model Performance</a></li>
<li><a href="classification-model-performance.html#classification-model-performance" id="toc-classification-model-performance"><span class="toc-section-number">8.2</span> Classification Model Performance</a>
<ul>
<li><a href="classification-model-performance.html#confusion-matrix" id="toc-confusion-matrix"><span class="toc-section-number">8.2.1</span> Confusion Matrix</a></li>
<li><a href="classification-model-performance.html#kappa-statistic" id="toc-kappa-statistic"><span class="toc-section-number">8.2.2</span> Kappa Statistic</a></li>
<li><a href="classification-model-performance.html#roc" id="toc-roc"><span class="toc-section-number">8.2.3</span> ROC</a></li>
<li><a href="classification-model-performance.html#gain-and-lift-charts" id="toc-gain-and-lift-charts"><span class="toc-section-number">8.2.4</span> Gain and Lift Charts</a></li>
</ul></li>
</ul></li>
<li><a href="regression-models.html#regression-models" id="toc-regression-models"><span class="toc-section-number">9</span> Regression Models</a>
<ul>
<li><a href="ordinary-least-square.html#ordinary-least-square" id="toc-ordinary-least-square"><span class="toc-section-number">9.1</span> Ordinary Least Square</a>
<ul>
<li><a href="ordinary-least-square.html#the-magic-p-value" id="toc-the-magic-p-value"><span class="toc-section-number">9.1.1</span> The Magic P-value</a></li>
<li><a href="ordinary-least-square.html#diagnostics-for-linear-regression" id="toc-diagnostics-for-linear-regression"><span class="toc-section-number">9.1.2</span> Diagnostics for Linear Regression</a></li>
</ul></li>
<li><a href="principal-component-regression-and-partial-least-square.html#principal-component-regression-and-partial-least-square" id="toc-principal-component-regression-and-partial-least-square"><span class="toc-section-number">9.2</span> Principal Component Regression and Partial Least Square</a></li>
</ul></li>
<li><a href="regularization-methods.html#regularization-methods" id="toc-regularization-methods"><span class="toc-section-number">10</span> Regularization Methods</a>
<ul>
<li><a href="ridge-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">10.1</span> Ridge Regression</a></li>
<li><a href="lasso.html#lasso" id="toc-lasso"><span class="toc-section-number">10.2</span> LASSO</a></li>
<li><a href="elastic-net.html#elastic-net" id="toc-elastic-net"><span class="toc-section-number">10.3</span> Elastic Net</a></li>
<li><a href="penalized-generalized-linear-model.html#penalized-generalized-linear-model" id="toc-penalized-generalized-linear-model"><span class="toc-section-number">10.4</span> Penalized Generalized Linear Model</a>
<ul>
<li><a href="penalized-generalized-linear-model.html#introduction-to-glmnet-package" id="toc-introduction-to-glmnet-package"><span class="toc-section-number">10.4.1</span> Introduction to <code>glmnet</code> package</a></li>
<li><a href="penalized-generalized-linear-model.html#penalized-logistic-regression" id="toc-penalized-logistic-regression"><span class="toc-section-number">10.4.2</span> Penalized logistic regression</a></li>
</ul></li>
</ul></li>
<li><a href="treemodel.html#treemodel" id="toc-treemodel"><span class="toc-section-number">11</span> Tree-Based Methods</a>
<ul>
<li><a href="tree-basics.html#tree-basics" id="toc-tree-basics"><span class="toc-section-number">11.1</span> Tree Basics</a></li>
<li><a href="splitting-criteria.html#splitting-criteria" id="toc-splitting-criteria"><span class="toc-section-number">11.2</span> Splitting Criteria</a>
<ul>
<li><a href="splitting-criteria.html#gini-impurity" id="toc-gini-impurity"><span class="toc-section-number">11.2.1</span> Gini impurity</a></li>
<li><a href="splitting-criteria.html#information-gain-ig" id="toc-information-gain-ig"><span class="toc-section-number">11.2.2</span> Information Gain (IG)</a></li>
<li><a href="splitting-criteria.html#information-gain-ratio-igr" id="toc-information-gain-ratio-igr"><span class="toc-section-number">11.2.3</span> Information Gain Ratio (IGR)</a></li>
<li><a href="splitting-criteria.html#sum-of-squared-error-sse" id="toc-sum-of-squared-error-sse"><span class="toc-section-number">11.2.4</span> Sum of Squared Error (SSE)</a></li>
</ul></li>
<li><a href="tree-pruning.html#tree-pruning" id="toc-tree-pruning"><span class="toc-section-number">11.3</span> Tree Pruning</a></li>
<li><a href="regression-and-decision-tree-basic.html#regression-and-decision-tree-basic" id="toc-regression-and-decision-tree-basic"><span class="toc-section-number">11.4</span> Regression and Decision Tree Basic</a>
<ul>
<li><a href="regression-and-decision-tree-basic.html#regression-tree" id="toc-regression-tree"><span class="toc-section-number">11.4.1</span> Regression Tree</a></li>
<li><a href="regression-and-decision-tree-basic.html#decision-tree" id="toc-decision-tree"><span class="toc-section-number">11.4.2</span> Decision Tree</a></li>
</ul></li>
<li><a href="bagging-tree-1.html#bagging-tree-1" id="toc-bagging-tree-1"><span class="toc-section-number">11.5</span> Bagging Tree</a></li>
<li><a href="random-forest.html#random-forest" id="toc-random-forest"><span class="toc-section-number">11.6</span> Random Forest</a></li>
<li><a href="gradient-boosted-machine.html#gradient-boosted-machine" id="toc-gradient-boosted-machine"><span class="toc-section-number">11.7</span> Gradient Boosted Machine</a>
<ul>
<li><a href="gradient-boosted-machine.html#adaptive-boosting" id="toc-adaptive-boosting"><span class="toc-section-number">11.7.1</span> Adaptive Boosting</a></li>
<li><a href="gradient-boosted-machine.html#stochastic-gradient-boosting" id="toc-stochastic-gradient-boosting"><span class="toc-section-number">11.7.2</span> Stochastic Gradient Boosting</a></li>
</ul></li>
</ul></li>
<li><a href="deeplearning.html#deeplearning" id="toc-deeplearning"><span class="toc-section-number">12</span> Deep Learning</a>
<ul>
<li><a href="feedforward-neural-network.html#feedforward-neural-network" id="toc-feedforward-neural-network"><span class="toc-section-number">12.1</span> Feedforward Neural Network</a>
<ul>
<li><a href="feedforward-neural-network.html#logisticregasneuralnetwork" id="toc-logisticregasneuralnetwork"><span class="toc-section-number">12.1.1</span> Logistic Regression as Neural Network</a></li>
<li><a href="feedforward-neural-network.html#stochastic-gradient-descent" id="toc-stochastic-gradient-descent"><span class="toc-section-number">12.1.2</span> Stochastic Gradient Descent</a></li>
<li><a href="feedforward-neural-network.html#deepneuralnetwork" id="toc-deepneuralnetwork"><span class="toc-section-number">12.1.3</span> Deep Neural Network</a></li>
<li><a href="feedforward-neural-network.html#activationfunction" id="toc-activationfunction"><span class="toc-section-number">12.1.4</span> Activation Function</a></li>
<li><a href="feedforward-neural-network.html#optimization" id="toc-optimization"><span class="toc-section-number">12.1.5</span> Optimization</a></li>
<li><a href="feedforward-neural-network.html#deal-with-overfitting" id="toc-deal-with-overfitting"><span class="toc-section-number">12.1.6</span> Deal with Overfitting</a></li>
<li><a href="feedforward-neural-network.html#ffnnexample" id="toc-ffnnexample"><span class="toc-section-number">12.1.7</span> Image Recognition Using FFNN</a></li>
</ul></li>
<li><a href="convolutional-neural-network.html#convolutional-neural-network" id="toc-convolutional-neural-network"><span class="toc-section-number">12.2</span> Convolutional Neural Network</a>
<ul>
<li><a href="convolutional-neural-network.html#convolution-layer" id="toc-convolution-layer"><span class="toc-section-number">12.2.1</span> Convolution Layer</a></li>
<li><a href="convolutional-neural-network.html#padding-layer" id="toc-padding-layer"><span class="toc-section-number">12.2.2</span> Padding Layer</a></li>
<li><a href="convolutional-neural-network.html#pooling-layer" id="toc-pooling-layer"><span class="toc-section-number">12.2.3</span> Pooling Layer</a></li>
<li><a href="convolutional-neural-network.html#convolution-over-volume" id="toc-convolution-over-volume"><span class="toc-section-number">12.2.4</span> Convolution Over Volume</a></li>
<li><a href="convolutional-neural-network.html#cnnexample" id="toc-cnnexample"><span class="toc-section-number">12.2.5</span> Image Recognition Using CNN</a></li>
</ul></li>
<li><a href="recurrent-neural-network.html#recurrent-neural-network" id="toc-recurrent-neural-network"><span class="toc-section-number">12.3</span> Recurrent Neural Network</a>
<ul>
<li><a href="recurrent-neural-network.html#rnn-model" id="toc-rnn-model"><span class="toc-section-number">12.3.1</span> RNN Model</a></li>
<li><a href="recurrent-neural-network.html#lstm" id="toc-lstm"><span class="toc-section-number">12.3.2</span> Long Short Term Memory</a></li>
<li><a href="recurrent-neural-network.html#embedding" id="toc-embedding"><span class="toc-section-number">12.3.3</span> Word Embedding</a></li>
<li><a href="recurrent-neural-network.html#rnnexample" id="toc-rnnexample"><span class="toc-section-number">12.3.4</span> Sentiment Analysis Using RNN</a></li>
</ul></li>
</ul></li>
<li><a href="appendix.html#appendix" id="toc-appendix">Appendix</a></li>
<li><a href="largelocaldata.html#largelocaldata" id="toc-largelocaldata"><span class="toc-section-number">13</span> Handling Large Local Data</a>
<ul>
<li><a href="readr.html#readr" id="toc-readr"><span class="toc-section-number">13.1</span> <code>readr</code></a></li>
<li><a href="data.table-enhanced-data.html#data.table-enhanced-data.frame" id="toc-data.table-enhanced-data.frame"><span class="toc-section-number">13.2</span> <code>data.table</code>— enhanced <code>data.frame</code></a></li>
</ul></li>
<li><a href="r-code-for-data-simulation.html#r-code-for-data-simulation" id="toc-r-code-for-data-simulation"><span class="toc-section-number">14</span> R code for data simulation</a>
<ul>
<li><a href="appendixdata1.html#appendixdata1" id="toc-appendixdata1"><span class="toc-section-number">14.1</span> Customer Data for Clothing Company</a></li>
<li><a href="appendixdata3.html#appendixdata3" id="toc-appendixdata3"><span class="toc-section-number">14.2</span> Swine Disease Breakout Data</a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Practitioner’s Guide to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lasso" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> LASSO<a href="lasso.html#lasso" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Even though the ridge regression shrinks the parameter estimates towards 0, it won’t shink any estimates to be exactly 0 which means it includes all predictors in the final model. So it can’t select variables. It may not be a problem for prediction but it is a huge disadvantage if you want to interpret the model especially when the number of variables is large. A popular alternative to the ridge penalty is the <strong>Least Absolute Shrinkage and Selection Operator</strong> (LASSO) <span class="citation">(<a href="#ref-Tibshirani1996" role="doc-biblioref">R 1996</a>)</span>.</p>
<p>Similar to ridge regression, lasso adds a penalty. The lasso coefficients <span class="math inline">\(\hat{\beta}_{\lambda}^{L}\)</span> minimize the following:</p>
<p><span class="math display" id="eq:lasso">\[\begin{equation}
\Sigma_{i=1}^{n}(y_{i}-\beta_{0}-\Sigma_{j=1}^{p}\beta_{j}x_{ij})^{2}+\lambda\Sigma_{j=1}^{p}|\beta_{j}|=RSS+\lambda\Sigma_{j=1}^{p}|\beta_{j}|
\tag{10.2}
\end{equation}\]</span></p>
<p>The only difference between lasso and ridge is the penalty. In statistical parlance, ridge uses <span class="math inline">\(L_2\)</span> penalty (<span class="math inline">\(\beta_{j}^{2}\)</span>) and lasso uses <span class="math inline">\(L_1\)</span> penalty (<span class="math inline">\(|\beta_{j}|\)</span>). <span class="math inline">\(L_1\)</span> penalty can shrink the estimates to 0 when <span class="math inline">\(\lambda\)</span> is big enough. So lasso can be used as a feature selection tool. It is a huge advantage because it leads to a more explainable model.</p>
<p>Similar to other models with tuning parameters, lasso regression requires cross-validation to tune the parameter. You can use <code>train()</code> in a similar way as we showed in the ridge regression section. To tune parameter, we need to set cross-validation and parameter range. Also, it is advised to standardize the predictors:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="lasso.html#cb238-1" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb238-2"><a href="lasso.html#cb238-2" aria-hidden="true" tabindex="-1"></a>lassoGrid <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fraction =</span> <span class="fu">seq</span>(.<span class="dv">8</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">20</span>))</span>
<span id="cb238-3"><a href="lasso.html#cb238-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb238-4"><a href="lasso.html#cb238-4" aria-hidden="true" tabindex="-1"></a>lassoTune <span class="ot">&lt;-</span> <span class="fu">train</span>(trainx, trainy,</span>
<span id="cb238-5"><a href="lasso.html#cb238-5" aria-hidden="true" tabindex="-1"></a>                      <span class="do">## set the method to be lasso</span></span>
<span id="cb238-6"><a href="lasso.html#cb238-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">method =</span> <span class="st">&quot;lars&quot;</span>,</span>
<span id="cb238-7"><a href="lasso.html#cb238-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">tuneGrid =</span> lassoGrid,</span>
<span id="cb238-8"><a href="lasso.html#cb238-8" aria-hidden="true" tabindex="-1"></a>                      <span class="at">trControl =</span> ctrl,</span>
<span id="cb238-9"><a href="lasso.html#cb238-9" aria-hidden="true" tabindex="-1"></a>                      <span class="do">## standardize the predictors</span></span>
<span id="cb238-10"><a href="lasso.html#cb238-10" aria-hidden="true" tabindex="-1"></a>                      <span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span>
<span id="cb238-11"><a href="lasso.html#cb238-11" aria-hidden="true" tabindex="-1"></a>lassoTune</span></code></pre></div>
<pre><code>## Least Angle Regression 
## 
## 999 samples
##  10 predictor
## 
## Pre-processing: centered (10), scaled (10) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 899, 899, 899, 899, 899, 900, ... 
## Resampling results across tuning parameters:
## 
##   fraction  RMSE  Rsquared  MAE  
##   0.8000    1763  0.7921    787.5
##   0.8105    1760  0.7924    784.1
##   0.8211    1758  0.7927    780.8
##   0.8316    1756  0.7930    777.7
##   0.8421    1754  0.7933    774.6
##   0.8526    1753  0.7936    771.8
##   0.8632    1751  0.7939    769.1
##   0.8737    1749  0.7942    766.6
##   0.8842    1748  0.7944    764.3
##   0.8947    1746  0.7947    762.2
##   0.9053    1745  0.7949    760.1
##   0.9158    1744  0.7951    758.3
##   0.9263    1743  0.7952    756.7
##   0.9368    1743  0.7953    755.5
##   0.9474    1742  0.7954    754.5
##   0.9579    1742  0.7954    754.0
##   0.9684    1742  0.7954    753.6
##   0.9789    1743  0.7953    753.4
##   0.9895    1743  0.7953    753.5
##   1.0000    1744  0.7952    754.0
## 
## RMSE was used to select the optimal model using
##  the smallest value.
## The final value used for the model was fraction
##  = 0.9579.</code></pre>
<p>The results show that the best value of the tuning parameter (<code>fraction</code> from the output) is 0.957 and the RMSE and <span class="math inline">\(R^{2}\)</span> are 1742 and 0.7954 correspondingly. The performance is nearly the same with ridge regression. You can see from the figure <a href="lasso.html#fig:lassoregtune">10.2</a>, as the <span class="math inline">\(\lambda\)</span> increase, the RMSE first decreases and then increases.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="lasso.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lassoTune)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lassoregtune"></span>
<img src="IDS_files/figure-html/lassoregtune-1.svg" alt="Test mean squared error for the lasso regression" width="80%" />
<p class="caption">
FIGURE 10.2: Test mean squared error for the lasso regression
</p>
</div>
<p>Once you select a value for tuning parameter, there are different functions to fit lasso regression, such as <code>lars()</code> in <code>lars</code>, <code>enet()</code> in <code>elasticnet</code>, <code>glmnet()</code> in <code>glmnet</code>. They all have very similar syntax.</p>
<p>Here we continue using <code>enet()</code>. The syntax is similar to ridge regression. The only difference is that you need to set <code>lambda = 0</code> because the argument <code>lambda</code> here is to control the ridge penalty. When it is 0, the function will return the lasso model object.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="lasso.html#cb241-1" aria-hidden="true" tabindex="-1"></a>lassoModel <span class="ot">&lt;-</span> <span class="fu">enet</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(trainx), <span class="at">y =</span> trainy, </span>
<span id="cb241-2"><a href="lasso.html#cb241-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">lambda =</span> <span class="dv">0</span>, <span class="at">normalize =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Set the fraction value to be 0.957 (the value we got above):</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="lasso.html#cb242-1" aria-hidden="true" tabindex="-1"></a>lassoFit <span class="ot">&lt;-</span> <span class="fu">predict</span>(lassoModel, <span class="at">newx =</span> <span class="fu">as.matrix</span>(trainx), </span>
<span id="cb242-2"><a href="lasso.html#cb242-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">s =</span> <span class="fl">0.957</span>, <span class="at">mode =</span> <span class="st">&quot;fraction&quot;</span>, <span class="at">type =</span> <span class="st">&quot;fit&quot;</span>)</span></code></pre></div>
<p>Again by setting <code>type = "fit"</code>, the above returns a list object. The <code>fit</code> item has the predictions:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="lasso.html#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(lassoFit<span class="sc">$</span>fit)</span></code></pre></div>
<pre><code>##      1      2      3      4      5      6 
## 1357.3  300.5  690.2 1228.2  838.4 1010.1</code></pre>
<p>You need to set <code>type = "coefficients"</code> to get parameter estimates:</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="lasso.html#cb245-1" aria-hidden="true" tabindex="-1"></a>lassoCoef <span class="ot">&lt;-</span> <span class="fu">predict</span>(lassoModel, </span>
<span id="cb245-2"><a href="lasso.html#cb245-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">newx =</span> <span class="fu">as.matrix</span>(trainx), </span>
<span id="cb245-3"><a href="lasso.html#cb245-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">s =</span> <span class="fl">0.95</span>, </span>
<span id="cb245-4"><a href="lasso.html#cb245-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mode =</span> <span class="st">&quot;fraction&quot;</span>, </span>
<span id="cb245-5"><a href="lasso.html#cb245-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type =</span> <span class="st">&quot;coefficients&quot;</span>)</span></code></pre></div>
<p>It also returns a list and the estimates are in the <code>coefficients</code> item:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="lasso.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="co"># didn&#39;t show the results</span></span>
<span id="cb246-2"><a href="lasso.html#cb246-2" aria-hidden="true" tabindex="-1"></a>LassoCoef <span class="ot">=</span> lassoCoef<span class="sc">$</span>coefficients</span></code></pre></div>
<p>Many researchers applied lasso to other learning methods, such as linear discriminant analysis <span class="citation">(<a href="#ref-Clem2011" role="doc-biblioref">Line Clemmensen and Ersbøll 2011</a>)</span>, partial least squares regression<span class="citation">(<a href="#ref-chun2010" role="doc-biblioref">Chun and Keleş 2010</a>)</span>. However, since the <span class="math inline">\(L_1\)</span> norm is not differentiable, optimization for lasso regression is more complicated. People come up with different algorithms to solve the computation problem. The biggest breakthrough is Least Angle Regression (LARS) from Bradley Efron etc. This algorithm works well for lasso regression especially when the dimension is high.</p>
<!--
## Variable selection property of the lasso

You may ask why lasso ($L_1$ penalty) has the feature selection property but not the ridge ($L_2$ penalty). To answer that question, let's look at the alternative representations of the optimization problem for lasso and ridge.  For lasso regression, it is identical to optimize the following two functions:

\begin{equation}
\Sigma_{i=1}^{n}(y_{i}-\beta_{0}-\Sigma_{j=1}^{p}\beta_{j}x_{ij})^{2}+\lambda\Sigma_{j=1}^{p}|\beta_{j}|=RSS+\lambda\Sigma_{j=1}^{p}|\beta_{j}|
(\#eq:lasso1)
\end{equation}

\begin{equation}
\underset{\beta}{min}\left\{ \Sigma_{i=1}^{n}\left(y_{i}-\beta_{0}-\Sigma_{j=1}^{p}\beta_{j}x_{ij}\right)^{2}\right\} ,\ \Sigma_{j=1}^{p}|\beta_{j}|\leq s
(\#eq:lasso2)
\end{equation}

For any value of tuning parameter $\lambda$, there exists a $s$ such that the coefficient estimates optimize equation \@ref(eq:lasso1) also optimize equation \@ref(eq:lasso2). Similarly, for ridge regression, the two representations are identical: 

\begin{equation}
\Sigma_{i=1}^{n}(y_{i}-\beta_{0}-\Sigma_{j=1}^{p}\beta_{j}x_{ij})^{2}+\lambda\Sigma_{j=1}^{p}\beta_{j}^{2}=RSS+\lambda\Sigma_{j=1}^{p}\beta_{j}^{2}
(\#eq:ridge1)
\end{equation}

\begin{equation}
\underset{\beta}{min}\left\{ \Sigma_{i=1}^{n}\left(y_{i}-\beta_{0}-\Sigma_{j=1}^{p}\beta_{j}x_{ij}\right)^{2}\right\} ,\ \Sigma_{j=1}^{p}\beta_{j}^{2}\leq s
(\#eq:ridge2)
\end{equation}

When $p＝2$, lasso estimates ($\hat{\beta}_{lasso}$ in figure \@ref(fig:lassoridge)) have the smallest RSS among all points that satisfy $|\beta*{1}|+|\beta_{2}|\leq s$ (i.e. within the diamond in figure \@ref(fig:lassoridge)). Ridge estimates have the smallest RSS among all points that satisfy $\beta_{1}^{2}+\beta_{2}^{2}\leq s$ (i.e. within the circle in figure \@ref(fig:lassoridge)). As s increases, the diamond and circle regions expand and get less restrictive. If s is large enough, the restrictive region will cover the least squares estimate ($\hat{\beta}_{LSE}$). Then, equations \@ref(eq:lasso2) and \@ref(eq:ridge2) will simply yield the least squares estimate. In contrast, if s is small, the grey region in figure \@ref(fig:lassoridge) will be small and hence restrict the magnitude of $\beta$. With the alternative formulations, we can answer the question of feature selection property.

<div class="figure" style="text-align: center">
<img src="images/LassoRidge.png" alt="Contours of the RSS and constrain functions for the lasso (left) and ridge regression (right)" width="100%" />
<p class="caption">(\#fig:lassoridge)Contours of the RSS and constrain functions for the lasso (left) and ridge regression (right)</p>
</div>

Figure \@ref(fig:lassoridge) illustrates the situations for lasso (left) and ridge (right). The least square estimate is marked as $\hat{\beta}$. The restrictive regions are in grey, the diamond region is for the lasso, the circle region is for the ridge. The least square estimates lie outside the grey region, so they are different from the lasso and ridge estimates. The ellipses centered around $\hat{\beta}$ represent contours of RSS. All the points on a given ellipse share an RSS. As the ellipses expand, the RSS increases. The lasso and ridge estimates are the first points at which an ellipse contracts the grey region. Since ridge regression has a circular restrictive region that doesn't have a sharp point, the intersecting point can't drop on the axis. But it is possible for lasso since it has corners at each of the axes.   When the intersecting point is on an axis, one of the parameter estimates is 0. If p > 2, the restrictive regions become sphere or hypersphere. In that case, when the intersecting point drops on an axis, multiple coefficient estimates can equal 0 simultaneously.
-->
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-chun2010" class="csl-entry">
Chun, Hyonho, and Sündüz Keleş. 2010. <span>“Sparse Partial Least Squares Regression for Simultaneous Dimension Reduction and Variable Selection.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 72 (1): 3–25.
</div>
<div id="ref-Clem2011" class="csl-entry">
Line Clemmensen, Daniela Witten, Trevor Hastie, and Bjarne Ersbøll. 2011. <span>“Sparse Discriminant Analysis.”</span> <em>Technometrics</em> 53 (4): 406–13.
</div>
<div id="ref-Tibshirani1996" class="csl-entry">
R, Tibshirani. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society Series B (Methodological)</em> 58 (1): 267–88.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ridge-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="elastic-net.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/10-Regularization.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
