<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="Introduction to Data Science">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li">


<meta name="date" content="2019-04-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="classification-model-performance.html">
<link rel="next" href="splitting-criteria.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="goal-of-the-book.html"><a href="goal-of-the-book.html"><i class="fa fa-check"></i>Goal of the Book</a></li>
<li class="chapter" data-level="" data-path="who-this-book-is-for.html"><a href="who-this-book-is-for.html"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="what-this-book-covers.html"><a href="what-this-book-covers.html"><i class="fa fa-check"></i>What This Book Covers</a></li>
<li class="chapter" data-level="" data-path="conventions.html"><a href="conventions.html"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html"><i class="fa fa-check"></i><b>1.1</b> Blind men and an elephant</a><ul>
<li class="chapter" data-level="1.1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html#data-science-roleskill-tracks"><i class="fa fa-check"></i><b>1.1.1</b> Data science role/skill tracks</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html"><i class="fa fa-check"></i><b>1.2</b> What should data science do?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#lets-dream-big"><i class="fa fa-check"></i><b>1.2.1</b> Let’s dream big</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#what-kind-of-questions-can-data-science-solve"><i class="fa fa-check"></i><b>1.2.2</b> What kind of questions can data science solve?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-the-data.html"><a href="introduction-to-the-data.html"><i class="fa fa-check"></i><b>2</b> Introduction to the data</a><ul>
<li class="chapter" data-level="2.1" data-path="customer-data-for-clothing-company.html"><a href="customer-data-for-clothing-company.html"><i class="fa fa-check"></i><b>2.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="2.2" data-path="customer-satisfaction-survey-data-from-airline-company.html"><a href="customer-satisfaction-survey-data-from-airline-company.html"><i class="fa fa-check"></i><b>2.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>3</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning.html"><a href="data-cleaning.html"><i class="fa fa-check"></i><b>3.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="3.2" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>3.2</b> Missing Values</a><ul>
<li class="chapter" data-level="3.2.1" data-path="missing-values.html"><a href="missing-values.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>3.2.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="3.2.2" data-path="missing-values.html"><a href="missing-values.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.2.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="3.2.3" data-path="missing-values.html"><a href="missing-values.html#bagging-tree"><i class="fa fa-check"></i><b>3.2.3</b> Bagging Tree</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="centering-and-scaling.html"><a href="centering-and-scaling.html"><i class="fa fa-check"></i><b>3.3</b> Centering and Scaling</a></li>
<li class="chapter" data-level="3.4" data-path="resolve-skewness.html"><a href="resolve-skewness.html"><i class="fa fa-check"></i><b>3.4</b> Resolve Skewness</a></li>
<li class="chapter" data-level="3.5" data-path="resolve-outliers.html"><a href="resolve-outliers.html"><i class="fa fa-check"></i><b>3.5</b> Resolve Outliers</a></li>
<li class="chapter" data-level="3.6" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>3.6</b> Collinearity</a></li>
<li class="chapter" data-level="3.7" data-path="sparse-variables.html"><a href="sparse-variables.html"><i class="fa fa-check"></i><b>3.7</b> Sparse Variables</a></li>
<li class="chapter" data-level="3.8" data-path="re-encode-dummy-variables.html"><a href="re-encode-dummy-variables.html"><i class="fa fa-check"></i><b>3.8</b> Re-encode Dummy Variables</a></li>
<li class="chapter" data-level="3.9" data-path="python-computing.html"><a href="python-computing.html"><i class="fa fa-check"></i><b>3.9</b> Python Computing</a><ul>
<li class="chapter" data-level="3.9.1" data-path="python-computing.html"><a href="python-computing.html#data-cleaning-1"><i class="fa fa-check"></i><b>3.9.1</b> Data Cleaning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html"><i class="fa fa-check"></i><b>4.1</b> Data Wrangling Using R</a><ul>
<li class="chapter" data-level="4.1.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#read-and-write-data"><i class="fa fa-check"></i><b>4.1.1</b> Read and write data</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#summarize-data"><i class="fa fa-check"></i><b>4.1.2</b> Summarize data</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#dplyr-package"><i class="fa fa-check"></i><b>4.1.3</b> <code>dplyr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy and Reshape Data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html#reshape2-package"><i class="fa fa-check"></i><b>4.2.1</b> <code>reshape2</code> package</a></li>
<li class="chapter" data-level="4.2.2" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html#tidyr-package"><i class="fa fa-check"></i><b>4.2.2</b> <code>tidyr</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-tuning-strategy.html"><a href="model-tuning-strategy.html"><i class="fa fa-check"></i><b>5</b> Model Tuning Strategy</a><ul>
<li class="chapter" data-level="5.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html"><i class="fa fa-check"></i><b>5.1</b> Systematic Error and Random Error</a><ul>
<li class="chapter" data-level="5.1.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-response"><i class="fa fa-check"></i><b>5.1.1</b> Measurement Error in the Response</a></li>
<li class="chapter" data-level="5.1.2" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-independent-variables"><i class="fa fa-check"></i><b>5.1.2</b> Measurement Error in the Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html"><i class="fa fa-check"></i><b>5.2</b> Data Splitting and Resampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#data-splitting"><i class="fa fa-check"></i><b>5.2.1</b> Data Splitting</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#resampling"><i class="fa fa-check"></i><b>5.2.2</b> Resampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="measuring-performance.html"><a href="measuring-performance.html"><i class="fa fa-check"></i><b>6</b> Measuring Performance</a><ul>
<li class="chapter" data-level="6.1" data-path="regression-model-performance.html"><a href="regression-model-performance.html"><i class="fa fa-check"></i><b>6.1</b> Regression Model Performance</a></li>
<li class="chapter" data-level="6.2" data-path="classification-model-performance.html"><a href="classification-model-performance.html"><i class="fa fa-check"></i><b>6.2</b> Classification Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>7</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="7.1" data-path="splitting-criteria.html"><a href="splitting-criteria.html"><i class="fa fa-check"></i><b>7.1</b> Splitting Criteria</a></li>
<li class="chapter" data-level="7.2" data-path="tree-pruning.html"><a href="tree-pruning.html"><i class="fa fa-check"></i><b>7.2</b> Tree Pruning</a></li>
<li class="chapter" data-level="7.3" data-path="regression-and-decision-tree-basic.html"><a href="regression-and-decision-tree-basic.html"><i class="fa fa-check"></i><b>7.3</b> Regression and Decision Tree Basic</a></li>
<li class="chapter" data-level="7.4" data-path="bagging-tree-1.html"><a href="bagging-tree-1.html"><i class="fa fa-check"></i><b>7.4</b> Bagging Tree</a></li>
<li class="chapter" data-level="7.5" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>7.5</b> Random Forest</a></li>
<li class="chapter" data-level="7.6" data-path="gradient-boosted-machine.html"><a href="gradient-boosted-machine.html"><i class="fa fa-check"></i><b>7.6</b> Gradient Boosted Machine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tree-based-methods" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Tree-Based Methods</h1>
<p>The tree-based models can be used for regression and classification. They are conceptually simple yet powerful. This type of model is often referred to as Classification And Regression Trees (CART). They are popular tools for many reasons:</p>
<ol style="list-style-type: decimal">
<li>Do not require user to specify the form of the relationship between predictors and response</li>
<li>Do not require (or if they do, very limited) data preprocessing and can handle different types of predictors (sparse, skewed, continuous, categorical, etc.)</li>
<li>Robust to co-linearity</li>
<li>Can handle missing data</li>
<li>Many pre-built packages make implementation as easy as a button push</li>
</ol>
<p>CART can refer to the tree model in general, but most of the time, it represents the algorithm initially proposed by Breiman <span class="citation">(al <a href="#ref-Breiman1984">1984</a>)</span>. After Breiman, there are many new algorithms, such as ID3, C4.5, and C5.0. C5.0 is an improved version of C4.5, but since C5.0 is not open source, the C4.5 algorithm is more popular. C4.5 was a major competitor of CART. But now, all those seem outdated. The most popular tree models are Random Forest (RF) and Gradient Boosting Machine (GBM). Despite being out of favor in application, it is important to understand the mechanism of the basic tree algorithm. Because the later models are based on the same foundation.</p>
<p>The original CART algorithm targets binary classification, and the later algorithms can handle multi-category classification. A single tree is easy to explain but has poor accuracy. More complicated tree models, such as RF and GBM, can provide much better prediction at the cost of explainability. As the model becoming more complicated, it is more like a black-box which makes it very difficult to explain the relationship among predictors. There is always a trade-off between explainability and predictability.</p>
<div class="figure">
<img src="../linhui.org/book/Figure/treeEN.png" />

</div>
<p>The reason why it is called “tree” is of course because the structure has similarities. But the direction of the decision tree is opposite to the real tree, the root is on the top, and the leaf is on the bottom. From the root node, a decision tree divides to different branches and generates more nodes. The new nodes are child nodes, and the previous node is the parent node. At each child node, the algorithm will decide whether to continue dividing. If it stops, the node is called a leaf node. If it continues, then the node becomes the new parent node and splits to produce the next layer of child nodes. At each non-leaf node, the algorithm needs to decide split into branches. The leaf node contains the final “decision,” final class the sample belongs to or the sample’s value has. Here are the important definitions in the tree model:</p>
<ul>
<li><strong>Classification tree</strong>: the outcome is discrete</li>
<li><strong>Regression tree</strong>: the outcome is continuous (e.g. the price of a house, or a patient’s length of stay in a hospital)</li>
<li><strong>Non-leaf node (or split node)</strong>: the algorithm needs to decide a split at each non-leaf node (eg age &lt;=25; 25<age<=35; age>35)</li>
<li><strong>Root node</strong>：the beginning node where the tree starts</li>
<li><strong>Leaf node (or Terminal node)</strong>: the node stops splitting. It has the final decision of the model</li>
<li><strong>Degree of the node</strong>: the number of subtrees of a node</li>
<li><strong>Degree of the tree</strong>: the maximum degree of a node in the tree</li>
<li><strong>Pruning</strong>: remove parts of the tree that do not provide power to classify instances</li>
<li><strong>Branch (or Subtree)</strong>: the whole part under a non-leaf node</li>
<li><strong>Child</strong>: the node directly after and connected to another node</li>
<li><strong>Parent</strong>: the converse notion of a child</li>
</ul>
<p>Single tree is easy to explain but has high variance and low accuracy, and hence is very limited. Minor changes in the training data can lead to large changes in the fitted tree. A series of rectangular decision regions defined by a single tree is often too naive to represent the relationship between the dependent variable and the predictors. To overcome these shortcomings, researchers have proposed ensemble methods which combine many trees. Ensemble tree models typically have much better predictive performance than a single tree. We will introduce those models in later sections.</p> 
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Breiman1984">
<p>al, Leo Breiman et. 1984. <em>Classification and Regression Trees</em>. ISBN 978-0412048418. Chapman; Hall/CRC.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-model-performance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="splitting-criteria.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/12-tree.Rmd",
"text": "Edit"
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
