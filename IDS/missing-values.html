<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="Introduction to Data Science">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li">


<meta name="date" content="2019-04-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="data-cleaning.html">
<link rel="next" href="centering-and-scaling.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="goal-of-the-book.html"><a href="goal-of-the-book.html"><i class="fa fa-check"></i>Goal of the Book</a></li>
<li class="chapter" data-level="" data-path="who-this-book-is-for.html"><a href="who-this-book-is-for.html"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="what-this-book-covers.html"><a href="what-this-book-covers.html"><i class="fa fa-check"></i>What This Book Covers</a></li>
<li class="chapter" data-level="" data-path="conventions.html"><a href="conventions.html"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html"><i class="fa fa-check"></i><b>1.1</b> Blind men and an elephant</a><ul>
<li class="chapter" data-level="1.1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html#data-science-roleskill-tracks"><i class="fa fa-check"></i><b>1.1.1</b> Data science role/skill tracks</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html"><i class="fa fa-check"></i><b>1.2</b> What should data science do?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#lets-dream-big"><i class="fa fa-check"></i><b>1.2.1</b> Let’s dream big</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#what-kind-of-questions-can-data-science-solve"><i class="fa fa-check"></i><b>1.2.2</b> What kind of questions can data science solve?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-the-data.html"><a href="introduction-to-the-data.html"><i class="fa fa-check"></i><b>2</b> Introduction to the data</a><ul>
<li class="chapter" data-level="2.1" data-path="customer-data-for-clothing-company.html"><a href="customer-data-for-clothing-company.html"><i class="fa fa-check"></i><b>2.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="2.2" data-path="customer-satisfaction-survey-data-from-airline-company.html"><a href="customer-satisfaction-survey-data-from-airline-company.html"><i class="fa fa-check"></i><b>2.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>3</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning.html"><a href="data-cleaning.html"><i class="fa fa-check"></i><b>3.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="3.2" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>3.2</b> Missing Values</a><ul>
<li class="chapter" data-level="3.2.1" data-path="missing-values.html"><a href="missing-values.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>3.2.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="3.2.2" data-path="missing-values.html"><a href="missing-values.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.2.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="3.2.3" data-path="missing-values.html"><a href="missing-values.html#bagging-tree"><i class="fa fa-check"></i><b>3.2.3</b> Bagging Tree</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="centering-and-scaling.html"><a href="centering-and-scaling.html"><i class="fa fa-check"></i><b>3.3</b> Centering and Scaling</a></li>
<li class="chapter" data-level="3.4" data-path="resolve-skewness.html"><a href="resolve-skewness.html"><i class="fa fa-check"></i><b>3.4</b> Resolve Skewness</a></li>
<li class="chapter" data-level="3.5" data-path="resolve-outliers.html"><a href="resolve-outliers.html"><i class="fa fa-check"></i><b>3.5</b> Resolve Outliers</a></li>
<li class="chapter" data-level="3.6" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>3.6</b> Collinearity</a></li>
<li class="chapter" data-level="3.7" data-path="sparse-variables.html"><a href="sparse-variables.html"><i class="fa fa-check"></i><b>3.7</b> Sparse Variables</a></li>
<li class="chapter" data-level="3.8" data-path="re-encode-dummy-variables.html"><a href="re-encode-dummy-variables.html"><i class="fa fa-check"></i><b>3.8</b> Re-encode Dummy Variables</a></li>
<li class="chapter" data-level="3.9" data-path="python-computing.html"><a href="python-computing.html"><i class="fa fa-check"></i><b>3.9</b> Python Computing</a><ul>
<li class="chapter" data-level="3.9.1" data-path="python-computing.html"><a href="python-computing.html#data-cleaning-1"><i class="fa fa-check"></i><b>3.9.1</b> Data Cleaning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html"><i class="fa fa-check"></i><b>4.1</b> Data Wrangling Using R</a><ul>
<li class="chapter" data-level="4.1.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#read-and-write-data"><i class="fa fa-check"></i><b>4.1.1</b> Read and write data</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#summarize-data"><i class="fa fa-check"></i><b>4.1.2</b> Summarize data</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#dplyr-package"><i class="fa fa-check"></i><b>4.1.3</b> <code>dplyr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy and Reshape Data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html#reshape2-package"><i class="fa fa-check"></i><b>4.2.1</b> <code>reshape2</code> package</a></li>
<li class="chapter" data-level="4.2.2" data-path="tidy-and-reshape-data.html"><a href="tidy-and-reshape-data.html#tidyr-package"><i class="fa fa-check"></i><b>4.2.2</b> <code>tidyr</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-tuning-strategy.html"><a href="model-tuning-strategy.html"><i class="fa fa-check"></i><b>5</b> Model Tuning Strategy</a><ul>
<li class="chapter" data-level="5.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html"><i class="fa fa-check"></i><b>5.1</b> Systematic Error and Random Error</a><ul>
<li class="chapter" data-level="5.1.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-response"><i class="fa fa-check"></i><b>5.1.1</b> Measurement Error in the Response</a></li>
<li class="chapter" data-level="5.1.2" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-independent-variables"><i class="fa fa-check"></i><b>5.1.2</b> Measurement Error in the Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html"><i class="fa fa-check"></i><b>5.2</b> Data Splitting and Resampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#data-splitting"><i class="fa fa-check"></i><b>5.2.1</b> Data Splitting</a></li>
<li class="chapter" data-level="5.2.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#resampling"><i class="fa fa-check"></i><b>5.2.2</b> Resampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="measuring-performance.html"><a href="measuring-performance.html"><i class="fa fa-check"></i><b>6</b> Measuring Performance</a><ul>
<li class="chapter" data-level="6.1" data-path="regression-model-performance.html"><a href="regression-model-performance.html"><i class="fa fa-check"></i><b>6.1</b> Regression Model Performance</a></li>
<li class="chapter" data-level="6.2" data-path="classification-model-performance.html"><a href="classification-model-performance.html"><i class="fa fa-check"></i><b>6.2</b> Classification Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>7</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="7.1" data-path="splitting-criteria.html"><a href="splitting-criteria.html"><i class="fa fa-check"></i><b>7.1</b> Splitting Criteria</a></li>
<li class="chapter" data-level="7.2" data-path="tree-pruning.html"><a href="tree-pruning.html"><i class="fa fa-check"></i><b>7.2</b> Tree Pruning</a></li>
<li class="chapter" data-level="7.3" data-path="regression-and-decision-tree-basic.html"><a href="regression-and-decision-tree-basic.html"><i class="fa fa-check"></i><b>7.3</b> Regression and Decision Tree Basic</a></li>
<li class="chapter" data-level="7.4" data-path="bagging-tree-1.html"><a href="bagging-tree-1.html"><i class="fa fa-check"></i><b>7.4</b> Bagging Tree</a></li>
<li class="chapter" data-level="7.5" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>7.5</b> Random Forest</a></li>
<li class="chapter" data-level="7.6" data-path="gradient-boosted-machine.html"><a href="gradient-boosted-machine.html"><i class="fa fa-check"></i><b>7.6</b> Gradient Boosted Machine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="missing-values" class="section level2">
<h2><span class="header-section-number">3.2</span> Missing Values</h2>
<p>You can write a whole book about missing value. This section will only show some of the most commonly used methods without getting too deep into the topic. Chapter 7 of the book by De Waal, Pannekoek and Scholtus <span class="citation">(Waal, Pannekoek, and Scholtus <a href="#ref-Ton2011">2011</a>)</span> makes a concise overview of some of the existing imputation methods. The choice of specific method depends on the actual situation. There is no best way.</p>
<p>One question to ask before imputation: Is there any auxiliary information? Being aware of any auxiliary information is critical. For example, if the system set customer who did not purchase as missing, then the real purchasing amount should be 0. Is missing a random occurrence? If so, it may be reasonable to impute with mean or median. If not, is there a potential mechanism for the missing data? For example, older people are more reluctant to disclose their ages in the questionnaire, so that the absence of age is not completely random. In this case, the missing values need to be estimated using the relationship between age and other independent variables. For example, use variables such as whether they have children, income, and other survey questions to build a model to predict age.</p>
<p>Also, the purpose of modeling is important for selecting imputation methods. If the goal is to interpret the parameter estimate or statistical inference, then it is important to study the missing mechanism carefully and to estimate the missing values using non-missing information as much as possible. If the goal is to predict, people usually will not study the absence mechanism rigorously (but sometimes the mechanism is obvious). If the absence mechanism is not clear, treat it as missing at random and use mean, median, or k-nearest neighbor to impute. Since statistical inference is sensitive to missing values, researchers from survey statistics have conducted in-depth studies of various imputation schemes which focus on valid statistical inference. The problem of missing values in the prediction model is different from that in the traditional survey. Therefore, there are not many papers on missing value imputation in the prediction model. Those who want to study further can refer to Saar-Tsechansky and Provost’s comparison of different imputation methods <span class="citation">(M and F 2007b)</span> and De Waal, Pannekoek and Scholtus’ book <span class="citation">(Waal, Pannekoek, and Scholtus <a href="#ref-Ton2011">2011</a>)</span>.</p>
<div id="impute-missing-values-with-medianmode" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Impute missing values with median/mode</h3>
<p>In the case of missing at random, a common method is to impute with the mean (continuous variable) or median (categorical variables). You can use <code>impute()</code> function in <code>imputeMissings</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># save the result as another object</span>
demo_imp&lt;-<span class="kw">impute</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;median/mode&quot;</span>)
<span class="co"># check the first 5 columns, there is no missing values in other columns</span>
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])</code></pre></div>
<pre class="pre"><code>      age           gender        income       house       store_exp      
 Min.   :16.00   Female:446   Min.   : 41776   No :372   Min.   :  155.8  
 1st Qu.:25.00   Male  :326   1st Qu.: 84930   Yes:400   1st Qu.:  202.7  
 Median :33.00                Median : 93023             Median :  293.0  
 Mean   :36.63                Mean   :109968             Mean   : 1265.4  
 3rd Qu.:45.00                3rd Qu.:121535             3rd Qu.:  540.2  
 Max.   :69.00                Max.   :317476             Max.   :50000.0 </code></pre>
<p>After imputation, <code>demo_imp</code> has no missing value. This method is straightforward and widely used. The disadvantage is that it does not take into account the relationship between the variables. When there is a significant proportion of missing, it will distort the data. In this case, it is better to consider the relationship between variables and study the missing mechanism. In the example here, the missing variables are numeric. If the missing variable is a categorical/factor variable, the <code>impute()</code> function will impute with the mode.</p>
<p>You can also use <code>preProcess()</code> function, but it is only for numeric variables, and can not impute categorical variables. Since missing values here are numeric, we can use the <code>preProcess()</code> function. The result is the same as the <code>impute()</code> function. <code>PreProcess()</code> is a powerful function that can link to a variety of data preprocessing methods. We will use the function later for other data preprocessing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;medianImpute&quot;</span>)
demo_imp2&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp2[,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])</code></pre></div>
</div>
<div id="k-nearest-neighbors" class="section level3">
<h3><span class="header-section-number">3.2.2</span> K-nearest neighbors</h3>
<p>K-nearest neighbor (KNN) will find the k closest samples (Euclidian distance) in the training set and impute the mean of those “neighbors.”</p>
<p>Use <code>preProcess()</code> to conduct KNN:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
<span class="co"># need to use predict() to get KNN result</span>
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)</code></pre></div>
<pre class="pre"><code>Error in `[.data.frame`(old, , non_missing_cols, drop = FALSE) : 
  undefined columns selected</code></pre>
<p>Now we get an error saying “undefined columns selected.” It is because <code>sim.dat</code> has non-numeric variables. The <code>preProcess()</code> in the first line will automatically ignore non-numeric columns, so there is no error. However, there is a problem when using <code>predict()</code> to get the result. Removing those variable will solve the problem.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># find factor columns</span>
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(sim.dat,class)<span class="op">==</span><span class="st">&quot;factor&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat[,<span class="op">-</span>idx])
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>])</code></pre></div>
<p><code>lapply(data,class)</code> can return a list of column class. Here the data frame is <code>sim.dat</code>, and the following code will give the list of column class:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># only show the first three elements</span>
<span class="kw">lapply</span>(sim.dat,class)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]</code></pre></div>
<p>Comparing the KNN result with the previous median imputation, the two are very different. This is because when you tell the <code>preProcess()</code> function to use KNN (the option <code>method =&quot; knnImpute&quot;</code>), it will automatically standardize the data. Another way is to use Bagging tree (in the next section). Note that KNN can not impute samples with the entire row missing. The reason is straightforward. Since the algorithm uses the average of its neighbors if none of them has a value, what does it apply to calculate the mean? Let’s append a new row with all values missing to the original data frame to get a new object called <code>temp</code>. Then apply KNN to <code>temp</code> and see what happens:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp&lt;-<span class="kw">rbind</span>(sim.dat,<span class="kw">rep</span>(<span class="ot">NA</span>,<span class="kw">ncol</span>(sim.dat)))
imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">5</span>)
idx&lt;-<span class="kw">which</span>(<span class="kw">lapply</span>(temp,class)<span class="op">==</span><span class="st">&quot;factor&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp&lt;-<span class="kw">predict</span>(imp,temp[,<span class="op">-</span>idx])</code></pre></div>
<pre class="pre"><code>Error in FUN(newX[, i], ...) : 
  cannot impute when all predictors are missing in the new data point</code></pre>
<p>There is an error saying “cannot impute when all predictors are missing in the new data point”. It is easy to fix by finding and removing the problematic row:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idx&lt;-<span class="kw">apply</span>(temp,<span class="dv">1</span>,<span class="cf">function</span>(x) <span class="kw">sum</span>(<span class="kw">is.na</span>(x)) )
<span class="kw">as.vector</span>(<span class="kw">which</span>(idx<span class="op">==</span><span class="kw">ncol</span>(temp)))</code></pre></div>
<p>It shows that row 1001 is problematic. You can go ahead to delete it.</p>
</div>
<div id="bagging-tree" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Bagging Tree</h3>
<p>Bagging (Bootstrap aggregating) was originally proposed by Leo Breiman. It is one of the earliest ensemble methods <span class="citation">(L 1966a)</span>. When used in missing value imputation, it will use the remaining variables as predictors to train a bagging tree and then use the tree to predict the missing values. Although theoretically, the method is powerful, the computation is much more intense than KNN. In practice, there is a trade-off between computation time and the effect. If a median or mean meet the modeling needs, even bagging tree may improve the accuracy a little, but the upgrade is so marginal that it does not deserve the extra time. The bagging tree itself is a model for regression and classification. Here we use <code>preProcess()</code> to impute <code>sim.dat</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(sim.dat,<span class="dt">method=</span><span class="st">&quot;bagImpute&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,sim.dat)
<span class="kw">summary</span>(demo_imp[,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])</code></pre></div>
<pre class="pre"><code>      age           gender        income       house       store_exp      
 Min.   :16.00   Female:554   Min.   : 41776   No :432   Min.   :  155.8  
 1st Qu.:25.00   Male  :446   1st Qu.: 86762   Yes:568   1st Qu.:  205.1  
 Median :36.00                Median : 94739             Median :  329.0  
 Mean   :38.58                Mean   :114665             Mean   : 1357.7  
 3rd Qu.:53.00                3rd Qu.:123726             3rd Qu.:  597.3  
 Max.   :69.00                Max.   :319704             Max.   :50000.0  </code></pre>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Ton2011">
<p>Waal, Ton de, Jeroen Pannekoek, and Sander Scholtus. 2011. <em>Handbook of Statistical Data Editing and Imputation</em>. John Wiley; Sons.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-cleaning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="centering-and-scaling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/04-DataPreprocessing.Rmd",
"text": "Edit"
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
