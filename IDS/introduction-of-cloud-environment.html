<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="Introduction to Data Science">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li">


<meta name="date" content="2019-04-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="power-of-cluster-of-computers.html">
<link rel="next" href="summary.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="goal-of-the-book.html"><a href="goal-of-the-book.html"><i class="fa fa-check"></i>Goal of the Book</a></li>
<li class="chapter" data-level="" data-path="who-this-book-is-for.html"><a href="who-this-book-is-for.html"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="what-this-book-covers.html"><a href="what-this-book-covers.html"><i class="fa fa-check"></i>What This Book Covers</a></li>
<li class="chapter" data-level="" data-path="conventions.html"><a href="conventions.html"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html"><i class="fa fa-check"></i><b>1.1</b> Blind men and an elephant</a><ul>
<li class="chapter" data-level="1.1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html#data-science-roleskill-tracks"><i class="fa fa-check"></i><b>1.1.1</b> Data science role/skill tracks</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html"><i class="fa fa-check"></i><b>1.2</b> What should data science do?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#lets-dream-big"><i class="fa fa-check"></i><b>1.2.1</b> Let’s dream big</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#what-kind-of-questions-can-data-science-solve"><i class="fa fa-check"></i><b>1.2.2</b> What kind of questions can data science solve?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html"><i class="fa fa-check"></i><b>2</b> Soft Skills for Data Scientists</a><ul>
<li class="chapter" data-level="2.1" data-path="comparison-between-statistician-and-data-scientist.html"><a href="comparison-between-statistician-and-data-scientist.html"><i class="fa fa-check"></i><b>2.1</b> Comparison between Statistician and Data Scientist</a></li>
<li class="chapter" data-level="2.2" data-path="where-does-data-science-team-fits.html"><a href="where-does-data-science-team-fits.html"><i class="fa fa-check"></i><b>2.2</b> Where Does Data Science Team Fits?</a></li>
<li class="chapter" data-level="2.3" data-path="beyond-data-and-analytics.html"><a href="beyond-data-and-analytics.html"><i class="fa fa-check"></i><b>2.3</b> Beyond Data and Analytics</a></li>
<li class="chapter" data-level="2.4" data-path="data-scientist-as-a-leader.html"><a href="data-scientist-as-a-leader.html"><i class="fa fa-check"></i><b>2.4</b> Data Scientist as a Leader</a></li>
<li class="chapter" data-level="2.5" data-path="three-pillars-of-knowledge.html"><a href="three-pillars-of-knowledge.html"><i class="fa fa-check"></i><b>2.5</b> Three Pillars of Knowledge</a></li>
<li class="chapter" data-level="2.6" data-path="common-pitfalls-of-data-science-projects.html"><a href="common-pitfalls-of-data-science-projects.html"><i class="fa fa-check"></i><b>2.6</b> Common Pitfalls of Data Science Projects</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-the-data.html"><a href="introduction-to-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction to the data</a><ul>
<li class="chapter" data-level="3.1" data-path="customer-data-for-clothing-company.html"><a href="customer-data-for-clothing-company.html"><i class="fa fa-check"></i><b>3.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="3.2" data-path="customer-satisfaction-survey-data-from-airline-company.html"><a href="customer-satisfaction-survey-data-from-airline-company.html"><i class="fa fa-check"></i><b>3.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
<li class="chapter" data-level="3.3" data-path="swine-disease-breakout-data.html"><a href="swine-disease-breakout-data.html"><i class="fa fa-check"></i><b>3.3</b> Swine Disease Breakout Data</a></li>
<li class="chapter" data-level="3.4" data-path="mnist-dataset.html"><a href="mnist-dataset.html"><i class="fa fa-check"></i><b>3.4</b> MNIST Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>4</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="4.1" data-path="data-cleaning.html"><a href="data-cleaning.html"><i class="fa fa-check"></i><b>4.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.2" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>4.2</b> Missing Values</a><ul>
<li class="chapter" data-level="4.2.1" data-path="missing-values.html"><a href="missing-values.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>4.2.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="4.2.2" data-path="missing-values.html"><a href="missing-values.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.2.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="4.2.3" data-path="missing-values.html"><a href="missing-values.html#bagging-tree"><i class="fa fa-check"></i><b>4.2.3</b> Bagging Tree</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="centering-and-scaling.html"><a href="centering-and-scaling.html"><i class="fa fa-check"></i><b>4.3</b> Centering and Scaling</a></li>
<li class="chapter" data-level="4.4" data-path="resolve-skewness.html"><a href="resolve-skewness.html"><i class="fa fa-check"></i><b>4.4</b> Resolve Skewness</a></li>
<li class="chapter" data-level="4.5" data-path="resolve-outliers.html"><a href="resolve-outliers.html"><i class="fa fa-check"></i><b>4.5</b> Resolve Outliers</a></li>
<li class="chapter" data-level="4.6" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>4.6</b> Collinearity</a></li>
<li class="chapter" data-level="4.7" data-path="sparse-variables.html"><a href="sparse-variables.html"><i class="fa fa-check"></i><b>4.7</b> Sparse Variables</a></li>
<li class="chapter" data-level="4.8" data-path="re-encode-dummy-variables.html"><a href="re-encode-dummy-variables.html"><i class="fa fa-check"></i><b>4.8</b> Re-encode Dummy Variables</a></li>
<li class="chapter" data-level="4.9" data-path="python-computing.html"><a href="python-computing.html"><i class="fa fa-check"></i><b>4.9</b> Python Computing</a><ul>
<li class="chapter" data-level="4.9.1" data-path="python-computing.html"><a href="python-computing.html#data-cleaning-1"><i class="fa fa-check"></i><b>4.9.1</b> Data Cleaning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>5</b> Data Wrangling</a><ul>
<li class="chapter" data-level="5.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html"><i class="fa fa-check"></i><b>5.1</b> Data Wrangling Using R</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#read-and-write-data"><i class="fa fa-check"></i><b>5.1.1</b> Read and write data</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#summarize-data"><i class="fa fa-check"></i><b>5.1.2</b> Summarize data</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#dplyr-package"><i class="fa fa-check"></i><b>5.1.3</b> <code>dplyr</code> package</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#tidy-and-reshape-data"><i class="fa fa-check"></i><b>5.1.4</b> Tidy and Reshape Data</a></li>
<li class="chapter" data-level="5.1.5" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#data-wrangling-using-python"><i class="fa fa-check"></i><b>5.1.5</b> Data Wrangling Using Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-tuning-strategy.html"><a href="model-tuning-strategy.html"><i class="fa fa-check"></i><b>6</b> Model Tuning Strategy</a><ul>
<li class="chapter" data-level="6.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html"><i class="fa fa-check"></i><b>6.1</b> Systematic Error and Random Error</a><ul>
<li class="chapter" data-level="6.1.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-response"><i class="fa fa-check"></i><b>6.1.1</b> Measurement Error in the Response</a></li>
<li class="chapter" data-level="6.1.2" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-independent-variables"><i class="fa fa-check"></i><b>6.1.2</b> Measurement Error in the Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html"><i class="fa fa-check"></i><b>6.2</b> Data Splitting and Resampling</a><ul>
<li class="chapter" data-level="6.2.1" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#data-splitting"><i class="fa fa-check"></i><b>6.2.1</b> Data Splitting</a></li>
<li class="chapter" data-level="6.2.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#resampling"><i class="fa fa-check"></i><b>6.2.2</b> Resampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="measuring-performance.html"><a href="measuring-performance.html"><i class="fa fa-check"></i><b>7</b> Measuring Performance</a><ul>
<li class="chapter" data-level="7.1" data-path="regression-model-performance.html"><a href="regression-model-performance.html"><i class="fa fa-check"></i><b>7.1</b> Regression Model Performance</a></li>
<li class="chapter" data-level="7.2" data-path="classification-model-performance.html"><a href="classification-model-performance.html"><i class="fa fa-check"></i><b>7.2</b> Classification Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>8</b> Feature Engineering</a><ul>
<li class="chapter" data-level="8.1" data-path="feature-construction.html"><a href="feature-construction.html"><i class="fa fa-check"></i><b>8.1</b> Feature Construction</a></li>
<li class="chapter" data-level="8.2" data-path="feature-extraction.html"><a href="feature-extraction.html"><i class="fa fa-check"></i><b>8.2</b> Feature Extraction</a></li>
<li class="chapter" data-level="8.3" data-path="feature-selection.html"><a href="feature-selection.html"><i class="fa fa-check"></i><b>8.3</b> Feature Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="feature-selection.html"><a href="feature-selection.html#filter-method"><i class="fa fa-check"></i><b>8.3.1</b> Filter Method</a></li>
<li class="chapter" data-level="8.3.2" data-path="feature-selection.html"><a href="feature-selection.html#wrapper-method"><i class="fa fa-check"></i><b>8.3.2</b> Wrapper Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>9</b> Regression Models</a><ul>
<li class="chapter" data-level="9.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>9.1</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="9.2" data-path="multivariate-adaptive-regression-splines.html"><a href="multivariate-adaptive-regression-splines.html"><i class="fa fa-check"></i><b>9.2</b> Multivariate Adaptive Regression Splines</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>9.3</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="9.4" data-path="pcr-and-pls.html"><a href="pcr-and-pls.html"><i class="fa fa-check"></i><b>9.4</b> PCR and PLS</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regularization-methods.html"><a href="regularization-methods.html"><i class="fa fa-check"></i><b>10</b> Regularization Methods</a><ul>
<li class="chapter" data-level="10.1" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>10.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="10.2" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>10.2</b> LASSO</a></li>
<li class="chapter" data-level="10.3" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>10.3</b> Elastic Net</a></li>
<li class="chapter" data-level="10.4" data-path="lasso-generalized-linear-model.html"><a href="lasso-generalized-linear-model.html"><i class="fa fa-check"></i><b>10.4</b> LASSO Generalized Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>11</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="11.1" data-path="splitting-criteria.html"><a href="splitting-criteria.html"><i class="fa fa-check"></i><b>11.1</b> Splitting Criteria</a></li>
<li class="chapter" data-level="11.2" data-path="tree-pruning.html"><a href="tree-pruning.html"><i class="fa fa-check"></i><b>11.2</b> Tree Pruning</a></li>
<li class="chapter" data-level="11.3" data-path="regression-and-decision-tree-basic.html"><a href="regression-and-decision-tree-basic.html"><i class="fa fa-check"></i><b>11.3</b> Regression and Decision Tree Basic</a></li>
<li class="chapter" data-level="11.4" data-path="bagging-tree-1.html"><a href="bagging-tree-1.html"><i class="fa fa-check"></i><b>11.4</b> Bagging Tree</a></li>
<li class="chapter" data-level="11.5" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>11.5</b> Random Forest</a></li>
<li class="chapter" data-level="11.6" data-path="gradient-boosted-machine.html"><a href="gradient-boosted-machine.html"><i class="fa fa-check"></i><b>11.6</b> Gradient Boosted Machine</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neural-network.html"><a href="neural-network.html"><i class="fa fa-check"></i><b>12</b> Neural Network</a><ul>
<li class="chapter" data-level="12.1" data-path="projection-pursuit-regression.html"><a href="projection-pursuit-regression.html"><i class="fa fa-check"></i><b>12.1</b> Projection Pursuit Regression</a></li>
<li class="chapter" data-level="12.2" data-path="standard-neural-network.html"><a href="standard-neural-network.html"><i class="fa fa-check"></i><b>12.2</b> Standard Neural Network</a><ul>
<li class="chapter" data-level="12.2.1" data-path="standard-neural-network.html"><a href="standard-neural-network.html#logistic_reg_as_neural_network"><i class="fa fa-check"></i><b>12.2.1</b> Logistic Regression as Neural Network</a></li>
<li class="chapter" data-level="12.2.2" data-path="standard-neural-network.html"><a href="standard-neural-network.html#one-layer-neural-network"><i class="fa fa-check"></i><b>12.2.2</b> One layer neural network</a></li>
<li class="chapter" data-level="12.2.3" data-path="standard-neural-network.html"><a href="standard-neural-network.html#activation-function"><i class="fa fa-check"></i><b>12.2.3</b> Activation Function</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="convolutional-neural-network.html"><a href="convolutional-neural-network.html"><i class="fa fa-check"></i><b>12.3</b> Convolutional Neural Network</a></li>
<li class="chapter" data-level="12.4" data-path="recurrent-neural-network.html"><a href="recurrent-neural-network.html"><i class="fa fa-check"></i><b>12.4</b> Recurrent Neural Network</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html"><i class="fa fa-check"></i><b>A</b> Big Data Cloud Platform</a><ul>
<li class="chapter" data-level="A.1" data-path="how-data-becomes-science.html"><a href="how-data-becomes-science.html"><i class="fa fa-check"></i><b>A.1</b> How Data becomes Science?</a></li>
<li class="chapter" data-level="A.2" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html"><i class="fa fa-check"></i><b>A.2</b> Power of Cluster of Computers</a><ul>
<li class="chapter" data-level="A.2.1" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#evolution-of-clustering-computing"><i class="fa fa-check"></i><b>A.2.1</b> Evolution of Clustering Computing</a></li>
<li class="chapter" data-level="A.2.2" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#hadoop"><i class="fa fa-check"></i><b>A.2.2</b> Hadoop</a></li>
<li class="chapter" data-level="A.2.3" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#spark"><i class="fa fa-check"></i><b>A.2.3</b> Spark</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="introduction-of-cloud-environment.html"><a href="introduction-of-cloud-environment.html"><i class="fa fa-check"></i><b>A.3</b> Introduction of Cloud Environment</a></li>
<li class="chapter" data-level="A.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>A.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="databases-and-sql.html"><a href="databases-and-sql.html"><i class="fa fa-check"></i><b>B</b> Databases and SQL</a><ul>
<li class="chapter" data-level="B.1" data-path="database-table-and-view.html"><a href="database-table-and-view.html"><i class="fa fa-check"></i><b>B.1</b> Database, Table and View</a></li>
<li class="chapter" data-level="B.2" data-path="sample-tables.html"><a href="sample-tables.html"><i class="fa fa-check"></i><b>B.2</b> Sample Tables</a></li>
<li class="chapter" data-level="B.3" data-path="basic-sql-statement.html"><a href="basic-sql-statement.html"><i class="fa fa-check"></i><b>B.3</b> Basic SQL Statement</a><ul>
<li class="chapter" data-level="B.3.1" data-path="basic-sql-statement.html"><a href="basic-sql-statement.html#simple-select-statement"><i class="fa fa-check"></i><b>B.3.1</b> Simple SELECT Statement</a></li>
<li class="chapter" data-level="B.3.2" data-path="basic-sql-statement.html"><a href="basic-sql-statement.html#aggregation-functions-and-group-by"><i class="fa fa-check"></i><b>B.3.2</b> Aggregation Functions and GROUP BY</a></li>
<li class="chapter" data-level="B.3.3" data-path="basic-sql-statement.html"><a href="basic-sql-statement.html#join-multiple-tables"><i class="fa fa-check"></i><b>B.3.3</b> Join Multiple Tables</a></li>
<li class="chapter" data-level="B.3.4" data-path="basic-sql-statement.html"><a href="basic-sql-statement.html#add-more-content-into-a-table"><i class="fa fa-check"></i><b>B.3.4</b> Add More Content into a Table</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="advanced-topics-in-database.html"><a href="advanced-topics-in-database.html"><i class="fa fa-check"></i><b>B.4</b> Advanced Topics in Database</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="other-useful-topics.html"><a href="other-useful-topics.html"><i class="fa fa-check"></i><b>C</b> Other Useful Topics</a><ul>
<li class="chapter" data-level="C.1" data-path="linux-operation-system.html"><a href="linux-operation-system.html"><i class="fa fa-check"></i><b>C.1</b> Linux Operation System</a></li>
<li class="chapter" data-level="C.2" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>C.2</b> Visualization</a></li>
<li class="chapter" data-level="C.3" data-path="gpu.html"><a href="gpu.html"><i class="fa fa-check"></i><b>C.3</b> GPU</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="r-code-for-data-simulation.html"><a href="r-code-for-data-simulation.html"><i class="fa fa-check"></i><b>D</b> R code for data simulation</a><ul>
<li class="chapter" data-level="D.1" data-path="customer-data-for-clothing-company-1.html"><a href="customer-data-for-clothing-company-1.html"><i class="fa fa-check"></i><b>D.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="D.2" data-path="customer-satisfaction-survey-data-from-airline-company-1.html"><a href="customer-satisfaction-survey-data-from-airline-company-1.html"><i class="fa fa-check"></i><b>D.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
<li class="chapter" data-level="D.3" data-path="swine-disease-breakout-data-1.html"><a href="swine-disease-breakout-data-1.html"><i class="fa fa-check"></i><b>D.3</b> Swine Disease Breakout Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-of-cloud-environment" class="section level2">
<h2><span class="header-section-number">A.3</span> Introduction of Cloud Environment</h2>
<p>There are many cloud computing environments such as Amazon’s AWS which provides a complete list of functions for heavy-duty enterprise applications. For example, Netflix runs its business entirely on AWS and Netflix does not own any data centers. For beginners, Databricks provides an easy to use cloud system for learning purpose. Databricks is a company founded by the creators of Apache Spark and it provides a user-friendly web-based notebook environment that can create Hadoop/Spark/GPU cluster on the fly and run R/Python/Scala/SQL. We will use Databricks’ community edition to run demos in this book. Please note the content of this section is adopted from the following web pages:</p>
<ul>
<li><a href="https://docs.databricks.com/user-guide/faq/sparklyr.html" class="uri">https://docs.databricks.com/user-guide/faq/sparklyr.html</a></li>
<li><a href="http://spark.rstudio.com/index.html" class="uri">http://spark.rstudio.com/index.html</a></li>
</ul>
<p><strong>Open Account and Create a Cluster</strong></p>
<p>Anyone can apply for a community edition for free through <a href="https://databricks.com/try-databricks" class="uri">https://databricks.com/try-databricks</a> and a short YouTube video illustrates the application process can be found <a href="https://youtu.be/vx-3-htFvrg" class="uri">https://youtu.be/vx-3-htFvrg</a>. Another short YouTube video shows how to create a cluster for a cloud computing environment and create an R notebook to run R codes which can be found at <a href="https://youtu.be/0HFujX3t6TU" class="uri">https://youtu.be/0HFujX3t6TU</a>. In fact, you can run Python/R/Scala/SQL cells, as well as markdown cells, in the same notebook by including a keyword at the beginning of each cell that we will discuss later.</p>
<p><strong>R Notebook</strong></p>
<p>In last section of the video, we created an R notebook. For an R notebook, it contains multiple cells and by default, the content within each cell are R scripts. Usually, each cell is a well-managed a few lines of codes that accomplish a specific task. For example, Figure 42 shows the default cell for an R notebook for cell 1. We can type in R scripts and comments same as we are using R console. By default, only the result from the last line will be shown following the cell. However, you can use <code>print()</code> function to output results for any lines. If we move the mouse to the middle of the lower edge of the cell below the results, a “+” symbol will show up and click on the symbol will insert a new cell below. When you click any area within a cell, it will make it editable and you will see a few icons on the top right corn of the cell where you can run the cell, as well as add a cell below or above, copy the cell, cut cell, high cell etc. One quick way to run the cell is Shift+Enter when the cell is chosen. You will become familiar with the notebook environment quickly.</p>
<center>
<img src="http://scientistcafe.com/CE_JSM2017/images/rnotebook.png" alt="R notebook default cell with R scripts" />
</center>
<p><strong>Markdown Cells</strong></p>
<p>For an R notebook, every cell by default will contain R scripts. But if we put %md, %sql or %python at the first line of a cell, that cell becomes Markdown cell, SQL script cell, and Python script cell accordingly. For example, Figure 43 shows a markdown cell with scripts and the actual appearance when exits editing mode. Markdown cell provides a straightforward way to descript what each cell is doing as well as what the entire notebook is about. It is a better way than simple comment within in the code.</p>
<center>
<img src="http://scientistcafe.com/CE_JSM2017/images/markdown_databrick.png" alt="An example of Markdown cell with scripts at top and actual appearance at bottom" />
</center>
<p><strong>Leverage Hadoop and Spark Parallel using R Notebook</strong></p>
<p>R is a powerful tool for data analysis given the data can be fit into memory. Because of the memory bounded dataset limit, R itself cannot be used directly for big data analysis where the data is likely stored in Hadoop and Spark system. By leverage <code>sparklyr</code> package created by RStudio, we can use Databricks’ R notebook to analyze data stored in Spark system where the data are stored across different nodes and computation are parallel in nature to use the collection of memory units across all nodes. And the process is relatively simple. In this section, we will illustrate how to use Databricks’ R notebook for big data analysis on top of Spark environment through <code>sparklyr</code> package.</p>
<p><strong>Library Installation</strong></p>
<p>First, we need to install <code>sparklyr</code> package which enables the connection between master or local node to Spark cluster environments. As it will install more than 10 dependencies, it may take more than 5 minutes to finish. Be patient while it is installing! Once the installation finishes, load the <code>sparklyr</code> package as illustrated by the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Installing sparklyr takes a few minutes, </span>
<span class="co"># because it installs +10 dependencies.</span>

<span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;sparklyr&quot;</span>)) {
  <span class="kw">install.packages</span>(<span class="st">&quot;sparklyr&quot;</span>)  
}

<span class="co"># Load sparklyr package.</span>
<span class="kw">library</span>(sparklyr)</code></pre></div>
<p><strong>Create Connection</strong></p>
<p>Once the library is loaded, we need to create a Spark Connection to link master / local node to Spark environment. Here we use the “databricks” option for parameter method which is specific for databricks’ system. In the enterprise environment, please consult your administrator for details. The created Spark Connection (i.e. sc) will be the pipe that connects master/local/terminal to the Spark Cluster. We can think of the web interface/terminal is running on a master node which has its local memory and CPU. The Spark Connection can be established with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create a sparklyr connection </span>
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">method =</span> <span class="st">&quot;databricks&quot;</span>)</code></pre></div>
<p><strong>Sample Dataset</strong></p>
<p>To simplify the learning process, let us use a very familiar dataset: the iris dataset. It is part of the <code>dplyr</code> library and let’s load that library to use the iris data frame. Here the iris dataset is still on the local node where the R notebook is running on. And we can see that the first a few lines of the iris dataset below the code after running:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">head</span>(iris)</code></pre></div>
<p><strong>IMPORTANT - Copy Data to Spark Environment</strong></p>
<p>In real applications, your data maybe massive and cannot fit onto a single hard disk. If the data is already in Hadoop/Spark ecosystem, you can use SparkDataFrame to analyze it in the Spark system directly. Here, we illustrate how to copy a local dataset to Spark environment and then work on that dataset in the Spark system. As we have already created the Spark Connection sc, it is easy to copy data to spark system by sdf_copy_to() function as below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_tbl &lt;-<span class="st"> </span><span class="kw">sdf_copy_to</span>(<span class="dt">sc =</span> sc, <span class="dt">x =</span> iris, <span class="dt">overwrite =</span> T)</code></pre></div>
<p>The above one line code copies iris dataset from the local node to Spark cluster environment. “<code>sc</code>” is the Spark Connection we just created; “<code>x</code>” is the data frame that we want to copy; “<code>overwrite</code>” is the option whether we want to overwrite the target object if the same name SparkDataFrame exists in the Spark environment. Finally, sdf_copy_to() function will return an R object wrapping the copied SparkDataFrame. So irir_tbl can be used to refer to the iris SparkDataFrame.</p>
<p>To check whether the iris data was copied to Spark environment successfully or not, we can use <code>src_tbls( )</code> function to the Spark Connection (sc):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">src_tbls</span>(sc) ## code to return all the data frames associated with sc</code></pre></div>
<p><strong>Analyzing the Data</strong></p>
<p>Now we have successfully copied the iris dataset to the Spark environment as a SparkDataFrame. This means that <code>iris_tbl</code> is an R object wrapping the iris SparkDataFrame and we can use <code>iris_tbl</code> to refer the iris dataset in the Spark system (i.e. the iris SparkDataFrame). With the <code>sparklyr</code> packages, we can use many functions in <code>dplyr</code> to SparkDataFrame directly through <code>iris_tbl</code>, same as we are applying <code>dplyr</code> functions to a local R data frame in our laptop. For example, we can use the <code>%&gt;%</code> operator to pass <code>iris_tbl</code> to the <code>count( )</code> function:</p>
<pre><code>iris_tbl %&gt;% count</code></pre>
<p>or using the <code>head( )</code> function to return the first few rows in iris_tbl:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(iris_tbl)</code></pre></div>
<p>or more advanced data manipulation directly to <code>iris_tbl</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sepal_Width =</span> <span class="kw">ROUND</span>(Sepal_Width <span class="op">*</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Bucketizing Sepal_Width</span>
<span class="st">  </span><span class="kw">group_by</span>(Species, Sepal_Width) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(), <span class="dt">Sepal_Length =</span> <span class="kw">mean</span>(Sepal_Length), <span class="dt">stdev =</span> <span class="kw">sd</span>(Sepal_Length))</code></pre></div>
<p><strong>Collect Results Back to Master Node</strong></p>
<p>Even though we can run many of the <code>dplyr</code> functions on SparkDataFrame, we cannot apply functions from other packages to SparkDataFrame direction (such as <code>ggplot()</code>). For functions that can only work on local R data frames, we must copy the SparkDataFrame back to the local node. To copy SparkDataFrame back to the local node, we use the <code>collect()</code> function where the argument to it is the name of the SparkDataFrame. The following code <code>collect()</code> the results of a few operations and assign the collected data to iris_summary variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_summary &lt;-<span class="st"> </span>
<span class="st">  </span>iris_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sepal_Width =</span> <span class="kw">ROUND</span>(Sepal_Width <span class="op">*</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Species, Sepal_Width) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(), <span class="dt">Sepal_Length =</span> <span class="kw">mean</span>(Sepal_Length), <span class="dt">stdev =</span> <span class="kw">sd</span>(Sepal_Length)) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span>collect</code></pre></div>
<p>Now, <code>iris_summary</code> is a local variable to the R notebook and we can use all R packages and functions to it. In the following code, we will apply <code>ggplot()</code> to it, exactly the same as a stand along R console:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(iris_summary, <span class="kw">aes</span>(Sepal_Width, Sepal_Length, <span class="dt">color =</span> Species)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Sepal_Length <span class="op">-</span><span class="st"> </span>stdev, <span class="dt">ymax =</span> Sepal_Length <span class="op">+</span><span class="st"> </span>stdev), <span class="dt">width =</span> <span class="fl">0.05</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> count), <span class="dt">vjust =</span> <span class="op">-</span><span class="fl">0.2</span>, <span class="dt">hjust =</span> <span class="fl">1.2</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;top&quot;</span>)</code></pre></div>
<p><strong>Fit Regression to SparkDataFrame</strong></p>
<p>One of the largest advantages is that, within Spark system, there are already many statistical and machine learning algorithms developed to run parallelly across many CPUs with data across many memory units. In this example, we have already uploaded the data to Spark system, and the data in the Spark system can be referred through iris_tbl. The linear regression implemented in Spark system can be called through <code>ml_linear_regression()</code> function. The syntax to call the function is to define the Spark Data Frame (i.e. iris_tbl), response variable (i.e. y-variable in linear regression in the Spark data frame iris_tbl) and features (i.e. the x-variable in linear regression in the Spark data frame iris_tbl). So, we can easily fit a linear regression for large dataset far beyond the memory limit of one single computer, and it is truly scalable and only constrained by the resource of the Spark cluster. Below is an illustration of how to fit a linear regression to SparkDataFrame using R notebook:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit1 &lt;-<span class="st">  </span><span class="kw">ml_linear_regression</span>(<span class="dt">x =</span> iris_tbl, <span class="dt">response =</span> <span class="st">&quot;Sepal_Length&quot;</span>, 
                              <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">&quot;Sepal_Width&quot;</span>, <span class="st">&quot;Petal_Length&quot;</span>, <span class="st">&quot;Petal_Width&quot;</span>))
<span class="kw">summary</span>(fit1)</code></pre></div>
<p>In the above code, x is the R object wrapping the SparkDataFrame; the response is y-variable, features are the collection of explanatory variables. For this function, both the data and computation are in the Spark cluster which leverages multiple CPUs and distributed memories.</p>
<p><strong>Fit a K-means Cluster</strong></p>
<p>Through the <code>sparklyr</code> package, we can use an R notebook to access many Spark Machine Learning Library (MLlib) algorithms such as linear regression, logistic regression, Survival Regression, Generalized Linear Regression, Decision Trees, Random Forests, Gradient-Boosted Trees, Principal Components Analysis, Naive-Bayes, K-Means Clustering and a few other methods. Below codes fit a k-means cluster algorithm:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Now fit a k-means clustering using iris_tbl data 
## with only two out of four features in iris_tbl
fit2 &lt;-<span class="st"> </span><span class="kw">ml_kmeans</span>(<span class="dt">x =</span> iris_tbl, <span class="dt">centers =</span> <span class="dv">3</span>, 
                  <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">&quot;Petal_Length&quot;</span>, <span class="st">&quot;Petal_Width&quot;</span>))

<span class="co"># print our model fit</span>
<span class="kw">print</span>(fit2)</code></pre></div>
<p>After the k-means model is fit, we can apply the model to predict other datasets through <code>sdf_predict()</code> function. Below code apply the model to <code>iris_tbl</code> again to predict and then the results are collected back to local variable prediction through <code>collect()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prediction =<span class="st"> </span><span class="kw">collect</span>(<span class="kw">sdf_predict</span>(fit2, iris_tbl)) </code></pre></div>
<p>As prediction is a local variable, we can apply any R functions from any libraries to it. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prediction  <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Petal_Length, Petal_Width)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Petal_Width, Petal_Length, <span class="dt">col =</span> <span class="kw">factor</span>(prediction <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)),
             <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> fit2<span class="op">$</span>centers, <span class="kw">aes</span>(Petal_Width, Petal_Length),
             <span class="dt">col =</span> scales<span class="op">::</span><span class="kw">muted</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;blue&quot;</span>)),
             <span class="dt">pch =</span> <span class="st">&#39;x&#39;</span>, <span class="dt">size =</span> <span class="dv">12</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;Predicted Cluster&quot;</span>,
                       <span class="dt">labels =</span> <span class="kw">paste</span>(<span class="st">&quot;Cluster&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">&quot;Petal Length&quot;</span>,
    <span class="dt">y =</span> <span class="st">&quot;Petal Width&quot;</span>,
    <span class="dt">title =</span> <span class="st">&quot;K-Means Clustering&quot;</span>,
    <span class="dt">subtitle =</span> <span class="st">&quot;Use Spark.ML to predict cluster membership with the iris dataset.&quot;</span>
  )</code></pre></div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="power-of-cluster-of-computers.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/19-Appendix.Rmd",
"text": "Edit"
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
