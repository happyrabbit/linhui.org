<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="Introduction to Data Science">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li">


<meta name="date" content="2019-05-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="tree-based-methods.html">
<link rel="next" href="tree-pruning.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="goal-of-the-book.html"><a href="goal-of-the-book.html"><i class="fa fa-check"></i>Goal of the Book</a></li>
<li class="chapter" data-level="" data-path="who-this-book-is-for.html"><a href="who-this-book-is-for.html"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="what-this-book-covers.html"><a href="what-this-book-covers.html"><i class="fa fa-check"></i>What This Book Covers</a></li>
<li class="chapter" data-level="" data-path="conventions.html"><a href="conventions.html"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html"><i class="fa fa-check"></i><b>1.1</b> Blind men and an elephant</a><ul>
<li class="chapter" data-level="1.1.1" data-path="blind-men-and-an-elephant.html"><a href="blind-men-and-an-elephant.html#data-science-roleskill-tracks"><i class="fa fa-check"></i><b>1.1.1</b> Data science role/skill tracks</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html"><i class="fa fa-check"></i><b>1.2</b> What should data science do?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#lets-dream-big"><i class="fa fa-check"></i><b>1.2.1</b> Let’s dream big</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-should-data-science-do.html"><a href="what-should-data-science-do.html#what-kind-of-questions-can-data-science-solve"><i class="fa fa-check"></i><b>1.2.2</b> What kind of questions can data science solve?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html"><i class="fa fa-check"></i><b>2</b> Soft Skills for Data Scientists</a><ul>
<li class="chapter" data-level="2.1" data-path="comparison-between-statistician-and-data-scientist.html"><a href="comparison-between-statistician-and-data-scientist.html"><i class="fa fa-check"></i><b>2.1</b> Comparison between Statistician and Data Scientist</a></li>
<li class="chapter" data-level="2.2" data-path="where-does-data-science-team-fits.html"><a href="where-does-data-science-team-fits.html"><i class="fa fa-check"></i><b>2.2</b> Where Does Data Science Team Fits?</a></li>
<li class="chapter" data-level="2.3" data-path="beyond-data-and-analytics.html"><a href="beyond-data-and-analytics.html"><i class="fa fa-check"></i><b>2.3</b> Beyond Data and Analytics</a></li>
<li class="chapter" data-level="2.4" data-path="data-scientist-as-a-leader.html"><a href="data-scientist-as-a-leader.html"><i class="fa fa-check"></i><b>2.4</b> Data Scientist as a Leader</a></li>
<li class="chapter" data-level="2.5" data-path="three-pillars-of-knowledge.html"><a href="three-pillars-of-knowledge.html"><i class="fa fa-check"></i><b>2.5</b> Three Pillars of Knowledge</a></li>
<li class="chapter" data-level="2.6" data-path="common-pitfalls-of-data-science-projects.html"><a href="common-pitfalls-of-data-science-projects.html"><i class="fa fa-check"></i><b>2.6</b> Common Pitfalls of Data Science Projects</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-the-data.html"><a href="introduction-to-the-data.html"><i class="fa fa-check"></i><b>3</b> Introduction to the data</a><ul>
<li class="chapter" data-level="3.1" data-path="customer-data-for-clothing-company.html"><a href="customer-data-for-clothing-company.html"><i class="fa fa-check"></i><b>3.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="3.2" data-path="customer-satisfaction-survey-data-from-airline-company.html"><a href="customer-satisfaction-survey-data-from-airline-company.html"><i class="fa fa-check"></i><b>3.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
<li class="chapter" data-level="3.3" data-path="swine-disease-breakout-data.html"><a href="swine-disease-breakout-data.html"><i class="fa fa-check"></i><b>3.3</b> Swine Disease Breakout Data</a></li>
<li class="chapter" data-level="3.4" data-path="mnist-dataset.html"><a href="mnist-dataset.html"><i class="fa fa-check"></i><b>3.4</b> MNIST Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>4</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="4.1" data-path="data-cleaning.html"><a href="data-cleaning.html"><i class="fa fa-check"></i><b>4.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.2" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>4.2</b> Missing Values</a><ul>
<li class="chapter" data-level="4.2.1" data-path="missing-values.html"><a href="missing-values.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>4.2.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="4.2.2" data-path="missing-values.html"><a href="missing-values.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.2.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="4.2.3" data-path="missing-values.html"><a href="missing-values.html#bagging-tree"><i class="fa fa-check"></i><b>4.2.3</b> Bagging Tree</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="centering-and-scaling.html"><a href="centering-and-scaling.html"><i class="fa fa-check"></i><b>4.3</b> Centering and Scaling</a></li>
<li class="chapter" data-level="4.4" data-path="resolve-skewness.html"><a href="resolve-skewness.html"><i class="fa fa-check"></i><b>4.4</b> Resolve Skewness</a></li>
<li class="chapter" data-level="4.5" data-path="resolve-outliers.html"><a href="resolve-outliers.html"><i class="fa fa-check"></i><b>4.5</b> Resolve Outliers</a></li>
<li class="chapter" data-level="4.6" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>4.6</b> Collinearity</a></li>
<li class="chapter" data-level="4.7" data-path="sparse-variables.html"><a href="sparse-variables.html"><i class="fa fa-check"></i><b>4.7</b> Sparse Variables</a></li>
<li class="chapter" data-level="4.8" data-path="re-encode-dummy-variables.html"><a href="re-encode-dummy-variables.html"><i class="fa fa-check"></i><b>4.8</b> Re-encode Dummy Variables</a></li>
<li class="chapter" data-level="4.9" data-path="python-computing.html"><a href="python-computing.html"><i class="fa fa-check"></i><b>4.9</b> Python Computing</a><ul>
<li class="chapter" data-level="4.9.1" data-path="python-computing.html"><a href="python-computing.html#data-cleaning-1"><i class="fa fa-check"></i><b>4.9.1</b> Data Cleaning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>5</b> Data Wrangling</a><ul>
<li class="chapter" data-level="5.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html"><i class="fa fa-check"></i><b>5.1</b> Data Wrangling Using R</a><ul>
<li class="chapter" data-level="5.1.1" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#read-and-write-data"><i class="fa fa-check"></i><b>5.1.1</b> Read and write data</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#summarize-data"><i class="fa fa-check"></i><b>5.1.2</b> Summarize data</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#dplyr-package"><i class="fa fa-check"></i><b>5.1.3</b> <code>dplyr</code> package</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#tidy-and-reshape-data"><i class="fa fa-check"></i><b>5.1.4</b> Tidy and Reshape Data</a></li>
<li class="chapter" data-level="5.1.5" data-path="data-wrangling-using-r.html"><a href="data-wrangling-using-r.html#data-wrangling-using-python"><i class="fa fa-check"></i><b>5.1.5</b> Data Wrangling Using Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-tuning-strategy.html"><a href="model-tuning-strategy.html"><i class="fa fa-check"></i><b>6</b> Model Tuning Strategy</a><ul>
<li class="chapter" data-level="6.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html"><i class="fa fa-check"></i><b>6.1</b> Systematic Error and Random Error</a><ul>
<li class="chapter" data-level="6.1.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-response"><i class="fa fa-check"></i><b>6.1.1</b> Measurement Error in the Response</a></li>
<li class="chapter" data-level="6.1.2" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-independent-variables"><i class="fa fa-check"></i><b>6.1.2</b> Measurement Error in the Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html"><i class="fa fa-check"></i><b>6.2</b> Data Splitting and Resampling</a><ul>
<li class="chapter" data-level="6.2.1" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#data-splitting"><i class="fa fa-check"></i><b>6.2.1</b> Data Splitting</a></li>
<li class="chapter" data-level="6.2.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html#resampling"><i class="fa fa-check"></i><b>6.2.2</b> Resampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="measuring-performance.html"><a href="measuring-performance.html"><i class="fa fa-check"></i><b>7</b> Measuring Performance</a><ul>
<li class="chapter" data-level="7.1" data-path="regression-model-performance.html"><a href="regression-model-performance.html"><i class="fa fa-check"></i><b>7.1</b> Regression Model Performance</a></li>
<li class="chapter" data-level="7.2" data-path="classification-model-performance.html"><a href="classification-model-performance.html"><i class="fa fa-check"></i><b>7.2</b> Classification Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>8</b> Feature Engineering</a><ul>
<li class="chapter" data-level="8.1" data-path="feature-construction.html"><a href="feature-construction.html"><i class="fa fa-check"></i><b>8.1</b> Feature Construction</a></li>
<li class="chapter" data-level="8.2" data-path="feature-extraction.html"><a href="feature-extraction.html"><i class="fa fa-check"></i><b>8.2</b> Feature Extraction</a></li>
<li class="chapter" data-level="8.3" data-path="feature-selection.html"><a href="feature-selection.html"><i class="fa fa-check"></i><b>8.3</b> Feature Selection</a><ul>
<li class="chapter" data-level="8.3.1" data-path="feature-selection.html"><a href="feature-selection.html#filter-method"><i class="fa fa-check"></i><b>8.3.1</b> Filter Method</a></li>
<li class="chapter" data-level="8.3.2" data-path="feature-selection.html"><a href="feature-selection.html#wrapper-method"><i class="fa fa-check"></i><b>8.3.2</b> Wrapper Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>9</b> Regression Models</a><ul>
<li class="chapter" data-level="9.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>9.1</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="9.2" data-path="multivariate-adaptive-regression-splines.html"><a href="multivariate-adaptive-regression-splines.html"><i class="fa fa-check"></i><b>9.2</b> Multivariate Adaptive Regression Splines</a></li>
<li class="chapter" data-level="9.3" data-path="generalized-linear-model.html"><a href="generalized-linear-model.html"><i class="fa fa-check"></i><b>9.3</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="9.4" data-path="pcr-and-pls.html"><a href="pcr-and-pls.html"><i class="fa fa-check"></i><b>9.4</b> PCR and PLS</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regularization-methods.html"><a href="regularization-methods.html"><i class="fa fa-check"></i><b>10</b> Regularization Methods</a><ul>
<li class="chapter" data-level="10.1" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>10.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="10.2" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>10.2</b> LASSO</a></li>
<li class="chapter" data-level="10.3" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>10.3</b> Elastic Net</a></li>
<li class="chapter" data-level="10.4" data-path="lasso-generalized-linear-model.html"><a href="lasso-generalized-linear-model.html"><i class="fa fa-check"></i><b>10.4</b> LASSO Generalized Linear Model</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>11</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="11.1" data-path="splitting-criteria.html"><a href="splitting-criteria.html"><i class="fa fa-check"></i><b>11.1</b> Splitting Criteria</a></li>
<li class="chapter" data-level="11.2" data-path="tree-pruning.html"><a href="tree-pruning.html"><i class="fa fa-check"></i><b>11.2</b> Tree Pruning</a></li>
<li class="chapter" data-level="11.3" data-path="regression-and-decision-tree-basic.html"><a href="regression-and-decision-tree-basic.html"><i class="fa fa-check"></i><b>11.3</b> Regression and Decision Tree Basic</a></li>
<li class="chapter" data-level="11.4" data-path="bagging-tree-1.html"><a href="bagging-tree-1.html"><i class="fa fa-check"></i><b>11.4</b> Bagging Tree</a></li>
<li class="chapter" data-level="11.5" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>11.5</b> Random Forest</a></li>
<li class="chapter" data-level="11.6" data-path="gradient-boosted-machine.html"><a href="gradient-boosted-machine.html"><i class="fa fa-check"></i><b>11.6</b> Gradient Boosted Machine</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neural-network.html"><a href="neural-network.html"><i class="fa fa-check"></i><b>12</b> Neural Network</a><ul>
<li class="chapter" data-level="12.1" data-path="projection-pursuit-regression.html"><a href="projection-pursuit-regression.html"><i class="fa fa-check"></i><b>12.1</b> Projection Pursuit Regression</a></li>
<li class="chapter" data-level="12.2" data-path="standard-neural-network.html"><a href="standard-neural-network.html"><i class="fa fa-check"></i><b>12.2</b> Standard Neural Network</a><ul>
<li class="chapter" data-level="12.2.1" data-path="standard-neural-network.html"><a href="standard-neural-network.html#logistic_reg_as_neural_network"><i class="fa fa-check"></i><b>12.2.1</b> Logistic Regression as Neural Network</a></li>
<li class="chapter" data-level="12.2.2" data-path="standard-neural-network.html"><a href="standard-neural-network.html#one-layer-neural-network"><i class="fa fa-check"></i><b>12.2.2</b> One layer neural network</a></li>
<li class="chapter" data-level="12.2.3" data-path="standard-neural-network.html"><a href="standard-neural-network.html#activation-function"><i class="fa fa-check"></i><b>12.2.3</b> Activation Function</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="convolutional-neural-network.html"><a href="convolutional-neural-network.html"><i class="fa fa-check"></i><b>12.3</b> Convolutional Neural Network</a></li>
<li class="chapter" data-level="12.4" data-path="recurrent-neural-network.html"><a href="recurrent-neural-network.html"><i class="fa fa-check"></i><b>12.4</b> Recurrent Neural Network</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html"><i class="fa fa-check"></i><b>A</b> Big Data Cloud Platform</a><ul>
<li class="chapter" data-level="A.1" data-path="how-data-becomes-science.html"><a href="how-data-becomes-science.html"><i class="fa fa-check"></i><b>A.1</b> How Data becomes Science?</a></li>
<li class="chapter" data-level="A.2" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html"><i class="fa fa-check"></i><b>A.2</b> Power of Cluster of Computers</a><ul>
<li class="chapter" data-level="A.2.1" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#evolution-of-clustering-computing"><i class="fa fa-check"></i><b>A.2.1</b> Evolution of Clustering Computing</a></li>
<li class="chapter" data-level="A.2.2" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#hadoop"><i class="fa fa-check"></i><b>A.2.2</b> Hadoop</a></li>
<li class="chapter" data-level="A.2.3" data-path="power-of-cluster-of-computers.html"><a href="power-of-cluster-of-computers.html#spark"><i class="fa fa-check"></i><b>A.2.3</b> Spark</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="introduction-of-cloud-environment.html"><a href="introduction-of-cloud-environment.html"><i class="fa fa-check"></i><b>A.3</b> Introduction of Cloud Environment</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="databases-and-sql.html"><a href="databases-and-sql.html"><i class="fa fa-check"></i><b>B</b> Databases and SQL</a></li>
<li class="chapter" data-level="C" data-path="r-code-for-data-simulation.html"><a href="r-code-for-data-simulation.html"><i class="fa fa-check"></i><b>C</b> R code for data simulation</a><ul>
<li class="chapter" data-level="C.1" data-path="customer-data-for-clothing-company-1.html"><a href="customer-data-for-clothing-company-1.html"><i class="fa fa-check"></i><b>C.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="C.2" data-path="customer-satisfaction-survey-data-from-airline-company-1.html"><a href="customer-satisfaction-survey-data-from-airline-company-1.html"><i class="fa fa-check"></i><b>C.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
<li class="chapter" data-level="C.3" data-path="swine-disease-breakout-data-1.html"><a href="swine-disease-breakout-data-1.html"><i class="fa fa-check"></i><b>C.3</b> Swine Disease Breakout Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="splitting-criteria" class="section level2">
<h2><span class="header-section-number">11.1</span> Splitting Criteria</h2>
<p>The splitting criteria used by the regression tree and the classification tree are different. Like the regression tree, the goal of the classification tree is to divide the data into smaller, more homogeneous groups. Homogeneity means that most of the samples at each node are from one class. The original CART algorithm uses Gini impurity as the splitting criterion; The later ID3, C4.5, and C5.0 use entropy. We will look at three most common splitting criteria.</p>
<p><strong>Gini impurity</strong></p>
<p>Gini impurity<span class="citation">(al <a href="#ref-Breiman1984">1984</a>)</span> is a measure of non-homogeneity. It is widely used in classification tree. For a two-class problem, the Gini impurity for a given node is defined as:</p>
<p><span class="math display">\[p_{1}(1-p_{1})+p_{2}(1-p_{2})\]</span></p>
<p>where <span class="math inline">\(p_{1}\)</span> and <span class="math inline">\(p_{2}\)</span> are probabilities for the two classes respectively. It is easy to see that when the sample set is pure, one of the probability is 0 and the Gini score is the smallest. Conversely, when <span class="math inline">\(p_{1}=p_{2}=0.5\)</span>, the Gini score is the largest, in which case the purity of the node is the smallest. Let’s look at an example. Suppose we want to determine which students are computer science (CS) majors. Here is the simple hypothetical classification tree result obtained with the gender variable.</p>
<center>
<img src="../linhui.org/book/Figure/giniEN.PNG" />
</center>
<p>Let’s calculate the Gini impurity for splitting node “Gender”:</p>
<ol style="list-style-type: decimal">
<li>Gini impurity for “Female” = <span class="math inline">\(\frac{1}{6}\times\frac{5}{6}+\frac{5}{6}\times\frac{1}{6}=\frac{5}{18}\)</span></li>
<li>Gini impurity for “Male” = <span class="math inline">\(0\times1+1\times 0=0\)</span></li>
</ol>
<p>The Gini impurity for the node “Gender” is the following weighted average of the above two scores:</p>
<p><span class="math display">\[\frac{3}{5}\times\frac{5}{18}+\frac{2}{5}\times 0=\frac{1}{6}\]</span></p>
<p>The Gini impurity for the 50 samples in the parent node is <span class="math inline">\(\frac{1}{2}\)</span>. It is easy to calculate the Gini impurity drop from <span class="math inline">\(\frac{1}{2}\)</span> to <span class="math inline">\(\frac{1}{6}\)</span> after splitting. The split using “gender” causes a Gini impurity decrease of <span class="math inline">\(\frac{1}{3}\)</span>. The algorithm will use different variables to split the data and choose the one that causes the most substantial Gini impurity decrease.</p>
<p><strong>Information gain</strong></p>
<p>Looking at the samples in the following three nodes, which one is the easiest to describe? It is obviously C. Because all the samples in C are of the same type, so the description requires the least amount of information. On the contrary, B needs more information, and A needs the most information. In other words, C has the highest purity, B is the second, and A has the lowest purity. We need less information to describe nodes with lower purity.</p>
<center>
<img src="../linhui.org/book/Figure/InfoGainEN.PNG" />
</center>
<p>A measure of the degree of disorder is entropy which is defined as:</p>
<p><span class="math display">\[Entropy=-plog_{2}p-(1-p)log_{2}(1-p)\]</span></p>
<p>where p is the percentage of one type of samples. If all the samples in one node are of one type (such as C), the entropy is 0. If the proportion of each type in a node is 50%－50%, the entropy is 1. We can use entropy as splitting criteria. The goal is to decrease entropy as the tree grows.</p>
<p>Similarly, the entropy of a splitting node is the weighted average of the entropy of each child. In the above tree for the students, the entropy of the root node with all 50 students is <span class="math inline">\(-\frac{25}{50}log_{2}\frac{25}{50}-\frac{25}{50}log_{2}\frac{25}{50}=1\)</span>. Here an entropy of 1 indicates that the purity of the node is the lowest, that is, each type takes up half of the samples.</p>
<p>The entropy of the split using variable “gender” can be calculated in three steps:</p>
<ol style="list-style-type: decimal">
<li>Entropy for “Female” = <span class="math inline">\(-\frac{5}{30}log_{2}\frac{5}{30}-\frac{25}{30}log_{2}\frac{25}{30}=0.65\)</span></li>
<li>Entropy for “Male” = <span class="math inline">\(0\times1+1\times 0=0\)</span></li>
<li>Entropy for the node “Gender” is the weighted average of the above two entropy numbers: <span class="math inline">\(\frac{3}{5}\times 0.65+\frac{2}{5}\times 0=0.39\)</span></li>
</ol>
<p>So entropy decreases from 1 to 0.39 after the split.</p>
<p><strong>Sum of Square Error (SSE)</strong></p>
<p>The previous two metrics are for classification tree. The SSE is the most widely used splitting metric for regression. Suppose you want to divide the data set <span class="math inline">\(S\)</span> into two groups of <span class="math inline">\(S_{1}\)</span> and <span class="math inline">\(S_{2}\)</span>, where the selection of <span class="math inline">\(S_{1}\)</span> and <span class="math inline">\(S_{2}\)</span> needs to minimize the sum of squared errors:</p>
<span class="math display" id="eq:treesse">\[\begin{equation}
SSE=\Sigma_{i\in S_{1}}(y_{i}-\bar{y}_{1})^{2}+\Sigma_{i\in S_{2}}(y_{i}-\bar{y}_{2})^{2}
\tag{11.1}
\end{equation}\]</span>
<p>In equation <a href="splitting-criteria.html#eq:treesse">(11.1)</a>, <span class="math inline">\(\bar{y}_{1}\)</span> and <span class="math inline">\(\bar{y}_{1}\)</span> are the average of the sample in <span class="math inline">\(S_{1}\)</span> and <span class="math inline">\(S_{2}\)</span>. The way regression tree grows is to automatically decide on the splitting variables and split points that can maximize <strong>SSE reduction</strong>. Since this process is essentially a recursive segmentation, this approach is also called recursive partitioning.</p>
<p>Take a look at this simple regression tree for the height of 10 students:</p>
<center>
<img src="images/varEN.png" />
</center>
<p>You can calculate the SSE using the following code:</p>
<ol style="list-style-type: decimal">
<li>SSE for “Female” is 136</li>
<li>SSE for “Male” is 32</li>
<li>SSE for splitting node “Gender” is the sum of the above two numbers which is 168</li>
</ol>
<p>SSE for the 10 students in root node is 522.9. After the split, SSE decreases from 522.9 to 168.</p>
<p>If there is another possible way of splitting, divide it by major, as follows:</p>
<center>
<img src="images/varEN2.png" />
</center>
<p>In this situation:</p>
<ol style="list-style-type: decimal">
<li>SSE for “Math” is 184</li>
<li>SSE for “English” is 302.8</li>
<li>SSE for splitting node “Major” is the sum of the above two numbers which is 486.8</li>
</ol>
<p>Splitting data using variable “gender” reduced SSE from 522.9 to 168; using variable “major” reduced SSE from 522.9 to 486.8. Based on SSE reduction, you should use gender to split the data.</p>
<p>The three splitting criteria mentioned above are the basis for building a tree model.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Breiman1984">
<p>al, Leo Breiman et. 1984. <em>Classification and Regression Trees</em>. ISBN 978-0412048418. Chapman; Hall/CRC.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tree-based-methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tree-pruning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/11-tree.Rmd",
"text": "Edit"
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
