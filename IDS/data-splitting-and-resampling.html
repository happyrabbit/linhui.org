<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="Introduction to Data Science">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://scientistcafe.com/IDS/" />
  
  <meta property="og:description" content="Introduction to Data Science" />
  <meta name="github-repo" content="happyrabbit/IntroDataScience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="Introduction to Data Science" />
  

<meta name="author" content="Hui Lin and Ming Li">


<meta name="date" content="2018-01-11">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="systematic-error-and-random-error.html">
<link rel="next" href="references.html">
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="goal-of-the-book.html"><a href="goal-of-the-book.html"><i class="fa fa-check"></i>Goal of the Book</a></li>
<li class="chapter" data-level="" data-path="who-this-book-is-for.html"><a href="who-this-book-is-for.html"><i class="fa fa-check"></i>Who This Book Is For</a></li>
<li class="chapter" data-level="" data-path="what-this-book-covers.html"><a href="what-this-book-covers.html"><i class="fa fa-check"></i>What This Book Covers</a></li>
<li class="chapter" data-level="" data-path="conventions.html"><a href="conventions.html"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-data-science.html"><a href="what-is-data-science.html"><i class="fa fa-check"></i><b>1.1</b> What is data science?</a></li>
<li class="chapter" data-level="1.2" data-path="what-kind-of-questions-can-data-science-solve.html"><a href="what-kind-of-questions-can-data-science-solve.html"><i class="fa fa-check"></i><b>1.2</b> What kind of questions can data science solve?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="what-kind-of-questions-can-data-science-solve.html"><a href="what-kind-of-questions-can-data-science-solve.html#prerequisites"><i class="fa fa-check"></i><b>1.2.1</b> Prerequisites</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-kind-of-questions-can-data-science-solve.html"><a href="what-kind-of-questions-can-data-science-solve.html#problem-type"><i class="fa fa-check"></i><b>1.2.2</b> Problem type</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="data-scientist-skill-set.html"><a href="data-scientist-skill-set.html"><i class="fa fa-check"></i><b>1.3</b> Data Scientist Skill Set</a></li>
<li class="chapter" data-level="1.4" data-path="types-of-learning.html"><a href="types-of-learning.html"><i class="fa fa-check"></i><b>1.4</b> Types of Learning</a></li>
<li class="chapter" data-level="1.5" data-path="types-of-algorithm.html"><a href="types-of-algorithm.html"><i class="fa fa-check"></i><b>1.5</b> Types of Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-the-data.html"><a href="introduction-to-the-data.html"><i class="fa fa-check"></i><b>2</b> Introduction to the data</a><ul>
<li class="chapter" data-level="2.1" data-path="customer-data-for-clothing-company.html"><a href="customer-data-for-clothing-company.html"><i class="fa fa-check"></i><b>2.1</b> Customer Data for Clothing Company</a></li>
<li class="chapter" data-level="2.2" data-path="customer-satisfaction-survey-data-from-airline-company.html"><a href="customer-satisfaction-survey-data-from-airline-company.html"><i class="fa fa-check"></i><b>2.2</b> Customer Satisfaction Survey Data from Airline Company</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>3</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning.html"><a href="data-cleaning.html"><i class="fa fa-check"></i><b>3.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="3.2" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>3.2</b> Missing Values</a><ul>
<li class="chapter" data-level="3.2.1" data-path="missing-values.html"><a href="missing-values.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>3.2.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="3.2.2" data-path="missing-values.html"><a href="missing-values.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.2.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="3.2.3" data-path="missing-values.html"><a href="missing-values.html#bagging-tree"><i class="fa fa-check"></i><b>3.2.3</b> Bagging Tree</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="centering-and-scaling.html"><a href="centering-and-scaling.html"><i class="fa fa-check"></i><b>3.3</b> Centering and Scaling</a></li>
<li class="chapter" data-level="3.4" data-path="resolve-skewness.html"><a href="resolve-skewness.html"><i class="fa fa-check"></i><b>3.4</b> Resolve Skewness</a></li>
<li class="chapter" data-level="3.5" data-path="resolve-outliers.html"><a href="resolve-outliers.html"><i class="fa fa-check"></i><b>3.5</b> Resolve Outliers</a></li>
<li class="chapter" data-level="3.6" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>3.6</b> Collinearity</a></li>
<li class="chapter" data-level="3.7" data-path="sparse-variables.html"><a href="sparse-variables.html"><i class="fa fa-check"></i><b>3.7</b> Sparse Variables</a></li>
<li class="chapter" data-level="3.8" data-path="re-encode-dummy-variables.html"><a href="re-encode-dummy-variables.html"><i class="fa fa-check"></i><b>3.8</b> Re-encode Dummy Variables</a></li>
<li class="chapter" data-level="3.9" data-path="python-computing.html"><a href="python-computing.html"><i class="fa fa-check"></i><b>3.9</b> Python Computing</a><ul>
<li class="chapter" data-level="3.9.1" data-path="python-computing.html"><a href="python-computing.html#data-cleaning-1"><i class="fa fa-check"></i><b>3.9.1</b> Data Cleaning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-tuning-strategy.html"><a href="model-tuning-strategy.html"><i class="fa fa-check"></i><b>4</b> Model Tuning Strategy</a><ul>
<li class="chapter" data-level="4.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html"><i class="fa fa-check"></i><b>4.1</b> Systematic Error and Random Error</a><ul>
<li class="chapter" data-level="4.1.1" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-response"><i class="fa fa-check"></i><b>4.1.1</b> Measurement Error in the Response</a></li>
<li class="chapter" data-level="4.1.2" data-path="systematic-error-and-random-error.html"><a href="systematic-error-and-random-error.html#measurement-error-in-the-independent-variables"><i class="fa fa-check"></i><b>4.1.2</b> Measurement Error in the Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-splitting-and-resampling.html"><a href="data-splitting-and-resampling.html"><i class="fa fa-check"></i><b>4.2</b> Data Splitting and Resampling</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>5</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-splitting-and-resampling" class="section level2">
<h2><span class="header-section-number">4.2</span> Data Splitting and Resampling</h2>
<p>Those highly adaptable models can model complex relationships. However, they tend to overfit which leads to the poor prediction by learning too much from the data. It means that the model is susceptible to the specific sample used to fit it. When future data is not exactly like the past data, the model prediction may have big mistakes. A simple model like ordinary linear regression tends instead to underfit which leads to a bad prediction by learning too little from the data. It systematically over-predicts or under-predicts the data regardless of how well future data resemble past data. Without evaluating models, the modeler will not know about the problem before the future samples. Data splitting and resampling are fundamental techniques to build sound models for prediction.</p>
<p><em>Data splitting</em> is to put part of the data aside as testing set (or Hold-outs, out of bag samples) and use the rest for model training. Training samples are also called in-sample. Model performance metrics evaluated using in-sample are retrodictive, not predictive.</p>
<p>The traditional business intelligence usually handles data description. Answer simple questions by querying and summarizing the data, such as:</p>
<ul>
<li>What is the monthly sales of a product in 2015?</li>
<li>What is the number of visits to our site in the past month?<br />
</li>
<li>What is the sales difference in 2015 for two different product designs?</li>
</ul>
<p>There is no need to go through the tedious process of splitting the data, tuning and testing model to answer questions of this kind. Instead, people usually use as complete data as possible and then sum or average the parts of interest.</p>
<p>Many models have parameters which cannot be directly estimated from the data, such as <span class="math inline">\(\lambda\)</span> in the lasso (penalty parameter), the number of trees in the random forest. This type of model parameter is called tuning parameter, and there is no analytical formula available to calculate the optimized value. Tuning parameters often control the complexity of the model. A poor choice can result in over-fitting or under-fitting. A standard approach to estimate tuning parameters is through cross-validation which is a data resampling approach.</p>
<p>To get a reasonable precision of the performance based on a single test set, the size of the test set may need to be large. So a conventional approach is to use a subset of samples to fit the model and use the rest to evaluate model performance. This process will repeat multiple times to get a performance profile. In that sense, resampling is based on splitting. The general steps are:</p>
<ul>
<li>Define a set of candidate values for tuning parameter(s)
<ul>
<li>For each candidate value in the set
<ul>
<li>Resample data</li>
<li>Fit model</li>
<li>Predict hold-out</li>
<li>Calculate performance</li>
</ul></li>
</ul></li>
<li>Aggregate the results</li>
<li>Determine the final tuning parameter</li>
<li>Refit the model with the entire data set</li>
</ul>
<div class="figure">
<img src="images/ParameterTuningProcess.png" alt="Parameter Tuning Process" style="width:80.0%" />
<p class="caption">Parameter Tuning Process</p>
</div>
<p>The above is an outline of the general procedure to tune parameters. Now let’s focus on the critical part of the process: data splitting. Ideally, we should evaluate model using samples that were not used to build or fine-tune the model. So it provides an unbiased sense of model effectiveness. When the sample size is large, it is a good practice to set aside part of the samples to evaluate the final model. People use “training” data to indicate samples used to fit or fine-tune the model and “test” or “validation” data set is used to validate performance.</p>
<p>The first decision to make for data splitting is to decide the proportion of data in the test set. There are two factors to consider here: (1) sample size; (2) computation intensity. If the sample size is large enough which is the most common situation according to my experience, you can try to use 20%, 30% and 40% of the data as the test set, and see which one works the best. If the model is computationally intense, then you may consider starting from a smaller sample of data to train the model hence will have a higher portion of data in the test set. Depending on how it performs, you may need to increase the training set. If the sample size is small, you can use cross-validation or bootstrap which is the topic in the next section.</p>
<p>The next decision is to decide which samples are in the test set. There is a desire to make the training and test sets as similar as possible. A simple way is to split data by random sampling which, however, does not control for any of the data attributes, such as the percentage of the retained customer in the data. So it is possible that the distribution of outcomes is substantially different between the training and test sets. There are three main ways to split the data that account for the similarity of resulted data sets. We will describe the three approaches using the clothing company customer data as examples.</p>
<ol style="list-style-type: decimal">
<li>Split data according to the outcome variable</li>
</ol>
<p>Assume the outcome variable is customer segment (column <code>segment</code>) and we decide to use 80% as training and 20% test. The goal is to make the proportions of the categories in the two sets as similar as possible. The <code>createDataPartition()</code> function in <code>caret</code> will return a balanced splitting based on assigned variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load data</span>
sim.dat&lt;-<span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv&quot;</span>)
<span class="kw">library</span>(caret)
<span class="co"># set random seed to make sure reproducibility</span>
<span class="kw">set.seed</span>(<span class="dv">3456</span>)
trainIndex &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(sim.dat$segment, <span class="dt">p =</span> .<span class="dv">8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)
<span class="kw">head</span>(trainIndex)</code></pre></div>
<pre><code>##      Resample1
## [1,]         1
## [2,]         2
## [3,]         3
## [4,]         4
## [5,]         6
## [6,]         7</code></pre>
<p>The <code>list = FALSE</code> in the call to <code>createDataPartition</code> is to return a data frame. The <code>times = 1</code> tells R how many times you want to split the data. Here we only do it once, but you can repeat the splitting multiple times. In that case, the function will return multiple vectors indicating the rows to training/test. You can set <code>times＝2</code> and rerun the above code to see the result. Then we can use the returned indicator vector <code>trainIndex</code> to get training and test sets:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get training set</span>
datTrain &lt;-<span class="st"> </span>sim.dat[ trainIndex,]
<span class="co"># get test set</span>
datTest &lt;-<span class="st"> </span>sim.dat[-trainIndex,]</code></pre></div>
<p>According to the setting, there are 800 samples in the training set and 200 in test set. Let’s check the distribution of the two sets:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plyr)
<span class="kw">ddply</span>(datTrain,<span class="st">&quot;segment&quot;</span>,summarise,<span class="dt">count=</span><span class="kw">length</span>(segment),
     <span class="dt">percentage=</span><span class="kw">round</span>( <span class="kw">length</span>(segment)/<span class="kw">nrow</span>(datTrain),<span class="dv">2</span>))</code></pre></div>
<pre><code>##       segment count percentage
## 1 Conspicuous   160       0.20
## 2       Price   200       0.25
## 3     Quality   160       0.20
## 4       Style   280       0.35</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ddply</span>(datTest,<span class="st">&quot;segment&quot;</span>,summarise,<span class="dt">count=</span><span class="kw">length</span>(segment),
      <span class="dt">percentage=</span><span class="kw">round</span>(<span class="kw">length</span>(segment)/<span class="kw">nrow</span>(datTest),<span class="dv">2</span>))</code></pre></div>
<pre><code>##       segment count percentage
## 1 Conspicuous    40       0.20
## 2       Price    50       0.25
## 3     Quality    40       0.20
## 4       Style    70       0.35</code></pre>
<p>The percentages are the same for these two sets. In practice, it is possible that the distributions are not exactly identical but should be close.</p>
<ol start="2" style="list-style-type: decimal">
<li>Divide data according to predictors</li>
</ol>
<p>An alternative way is to split data based on the predictors. The goal is to get a diverse subset from a dataset so that the sample is representative. In other words, we need an algorithm to identify the <span class="math inline">\(n\)</span> most diverse samples from a dataset with size <span class="math inline">\(N\)</span>. However, the task is generally infeasible for non-trivial values of <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span> <span class="citation">(Willett <a href="#ref-willett">2004</a>)</span>. And hence practicable approaches to dissimilarity-based selection involve approximate methods that are sub-optimal. A major class of algorithms split the data on <em>maximum dissimilarity sampling</em>. The process starts from:</p>
<ul>
<li>Initialize a single sample as starting test set</li>
<li>Calculate the dissimilarity between this initial sample and each remaining samples in the dataset</li>
<li>Add the most dissimilar unallocated sample to the test set</li>
</ul>
<p>To move forward, we need to define the dissimilarity between groups. Each definition results in a different version of the algorithm and hence a different subset. It is the same problem as in hierarchical clustering where you need to define a way to measure the distance between clusters. The possible approaches are to use minimum, maximum, sum of all distances, the average of all distances, etc. Unfortunately, there is not a single best choice, and you may have to try multiple methods and check the resulted sample sets. R users can implement the algorithm using <code>maxDissim()</code> function from <code>caret</code> package. The <code>obj</code> argument is to set the definition of dissimilarity. Refer to the help documentation for more details (<code>?maxDissim</code>).</p>
<p>Let’s use two variables (<code>age</code> and <code>income</code>) from the customer data as an example to illustrate how it works in R and compare maximum dissimilarity sampling with random sampling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lattice)
<span class="co"># select variables</span>
testing&lt;-<span class="kw">subset</span>(sim.dat,<span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;income&quot;</span> ))</code></pre></div>
<p>Random select 5 samples as initial subset (<code>start</code>) , the rest will be in <code>samplePool</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">5</span>)
<span class="co"># select 5 random samples</span>
startSet &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">dim</span>(testing)[<span class="dv">1</span>], <span class="dv">5</span>)
start &lt;-<span class="st"> </span>testing[startSet,]
<span class="co"># save the rest in data frame &quot;samplePool&quot;</span>
samplePool &lt;-<span class="st"> </span>testing[-startSet,]</code></pre></div>
<p>Use <code>maxDissim()</code> to select another 5 samples from <code>samplePool</code> that are as different as possible with the initical set <code>start</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">selectId &lt;-<span class="st"> </span><span class="kw">maxDissim</span>(start, samplePool,<span class="dt">obj =</span> minDiss, <span class="dt">n =</span> <span class="dv">5</span>)
minDissSet &lt;-samplePool[selectId, ]</code></pre></div>
<p>The <code>obj = minDiss</code> in the above code tells R to use minimum dissimilarity to define the distance between groups. Next, random select 5 samples from <code>samplePool</code> in data frame <code>RandomSet</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">selectId &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">dim</span>(samplePool)[<span class="dv">1</span>], <span class="dv">5</span>)
RandomSet&lt;-samplePool[selectId, ]</code></pre></div>
<p>Plot the resulted set to compare different sampling methods:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start$group&lt;-<span class="kw">rep</span>(<span class="st">&quot;start&quot;</span>,<span class="kw">nrow</span>(start))
minDissSet $group&lt;-<span class="kw">rep</span>(<span class="st">&quot;Maximum Dissimilarity Sampling&quot;</span>,<span class="kw">nrow</span>(minDissSet))
RandomSet$group&lt;-<span class="kw">rep</span>(<span class="st">&quot;Random Sampling&quot;</span>,<span class="kw">nrow</span>(RandomSet))
<span class="kw">xyplot</span>(age~income,<span class="dt">data=</span><span class="kw">rbind</span>(start, minDissSet, RandomSet),<span class="dt">grid =</span> <span class="ot">TRUE</span>,
       <span class="dt">group =</span> group, <span class="dt">auto.key =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:maxdis"></span>
<img src="IDS_files/figure-html/maxdis-1.svg" alt="Compare Maximum Dissimilarity Sampling with  Random Sampling" width="80%" />
<p class="caption">
FIGURE 4.5: Compare Maximum Dissimilarity Sampling with Random Sampling
</p>
</div>

</div>
<!-- </div> -->
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-willett">
<p>Willett, Peter. 2004. “Dissimilarity-Based Algorithms for Selecting Structurally Diverse Sets of Compounds.” <em>Journal of Computational Biology</em> 6(3-4) (doi:10.1089/106652799318382): 447–57.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="systematic-error-and-random-error.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/happyrabbit/IntroDataScience/07-ModelTuning.Rmd",
"text": "Edit"
},
"download": ["IDS.pdf", "IDS.epub", "IDS.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
