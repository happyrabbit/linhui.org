[
["index.html", "Python速成指南 第1章 版权声明", " Python速成指南 简单、快速、享受Python编程 Norm Matloff University of California, Davis翻译：林荟 DuPont Pioneer03 November 2016 第1章 版权声明 本书由Norm Matloff所著，作者授权林荟翻译。本作品采用知识共享署名-非商业性使用-禁止演绎3.0 美国许可协议进行许可。本书版权由Norm Matloff所有，但允许将内容用于教学，使用请注明作者和以上许可信息。本书作者尽力减少书中的错误，但不保证内容为完全无误。 "],
["section-2.html", "第2章 作者介绍", " 第2章 作者介绍 Norman Matloff 著名计算机科学家兼统计学家，美国加州大学戴维斯分校计算机科学系教授，曾是该校统计专业的创建者之一，并担任过统计学教授。他曾经在硅谷从事数据库软件开发，为公司（如Kaiser Permanente Health Plan）提供统计咨询。 Matloff教授生于洛杉矶，在洛杉矶东部和圣盖博谷长大。他从加州大学洛杉矶分校获得数学博士，方向是概率统计。他在统计和计算机期刊上发表了大量论文。当前的研究兴趣在并行处理，统计计算和回归方法。 Matloff还曾是11.3 IFIP工作小组的成员，这是一个专注于数据库软件安全的国际委员会，由联合国教科文组织的领导下成立。他是加州大学戴维斯分校统计学院的创建者之一，并且参与了该校计算机科学院的创立。他曾获得校园杰出教学奖和杰出公共服务奖。 Matloff著有两本教科书，撰写了许多关于计算机的网络教程，如Linux操作系统和Python编程。他和Peter Salzman博士共同著有“The Art of Debugging with GDB, DDD, and Eclipse”。Matloff的书《R语言编程艺术》出版于2011年。他的《数据科学并行计算》发表于2014年。同时他还是多本开源教科书的作者，包括“From Algorithms to Z-Scores: Probabilistic and Statistical Modeling in Computer Science (http://heather.cs.ucdavis.edu/probstatbook)”和“Programming on Parallel Machines (http://heather.cs.ucdavis.edu/˜matloff/ParProcBook.pdf)”。 "],
["section-3.html", "第3章 前言", " 第3章 前言 恭喜你！ 我敢打赌，你以为我恭喜你是因为你已经开始决定学习世界上最优雅、强大的编程语言之一。当然，这是值得祝贺的，但我恭喜你的真正原因是，由于你居然在阅读一本书的前言，这说明你明显属于那稀少的小部分读者群体——有思想，有眼光，有创意：）！ 我在前言中将会介绍什么是Python，我想要在这本书里讲什么，以及如何使用这本书。 什么是脚本语言（Scripting Languages）？ C和C++之类的语言可以在非常细节的层级编程，因此执行的速度快（尤其是C）。但在大部分应用中，速度并不是主要的问题——你为嘛要费尽心在写邮件的时候快那3微秒？因此，在许多情况下，人们都倾向于使用更高层级的语言。例如，对于文本操作应用，C/C++的基础单元是字符。然而对于Python和Perl这样的语言，基础单元是文本行和每行中的词。在C/C++中你能够对行和每个词进行操作，但你要花更多的努力去完成这些操作。因此，使用脚本语言在这个方面能够节省时间并且提高编程体验。 脚本语言这个词从来没有正式的定义，但下面是其典型特征： 对变量类型的使用比较随意。如，整数，浮点或者字符串变量之间区别很小。函数可以返回非数值结果，如阵列（array）。非数值变量也可以作为循环指针等。 许多该语言固有的高层级操作，如字符串连接，推/托栈（stack push/pop）。 直译语言，不需要像编译语言那样经过编译器现行编译为机器码。 "],
["section-4.html", "第4章 数据科学 4.1 什么是数据科学？ 4.2 什么是数据科学家？ 4.3 数据科学家需要的技能 4.4 数据科学可以解决什么问题？", " 第4章 数据科学 数据科学和数据科学家成为了流行词汇。当有人问你干什么，你回答说数据科学家。对方会恍然大悟，觉得特别高大上，奥，数据科学家啊，听说过。是啊，没听说过数据科学家那就out了。如果接着问，数据科学家具体干什么的？然后就没有然后了。不知道你们有没有听过这样一则轶事，美国最高法院法官Potter Stewart被问到什么是淫秽时，他回答：“看下才知道。”这和数据科学很类似，很多概念，在大而化之的时候都可以存在，大家口耳相传，聊的不亦乐乎，但一追究细节，立即土崩瓦解。那么什么是数据科学家呢？我谷歌了一下数据科学家的定义，下面是其中的一些： 住在加州的数据分析师 数据科学家是商业（数据）分析师的进化版 比软件学家更懂统计，比统计学家更懂软件科学的人 拥有出众数据分析能力的BI咨询师，尤其是能用大量数据增加商业竞争力的人 会编程，懂统计，能通过多种方式从数据中掘金的人 此外，很多其它职位其职责都和“从数据中获取信息”有关，比如：数据分析师，BI咨询师，统计学家，金融分析师、商业分析师，预测分析师……这些不同职业有什么区别？即便都是数据科学家，教育背景等等也是千差万别。由于媒体的炒作以及对“数据科学家”这个名称的滥用，尽管总的分析行业正在飞速发展，但大家对这个行业从业人员的认识却越来越混乱。现在大部分商业领域所谓的分析都达不到“科学”的程度，而仅仅是加减乘除的游戏。 这些不同的职位要求有何不同？在北美总体说来： 金融分析师一般有金融方向的MBA学位。他／她会用电子表格，知道会计软件，分析各部门的预算数据，分析实际经营结果和预测之间的差别，做一些预测，但这里的预测不会涉及复杂的机器学习，统计模型。 数据分析师一般有MBA学位，有一些计算机背景，很擅长使用电子表格，会用高阶的电子表格编程功能如VBA，自定义函数，宏。根据情况，会使用一些BI的软件，如Tableau，主要都是用鼠标点拖的方式。会用SQL从数据库中读取数据。我所见的商业分析师拥有很少（或没有）统计知识。所以这部分人有处理数据的知识，但是没有统计学的知识，能做的分析非常有限。 统计学家一般多在药厂，生物技术公司，做一些非常传统的混合效应模型，方差分析等生物统计分析。由于行业要求，多用SAS而非开源软件R。 BI咨询师，一般也是工商管理专业，有MBA学位，受传统的商学院教育（熟悉4Ps或6Ps,4Cs,使用SWOT法分析市场），熟练使用电子表格，很少或没有其它技术背景。 数据科学家，多是数学／统计，计算机，工程学专业出身，会使用R,Python等多种编程语言，熟悉数据可视化。大多数在入职前没有太多市场营销知识。掌握高等概率统计，熟悉如下概念：抽样，概率分布，假设检验，方差分析，拟合优度检验，回归，时间序列预测模型，非参数估计，实验设计，决策树，马尔可夫链，贝叶斯统计（很快就能在白板上写下贝叶斯定理） 数据科学家都分布在哪些行业呢？根据Burtch Works Executive Recruiting在2015年4月发布的“数据科学家薪资调查报告”，科技公司（包括互联网）是数据科学家最大的雇主。其次是一些为其它公司提供如广告，市场调查，市场分析等商业服务的公司。这两者之和超过了50%。2014年创业公司雇佣了29.4%的数据科学家，2015年这个比例降至14.3%，原因不是创业公司招的数据科学家职位少了，而是大公司招入的数据科学家增长迅速，整体基数变大。总体来说数据科学家就业前景在北美是非常好的。调查还显示，在北美，大部分数据科学家（70%）工作经验小于10年。因此数据科学还是个很年轻的行业。现在，大家对数据科学领域应该有个大致的感觉了。下面我们对其进一步探讨。 4.1 什么是数据科学？ 50年前，John Tukey他老人家就预言有个类似今天的数据科学的东西会出现。早在1962年，他在“数据分析的未来（The Future of Data Analysis）”中[1]就嚷着要对学术统计进行改革。这篇文章当时发表在“数理统计年鉴（The Annals of Mathematical Statistics）”上，他的观点震惊了许多统计界的同事，这都是一群根正苗红的数理统计出身的大神们，那会数理统计年鉴中的文章都是满满的数学公式推导，从定义，定理到证明，逻辑缜密，理论精确。当然牛人最大的特点就是可以随时任性。John推了大半辈子公式突然有天发现统计不是这么玩的，于是他跳出来说： “很长一段时间我觉得自己是统计学家，对统计推断情有独钟，将从小样本上研究得到的结论推广到更大的群体。但随着数理统计的发展，我越发觉得这个路数不大对…总的来说，我觉得自己感兴趣的是数据分析，它包括：分析数据的过程，解释该过程得到结果的技术，合理计划收集数据的方案使得之后的分析过程更方便准确，以及所有分析中需要用到的仪器和数学理论。” 用简短的一句话概括就是：仅仅研究数学理论不是数据科学，数据科学的内容涵盖更广。 美国密歇根大学在2015年9月宣布了一个1亿美金的“数据科学项目（Data Science Initiative）”，计划在未来4年聘请35名新教授，支持与数据相关的跨学科研究。大学媒体大胆的宣称： “数据科学已经成为第4大科学发现手段，前三个为：实验，模型和计算。” 这里的数据科学指的是什么？该项目的网站上有如下对数据科学的描述： “数据科学是科学发现和实践的结合，其包括对大量类型各异的数据进行收集，管理，清理，分析，可视化和结果解释。其应用遍及各种科学，平移和交叉领域。” 如前所述，数据科学是一个新兴领域。在美国，对数据分析类专业人才的需求不断上升。研究估计 [2]，从2015到2018年，美国预计有400-500万工作岗位要求数据分析技能，大部分这些岗位的人才需要经过特殊训练。前面已经介绍过各种和数据分析相关的行业，这些行业对专业训练的要求参差不齐。其中数据科学家的门槛是最高的。成为一个数据科学家不是容易的事。不可否认，即使是数据科学家这个职业名称，当前也被滥用了。这些工作的本质都是从数据中获取信息。但不是每个都能称为“科学”。什么样的东西能够称为科学？我们看看John Tukey在50年前是怎么说的[1]： 怎样才能称为科学呢？回答因人而异。但下面3点大多数人都同意： 学术知识（intellectual content） 用能让人理解的方式组织起来 实践是检验其结果的最终标准 也就是说，数据分析要通过上面3条检验才能称为数据科学。我是这样定义数据科学的： 数据科学=数据+科学=从数据中获取信息的科学 这是一门新的科学，有各种因素推动了这门科学的产生。John提到了4个驱动因素： 正统统计学理论 计算机和电子显示设备的高速发展 很多领域内更多更大的数据提出的挑战 定量分析在更广的领域受到重视 很难想象这些观点是在1962年提出的，现在看来一点也不过时。7年之后，Tukey和Wilk在1969年又将这门科学和已经存在的科学进行对比，进一步限定了统计学在数据科学中所扮演的角色： “…数据科学是一个困难的领域。它需要和人们能用数据做什么和想用数据做什么这样的外在条件相适应。从某种意义上说，生物比物理困难，行为科学比这两者都难，很可能总体数据科学的问题比这三者还要难。无论在现在还是短期的将来，要建立一个正式的能够给数据分析实践提供高效指导的数据科学的结构还有很长的路要走。数据科学可以从正规正统统计学那里获得很多，但它们之间也需要保持适当的距离。” 数据科学不仅是个科学领域，而且和其它已经存在很久的科学领域一样困难。统计理论只在数据科学中扮演了部分角色，因为数据科学还有艺术的一面，艺术部分的发挥就需要数据科学家啦！ 4.2 什么是数据科学家？ 数据科学家=数据+科学+艺术家=用数据和科学从事艺术创作的人 数据科学家立足于科学，但不止于科学。从数据中提取出信息无疑是重要且有意义的过程，但这还不够。因为分析的终极目标是能够解决问题，实现价值。而从信息到具体应用领域的知识，进而应用所得知识创造价值，这两步都是需要一些艺术的，需要一点想象力。在之后“数据分析一般流程”那章中我会进一步讨论这个职业中艺术的部分。科学家需要不断学习，数据科学家是一个需要终身学习职业，其实很多职业都要求这一点。当然，你进入这个领域之前有一个门槛得要跨过去，有些基本的技能需要掌握。上面关于数据科学以及数据科学家的定义听起来非常高大上，可能有些抽象，感觉自己是个文艺女青年。其实也可以用一种更接地气的方式表达： 数据科学=从数据中得到问题答案的科学 数据科学家=通过科学方法从数据中得到有实际意义 的问题答案的人 数据科学结合了一整套科学工具与技术（数学，计算，视觉，分析，统计，试验，问题界定，模型建立与检验等），用于从数据收集中获得新发现、洞察与价值。使用数据科学的根本目的是解决实际问题。David Donoho在他2015年的文章“数据科学50年（50 years of Data Science）”中[3]讨论了当今数据科学的全貌，其中他将数据科学这个大领域分成6块： 数据探索和准备 数据表示和变换 数据编程计算 数据建模 数据可视化和展示 数据科学的科学 而一个合格的数据科学家，应该掌握这6个子领域的相关技能。我们会在本书剩余的部分围绕这6个方面展开讨论。 4.3 数据科学家需要的技能 我们在之前介绍北美各种和数据分析相关职位要求的时候，从技术层面上列举了一些数据科学家需要的技能。我们现在进一步讨论下这个职业需要的不同方面技能。 首先谈谈数据科学家的教育背景。数学、统计、计算机或其它定量分析学科（电子工程，运筹学等）的本科以上学历是必须的。根据2015年的统计数据，美国的数据科学家有48%有博士学位，44%有硕士学位，只有8%是本科。研究生博士期间的课题最好偏向机器学习，数据挖掘或预测模型。其次需要的是数据库操作技能。在工作中通常需要用SQL从数据库读取数据。所以能熟练使用SQL是基础。对于统计或者数学专业的学生，在校期间可能不需要使用SQL，因此不太熟悉。这没有关系，我也是工作以后才开始使用SQL的。但你要确保自己至少精通一种程序语言，之后遇到需要用到的新语言可以迅速学习。在学校期间的主要目的不是学会毕业后所需的全部技能，这是不可能完成的任务。高等教育（本科，研究生和博士）后应该具有的是基本的专业知识和自学能力。数据科学和很多其它领域一样，需要终身学习。有很多人问，要成为优秀的数据科学家是不是一定需要博士？这个问题很难用简单的是或者不是来回答。我看到的大多数优秀数据科学家确实都有博士学位，其余也都是硕士。我并不是要说高学历是成为优秀数据科学家的必要条件，其实真正重要的不是那个学历本身，而是拿到那个学历的过程，以及会选择获许这些学位的人共有的一些特质。 在美国，一般情况下，如果你拿到数理专业的博士学位，至少说明一个问题，就是你对学习的东西有兴趣。这样成天在电脑前面分析数据，编写程序的生活，对于那些对此不感兴趣的人来说必定是难以想象的痛苦。其次是研究生期间系统的理论训练。很多人可能觉得模型背后的数理知识不重要，只要会用模型就可以。统计软件使得很多模型使用者不需要知道具体的模型原理。了解模型原理是否能够帮助你更好的使用模型？当然会有帮助。但问题是这个帮助有多大？是不是值得我们花几年时间去学习？学习很多东西的好处是很难用短期去衡量的。我没有严格的分析，只是个人觉得了解模型原理是必要的。我很喜欢一个词“匠人精神”，也很乐意将“数据科学家”称为匠人，这是一种精益求精的精神。当然这种精神和学位没有必然联系，有本科毕业而对数据科学很感兴趣，自己学习也能够对这个学科有很深的理解。但大多数对这个领域感兴趣又具有“匠人精神”的人都有相关领域的更高等学历。最后，当然就是学习的能力。即使拿到博士学位，也不意味着学完了所有知识，而是具备进一步自学的能力，可以自己看懂数新方法的论文，也就是具备了在这个领域发展的自学能力。总的来说，这个领域的高学历现象并不能说明学历是必要条件，也不是充分条件。真正重要的是兴趣、匠人精神和自学能力。 编程能力也是数据科学家需要的基本技能。熟练使用一种编程语言是必须的，如R，Phython，C等。有人可能会问，只会SAS够不够？个人意见是：不够。这里不想对SAS过多评价。我的建议是大家至少要熟悉一门开源语言。当然，这些都只是工具，工具是解决问题的手段，而非目的。你必须要有一个能用来进行数据分析的工具，偏好因人而异，但你选择工具的时候最好考虑工具的灵活性和可扩展性。 接下来就要提到具体的分析技能。数据科学家应该掌握高等概率统计，能够熟练进行t检验，开方检验，拟合优度检验，方差分析。能够清楚的解释Spearman秩相关和Pearson相关之间的区别。熟悉抽样，概率分布，实验设计相关概念。了解贝叶斯统计（很快就能在白板上写下贝叶斯定理）。知道什么是有监督学习，什么是无监督学习。知道重要的聚类，判别和回归方法。知道基于罚函数的模型，关联法则分析。如果从事心理相关的应用的话（如消费者认知调查），还需要知道基本的潜变量模型，如探索性因子分析，验证性因子分析，结构方程模型。这个单子还可以一直列下去。看起来是不是不只一点吓人？我说过，数据科学家不是一个低门槛的行业，之前需要接受的训练对于没有兴趣的人来说是无比痛苦的。还有，单子是动态的，因为你在工作过程中还是需要不断学习。这些技能只是让你能够很好的开始。再次强调自学能力和成为一个终生学习者是优秀的数据科学家的必要条件。 除了技术能力以外，还需要其它一些非技术的能力。这些包括将实际问题转化成数据问题的能力，这一过程需要交流，也就要求良好的交流沟通能力。关注细节，分析是一个需要细心和耐心的职业。还有就是展示结果的能力，如何让没有分析背景的客户理解模型的结果，并且最终在实践中应用模型的结论。“数据科学家技能表”中总结了数据科学家需要的各方面技能。 总而言之，关于数据科学家有三个关键词：数据，科学和艺术。数据是基础；科学是工具；艺术是纽带，最终通过艺术将数据和科学结合得出的结果转化成相关领域的可应用知识，解决问题，真正产生价值。在实际应用中，以需要解决的问题为导向的思维方式很重要，否则分析很容易沦落为手段淹没目的的过程，很多分析行业的人就会犯这个错误，一味追求高大上的模型，酷炫的可视化，而忘了分析的根本目的是为了解决问题。说到这里，大家应该对这个行业有了一些概念性的了解，可能有读者会问：你这么强调数据科学是为了解决问题的，那么都解决哪些问题呢？我们在接下来的小节会介绍数据学科家都使用什么技术，解决哪些问题。 在此之前，插播下数据科学家和数据工程师的区别。因为这两个角色确实很令人混淆，他们之间的合作最密切，而且其合作的融洽度很大程度上决定了数据科学在组织内能否高效产生价值。这两个角色的区别当然在某种程度上和具体工作环境有关。比如在互联网行业，这两个角色重叠的部分更多。在传统行业各自的职责更加明晰。数据科学家需要知道数据能解决哪些问题，需要哪些数据以及用什么方法解决这些问题。找到问题的答案需要统计，机器学习等相关知识，在需要的时候，数据科学家得很快学会新的模型方法，以及如何用计算实施。这也是为什么数据科学家也要具备一定编程能力的原因，包括R、Python和MySQL。 数据工程师能够让数据科学家更加高效的工作。有的公司也会将其称为数据构架师。他们收集，储存数据，对数据进行批量处理或者实时处理。有的公司的数据科学家通过API获取数据，这样更容易不需要使用SQL。但也有很大一部分公司的科学家是通过SQL获取数据，这样有更高的灵活度，也更利于两者的合作。当前有很多大数据的工具可以用于收集，储存和处理数据，数据工程师的重要职责之一是选择好的工具，这里需要能够用专业知识有理有据的支撑这个选择，而不是选择当前最流行的。因此数据工程师需要有很强的软件工程相关知识，他们不仅仅要能够学习如何使用这些工具 ，也要能够在必要的时候优化这些工具。一个好的数据工程师需要精通数据库和强大的工程实践能力，包括处理和记录错误，检测系统，设计具有容错能力的数据管道，理解如果要要对当前构架进行扩展需要什么（为日后可能的新数据做准备），并且要持续处理各种可能的系统整合，数据库管理，清理和维护，保证数据管道通向的是想要达成的目标。 这两者之间也会有重叠的地方，比如数据科学家可能也会使用Hadoop生态群来解决某些数据问题，而数据工程师有时也可能可能在Spark集群上运行机器学习算法。最好的情况是这两个角色都能一定程度上了解对方的技能，这样对他们之间的合作有极大的帮助。可以这样比喻，数据工程师是提供建房材料的人，而数据科学家是那个造房子的人。这样可能就很容易理解为什么这两者之间的合作对于一个成功的数据科学团队来说如此重要了。如果没有很好的沟通，建房的材料不符合房子建造者的需要，那即使建造者技术再好，也很难建造出好的房子，而且造成资源的极大浪费。 4.4 数据科学可以解决什么问题？ 4.4.1 前提要求 数据科学不是万能药，数据科学家也不是魔术师，有些问题我们无法用数据科学解决，最好在一开始就对问题做出判断，对于那些无法解决的问题，诚实的告诉对方并解释原因，那我们对问题有什么要求呢？ 你的问题需要尽可能具体 来看两个例子： 问题1: 如何提高产品销售量？ 问题2: 今年年初推出的新促销手段是不是提高了先锋先玉696玉米种子在西南地区的销售量？ 比较上面这两个问题，大家是不是很快能发现它们的差别？问题1从语法上是个正确的问题，但从解决的角度，并不是一个能够用分析给出答案的问题。为什么？因为问题太泛了，根本无从定义该问题背后的自变量和应变量。而问题2就是一个恰当的问题。从分析的角度，应变量很明显是“先锋先玉696玉米种子在西南地区的销售量”，感兴趣的自变量是“今年年初推出的新促销手段”，我们想要研究的就是这两者之间的关系。从这里开始再去寻找其它变量，这样就慢慢的进入分析流程了。当然，问题具体不代表就能够回答。比如我曾经遇到一个很具体的供应链问题，问的是针对某一个特定产品在特定区域的库存该是多少。这个问题为什么无法回答呢？这个项目一开始我通过多元自适应回归样条（MARS）模型以为找到了一个合理的答案，但到项目的最后才发现，他们给我的供应相关的数据极其不准确，很多地区的供应量都只是估计。这是我从业生涯中的一次教训，这告诉我们下面将要提到的一点。 你要有和问题相关的必要数据 巧妇难为无米之炊，这老古人的话放在那里时刻闪闪发光。艺术源于生活，所以你首先得要有数据，之所以数据科学会火也是因为计算机的发展，使数据的收集更容易。上面提到的供给问题就是一个很好的例子，没有相对准确的数据，之后任何模型都没有意义。当然，任何数据都是存在误差的，但是误差必须在一定范围内。尤其是感兴趣的自变量（如之前问题2里的“新促销手段”相关的数据）和应变量（“先锋先玉696玉米种子在西南地区的销售量”），如果这些必要的变量有很大缺失，或者不准确的话，模型是无法发挥作用的。再如，你要预测某个产品的消费者中谁最可能在接下来的3个月内购买该产品。要解决这个问题，你需要有目标消费者群体历史购买行为的信息：上一次购买的时间，消费量，优惠券使用情况等等。如果你仅仅知道这些客户的银行卡号，身份证号，出生月份之类的信息是不会对你的预测有任何帮助的。 很多时候数据的质量比数量重要，但数量也是不容忽视的。在能保证数据质量的前提下，数量越多越好。样本量越大，你能够回答的问题也就更细，且模型发现的置信度也更高。如果你有一个具体合理的问题，有足够大，质量合理的相关数据集，那么恭喜你，可以开始玩数据科学啦！ 4.4.2 问题种类 很多数据科学的书籍都从技术的角度对各种模型分类。比如有监督模型和无监督模型，线性模型和非线性模型，参数模型和参数模型等等。这里我们换而使用之前提到的“问题导向”的思维方式，对数据科学回答的问题进行分类，然后介绍哪些模型可以用于回答相应类别的问题，希望这些分组能在你面对自己的问题时帮助思考。 比较 第一类常见的问题是比较组之间不同的问题。常见的句式是：A在某方面是不是比B好？或者多者比较：A、B、C之间在某方面有没有差别？下面是一些问题的例子： 参与促销活动和没有参与促销活动消费者购买量有差异么？ 男性是不是比女性更倾向于购买我们的产品？ 用户满意度在不同商业区是不是有不同？ 服用某种药物的老鼠比没有服用药物的老鼠体重增长的是否更快？ 携带某种基因的大豆是不是比普通大豆产油量高？ 对于这类数据，通常从各组观测的基本统计量和可视化开始初步探索数据。在对数据分布和组之间的差异有个初步直观了解之后，通过统计检验测试组间是否在感兴趣的变量上有显著不同。处理这类问题常用的是经典统计推断：开方检验，t检验和方差分析。放在贝叶斯框架下也有一种比较组间不同的方法。如果因子增加，结构变得复杂（如在生物医药领域的复杂实验设计有随机效应因子），则需要使用更加复杂的混合效应模型。 描述 在分析中不可避免的要描述数据。比如聚类问题。当你通过算法找到不同的样本分类后，就需要对类进行定义，这要通过比较各类中变量的描述统计量得到。常用的描述问题有： 样本中家庭年观测的收入是不是无偏的？ 某产品在不同区域的月销售量均值／方差是多少？ 变量的量级差异大么？（决定是否需要对数据标准化） 模型中的预测变量观测缺失情况如何？ 问卷调查回复者的年龄分布范围是多少？ 这类数据描述常用于检查数据，找到合适的数据预处理方法，以及拟合模型后对结果的分析和展示。 聚类 聚类是一个极其常见的问题，其通常和判别联系在一起。聚类模型回答的问题是： 哪些消费者有相似的产品偏好？（市场营销） 哪些打印机损坏的模式相同？（质量控制） 公司员工在对公司评价上可以分为几类？（人力资源） 哪些词更经常同时出现？（自然语义处理） 哪些文档可能有相似的主题？（自然语义处理） 聚类是无监督分析。 判别 判别是另外一个经典的分析问题。通常用类别已知的样本作为训练集拟合判别器，然后用训练好的判别器预测新样本的类别。下面是一些关于判别的问题： 哪些新客户最有可能转化（购买）？ 当前的压力度数是正常的么？ 某贷款人有不还款的风险么？ 这个消费者还可能喜欢什么产品？ 这本书的作者可能是谁？ 这封邮件是不是垃圾邮件？ 关于判别的模型有数百种，在实践中我们其实不必要尝试所有的模型而只要拟合其中几种在大部分情况下表现最好的模型即可。我们在后面判别的章节还会介绍。 回归 当你感兴趣的量是一个数值而非类别时，通常就是一个回归问题。比如： 明天的气温可能会是多少？ 公司今年第4季度的销售额会是多少？ 某品牌打印机明年上半年在北京市的销量会是多少？ 该引擎还能工作多久？ 这次活动中需要准备多少啤酒？ 通常情况下，回归能够给出一个数值答案。回归通常解决“…是多少？”这样的问题。在有些时候模型给出的负数结果可能需要解释为0，或者有小数点的结果需要解释为最近的整数。 "]
]
