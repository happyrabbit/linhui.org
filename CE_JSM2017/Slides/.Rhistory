library(readr)
sim.dat <- read_csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv ")
head(sim.dat)
head(sim.dat)
sim.dat
dat=read_csv("2015,2016,2017
100,200,300
canola,soybean,corn")
print(dat)
dat=read_csv("# I will never let you know that
# my favorite food is carrot
Date,Food,Mood
Monday,carrot,happy
Tuesday,carrot,happy
Wednesday,carrot,happy
Thursday,carrot,happy
Friday,carrot,happy
Saturday,carrot,extremely happy
Sunday,carrot,extremely happy", skip = 2)
print(dat)
dat=read_csv("Saturday,carrot,extremely happy
Sunday,carrot,extremely happy", col_names=FALSE)
print(dat)
dat=read_csv("Q1,Q2,Q3
5, 4,99",na="99")
print(dat)
library(data.table)
# covert the existing data frame to data table
dt <- data.table(sim.dat)
class(dt)
dt[, mean(online_trans)]
sim.dat[,mean(online_trans)]
dt[ , mean(online_trans), by = gender]
dt[ , mean(online_trans), by = .(gender, house)]
dt[ , .(avg = mean(online_trans)), by = .(gender, house)]
dt[age < 20 & income > 80000]
# select the first two rows
dt[1:2]
ans <- dt[, age]
head(ans)
âˆš
ans <- dt[, age]
head(ans)
dt[, -(age:online_exp), with = T]
dt[, -(age:online_exp), with = F]
dt[, .N]
dt[, .N, by= gender]
dt[age < 30, .(count=.N), by= gender]
dt[order(gender, -online_exp)][1:5]
x <- cbind(x1 =1:8, x2 = c(4:1, 2:5))
dimnames(x)[[1]] <- letters[1:8]
apply(x, 2, mean)
col.sums <- apply(x, 2, sum)
row.sums <- apply(x, 1, sum)
X
x
apply(x, 2, mean)
apply(x, 1, sum)
ma <- matrix(c(1:4, 1, 6:8), nrow = 2)
ma
apply(ma, 1, table)  #--> a list of length 2
apply(ma, 1, stats::quantile) # 5 x n matrix with rownames
apply(x, 2, sum)
x
apply(x, 1, sum)
z <- array(1:24, dim = 2:4)
zseq <- apply(z, 1:2, function(x) seq_len(max(x)))
zseq
typeof(zseq) ## list
zseq[[1]]
sdat<-sim.dat[,!lapply(sim.dat,class)=="factor"]
lapply(sim.dat,class)
apply(sim.dat,class)
apply(sim.dat,2,class)
apply(sim.dat,2,class)
lapply(sim.dat,class)
library(dplyr)
tbl_df(sim.dat)
glimpse(sim.dat)
library(magrittr)
filter(sim.dat, income >300000) %>%
tbl_df()
sim.dat %>%
filter(!is.na(income)) %>%
group_by(segment) %>%
summarise(
ave_online_exp = mean(online_exp),
n = n() ) %>%
filter(n > 200)
sim.dat %>%
filter(,!is.na(income))
sim.dat %>%
filter(.,!is.na(income))
sim.dat %>%
filter(.,!is.na(income))
x<-c(1,2,2,4)
unique(x)
x1<-c(1,2,4)
x2<-c(1,2,4)
x<-data.frame(rbind(x1,x2))
x
unique(x)
distinct::(x)
distinct(x)
library(caret)
dplyr::sample_n(sim.dat, 100000, replace = F)
slice(sim.dat, 10:15)
sim.dat[10:15,]
top_n(sim.dat,2,income)
select(sim.dat, num_range("Q", 1:5))
plyr::select(sim.dat, one_of(c("age", "income")))
dplyr::select(sim.dat, one_of(c("age", "income")))
summarise(sim.dat, avg_online = mean(online_trans))
sim.dat %>%
filter(!is.na(income)) %>%
group_by(segment) %>%
summarise(
ave_online_exp = mean(online_exp),
n = n() )
summarise_each(sim.dat, funs_(c("anyNA")))
summarise_each(sim.dat, funs_(c("anyNA","n")))
summarise_each(sim.dat, funs_(c("anyNA","n()")))
summarise_each(sim.dat, funs_(c("anyNA","length")))
summarise_each(sim.dat, funs_(c("anyNA","length")))
transmute(sim.dat, total_exp = store_exp + online_exp)
mutate(sim.dat, total_exp = store_exp + online_exp)
(x<-data.frame(cbind(ID=c("A","B","C"),x1=c(1,2,3))))
(y<-data.frame(cbind(ID=c("B","C","D"),y1=c(T,T,F))))
left_join(x,y,by="ID")
mutate_each(sim.dat, funs(min_rank))
dim(sim.dat)
mutate_each(sim.dat, function(x)(x+1))
mutate_each(sim.dat, funs( cumsum)
)
