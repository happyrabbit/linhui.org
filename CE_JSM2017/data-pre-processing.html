<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Preparing Statistician/Statistics Graduates to be Enterprise Data Scientist</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is the handouts for CE course at JSM 2017">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="Preparing Statistician/Statistics Graduates to be Enterprise Data Scientist" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the handouts for CE course at JSM 2017" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Preparing Statistician/Statistics Graduates to be Enterprise Data Scientist" />
  
  <meta name="twitter:description" content="This is the handouts for CE course at JSM 2017" />
  

<meta name="author" content="Hui Lin and Ming Li">

<meta name="date" content="2016-12-20">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="data-wrangling.html">
<link rel="next" href="r-shiny-introduction.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://scientistcafe.com">Homepage</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-is-data-science"><i class="fa fa-check"></i><b>1.1</b> What is data science?</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#what-kind-of-questions-can-data-science-solve"><i class="fa fa-check"></i><b>1.2</b> What kind of questions can data science solve?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#what-are-the-required-skills-for-data-scientist"><i class="fa fa-check"></i><b>1.3</b> What are the required skills for data scientist?</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#general-process-of-data-science"><i class="fa fa-check"></i><b>1.4</b> General Process of Data Science</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#cloud-based-computation-environment"><i class="fa fa-check"></i><b>1.5</b> Cloud-based computation environment</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html"><i class="fa fa-check"></i><b>2</b> Big Data Cloud Platform</a><ul>
<li class="chapter" data-level="2.1" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html#introduction-of-databricks-cloud-based-distributed-system"><i class="fa fa-check"></i><b>2.1</b> Introduction of Databricks cloud-based distributed system</a></li>
<li class="chapter" data-level="2.2" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html#linux-system-and-hadoop-environment"><i class="fa fa-check"></i><b>2.2</b> Linux system and Hadoop environment</a></li>
<li class="chapter" data-level="2.3" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html#database-basic-through-hive"><i class="fa fa-check"></i><b>2.3</b> Database basic through Hive</a></li>
<li class="chapter" data-level="2.4" data-path="big-data-cloud-platform.html"><a href="big-data-cloud-platform.html#spark-and-h2o"><i class="fa fa-check"></i><b>2.4</b> Spark and H2O</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>3</b> Data Wrangling</a><ul>
<li class="chapter" data-level="3.1" data-path="data-wrangling.html"><a href="data-wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.1</b> Tidy data</a></li>
<li class="chapter" data-level="3.2" data-path="data-wrangling.html"><a href="data-wrangling.html#reshape-data"><i class="fa fa-check"></i><b>3.2</b> Reshape data</a></li>
<li class="chapter" data-level="3.3" data-path="data-wrangling.html"><a href="data-wrangling.html#subset-data"><i class="fa fa-check"></i><b>3.3</b> Subset data</a></li>
<li class="chapter" data-level="3.4" data-path="data-wrangling.html"><a href="data-wrangling.html#summarize-data"><i class="fa fa-check"></i><b>3.4</b> Summarize data</a></li>
<li class="chapter" data-level="3.5" data-path="data-wrangling.html"><a href="data-wrangling.html#combine-data"><i class="fa fa-check"></i><b>3.5</b> Combine data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-pre-processing.html"><a href="data-pre-processing.html"><i class="fa fa-check"></i><b>4</b> Data Pre-processing</a><ul>
<li class="chapter" data-level="4.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#start"><i class="fa fa-check"></i><b>4.1</b> Start</a></li>
<li class="chapter" data-level="4.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#centering-and-scaling"><i class="fa fa-check"></i><b>4.2</b> <strong>Centering and Scaling</strong></a></li>
<li class="chapter" data-level="4.3" data-path="data-pre-processing.html"><a href="data-pre-processing.html#resolve-skewness"><i class="fa fa-check"></i><b>4.3</b> <strong>Resolve Skewness</strong></a></li>
<li class="chapter" data-level="4.4" data-path="data-pre-processing.html"><a href="data-pre-processing.html#resolve-outliers"><i class="fa fa-check"></i><b>4.4</b> <strong>Resolve Outliers</strong></a></li>
<li class="chapter" data-level="4.5" data-path="data-pre-processing.html"><a href="data-pre-processing.html#missing-values"><i class="fa fa-check"></i><b>4.5</b> <strong>Missing Values</strong></a><ul>
<li class="chapter" data-level="4.5.1" data-path="data-pre-processing.html"><a href="data-pre-processing.html#impute-missing-values-with-medianmode"><i class="fa fa-check"></i><b>4.5.1</b> Impute missing values with median/mode</a></li>
<li class="chapter" data-level="4.5.2" data-path="data-pre-processing.html"><a href="data-pre-processing.html#impute-missing-values-based-on-k-nearest-neighbors"><i class="fa fa-check"></i><b>4.5.2</b> Impute missing values based on K-nearest neighbors</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="data-pre-processing.html"><a href="data-pre-processing.html#collinearity"><i class="fa fa-check"></i><b>4.6</b> <strong>Collinearity</strong></a></li>
<li class="chapter" data-level="4.7" data-path="data-pre-processing.html"><a href="data-pre-processing.html#sparse-variables"><i class="fa fa-check"></i><b>4.7</b> <strong>Sparse Variables</strong></a></li>
<li class="chapter" data-level="4.8" data-path="data-pre-processing.html"><a href="data-pre-processing.html#re-encode-dummy-variables"><i class="fa fa-check"></i><b>4.8</b> <strong>Re-encode Dummy Variables</strong></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-shiny-introduction.html"><a href="r-shiny-introduction.html"><i class="fa fa-check"></i><b>5</b> R-Shiny Introduction</a></li>
<li class="chapter" data-level="6" data-path="dynamicreproducible-report.html"><a href="dynamicreproducible-report.html"><i class="fa fa-check"></i><b>6</b> Dynamic/Reproducible report</a></li>
<li class="chapter" data-level="7" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html"><i class="fa fa-check"></i><b>7</b> Soft Skills for Data Scientists</a><ul>
<li class="chapter" data-level="7.1" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html#introduction-to-agile"><i class="fa fa-check"></i><b>7.1</b> Introduction to agile</a></li>
<li class="chapter" data-level="7.2" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html#effective-communication-with-business-partners"><i class="fa fa-check"></i><b>7.2</b> Effective communication with business partners</a></li>
<li class="chapter" data-level="7.3" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html#leadership-skills"><i class="fa fa-check"></i><b>7.3</b> Leadership skills</a></li>
<li class="chapter" data-level="7.4" data-path="soft-skills-for-data-scientists.html"><a href="soft-skills-for-data-scientists.html#decision-making-with-uncertainty"><i class="fa fa-check"></i><b>7.4</b> Decision making with uncertainty</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preparing Statistician/Statistics Graduates to be Enterprise Data Scientist</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-pre-processing" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Data Pre-processing</h1>
<div id="start" class="section level2">
<h2><span class="header-section-number">4.1</span> Start</h2>
<p>There are a number of reasons a predictive model falls <span class="citation">(Max Kuhn <a href="#ref-APM">2013</a>)</span>, such as:</p>
<ul>
<li>Inadequate data pre-processing</li>
<li>Inadequate model validation</li>
<li>Unjustified extrapolation</li>
<li>Over-fitting</li>
</ul>
<p>In this blog post, I am going to summarize some common data pre-processing approaches.</p>
</div>
<div id="centering-and-scaling" class="section level2">
<h2><span class="header-section-number">4.2</span> <strong>Centering and Scaling</strong></h2>
<p>It is the most straightforward data transformation. It centers and scales a variable to mean 0 and standard deviation 1. It ensures that the criterion for finding linear combinations of the predictors is based on how much variation they explain and therefore improves the numerical stability. Models involving finding linear combinations of the predictors to explain response/predictors variation need data centering and scaling, such as PCA and PLS. You can easily writing code yourself to conduct this transformation. Or the function <code>preProcess()</code> in package <code>caret</code> can apply this transformation to a set of predictors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#install packages needed</span>
<span class="kw">library</span>(caret)
<span class="kw">library</span>(e1071)
<span class="kw">library</span>(gridExtra) 
<span class="kw">library</span>(lattice)
<span class="kw">library</span>(imputeMissings)
<span class="kw">library</span>(RANN)
<span class="kw">library</span>(corrplot)
<span class="kw">library</span>(nnet)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(cars)</code></pre></div>
<pre><code>##   speed dist
## 1     4    2
## 2     4   10
## 3     7    4
## 4     7   22
## 5     8   16
## 6     9   10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trans&lt;-<span class="kw">preProcess</span>(cars,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))
transformed&lt;-<span class="kw">predict</span>(trans,cars)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(cars$dist,<span class="dt">main=</span><span class="st">&quot;Original&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;dist&quot;</span>)
<span class="kw">hist</span>(transformed$dist,<span class="dt">main=</span><span class="st">&quot;Centered and Scaled&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;dist&quot;</span>)</code></pre></div>
<p><img src="CE_JSM2017_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Sometimes you only need to scale the variable. For example, if the model adds penalty to the parameter estimates (such as <span class="math inline">\(L_2\)</span> penalty is ridge regression and <span class="math inline">\(L_1\)</span> penalty in LASSO), the variables need to have similar scale to ensure a fair variable selection. I am heavy user of this kind of penalty-based model in my work and I used the following quantile transformation:</p>
<p><span class="math display">\[
x_{ij}^{*}=\frac{x_{ij}-quantile(x_{.j},0.01)}{quantile(x_{.j}-0.99)-quantile(x_{-j},0.01)}
\]</span></p>
<p>The reason to use 99% and 1% quantile instead of maximum and minimum values is to resist the impact of outliers.</p>
<p>It is easy to write a function to do it:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qscale&lt;-function(dat){
  for (i in <span class="dv">1</span>:<span class="kw">ncol</span>(dat)){
    up&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.99</span>)
    low&lt;-<span class="kw">quantile</span>(dat[,i],<span class="fl">0.01</span>)
    diff&lt;-up-low
    dat[,i]&lt;-(dat[,i]-low)/diff
  }
  <span class="kw">return</span>(dat)
}</code></pre></div>
<p>In order to illustrate, let’s simulate a data set with two variables: income and age.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2015</span>)
income&lt;-<span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">50000</span>,<span class="dv">150000</span>,<span class="dt">by=</span><span class="dv">500</span>),<span class="dv">95</span>)
age&lt;-income/<span class="dv">2000-10</span>
noise&lt;-<span class="kw">round</span>(<span class="kw">runif</span>(<span class="dv">95</span>)*<span class="dv">10</span>,<span class="dv">0</span>)
age&lt;-age+noise
income&lt;-<span class="kw">c</span>(income,<span class="dv">10000</span>,<span class="dv">15000</span>,<span class="dv">300000</span>,<span class="dv">250000</span>,<span class="dv">230000</span>)
age&lt;-<span class="kw">c</span>(age,<span class="dv">30</span>,<span class="dv">20</span>,<span class="dv">25</span>,<span class="dv">35</span>,<span class="dv">95</span>)
demo&lt;-<span class="kw">data.frame</span>(income,age)
demo$education&lt;-<span class="kw">as.factor</span>(<span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;High School&quot;</span>,<span class="st">&quot;Bachelor&quot;</span>,<span class="st">&quot;Master&quot;</span>,<span class="st">&quot;Doctor&quot;</span>),<span class="dv">100</span>,<span class="dt">replace =</span> T,<span class="dt">prob =</span><span class="kw">c</span>(<span class="fl">0.7</span>,<span class="fl">0.15</span>,<span class="fl">0.12</span>,<span class="fl">0.03</span>) ))
<span class="kw">summary</span>(demo[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])</code></pre></div>
<pre><code>##      income            age       
##  Min.   : 10000   Min.   :20.00  
##  1st Qu.: 76375   1st Qu.:30.25  
##  Median : 98750   Median :44.25  
##  Mean   :103480   Mean   :44.92  
##  3rd Qu.:126375   3rd Qu.:56.88  
##  Max.   :300000   Max.   :95.00</code></pre>
<p>It is clear that income and age are not on the same scale. Now apply the function <code>qscale()</code> on the simulated data <code>demo</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">qscale</span>(demo[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])
<span class="kw">summary</span>(transformed)</code></pre></div>
<pre><code>##      income              age          
##  Min.   :-0.02101   Min.   :-0.01904  
##  1st Qu.: 0.26077   1st Qu.: 0.17814  
##  Median : 0.35576   Median : 0.44746  
##  Mean   : 0.37584   Mean   : 0.46044  
##  3rd Qu.: 0.47304   3rd Qu.: 0.69033  
##  Max.   : 1.21015   Max.   : 1.42375</code></pre>
</div>
<div id="resolve-skewness" class="section level2">
<h2><span class="header-section-number">4.3</span> <strong>Resolve Skewness</strong></h2>
<p><a href="https://en.wikipedia.org/wiki/Skewness">Skewness</a> is defined to be the third standardized central moment. The formula for the sample skewness statistics is: <span class="math display">\[ skewness=\frac{\sum(x_{i}+\bar{x})^{3}}{(n-1)v^{3/2}}\]</span> <span class="math display">\[v=\frac{\sum(x_{i}=\bar{x})^{2}}{(n-1)}\]</span> Skewness=0 means that the destribution is symmetric, i.e. the probability of falling on either side of the distribution’s mean is equal.</p>
<p>You can easily tell if a distribution is skewed by simple visualization. There are different ways may help to remove skewness such as log, square root or inverse. However it is often difficult to determine from plots which transformation is most appropriate for correcting skewness. The Box-Cox procedure automatically identified a transformation from the family of power transformations that are indexed by a parameter <span class="math inline">\(\lambda\)</span>.</p>
<p><span class="math display">\[
x^{*}=\begin{cases}
\begin{array}{c}
\frac{x^{\lambda}-1}{\lambda}\\
log(x)
\end{array} &amp; \begin{array}{c}
if\ \lambda\neq0\\
if\ \lambda=0
\end{array}\end{cases}
\]</span></p>
<p>It is easy to see that this family includes log transformation (<span class="math inline">\(\lambda=0\)</span>), square transformation (<span class="math inline">\(\lambda=2\)</span>), square root (<span class="math inline">\(\lambda=0.5\)</span>), inverse (<span class="math inline">\(\lambda=-1\)</span>) and others in-between. We can still use function <code>preProcess()</code> in package <code>caret</code> to apply this transformation by chaning the <code>method</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(trans&lt;-<span class="kw">preProcess</span>(cars,<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;BoxCox&quot;</span>)))</code></pre></div>
<pre><code>## Created from 50 samples and 2 variables
## 
## Pre-processing:
##   - Box-Cox transformation (2)
##   - ignored (0)
## 
## Lambda estimates for Box-Cox transformation:
## 1, 0.5</code></pre>
<p>The output shows the sample size (50), number of variables (2) and the <span class="math inline">\(\lambda\)</span> estimates for each variable. After calling the <code>preProcess()</code> function, the <code>predict()</code> method applies the results to a data frame.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,cars)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">hist</span>(cars$dist,<span class="dt">main=</span><span class="st">&quot;Original&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;dist&quot;</span>)
<span class="kw">hist</span>(transformed$dist,<span class="dt">main=</span><span class="st">&quot;After BoxCox Transformation&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;dist&quot;</span>)</code></pre></div>
<p><img src="CE_JSM2017_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>An alternative is to use function <code>BoxCoxTrans()</code> in package <code>caret</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(trans&lt;-<span class="kw">BoxCoxTrans</span>(cars$dist))</code></pre></div>
<pre><code>## Box-Cox Transformation
## 
## 50 data points used to estimate Lambda
## 
## Input data summary:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    2.00   26.00   36.00   42.98   56.00  120.00 
## 
## Largest/Smallest: 60 
## Sample Skewness: 0.759 
## 
## Estimated Lambda: 0.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">transformed&lt;-<span class="kw">predict</span>(trans,cars$dist)
<span class="kw">skewness</span>(transformed)</code></pre></div>
<pre><code>## [1] -0.01902765</code></pre>
<p>The estimated <span class="math inline">\(\lambda\)</span> is the same 0.5. Original skewness is 0.759 and after transformation, the skewness is -0.01902765 which is close to 0. You can use function <code>skewness()</code> in package <code>e1071</code> to get the skewness statistics.</p>
</div>
<div id="resolve-outliers" class="section level2">
<h2><span class="header-section-number">4.4</span> <strong>Resolve Outliers</strong></h2>
<p>Even under certain assumptions we can statistically define outliers, it can be hard to define in some situations. You can refer to <a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm">“Detection of Outliers”</a> for more information. Some models are resistant to outliers (such as tree-based model and support vector machine). If a model is sensitive to outliers (such as linear regression and logistic regression), we can use <em>spatial sign</em> transformation to minimize the problem. It projects the original sample points to the surface of a sphere by:</p>
<p><span class="math display">\[x_{ij}^{*}=\frac{x_{ij}}{\sqrt{\sum_{j=1}^{p}x_{ij}^{2}}}\]</span></p>
<p>As noted in the book “<a href="http://appliedpredictivemodeling.com/">Applied Predictive Modeling</a>”,</p>
<blockquote>
<p>Since the denominator is intended to measure the squared distance to the center of the predictor’s distribution, it is important to center and scale the predictor data prior to using this transformation. Note that, unlike centering or scaling, this manipulation of the predictors <em>transforms them as a group</em>.</p>
</blockquote>
<p>We can use <code>spatialSign()</code> function in <code>caret</code> to conduct spatial sign on <code>demo</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trans&lt;-<span class="kw">preProcess</span>(demo[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)],<span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>))
transformed&lt;-<span class="kw">predict</span>(trans,demo[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])
transformed2 &lt;-<span class="st"> </span><span class="kw">spatialSign</span>(transformed)
transformed2 &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(transformed2)
p1&lt;-<span class="kw">xyplot</span>(income ~<span class="st"> </span>age,
       <span class="dt">data =</span> transformed,
       <span class="dt">main=</span><span class="st">&quot;Original&quot;</span>)
p2&lt;-<span class="kw">xyplot</span>(income ~<span class="st"> </span>age,
       <span class="dt">data =</span> transformed2,
       <span class="dt">main=</span><span class="st">&quot;After Spatial Sign&quot;</span>)
<span class="kw">grid.arrange</span>(p1,p2, <span class="dt">ncol=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="CE_JSM2017_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="missing-values" class="section level2">
<h2><span class="header-section-number">4.5</span> <strong>Missing Values</strong></h2>
<p>We need a book to fully explicate this topic. Before we decide how to handle missing value, it is important to understand why the values are missing. Do the missing values have information related outcomes? Or are they missing at random? It is not the goal here to illustrate which methods to use in different missing situation. You can refer to Section 3.4 of “<a href="http://appliedpredictivemodeling.com/">Applied Predictive Modeling</a>” for more discussion on that. The objective of this post is to introduce some imputation methods and corresponding application examples using R. Survey statistics has studied the imputation extensively which focuses on making valid inferences. Missing value imputation in predictive modeling is a different problem. Saar-Tsechansky and Provost compared several different methods for applying classification to instance with missing values. “<a href="http://www.jmlr.org/papers/volume8/saar-tsechansky07a/saar-tsechansky07a.pdf">Handling Missing Values when Applying Classification Models</a>”</p>
<p>The following code randomly assigns some missing values to the previous data <code>demo</code> and names the new data set <code>demo_missing</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
id1&lt;-<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(demo),<span class="dv">15</span>)
id2&lt;-<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(demo),<span class="dv">10</span>)
id3&lt;-<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(demo),<span class="dv">10</span>)
demo_missing&lt;-demo
demo_missing$age[id1]&lt;-<span class="ot">NA</span>
demo_missing$income[id2]&lt;-<span class="ot">NA</span>
demo_missing$education[id3]&lt;-<span class="ot">NA</span>
<span class="kw">summary</span>(demo_missing)</code></pre></div>
<pre><code>##      income            age              education 
##  Min.   : 15000   Min.   :20.00   Bachelor   :13  
##  1st Qu.: 77125   1st Qu.:30.25   Doctor     : 2  
##  Median : 98750   Median :44.25   High School:70  
##  Mean   :102811   Mean   :44.43   Master     : 5  
##  3rd Qu.:125250   3rd Qu.:56.25   NA&#39;s       :10  
##  Max.   :300000   Max.   :95.00                   
##  NA&#39;s   :10       NA&#39;s   :15</code></pre>
<div id="impute-missing-values-with-medianmode" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Impute missing values with median/mode</h3>
<p>You can use function <code>impute()</code> under package <code>imputeMissings</code> to impute missing values with mdedian/mode. This method is simple, fast but treats each predictor independently, and may not be accurate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">demo_imp&lt;-<span class="kw">impute</span>(demo_missing,<span class="dt">method=</span><span class="st">&quot;median/mode&quot;</span>)
<span class="kw">summary</span>(demo_imp)</code></pre></div>
<pre><code>##      income            age              education 
##  Min.   : 15000   Min.   :20.00   Bachelor   :13  
##  1st Qu.: 79250   1st Qu.:32.19   Doctor     : 2  
##  Median : 98750   Median :44.25   High School:80  
##  Mean   :102405   Mean   :44.40   Master     : 5  
##  3rd Qu.:122875   3rd Qu.:54.50                   
##  Max.   :300000   Max.   :95.00</code></pre>
<p>Note that the median/mode method imputes mode to character vectors and median to numeric and integer vectors.So you can see the 10 missing values for variable “education” are imputed with “High School” since it is the mode.</p>
<p>You can also use function ‘preProcess()’ to attain this.But it only works for numeric variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(demo_missing[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)],<span class="dt">method=</span><span class="st">&quot;medianImpute&quot;</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,demo_missing[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])
<span class="kw">summary</span>(demo_imp)</code></pre></div>
<pre><code>##      income            age       
##  Min.   : 15000   Min.   :20.00  
##  1st Qu.: 79250   1st Qu.:32.19  
##  Median : 98750   Median :44.25  
##  Mean   :102405   Mean   :44.40  
##  3rd Qu.:122875   3rd Qu.:54.50  
##  Max.   :300000   Max.   :95.00</code></pre>
</div>
<div id="impute-missing-values-based-on-k-nearest-neighbors" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Impute missing values based on K-nearest neighbors</h3>
<p>k-nearest neighbor will find the k closest samples (Euclidian distance) in the training set and impute the mean of those “neighbors”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp&lt;-<span class="kw">preProcess</span>(demo_missing[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)],<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">2</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,demo_missing[,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])</code></pre></div>
<pre><code>## Error in FUN(newX[, i], ...): cannot impute when all predictors are missing in the new data point</code></pre>
<p>Now we get a error saying “cannot impute when all predictors are missing in the new data point”. It is because there is at least one sample with both “income” and “age” missing. We can delete the corresponding row and do it again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idx&lt;-<span class="kw">which</span>(<span class="kw">is.na</span>(demo_missing$income)&amp;<span class="kw">is.na</span>(demo_missing$age))

imp&lt;-<span class="kw">preProcess</span>(demo_missing[-idx,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)],<span class="dt">method=</span><span class="st">&quot;knnImpute&quot;</span>,<span class="dt">k=</span><span class="dv">2</span>)
demo_imp&lt;-<span class="kw">predict</span>(imp,demo_missing[-idx,<span class="kw">c</span>(<span class="st">&quot;income&quot;</span>,<span class="st">&quot;age&quot;</span>)])
<span class="kw">summary</span>(demo_imp)</code></pre></div>
<pre><code>##      income               age          
##  Min.   :-2.259679   Min.   :-1.53784  
##  1st Qu.:-0.686725   1st Qu.:-0.88276  
##  Median :-0.104506   Median :-0.01129  
##  Mean   :-0.006233   Mean   : 0.01103  
##  3rd Qu.: 0.593512   3rd Qu.: 0.72444  
##  Max.   : 5.074342   Max.   : 3.18343</code></pre>
<p>The error doesn’t show up this time. This method considers all predictors together but it requires them to be in the same scale since the “euclidian distance” is used to find the neighbours.</p>
</div>
</div>
<div id="collinearity" class="section level2">
<h2><span class="header-section-number">4.6</span> <strong>Collinearity</strong></h2>
<p>It is probably a technical term that many un-technical people also know. There is an excellent function in <code>corrplot</code> package with the same name <code>corrplot()</code> that can visualize correlation structure of a set of predictors. The function has option to reorder the variables in a way that reveals clusters of highly correlated ones. We add some columns to <code>demo</code> that are correlated.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adddemo&lt;-demo[,-<span class="dv">3</span>]
adddemo$added1&lt;-<span class="kw">sqrt</span>(demo$age)+<span class="dv">10</span>
adddemo$added2&lt;-<span class="kw">log</span>(demo$income)+demo$age
adddemo$added2&lt;-<span class="kw">log</span>(demo$age)
adddemo$added4&lt;-demo$income/<span class="dv">1000+5</span>*demo$age
adddemo$added5&lt;-<span class="kw">sin</span>(demo$age)</code></pre></div>
<p>The following command will produce visualization for the correlation matrix of <code>adddemo</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">corrplot</span>(<span class="kw">cor</span>(adddemo),<span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>)</code></pre></div>
<p><img src="CE_JSM2017_files/figure-html/unnamed-chunk-18-1.png" width="672" /> The size and color of the points are associated with the strength of corresponding correlation. Section 3.5 of “<a href="http://appliedpredictivemodeling.com/">Applied Predictive Modeling</a>” presents a heuristic algorithm to remove minium number of predicitors to ensure all pairwise corelations are below a certain threshold:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>Calculate the correlation matrix of the predictors.</li>
<li>Determine the two predictors associated with the largest absolute pairwise correlation (call them predictors A and B).</li>
<li>Determine the average correlation between A and the other variables. Do the same for predictor B.</li>
<li>If A has a larger average correlation, remove it; otherwise, remove predictor B.</li>
<li>Repeat Step 2-4 until no absolute correlations are above the threshold.</li>
</ol>
</blockquote>
<p>The <code>findCorrelation()</code> function in package <code>caret</code> will apaply the above algorithm.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(highCorr&lt;-<span class="kw">findCorrelation</span>(<span class="kw">cor</span>(adddemo),<span class="dt">cutoff=</span>.<span class="dv">75</span>))</code></pre></div>
<pre><code>## [1] 5 2 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># remove columns with high correlations</span>
filter_demo&lt;-adddemo[,-highCorr]
<span class="co"># correlation matrix for filtered data</span>
<span class="kw">corrplot</span>(<span class="kw">cor</span>(filter_demo),<span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>)</code></pre></div>
<p><img src="CE_JSM2017_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="sparse-variables" class="section level2">
<h2><span class="header-section-number">4.7</span> <strong>Sparse Variables</strong></h2>
<p>Other than the highly related predictors, predictors with degenerate distributions need to be removed as well. Removing those variables can significant improve some models’ performance and/or stability (such as linear regression and logistic regression but tree based model is impervious to this type of predictors). One extreme example is a variable with single value which is called zero-variance variable.</p>
<p>Similarly those variables with very low frequency of unique values are <strong><em>near-zero variance predictors</em></strong>. How to detect those variables? There are two rules: - The fraction of unique values over the sample size - The ratio of the frequency of the most prevalent value to the frequency of the second most prevalent value. The <code>caret</code> package funciton <code>nearZeroVar()</code> can filter near-zero variance predictors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#add two variables with low variance </span>
zero_demo&lt;-demo
zero_demo$zero1&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">nrow</span>(demo))
zero_demo$zero2&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">nrow</span>(demo)-<span class="dv">1</span>))
<span class="co"># zero1 only has one unique value</span>
<span class="co"># zero2 is a vector with the first element 1 and the rest are 0s</span>
<span class="kw">summary</span>(zero_demo)</code></pre></div>
<pre><code>##      income            age              education      zero1  
##  Min.   : 10000   Min.   :20.00   Bachelor   :15   Min.   :0  
##  1st Qu.: 76375   1st Qu.:30.25   Doctor     : 2   1st Qu.:0  
##  Median : 98750   Median :44.25   High School:77   Median :0  
##  Mean   :103480   Mean   :44.92   Master     : 6   Mean   :0  
##  3rd Qu.:126375   3rd Qu.:56.88                    3rd Qu.:0  
##  Max.   :300000   Max.   :95.00                    Max.   :0  
##      zero2     
##  Min.   :0.00  
##  1st Qu.:0.00  
##  Median :0.00  
##  Mean   :0.01  
##  3rd Qu.:0.00  
##  Max.   :1.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the function will return a vector of integers indicating which columns to remove</span>
<span class="kw">nearZeroVar</span>(zero_demo,<span class="dt">freqCut =</span> <span class="dv">95</span>/<span class="dv">5</span>, <span class="dt">uniqueCut =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>## [1] 4 5</code></pre>
<p>Note the two arguments in the function <code>freqCut =</code> and <code>uniqueCut =</code>. They are corresponding to the previous two rules.</p>
<ul>
<li><p><code>freqCut</code>: the cutoff for the ratio of the most common value to the second most common value</p></li>
<li><p><code>uniqueCut</code>:the cutoff for the percentage of distinct values out of the number of total samples</p></li>
</ul>
</div>
<div id="re-encode-dummy-variables" class="section level2">
<h2><span class="header-section-number">4.8</span> <strong>Re-encode Dummy Variables</strong></h2>
<p>Sometimes we need to recode categories to smaller bits of information named <strong>“dummy variables”</strong>. Take the variable “education” in demo for example. It has four categories: “High School”,“Bachelor”,“Master” and “Doctor”. If we recode it to be dummy variables, each category get its own dummy variable that is 0/1 indicator for that category.</p>
<p>For a single categorical variable, we can use function <code>class.ind()</code> in package <code>nnet</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumVar&lt;-<span class="kw">class.ind</span>(demo$education)
<span class="kw">head</span>(dumVar)</code></pre></div>
<pre><code>##      Bachelor Doctor High School Master
## [1,]        0      0           1      0
## [2,]        0      0           1      0
## [3,]        0      0           1      0
## [4,]        0      0           1      0
## [5,]        0      0           1      0
## [6,]        0      0           1      0</code></pre>
<p>If we want to determine encodeings for more than one variables, we can use <code>dummyVars()</code> in <code>caret</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~income+education,
                  <span class="dt">data=</span>demo,
                  <span class="co"># Remove the variable name from the column name</span>
                  <span class="dt">levelsOnly=</span>T)
<span class="kw">predict</span>(dumMod,<span class="kw">head</span>(demo))</code></pre></div>
<pre><code>##   income Bachelor Doctor High School Master
## 1  56000        0      0           1      0
## 2 133500        0      0           1      0
## 3  79500        0      0           1      0
## 4  53000        0      0           1      0
## 5  63500        0      0           1      0
## 6  84500        0      0           1      0</code></pre>
<p>To add some more complexity, we could assume <em>joint</em> effect of income and education. In this case, this will add 4 more columns to the resulted data frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dumMod&lt;-<span class="kw">dummyVars</span>(~income+education+income:education,
                  <span class="dt">data=</span>demo,
                  <span class="dt">levelsOnly=</span>T)
<span class="kw">predict</span>(dumMod,<span class="kw">head</span>(demo))</code></pre></div>
<pre><code>##   income Bachelor Doctor High School Master income:Bachelor income:Doctor
## 1  56000        0      0           1      0               0             0
## 2 133500        0      0           1      0               0             0
## 3  79500        0      0           1      0               0             0
## 4  53000        0      0           1      0               0             0
## 5  63500        0      0           1      0               0             0
## 6  84500        0      0           1      0               0             0
##   income:High School income:Master
## 1              56000             0
## 2             133500             0
## 3              79500             0
## 4              53000             0
## 5              63500             0
## 6              84500             0</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-APM">
<p>Max Kuhn, Kjell Johnston. 2013. <em>Applied Predictive Modeling</em>. Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-wrangling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="r-shiny-introduction.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-DataPreprocessing.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
